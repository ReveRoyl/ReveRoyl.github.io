{"meta":{"version":1,"warehouse":"6.0.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/about/CV_Lei_Luo.pdf","path":"about/CV_Lei_Luo.pdf","modified":1,"renderable":0},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":1,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/logo.png","path":"medias/logo.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/avatar.jpg","path":"medias/avatars/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/555.jpg","path":"medias/extra/555.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/777.jpg","path":"medias/extra/777.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/7MW7877.jpeg","path":"medias/extra/7MW7877.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/7lXbbhT.jpeg","path":"medias/extra/7lXbbhT.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/DH0lPiz.jpeg","path":"medias/extra/DH0lPiz.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/DrOnn9n.jpeg","path":"medias/extra/DrOnn9n.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/KCKc4Dj.jpeg","path":"medias/extra/KCKc4Dj.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/SrXFZMq.jpeg","path":"medias/extra/SrXFZMq.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/MCqwnVp.jpeg","path":"medias/extra/MCqwnVp.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/TYPpacm.jpeg","path":"medias/extra/TYPpacm.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/U6o2o8v.jpeg","path":"medias/extra/U6o2o8v.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/XC5Trd9.jpeg","path":"medias/extra/XC5Trd9.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/XV0xvVF.jpeg","path":"medias/extra/XV0xvVF.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/cMCj5WO.jpeg","path":"medias/extra/cMCj5WO.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/detroit-become-human-2018-games-hd-games-wallpaper-preview.jpg","path":"medias/extra/detroit-become-human-2018-games-hd-games-wallpaper-preview.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/duXfgC6.jpeg","path":"medias/extra/duXfgC6.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/gZQ5ojS.jpeg","path":"medias/extra/gZQ5ojS.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/iUQJFup.jpeg","path":"medias/extra/iUQJFup.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/jG0hnRG.jpeg","path":"medias/extra/jG0hnRG.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/l24ljsb.jpeg","path":"medias/extra/l24ljsb.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/lbRWFih.jpeg","path":"medias/extra/lbRWFih.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/m9EOIXp.jpeg","path":"medias/extra/m9EOIXp.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/oknqyte.jpeg","path":"medias/extra/oknqyte.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/pZgQqm9.jpeg","path":"medias/extra/pZgQqm9.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/xm4QiMj.jpeg","path":"medias/extra/xm4QiMj.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/svykO2P.jpeg","path":"medias/extra/svykO2P.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/extra/zrBM6pg.jpeg","path":"medias/extra/zrBM6pg.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/24.jpg","path":"medias/featureimages/24.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/25.jpg","path":"medias/featureimages/25.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/26.jpg","path":"medias/featureimages/26.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/27.jpg","path":"medias/featureimages/27.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/28.jpg","path":"medias/featureimages/28.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/29.jpg","path":"medias/featureimages/29.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/Reflections of the Moon on Erquan.mp3","path":"medias/music/Reflections of the Moon on Erquan.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/Sky Castle.mp4","path":"medias/music/Sky Castle.mp4","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/The 2nd Melody of the Night.mp3","path":"medias/music/The 2nd Melody of the Night.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/The 4nd Melody of the Night.mp3","path":"medias/music/The 4nd Melody of the Night.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","path":"libs/codeBlock/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","path":"libs/jquery/jquery-2.2.0.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/explosion.min.js","path":"libs/others/explosion.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/fireworks.js","path":"libs/others/fireworks.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/text.js","path":"libs/others/text.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/snow.js","path":"libs/others/snow.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/Reflections of the Moon on Erquan.jpg","path":"medias/music/avatars/Reflections of the Moon on Erquan.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/Sky Castle.jpeg","path":"medias/music/avatars/Sky Castle.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/The 4nd Melody of the Night.jpg","path":"medias/music/avatars/The 4nd Melody of the Night.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/The 2nd Melody of the Night.jpg","path":"medias/music/avatars/The 2nd Melody of the Night.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","path":"libs/awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","path":"libs/awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","path":"libs/awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","path":"libs/awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","path":"libs/awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","path":"libs/awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","path":"libs/awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1661360919277},{"_id":"source/404.md","hash":"bc0e8670b0311a77fd2344806af53e7ed4cd1e5e","modified":1661360919277},{"_id":"source/_data/musics.json","hash":"3608e8bb2c235362a216151bab814fa750928cb7","modified":1661360919278},{"_id":"source/archives/index.md","hash":"a62b7d9b8a8bdf966ec5c823e71581d2b185156e","modified":1661360919390},{"_id":"source/about/index.md","hash":"656569a819e9b1712fe4b59c30b18c21538f8f91","modified":1764001652270},{"_id":"source/_posts/01_03_22.md","hash":"e9b08f684e9a199627bf4115340e141e89bde014","modified":1661360919283},{"_id":"source/categories/index.md","hash":"76889deb16e0d61d5c585f26a0e69f01de6cab74","modified":1661360919391},{"_id":"source/_posts/07_02_22.md","hash":"6832639d7a9b22bccf7f9b2c9c84a8173e0f195a","modified":1661360919290},{"_id":"source/_posts/03_03_22.md","hash":"0547a3b6c243cc2de115ac32aa00464c681157f0","modified":1661360919290},{"_id":"source/_posts/02_03_22.md","hash":"52db56c3ba413879b907c6fcd7af9358bea451c2","modified":1661360919284},{"_id":"source/_posts/07_03_22.md","hash":"743408cfc7c84beffa1a80284e28fbe0bc7f4240","modified":1661360919296},{"_id":"source/_posts/08_03_22.md","hash":"3330d5d0296c964dd668d7541c763feae5b5b438","modified":1661360919302},{"_id":"source/_posts/10_03_22.md","hash":"097a51e108653f2160ba3a24625586e795a6771b","modified":1661360919307},{"_id":"source/_posts/08_02_22.md","hash":"f9865066031014e8844287b2096c1fb431b0acb1","modified":1661360919296},{"_id":"source/_posts/09_02_22.md","hash":"7fc7004af97c7c994eb8077d803ac43283c636f9","modified":1661360919302},{"_id":"source/_posts/13_03_22Backup blog source files.md","hash":"d41f7e67d5e95dffda35cd5d582dfdd2e94a574d","modified":1661360919316},{"_id":"source/_posts/11_03_22.md","hash":"6560bd8eddd414d8b945139b5c6a4e8a034618b5","modified":1661360919312},{"_id":"source/_posts/15_02_22.md","hash":"b9291eb2d5f390cdef6dc6f0185b354764df2858","modified":1661360919327},{"_id":"source/_posts/14_02_22.md","hash":"a3573338037eb45e29ad985940da7f01009be9a0","modified":1661360919320},{"_id":"source/_posts/10_02_22.md","hash":"3fd09209bce0f2596da1e0c2237203bfc35e0340","modified":1661360919303},{"_id":"source/_posts/16_02_22Update of theme.md","hash":"892cf28938e62fb798d01c01263339f787973cef","modified":1661360919327},{"_id":"source/_posts/17_02_22.md","hash":"10b3e687bd01e588f31fd5f1780b93ad25375f3f","modified":1661360919331},{"_id":"source/_posts/2021-11-28-Lei-model-species-essay.md","hash":"9eb32006d85ea60e31e09761269575bf6bc319ba","modified":1661360919332},{"_id":"source/_posts/2022-01-04-Lei-half-a-year-in-London.md","hash":"ee59f198ad73b054117e224aa823d668f62b82b6","modified":1661360919333},{"_id":"source/_posts/16_02_22.md","hash":"7294702c4f21ae00164d1bdcfce6c7941092cd71","modified":1661360919327},{"_id":"source/_posts/2022-01-18-NMDA-receptor-dependent-LTP-roles.md","hash":"b73100c2785868b2bd9fba2e2e359d6a3e13153a","modified":1661360919334},{"_id":"source/_posts/2021-12-13-Lei-proteinopathies-essay.md","hash":"184f1f69f123fd79cb9657720caebcdb5dc7611d","modified":1661360919332},{"_id":"source/_posts/2022-01-22-Nature-of-dopamine-dysfunction-in-schizophrenia.md","hash":"5e50b0703b0e94d78034900fd7cd3be82d6d6993","modified":1661360919335},{"_id":"source/_posts/2022-01-22-Usages-of-animal-models-in-the-study-of-human-brain-structural-connectivity.md","hash":"b40262abeb5af8a7687fce2f0f9ea88c6c3354f0","modified":1661360919337},{"_id":"source/_posts/2022-09-21-春去秋来.md","hash":"97ad3599b60e402ae691cec94c1e38480d378908","modified":1663774067042},{"_id":"source/_posts/2022-01-22-Phenomenon-of-‘Blocking’-on-predicted-reward.md","hash":"a57817716351cee63af8096fc076ab9115ab07b8","modified":1661360919335},{"_id":"source/_posts/23_11_21Glossary.md","hash":"3221073432fcdff99ca4cdc81818a8f7765c156e","modified":1661360919337},{"_id":"source/_posts/24_02_22Update for RSS subscription and music player.md","hash":"242592b300ee6952584399c39195f7fa38e0ba2e","modified":1661360919338},{"_id":"source/_posts/28_02_22.md","hash":"9b62ced1888de20d448305a8d1977d2efbcd2e12","modified":1661360919344},{"_id":"source/_posts/Chatgpt.md","hash":"92c3e99d88db063603533e827f9eb41107ab088b","modified":1679292758469},{"_id":"source/_posts/Albania.md","hash":"70383669870bb9ccd1679fd90f05d5fccdf11b7c","modified":1662650482016},{"_id":"source/_posts/Chengdu.md","hash":"bb8f06f7af287e3fac199f7c9f447680783e3e1b","modified":1679293128306},{"_id":"source/_posts/Cpp learning.md","hash":"c525b4b26c263da8c9067db74e9bab14bd875f59","modified":1661363318611},{"_id":"source/_posts/Installing Jupyter lab.md","hash":"6a52ddd498f8a716402e1a006b07399401887258","modified":1661360919362},{"_id":"source/_posts/DLL injection.md","hash":"a7f4b6023dc2982761310ea7948968385ab264aa","modified":1661363370811},{"_id":"source/_posts/Machine Learning.md","hash":"e9084a6f7cdf7693d11b45002724e38575312604","modified":1661363498399},{"_id":"source/_posts/Mylove.md","hash":"c5355f9c221d9c47d27f21f532b37829b4605303","modified":1730021060467},{"_id":"source/_posts/Pandas.md","hash":"801f94f4d4e620979290f395a01b2ef423569ad8","modified":1661433484757},{"_id":"source/_posts/Python learning.md","hash":"0057bc514c0953734b392a59d90a1b6399592992","modified":1661360919375},{"_id":"source/_posts/Tips for programming.md","hash":"6763ac69aba372a500dfd2ecafdab6c80e434d0f","modified":1661363253445},{"_id":"source/_posts/handbook.md","hash":"cdd1aad1c11e801e7cf88d65bcf2a9cc449c0b10","modified":1763999552473},{"_id":"source/contact/index.md","hash":"801288b1cbf6738e16af277bab042a85b9c450d3","modified":1661433254230},{"_id":"source/_posts/台湾旅游攻略.md","hash":"f59e30221977a53748b4d85526134420c3f2286c","modified":1733074757557},{"_id":"source/tags/index.md","hash":"b5044e257ef9f38c3906c8db18247ef26a6399f9","modified":1661360919392},{"_id":"source/about/CV_Lei_Luo.pdf","hash":"459aafff976fce4b8160b0a158c0e006d4e59baa","modified":1764001462998},{"_id":"source/_posts/Thesis.md","hash":"4df85145ade83c086e53f1e42d9db5451c215dfd","modified":1661434027127},{"_id":"source/_posts/master project.md","hash":"f94f1f4d9bce99d983ba81b26c5a5acd4cc9199c","modified":1697867343036},{"_id":"themes/matery/.gitignore","hash":"eaa3d84cb77d92a21b111fd1e37f53edc1ff9de0","modified":1661360919392},{"_id":"themes/matery/README.md","hash":"7ef16198a2c5ff580f006582286354caf160c7fe","modified":1661360919393},{"_id":"themes/matery/README_CN.md","hash":"812fb1a2572d3ab36257d2c2b2ae64d6dbcb0cb9","modified":1661360919394},{"_id":"themes/matery/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1661360919393},{"_id":"themes/matery/_config.yml","hash":"709aeea63085e3ff3197ae19533b2584683a7fd2","modified":1661360919394},{"_id":"themes/matery/languages/default.yml","hash":"527c795b8c41fe62bf35603ffebfa6d4a7929a2c","modified":1661360919395},{"_id":"themes/matery/languages/zh-CN.yml","hash":"d92db4b986bb6f0d228e9a8249383103bf56342d","modified":1661360919395},{"_id":"themes/matery/layout/categories.ejs","hash":"c431e772d0f7700592228bbd9502793bdc28a893","modified":1661360919414},{"_id":"themes/matery/layout/about.ejs","hash":"e87752e59f021b5139b1155a264da11ab469a9aa","modified":1661360919413},{"_id":"themes/matery/layout/404.ejs","hash":"f08a0f507b36f3652520a41381f71167488405c7","modified":1661360919396},{"_id":"themes/matery/layout/category.ejs","hash":"2d421e10c3b8fd2c4f725e5eaa967c4a1429c707","modified":1661360919414},{"_id":"themes/matery/layout/archive.ejs","hash":"1b5023571894404d75caffa28128fc9c49f9095d","modified":1661360919413},{"_id":"themes/matery/layout/contact.ejs","hash":"1513c5a40b7cc0b6e5854cf8c3253958bcb486cb","modified":1661360919415},{"_id":"themes/matery/layout/index.ejs","hash":"7fc5a6c4f0229c0be43b7d1315524c468346fbb8","modified":1661360919415},{"_id":"themes/matery/layout/layout.ejs","hash":"e512de0ed92bf606f2b771d4d0ce4ce9f385098b","modified":1661360919416},{"_id":"themes/matery/layout/friends.ejs","hash":"895e40a864796680fbef581e4b09f252fbdd963a","modified":1661360919415},{"_id":"themes/matery/layout/tag.ejs","hash":"5cdf3a1d72f54285ee9cb826fd0e4a0449093215","modified":1661360919416},{"_id":"themes/matery/layout/post.ejs","hash":"f1a35f32e5901e167ae9a750e7cb3635549cea2e","modified":1661360919416},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"cb99dc352397ec5d0765794d7b8884972e61973b","modified":1661360919396},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"42dda8e67f7f09d148347887e52f18aea546df26","modified":1661360919397},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"ab610754bf6aea844b5ae0802ed37c73b5f1dc9f","modified":1661360919397},{"_id":"themes/matery/layout/tags.ejs","hash":"851c0ee599e91e7b1d657673859e8b6ff79cf50b","modified":1661360919417},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"d5a7b9bb96e04c0a3485dd873748f19c50a6a04f","modified":1661360919397},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"a3a140e6aeeb6f289e4b821a577ef548267f3de1","modified":1661360919398},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"d8c40dbc8106b5bc53ceb727ad968c1d8f234261","modified":1661360919399},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"7ebc78bd234b66fee30d7af429c6cbf713e63b4a","modified":1661360919398},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"fd4034bca2eb3987dcf113e6477260bee97eb1e7","modified":1661360919399},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"890c8f04c1f4905dfceb3ea9fd6efdd040d79c01","modified":1661360919399},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"fb572df037b5a6eb563912caa1f1967ca835a70a","modified":1661360919400},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"e761f0104fbf431671bbe6bebc91ca82f737f4d2","modified":1661360919401},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"821e1af65990521c9e0288178d8e5b18c73a9cab","modified":1661360919400},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"d4042e5521ceb5f3255cd4455ac7ccd227fee6df","modified":1661360919401},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"dfdeea9c59d157acb851d4bf44bf95f81787523c","modified":1661360919402},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"42728561c09589f79b698eb059ab4def53ed3642","modified":1661360919401},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"3b42900247d5ea4ea5b68e2be44420a0d54785ad","modified":1661360919404},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"166c0b9753f3f913bd801e82ad5b268004be198d","modified":1661360919403},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"82cb8090cde663fa7ad67418a802997b3057e957","modified":1661360919403},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"3f208f33e4e12becdb8323e6e64e20ad60c3fb2a","modified":1661360919403},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"e859fe6e0259e0c123cb7ceda6e4cac836318ffc","modified":1661360919405},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"3a82fcb6f31d69971cb564985842c14ac02cdca0","modified":1661360919402},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"73624d9db81e87ff0c12310bb873fbd0b5221021","modified":1661360919405},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"f85a222ec3f9bc27eb7978015e63a16514b38791","modified":1661360919405},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"4e73f10eacb5d00a0681cb44fe5c039cd8ab03cd","modified":1661360919404},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"b2b22d4fc4e46b051f67216c391f629f4ff552b5","modified":1661360919407},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"51035e5f4ffd5df28e16db4ce70dcf046eb62869","modified":1661360919406},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"0f2e1e27d21492cf228e786daead985b1e1dcea4","modified":1661360919406},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"6ae58a57b83a5999d0b6a737ec868f084d208f89","modified":1661360919408},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"c3039180ddb2eb17e724b8441e5f93e79859aef7","modified":1661360919407},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"5284712d84bbaa4f0d88026ac3ec5a8c13e00056","modified":1661360919408},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"fc50cb4bbc1f4d0e4c9f5941f1c3c74bea742db7","modified":1661360919408},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"c6f713316ce75ad08ac5d1587bd8ce42e894e9ae","modified":1661360919410},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"785cb588a31215876f6737213054ba0e8552fff0","modified":1661360919410},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"9ea672db65f1e5b8fad1ffafb1614f25adc97e63","modified":1661360919409},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"d439d86818de179d64965d4f7f5fa56147fd9221","modified":1661360919411},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"4608af6151f0e32f668c89f09343748340021478","modified":1661360919410},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"0aaf0a111b9aa07ff37f6286eeac5506283f47f8","modified":1661360919411},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"bf604fe9c435f0fb9a559cac9c35772579b590e8","modified":1661360919412},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"6310903eb0e434d6f9a59ca669aab7fae38d4797","modified":1661360919412},{"_id":"themes/matery/source/js/matery.js","hash":"208b7806caa943c115aa0825c9c72a0781404775","modified":1661360919420},{"_id":"themes/matery/source/js/search.js","hash":"77ecae23dd3edd8ad962c5b12954652bb2f7a1b6","modified":1661360919420},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"05f5e2acace5730cdf7bed650375ad88f6b5d1b7","modified":1661360919412},{"_id":"themes/matery/source/css/gitment.css","hash":"d5ef623065d1fbc897119f7b70ccf7563e329917","modified":1661360919418},{"_id":"themes/matery/source/css/matery.css","hash":"0d345a72318fd7aadcb6fcaa6f3abac94b91001c","modified":1661360919418},{"_id":"themes/matery/source/css/my.css","hash":"37683a9f11c68903a53e2b8593ca8c095a721896","modified":1661360919419},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"4e3e855767ac5a48b13af1d6a42df13d8975e03f","modified":1661360919419},{"_id":"themes/matery/source/medias/extra/detroit-become-human-2018-games-hd-games-wallpaper-preview.jpg","hash":"0d9e3480d3f5355edabaa68d1692a85d407470e2","modified":1661360919661},{"_id":"themes/matery/source/medias/featureimages/0.jpg","hash":"1f8bbfbd625448b4b2a748b75636e456b826dcd3","modified":1661360919680},{"_id":"themes/matery/source/medias/featureimages/18.jpg","hash":"61f8f0a98af9fc525fe0fb8a609d5a5bf52694a7","modified":1661360919700},{"_id":"themes/matery/source/medias/featureimages/5.jpg","hash":"c4cc724f4572a9bcede7443a4f4c0393d3073868","modified":1661360919750},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"5dfcbcee866e9dc564916416281885f3e320871e","modified":1661360919421},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"ded9739f803d114c9168d3351fded72b3b478b4c","modified":1661360919422},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"33810b2b757fc4327bc1d3b83bb5e0d3dc1fec5b","modified":1661360919439},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"7f4f8913f2d46ade2def5134e2cc8684a4b87939","modified":1661360919423},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"5a8e6d07ffa55642418ab3fd4b263aa08284b77a","modified":1661360919422},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","hash":"98f626d784a94ebe653b13f3a4c79e483264cae7","modified":1661360919436},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"70c0c4a9bf698747b7c058c21287ad617355e5dd","modified":1661360919423},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","hash":"a8133367d48199e7505c2d831ca848b4202b9ba6","modified":1661360919437},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","hash":"6ad8984746f0ff4e2fc81f0c04f12874fa752683","modified":1661360919437},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","hash":"d54f6205b35dceba1d66da761c00ff9fad9cf857","modified":1661360919437},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","hash":"743114dcd6f3addc973778b1b248f88d42b05278","modified":1661360919438},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"5d52d3b34fceb9d7e11f1beaf7ed380b4249dec4","modified":1661360919440},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"26849509f196a2d21bbfd15696e5d5153163b8f1","modified":1661360919449},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"a0625d8b432af8bdc820f8768d36cde439e7257c","modified":1661360919448},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"4e6538c8312aeeab845d361c37a8c1a0931241f0","modified":1661360919449},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"021898a16279ac2ffe75af4f902fab2a0a39f11a","modified":1661360919446},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"f81cd7bfcf7aa2d043bd3e6077df42656fc44b82","modified":1661360919456},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1661360919458},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1661360919459},{"_id":"themes/matery/source/libs/others/explosion.min.js","hash":"5b76fa72a85cfb27d54b00128393ece773d65386","modified":1661360919459},{"_id":"themes/matery/source/libs/others/fireworks.js","hash":"e9c74f2dd3953d4d8dec44e9977574d00702e84d","modified":1661360919460},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1661360919461},{"_id":"themes/matery/source/libs/others/snow.js","hash":"b393f069781eef788a0ae66b2681cece8fea2851","modified":1661360919460},{"_id":"themes/matery/source/libs/others/text.js","hash":"fdf18f65977e4bc358dfb5fb0b7c98492ae72efd","modified":1661360919461},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"f646f2bb75bcd1eb65b2788ac7bf15d4fd243ce9","modified":1661360919466},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1661360919466},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1661360919424},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1661360919451},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1661360919451},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1661360919452},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1661360919452},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"f8cd48e1fff82ecd54a7ce3e69de8dba7c92d113","modified":1661360919455},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1661360919452},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1661360919453},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1661360919453},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1661360919454},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1661360919454},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1661360919465},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1661360919463},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1661360919465},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"7126de5cec8371e580b7b1f22512da0985cc39e5","modified":1661360919462},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1661360919464},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1661360919463},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1661360919464},{"_id":"themes/matery/source/medias/extra/777.jpg","hash":"1038225cb7589943bcd836f294d0fdaf526c118c","modified":1661360919639},{"_id":"themes/matery/source/medias/extra/7lXbbhT.jpeg","hash":"91dc888ec080426f7d10dba51e600efb3ccaa8f6","modified":1661360919643},{"_id":"themes/matery/source/medias/extra/lbRWFih.jpeg","hash":"aaa1b4955b8695f549d5b58ea80ab6a1339bcfff","modified":1661360919670},{"_id":"themes/matery/source/medias/featureimages/15.jpg","hash":"5b80fa97837179ff9c55d4f14b2c4adf32c7eac5","modified":1661360919693},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"82276be41d2001e820020a219b90ad5b026302d1","modified":1661360919441},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"5a13983930b019450e4fe01a407c64b3dd316be4","modified":1661360919449},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","hash":"7a551393b8360731104fdef1af36a6f3638f5855","modified":1661360919450},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"f1558f12d96a352e490166d543a8e821dd3bb2bc","modified":1661360919467},{"_id":"themes/matery/source/medias/music/avatars/Reflections of the Moon on Erquan.jpg","hash":"154acd793329cf3a88505d9347de9643a5227418","modified":1661360920026},{"_id":"themes/matery/source/medias/music/avatars/The 2nd Melody of the Night.jpg","hash":"12928885e69d210e77ce2fff52c195d307939dd7","modified":1661360920031},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1661360919435},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1661360919436},{"_id":"themes/matery/source/medias/extra/KCKc4Dj.jpeg","hash":"23f6bb28529beeea20f973c58c75ce0f8ade6be6","modified":1661360919649},{"_id":"themes/matery/source/medias/extra/U6o2o8v.jpeg","hash":"4080999579fd2b397a936c1c12a0876660229522","modified":1661360919655},{"_id":"themes/matery/source/medias/extra/iUQJFup.jpeg","hash":"a7fc38728763c63d22bfcafc59589c1263bb47ac","modified":1661360919665},{"_id":"themes/matery/source/medias/extra/l24ljsb.jpeg","hash":"7e5741e55ff05847a740d6333b343dca99a52758","modified":1661360919668},{"_id":"themes/matery/source/medias/extra/oknqyte.jpeg","hash":"ee1f898d61881521d7f1d3258e68d1a91bb972bb","modified":1661360919673},{"_id":"themes/matery/source/medias/featureimages/13.jpg","hash":"d8cc7a730668943dcb0776cfa240a0cf76826363","modified":1661360919690},{"_id":"themes/matery/source/medias/featureimages/21.jpg","hash":"e206e2e7d2e9515a61ca87ea2ee3458f01871777","modified":1661360919713},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"2c27939768606603bee3b5e6c8a722596a667e60","modified":1661360919457},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"f63c7c489524ccb5d95e74fcd6618116c58fb305","modified":1661360919448},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c843f0dc497314574c608ca28cc742bb041786d5","modified":1661360919458},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"04c6b2782ce4610c429563110f6a20a47432fc4c","modified":1661360919468},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1661360919428},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1661360919426},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1661360919434},{"_id":"themes/matery/source/medias/extra/DH0lPiz.jpeg","hash":"73ad93153c653dac0730b9a2d5b2787a79e10219","modified":1661360919645},{"_id":"themes/matery/source/medias/extra/XV0xvVF.jpeg","hash":"fb161ad81d6c4a325a3496d9f475c7db89bca268","modified":1661360919659},{"_id":"themes/matery/source/medias/extra/cMCj5WO.jpeg","hash":"beed137097d3fdcb44d10b2a61ddb83491d5fae1","modified":1661360919660},{"_id":"themes/matery/source/medias/extra/gZQ5ojS.jpeg","hash":"bb4cea3734b7eab9828e48f94960fab4fc46f3bf","modified":1661360919664},{"_id":"themes/matery/source/medias/extra/svykO2P.jpeg","hash":"2f2e66d7e4c8c72afaab3d405acac3ea966ae075","modified":1661360919677},{"_id":"themes/matery/source/medias/extra/zrBM6pg.jpeg","hash":"f9579ddb2774525028ea9ed51ad4495395b48d30","modified":1661360919679},{"_id":"themes/matery/source/medias/featureimages/12.jpg","hash":"c2892770fd5617418fd33d6f834879e05b2cdafd","modified":1661360919689},{"_id":"themes/matery/source/medias/featureimages/16.jpg","hash":"18b5f341e57e7b7f73f32141a08fa1d8278d164f","modified":1661360919695},{"_id":"themes/matery/source/medias/featureimages/20.jpg","hash":"61e04e767b2fc70970b8de2e4e7493fef0dd2d4d","modified":1661360919712},{"_id":"themes/matery/source/medias/extra/MCqwnVp.jpeg","hash":"8e04e5e5119942bdf204432b623d79a0d89c06ac","modified":1661360919650},{"_id":"themes/matery/source/medias/extra/TYPpacm.jpeg","hash":"8e7c889d68b8360de298868560ec4fcdabb058f4","modified":1661360919654},{"_id":"themes/matery/source/medias/extra/XC5Trd9.jpeg","hash":"1da7ff148da2dd242d71feb94582aca93c1fed46","modified":1661360919657},{"_id":"themes/matery/source/medias/extra/duXfgC6.jpeg","hash":"7713bd171372760f1aefd1d9797125427b1bcafa","modified":1661360919663},{"_id":"themes/matery/source/medias/extra/jG0hnRG.jpeg","hash":"da8abc0c419adfaeee7c1e5099f8a0fcea21367a","modified":1661360919666},{"_id":"themes/matery/source/medias/extra/m9EOIXp.jpeg","hash":"7fa2eb2e03cf80a3e17cacfc232675cec580ce21","modified":1661360919672},{"_id":"themes/matery/source/medias/extra/xm4QiMj.jpeg","hash":"fbdbb150c822f97fe19e5d75a4ed076a430c5e79","modified":1661360919678},{"_id":"themes/matery/source/medias/featureimages/2.jpg","hash":"1d8863277d744e1a18a2778ac26041bda5b03a98","modified":1661360919711},{"_id":"themes/matery/source/medias/featureimages/25.jpg","hash":"d0668539783fc615f14178644e486a6befb90c0c","modified":1661360919734},{"_id":"themes/matery/source/medias/featureimages/28.jpg","hash":"c73036359640a67a8b17db7ba0e968c088957ab8","modified":1661360919740},{"_id":"themes/matery/source/medias/featureimages/3.jpg","hash":"ceb8e0c195a7fe7420334efa114e98cd0e1c6523","modified":1661360919745},{"_id":"themes/matery/source/medias/banner/0.jpg","hash":"579c7842c852a5e26fb24f6702029638e367ba18","modified":1661360919507},{"_id":"themes/matery/source/medias/extra/DrOnn9n.jpeg","hash":"e3adf8ac0e4b64170f48566b649ef9c5d3276011","modified":1661360919647},{"_id":"themes/matery/source/medias/extra/SrXFZMq.jpeg","hash":"ee24e9412aaddcacce31226a9e4aaa36413db230","modified":1661360919652},{"_id":"themes/matery/source/medias/featureimages/10.jpg","hash":"66de48d963e7f221931e550b2442da0cd40cbaa8","modified":1661360919684},{"_id":"themes/matery/source/medias/featureimages/27.jpg","hash":"7ea6f890cc59def8b1c9f393e4ae77cd16c79aad","modified":1661360919738},{"_id":"themes/matery/source/medias/featureimages/26.jpg","hash":"c66a4e7a2e670b63759a091f9428ee7f971d7b56","modified":1661360919736},{"_id":"themes/matery/source/medias/featureimages/7.jpg","hash":"bd400da9123424afe7ba6c839be9ad7697c1245b","modified":1661360919755},{"_id":"themes/matery/source/medias/featureimages/6.jpg","hash":"698fc46e97428d73c9d4e3d254e88b9b66fb38cd","modified":1661360919753},{"_id":"themes/matery/source/medias/extra/7MW7877.jpeg","hash":"653f5ba0b86be4f95ef11424fe7e9c153ae2a2dd","modified":1661360919642},{"_id":"themes/matery/source/medias/extra/pZgQqm9.jpeg","hash":"1c19bdc86c144072be47f69e5181627585d420c7","modified":1661360919676},{"_id":"themes/matery/source/medias/featureimages/11.jpg","hash":"2b30186c6d78ed76fa5f278be57290c1bd22c96a","modified":1661360919687},{"_id":"themes/matery/source/medias/featureimages/1.jpg","hash":"f1d720039d654d693c32150c06c78cfc3663b0b4","modified":1661360919682},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1661360919432},{"_id":"themes/matery/source/medias/featureimages/14.jpg","hash":"8ed1f7012ccc5e11c609438f1477a05ef823e1c2","modified":1661360919692},{"_id":"themes/matery/source/medias/music/avatars/Sky Castle.jpeg","hash":"5a66376c272972114e76ea55f07dc9a169c701e1","modified":1661360920030},{"_id":"themes/matery/source/medias/music/avatars/The 4nd Melody of the Night.jpg","hash":"98cb79003c240df73e2693cbdba2d933ca4ef369","modified":1661360920035},{"_id":"themes/matery/source/medias/banner/1.jpg","hash":"52cd0c8aa4c5ee6405689dd076668e3e3436b920","modified":1661360919513},{"_id":"themes/matery/source/medias/featureimages/22.jpg","hash":"1549546a7da979f756da717d8cca04ec90d2caef","modified":1661360919716},{"_id":"themes/matery/source/medias/featureimages/29.jpg","hash":"c70569889c0260d8a0ffb667d708022473fc4235","modified":1661360919743},{"_id":"themes/matery/source/medias/featureimages/8.jpg","hash":"f81e97edf705ab45b989b2b15d6a13c005ccaa32","modified":1661360919759},{"_id":"themes/matery/source/medias/featureimages/23.jpg","hash":"c145d49cf05ad810b4dc980717260934828719d6","modified":1661360919720},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"8789b5e4daf0029a6c88f238f10e54d01c4fce82","modified":1661360919445},{"_id":"themes/matery/source/medias/banner/6.jpg","hash":"75742dd0a63ab7d9e37765a7fc699608d8f263c1","modified":1661360919632},{"_id":"themes/matery/timesbi.ttf","hash":"8092a0cdfea960d2ae19c71dcbe029c4497a7eb5","modified":1661360920084},{"_id":"themes/matery/source/medias/logo.png","hash":"db5f912d634625c8c12e966ca5f75f5dc4692cb4","modified":1661360919771},{"_id":"themes/matery/timesi.ttf","hash":"d34f572f1e8e2573c91f62bc4ec65db5b7dfacaa","modified":1661360920095},{"_id":"themes/matery/source/medias/featureimages/9.jpg","hash":"cd54b116609f5741cc7db0f7f49bf56ac356ddfb","modified":1661360919764},{"_id":"themes/matery/timesbd.ttf","hash":"12eaecaabfbaa5d5e4af58414d11aa83d7dfb9d4","modified":1661360920075},{"_id":"themes/matery/source/medias/banner/4.jpg","hash":"e570bc765b06dde03391f170973f11c3e9b7b819","modified":1661360919605},{"_id":"themes/matery/times.ttf","hash":"e763030b5cd2cc5a8ed9662bf7e8aa496999dd4b","modified":1661360920055},{"_id":"themes/matery/source/medias/extra/555.jpg","hash":"449be5b5dc89c44459d8801caf3eaad8c64aeb51","modified":1661360919638},{"_id":"themes/matery/source/medias/featureimages/17.jpg","hash":"449be5b5dc89c44459d8801caf3eaad8c64aeb51","modified":1661360919700},{"_id":"themes/matery/source/medias/featureimages/4.jpg","hash":"e06afe32a867f7a6e861618e0b5ac9d93cd71d05","modified":1661360919749},{"_id":"themes/matery/source/medias/featureimages/19.jpg","hash":"b7a0fa17ae2e7732e17e5ea797e7306afab22b0d","modified":1661360919708},{"_id":"themes/matery/source/medias/featureimages/24.jpg","hash":"ae2951e58e38e47a4ca309a041258ac1f63a163f","modified":1661360919732},{"_id":"themes/matery/source/medias/banner/3.jpg","hash":"59cd7277a61f00d8edd3d02e644bb28cd8877b97","modified":1661360919600},{"_id":"themes/matery/source/medias/banner/5.jpg","hash":"7c8b5f0801b7a9af9e33bf9095d17ba4689df11a","modified":1661360919627},{"_id":"themes/matery/source/medias/avatars/avatar.jpg","hash":"9e8b7d41368b75b37906a73b844ef5a12ca28dbb","modified":1661360919505},{"_id":"themes/matery/source/medias/music/The 2nd Melody of the Night.mp3","hash":"a4451bfbba2e157e4e449469a599dec84f436dae","modified":1661360919979},{"_id":"themes/matery/source/medias/music/The 4nd Melody of the Night.mp3","hash":"30862b1df21eab8d135b3c7afa6b80e15f3e039c","modified":1661360920025},{"_id":"themes/matery/source/medias/banner/2.jpg","hash":"7420bd4a4248510ea1c0c4a8645616dac62ea9a3","modified":1661360919581},{"_id":"themes/matery/source/medias/music/Sky Castle.mp4","hash":"f965956d37b3d9b6d687a9125cc6f37e2884006d","modified":1661360919944},{"_id":"themes/matery/source/medias/music/Reflections of the Moon on Erquan.mp3","hash":"798985dca4fbbd3b9466a72648fb6978999559a0","modified":1661360919884},{"_id":"public/baidu_urls.txt","hash":"d25284d086d0bfeda2ba3ddf943982753fee9ef8","modified":1764001672980},{"_id":"public/baidusitemap.xml","hash":"c48e2637138db75efe844cb9bfe8ea711636b5a8","modified":1764001672980},{"_id":"public/atom.xml","hash":"39b3de5eb4663d4977f2b5d8065edf0e984925f3","modified":1764001672980},{"_id":"public/sitemap.xml","hash":"8032338eb1895330d17d780bfd61a92e220bfe83","modified":1764001672980},{"_id":"public/search.xml","hash":"e1afacc5d1bda203eed8742ee8817716868d82d3","modified":1764001672980},{"_id":"public/categories/index.html","hash":"1851551665c0418f3fa3063687749bbc3f85750d","modified":1764001672980},{"_id":"public/archives/index.html","hash":"a6800a20539a24c40d52d5a560d27a0784121108","modified":1764001672980},{"_id":"public/about/index.html","hash":"b0bf6e50b6f8d7bc3dd1f31c48c5c2655a8ca9d7","modified":1764001672980},{"_id":"public/contact/index.html","hash":"4d7cb80db78f538b719cdca13ad2367d860cf83c","modified":1764001672980},{"_id":"public/404.html","hash":"417833e4d538808e3fd840709f75ca3aa3048553","modified":1764001672980},{"_id":"public/tags/index.html","hash":"f902f57f1b488fe603b9930f8ee2f6bbafd89729","modified":1764001672980},{"_id":"public/2024/10/25/handbook/index.html","hash":"f4e0f3d9f2424f52dbe3064a93fa9137640c902c","modified":1764001672980},{"_id":"public/2024/10/25/tai-wan-lu-you-gong-lue/index.html","hash":"1f43d3201960af4a966aa121b933c19ecb1e3b37","modified":1764001672980},{"_id":"public/2023/03/20/chengdu/index.html","hash":"fc0483f5fac53f59d05e7775af05da71076afda0","modified":1764001672980},{"_id":"public/2023/10/17/mylove/index.html","hash":"7b74c23b2d973fd7f14e272f3fc9b1d74ad8f041","modified":1764001672980},{"_id":"public/2023/03/20/chatgpt/index.html","hash":"d30c835cd6977c0e1d9ca64f978230f727da6ab2","modified":1764001672980},{"_id":"public/2022/09/21/2022-09-21-chun-qu-qiu-lai/index.html","hash":"746ee704a4ef866b0d886b531ec578b4f9f93932","modified":1764001672980},{"_id":"public/2022/09/08/albania/index.html","hash":"c7affbda8e6041d48cdedb38a2a46bc0d4c91ef7","modified":1764001672980},{"_id":"public/2022/08/22/pandas/index.html","hash":"586475f5a4bf993663629942018bb18faf1fe024","modified":1764001672980},{"_id":"public/2022/08/24/thesis/index.html","hash":"609fb8d52a0c3eeaa1bb8522df5d70bd4492cc44","modified":1764001672980},{"_id":"public/2022/07/12/installing-jupyter-lab/index.html","hash":"e4b39b887f67bddc6be8c0efdbc83f3977bb883b","modified":1764001672980},{"_id":"public/CNAME","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1764001672980},{"_id":"public/2022/04/06/python-learning/index.html","hash":"3edf437f3e351dcfbdedefe1e93a5868960b4c5e","modified":1764001672980},{"_id":"public/2022/05/16/master-project/index.html","hash":"d15944c9f6be10c44542b16dd5ddba3b2c0575fc","modified":1764001672980},{"_id":"public/2022/04/05/cpp-learning/index.html","hash":"d9b40a9c1efda8a750120185b9a41b8d19f6e9f6","modified":1764001672980},{"_id":"public/2022/04/04/dll-injection/index.html","hash":"b834667ba89508793906b0b35a9ffb36eaff8259","modified":1764001672980},{"_id":"public/2022/04/04/tips-for-programming/index.html","hash":"0843e062902db150731bdddc49b1b63d02499ecf","modified":1764001672980},{"_id":"public/2022/04/03/machine-learning/index.html","hash":"a59e83a0c753b5d9deba97cdc6811ff5b2b6ebcd","modified":1764001672980},{"_id":"public/2022/03/11/11-03-22/index.html","hash":"f7c72cfdb91637c0171aacecb22924ed3ccce98a","modified":1764001672980},{"_id":"public/2022/03/13/13-03-22backup-blog-source-files/index.html","hash":"e9e8d521e410ad48149e7d77040756a507898921","modified":1764001672980},{"_id":"public/2022/03/10/10-03-22/index.html","hash":"b495dd4531e61a131c80cee2ad6c3fd12c6401d2","modified":1764001672980},{"_id":"public/2022/03/08/08-03-22/index.html","hash":"d434b6686de095db80607a1c56cc3d0f30276e5f","modified":1764001672980},{"_id":"public/2022/03/07/07-03-22/index.html","hash":"62cca23e29a33cf6f0cb82319bbe138723be297d","modified":1764001672980},{"_id":"public/2022/03/03/03-03-22/index.html","hash":"0dbd650c727f35e33dfb8dc146e6570ef502c530","modified":1764001672980},{"_id":"public/2022/03/02/02-03-22/index.html","hash":"f6d6071cb6dea394a6cd7af1cb825e51d1411172","modified":1764001672980},{"_id":"public/2022/02/24/24-02-22update-for-rss-subscription-and-music-player/index.html","hash":"e5d20d5ed69df104b9316f55d38885b7d38ce432","modified":1764001672980},{"_id":"public/2022/03/01/01-03-22/index.html","hash":"df8adc91811e9384037858d425b3c815ce2ad632","modified":1764001672980},{"_id":"public/2022/02/28/28-02-22/index.html","hash":"81164d92d816253f2b46b77f0553830b99367eb2","modified":1764001672980},{"_id":"public/2022/02/17/17-02-22/index.html","hash":"a65f1224d01bf06c89328e3993e2d110765dcde8","modified":1764001672980},{"_id":"public/2022/02/16/16-02-22update-of-theme/index.html","hash":"d053febef9477371d10efd4db5abf3f5f2583e53","modified":1764001672980},{"_id":"public/2022/02/16/16-02-22/index.html","hash":"4469d990ca7f6b4d29dd118ad00d568b0cf28050","modified":1764001672980},{"_id":"public/2022/02/15/15-02-22/index.html","hash":"4f5d6e1b41d55eefbf384e8fc87a37ff81c357ff","modified":1764001672980},{"_id":"public/2022/02/10/10-02-22/index.html","hash":"cf90f9491171543a2e5a7085e7403b2054dcb22c","modified":1764001672980},{"_id":"public/2022/02/14/14-02-22/index.html","hash":"72c8ce1792c13bb2248352e4e262d4dbdc9742cc","modified":1764001672980},{"_id":"public/2022/02/09/09-02-22/index.html","hash":"00dc2a3c5341dd3dcade1a3032534ba4555fab7d","modified":1764001672980},{"_id":"public/2022/02/08/08-02-22/index.html","hash":"2f8ea7f728cebe193db4855ad67a11acd946e08d","modified":1764001672980},{"_id":"public/2022/02/07/07-02-22/index.html","hash":"cce4aaf047db21919585d3c854beab6076514dbc","modified":1764001672980},{"_id":"public/2022/01/22/2022-01-22-nature-of-dopamine-dysfunction-in-schizophrenia/index.html","hash":"ca69a540504ac68f0bf1412b5548e797ec2538d4","modified":1764001672980},{"_id":"public/2022/01/22/2022-01-22-phenomenon-of-blocking-on-predicted-reward/index.html","hash":"9cd6f7d8a921f8973cba2cd38d152b4466691bae","modified":1764001672980},{"_id":"public/2022/01/22/2022-01-22-usages-of-animal-models-in-the-study-of-human-brain-structural-connectivity/index.html","hash":"86fab0fbba56f5889ec6b6a0455222315965b43f","modified":1764001672980},{"_id":"public/2022/01/18/2022-01-18-nmda-receptor-dependent-ltp-roles/index.html","hash":"1c91452e585da640d42c563f4b001dc8824eb8f3","modified":1764001672980},{"_id":"public/2021/12/13/2022-01-04-lei-half-a-year-in-london/index.html","hash":"e7f6bf5d3d55ebb269a7201b1dc7eacf8c7c178b","modified":1764001672980},{"_id":"public/2021/12/13/2021-12-13-lei-proteinopathies-essay/index.html","hash":"1b56157d01c063c27dd2163c1bb873209822f5ab","modified":1764001672980},{"_id":"public/2021/11/28/2021-11-28-lei-model-species-essay/index.html","hash":"096aa11a92842c0dc91c2793336c9e46c78d2c5a","modified":1764001672980},{"_id":"public/2021/11/23/23-11-21glossary/index.html","hash":"ae2e08c75cc081210735a6df2268a299978724dc","modified":1764001672980},{"_id":"public/categories/Neuroscience/index.html","hash":"59f578126a7958c359a6f13f5e1fb24fd505adaa","modified":1764001672980},{"_id":"public/categories/Neuroscience/page/2/index.html","hash":"4f80e761ae1db4f00603fa481610819dcf3818e3","modified":1764001672980},{"_id":"public/categories/programming/index.html","hash":"982184862c1e81059e77be26edd7e6aacbceb55e","modified":1764001672980},{"_id":"public/categories/daily-life/index.html","hash":"1aa59540784b5a2efabcd989bdaf5d26fd29fed6","modified":1764001672980},{"_id":"public/categories/discussion/index.html","hash":"7c540f0fb3ef74bec116322b0e8b1835383b0c0e","modified":1764001672980},{"_id":"public/categories/Neuroscience-programming/index.html","hash":"f6b26d3e03738f1c23c213239b468d0633c2b3b6","modified":1764001672980},{"_id":"public/categories/Neruroscience-programming/index.html","hash":"bfffae8aeeca9a3c365269ce9f2aa8f25b30819c","modified":1764001672980},{"_id":"public/categories/Traveling/index.html","hash":"5b2025458af3f03a00638d4dfb324eb83705abd3","modified":1764001672980},{"_id":"public/categories/life/index.html","hash":"0c2fe675d68366331edcb8b897f6e00e799a4629","modified":1764001672980},{"_id":"public/archives/page/2/index.html","hash":"6244df243b2c24e0c4657d614018a78473ed2565","modified":1764001672980},{"_id":"public/archives/page/3/index.html","hash":"4663313a9cc93a976e0e0932dcb83c508c93a778","modified":1764001672980},{"_id":"public/archives/page/4/index.html","hash":"7a001856d3e133817a65d4f60c7b503670b72920","modified":1764001672980},{"_id":"public/archives/2021/index.html","hash":"05d3f84e67e03868ea7f3ea7151e75c3a6715b30","modified":1764001672980},{"_id":"public/archives/2021/11/index.html","hash":"fc9f9ea3e4e532199b2c1d753b222a6d220bbac6","modified":1764001672980},{"_id":"public/archives/2021/12/index.html","hash":"ff4e29b832555a1fb2ec826a0bd890db03039928","modified":1764001672980},{"_id":"public/archives/2022/index.html","hash":"ed66d1535d0fc4966e0f0d2846c43f2b3b6a3312","modified":1764001672980},{"_id":"public/archives/2022/page/2/index.html","hash":"38c4e077f5814bb71e8320d273b509c79f41e630","modified":1764001672980},{"_id":"public/archives/2022/page/3/index.html","hash":"cd5b11592a4539a4cc67c028a2771718c99e4059","modified":1764001672980},{"_id":"public/archives/2022/02/index.html","hash":"0d2f4592b8d4187229c85b2bdbd881fc9f5e3ade","modified":1764001672980},{"_id":"public/archives/2022/01/index.html","hash":"11863a1399f925df75633436c71ad34668e956f5","modified":1764001672980},{"_id":"public/archives/2022/03/index.html","hash":"801b5678a76278215da07ddd0f0542a60593b8e7","modified":1764001672980},{"_id":"public/archives/2022/04/index.html","hash":"a7b47d82dc290132d7358c24405d57a43c5cafc1","modified":1764001672980},{"_id":"public/archives/2022/05/index.html","hash":"0a1be9f4c17b1aa7843d13b0f4a6688747a75d0e","modified":1764001672980},{"_id":"public/archives/2022/07/index.html","hash":"19f9462556fb0604abb8ce9669838c8a5854913c","modified":1764001672980},{"_id":"public/archives/2022/08/index.html","hash":"4d90c666b81ccf8d710f56cb54fa4d17cee39e9d","modified":1764001672980},{"_id":"public/archives/2022/09/index.html","hash":"7630d792b4374a3a62d56378c4e1a868d29dae92","modified":1764001672980},{"_id":"public/archives/2023/index.html","hash":"9264b3564d19db4cc93b8b78e638fe125a4ad505","modified":1764001672980},{"_id":"public/archives/2023/10/index.html","hash":"d18add4e67cb6a85983fe4d423b15a23ddcccd16","modified":1764001672980},{"_id":"public/archives/2023/03/index.html","hash":"80ff77d3ea9dfafae5a8d13ac89782903d51628d","modified":1764001672980},{"_id":"public/archives/2024/index.html","hash":"d5fa9b9967edf92780b6531b0f65f537c09d8482","modified":1764001672980},{"_id":"public/archives/2024/10/index.html","hash":"8b11bb4edc56f8c628231e78c8a9eb1dbb044db0","modified":1764001672980},{"_id":"public/page/3/index.html","hash":"b15016f4ee67551c6b6282e19cbcb51c4f157b0d","modified":1764001672980},{"_id":"public/page/2/index.html","hash":"1f57e7542c571843dde782325158a5a89c7d8280","modified":1764001672980},{"_id":"public/page/4/index.html","hash":"518b0ab9b33af3aaea74a689a8612bc5008516b7","modified":1764001672980},{"_id":"public/tags/Lecture-Note/index.html","hash":"cb02008447c18c87de64baef87ad0bec36e461c1","modified":1764001672980},{"_id":"public/index.html","hash":"fabdc0ab041d14fc6dd68bf97ecc8f2b31beb091","modified":1764001672980},{"_id":"public/tags/Lecture-Note/page/2/index.html","hash":"4b67b6d0b8dda8e8295b727c49359d07e182d436","modified":1764001672980},{"_id":"public/tags/blog-building/index.html","hash":"f583aa89e2454375a06a442a9f54ca772157b4b9","modified":1764001672980},{"_id":"public/tags/diary/index.html","hash":"ddccf415c58dabca9d431619bb853ec725d20582","modified":1764001672980},{"_id":"public/tags/Essay/index.html","hash":"b602b60d8697d70f919d22e624b9850b4fb415f8","modified":1764001672980},{"_id":"public/tags/Neuroscience/index.html","hash":"0d7413f6bc7286a93bd9dc4eedf84e287cbf42e5","modified":1764001672980},{"_id":"public/tags/glossary/index.html","hash":"9e89ae5624799d48fccd8f09bd78622761580313","modified":1764001672980},{"_id":"public/tags/Chengdu/index.html","hash":"2a3d4680281f2ab11fd5a2f7de6538273bd05709","modified":1764001672980},{"_id":"public/tags/Cpp/index.html","hash":"b834748af78e232b86319d8726572ccd229aa091","modified":1764001672980},{"_id":"public/tags/tips/index.html","hash":"419ea6a800c757939a32ecb1e45a42a8e351826b","modified":1764001672980},{"_id":"public/tags/Albania/index.html","hash":"db3d946fa35e26664fc4487e2d5ad57a4ff151fc","modified":1764001672980},{"_id":"public/tags/DLL/index.html","hash":"c998cccb1bfb2ac4ab927b4d08c6b831ff61b31b","modified":1764001672980},{"_id":"public/tags/ML/index.html","hash":"5fd7c6d426183ad1ee684db1e36b13a99c0c8813","modified":1764001672980},{"_id":"public/tags/project/index.html","hash":"caf94b927fe4d30cae44d5bc809435d4bee70167","modified":1764001672980},{"_id":"public/tags/python/index.html","hash":"60b35470476da1573fdb430b8d0cb89717dba29c","modified":1764001672980},{"_id":"public/tags/Pandas/index.html","hash":"0cdfa3b4e04ba0351600ea49bb6985936f5c3da5","modified":1764001672980},{"_id":"public/tags/PhD/index.html","hash":"f9a8ed016499a89078965c68a669482bd92cdf21","modified":1764001672980},{"_id":"public/tags/Mylove/index.html","hash":"21dd9594cd3dc7094509285b760517e3aba0aa7a","modified":1764001672980},{"_id":"public/tags/Taiwan/index.html","hash":"0b90884eb731a947aaf10f52ad1134a955f1889c","modified":1764001672980},{"_id":"public/medias/extra/detroit-become-human-2018-games-hd-games-wallpaper-preview.jpg","hash":"0d9e3480d3f5355edabaa68d1692a85d407470e2","modified":1764001672980},{"_id":"public/medias/featureimages/0.jpg","hash":"1f8bbfbd625448b4b2a748b75636e456b826dcd3","modified":1764001672980},{"_id":"public/medias/featureimages/18.jpg","hash":"61f8f0a98af9fc525fe0fb8a609d5a5bf52694a7","modified":1764001672980},{"_id":"public/medias/featureimages/5.jpg","hash":"c4cc724f4572a9bcede7443a4f4c0393d3073868","modified":1764001672980},{"_id":"public/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1764001672980},{"_id":"public/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1764001672980},{"_id":"public/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1764001672980},{"_id":"public/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1764001672980},{"_id":"public/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1764001672980},{"_id":"public/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1764001672980},{"_id":"public/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1764001672980},{"_id":"public/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1764001672980},{"_id":"public/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1764001672980},{"_id":"public/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1764001672980},{"_id":"public/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1764001672980},{"_id":"public/css/prism-line-numbers.css","hash":"a1692758d22c6cdf6fd1a8dafc9b4b98e41d3138","modified":1764001672980},{"_id":"public/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1764001672980},{"_id":"public/css/prism-tomorrow.css","hash":"3b99487dfc9b4e51e9105a93743b92a761840e34","modified":1764001672980},{"_id":"public/about/CV_Lei_Luo.pdf","hash":"459aafff976fce4b8160b0a158c0e006d4e59baa","modified":1764001672980},{"_id":"public/medias/extra/777.jpg","hash":"1038225cb7589943bcd836f294d0fdaf526c118c","modified":1764001672980},{"_id":"public/medias/extra/7lXbbhT.jpeg","hash":"91dc888ec080426f7d10dba51e600efb3ccaa8f6","modified":1764001672980},{"_id":"public/medias/extra/lbRWFih.jpeg","hash":"aaa1b4955b8695f549d5b58ea80ab6a1339bcfff","modified":1764001672980},{"_id":"public/medias/featureimages/15.jpg","hash":"5b80fa97837179ff9c55d4f14b2c4adf32c7eac5","modified":1764001672980},{"_id":"public/medias/music/avatars/The 2nd Melody of the Night.jpg","hash":"12928885e69d210e77ce2fff52c195d307939dd7","modified":1764001672980},{"_id":"public/medias/music/avatars/Reflections of the Moon on Erquan.jpg","hash":"154acd793329cf3a88505d9347de9643a5227418","modified":1764001672980},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1764001672980},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1764001672980},{"_id":"public/js/matery.js","hash":"92f07106944f5ef7cd72e84bb3534513d00eebe1","modified":1764001672980},{"_id":"public/css/matery.css","hash":"caa63c2c7908e45ebbbea0fbdc72d09b7b6d5b76","modified":1764001672980},{"_id":"public/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1764001672980},{"_id":"public/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1764001672980},{"_id":"public/css/my.css","hash":"497e50351f7838f8546cac76850a42e7e380a110","modified":1764001672980},{"_id":"public/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1764001672980},{"_id":"public/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1764001672980},{"_id":"public/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1764001672980},{"_id":"public/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1764001672980},{"_id":"public/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1764001672980},{"_id":"public/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1764001672980},{"_id":"public/libs/codeBlock/codeCopy.js","hash":"b74a381adf6ef8404d6a0452c2b9f44b47219c80","modified":1764001672980},{"_id":"public/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1764001672980},{"_id":"public/libs/codeBlock/clipboard.min.js","hash":"9cd57c67fbd3e3067f80793ef8445f5ff7783563","modified":1764001672980},{"_id":"public/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1764001672980},{"_id":"public/libs/codeBlock/codeLang.js","hash":"ea8b51e4d75e7b2cd63e4d5bcb8db2cf7f23f5db","modified":1764001672980},{"_id":"public/libs/codeBlock/codeShrink.js","hash":"215910dc8f63fd50b97957e5fcdc8480aa2728cb","modified":1764001672980},{"_id":"public/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1764001672980},{"_id":"public/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1764001672980},{"_id":"public/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1764001672980},{"_id":"public/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1764001672980},{"_id":"public/libs/gitalk/gitalk.css","hash":"3aac1db83b0135c521187254ff302d125cc30706","modified":1764001672980},{"_id":"public/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1764001672980},{"_id":"public/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1764001672980},{"_id":"public/libs/materialize/materialize.min.css","hash":"4d46df5f22cbc24eefa76228c7ee308dc3585594","modified":1764001672980},{"_id":"public/libs/jquery/jquery-2.2.0.min.js","hash":"5d7e5bbfa540f0e53bd599e4305e1a4e815b5dd1","modified":1764001672980},{"_id":"public/libs/gitalk/gitalk.min.js","hash":"28bdb33c9eb609c2f30d431df1a4cf8ca70bf841","modified":1764001672980},{"_id":"public/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1764001672980},{"_id":"public/libs/others/explosion.min.js","hash":"417b68e2cf2c6de2119c57626f4412105a8457f5","modified":1764001672980},{"_id":"public/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1764001672980},{"_id":"public/libs/others/fireworks.js","hash":"53981959bc6def4a85bbbb41b07e4b1474a2124d","modified":1764001672980},{"_id":"public/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1764001672980},{"_id":"public/libs/others/text.js","hash":"1791782cde0d1e4197f2ed58ecb7dd6aefddd169","modified":1764001672980},{"_id":"public/libs/others/snow.js","hash":"7f3b1ad2f64d4473210a2c3218893649c73c980e","modified":1764001672980},{"_id":"public/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1764001672980},{"_id":"public/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1764001672980},{"_id":"public/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1764001672980},{"_id":"public/libs/awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1764001672980},{"_id":"public/libs/valine/Valine.min.js","hash":"4e34802ccbb59f1daa58a62241ff57f923e50600","modified":1764001672980},{"_id":"public/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1764001672980},{"_id":"public/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1764001672980},{"_id":"public/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1764001672980},{"_id":"public/libs/valine/av-min.js","hash":"2577e72b52b736d99649f9e95be8976d58563333","modified":1764001672980},{"_id":"public/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1764001672980},{"_id":"public/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1764001672980},{"_id":"public/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1764001672980},{"_id":"public/medias/extra/KCKc4Dj.jpeg","hash":"23f6bb28529beeea20f973c58c75ce0f8ade6be6","modified":1764001672980},{"_id":"public/medias/extra/U6o2o8v.jpeg","hash":"4080999579fd2b397a936c1c12a0876660229522","modified":1764001672980},{"_id":"public/medias/extra/iUQJFup.jpeg","hash":"a7fc38728763c63d22bfcafc59589c1263bb47ac","modified":1764001672980},{"_id":"public/medias/extra/l24ljsb.jpeg","hash":"7e5741e55ff05847a740d6333b343dca99a52758","modified":1764001672980},{"_id":"public/medias/extra/oknqyte.jpeg","hash":"ee1f898d61881521d7f1d3258e68d1a91bb972bb","modified":1764001672980},{"_id":"public/medias/featureimages/13.jpg","hash":"d8cc7a730668943dcb0776cfa240a0cf76826363","modified":1764001672980},{"_id":"public/medias/featureimages/21.jpg","hash":"e206e2e7d2e9515a61ca87ea2ee3458f01871777","modified":1764001672980},{"_id":"public/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1764001672980},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1764001672980},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1764001672980},{"_id":"public/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1764001672980},{"_id":"public/medias/extra/DH0lPiz.jpeg","hash":"73ad93153c653dac0730b9a2d5b2787a79e10219","modified":1764001672980},{"_id":"public/medias/extra/XV0xvVF.jpeg","hash":"fb161ad81d6c4a325a3496d9f475c7db89bca268","modified":1764001672980},{"_id":"public/medias/extra/cMCj5WO.jpeg","hash":"beed137097d3fdcb44d10b2a61ddb83491d5fae1","modified":1764001672980},{"_id":"public/medias/extra/gZQ5ojS.jpeg","hash":"bb4cea3734b7eab9828e48f94960fab4fc46f3bf","modified":1764001672980},{"_id":"public/medias/extra/svykO2P.jpeg","hash":"2f2e66d7e4c8c72afaab3d405acac3ea966ae075","modified":1764001672980},{"_id":"public/medias/extra/zrBM6pg.jpeg","hash":"f9579ddb2774525028ea9ed51ad4495395b48d30","modified":1764001672980},{"_id":"public/medias/featureimages/12.jpg","hash":"c2892770fd5617418fd33d6f834879e05b2cdafd","modified":1764001672980},{"_id":"public/medias/featureimages/16.jpg","hash":"18b5f341e57e7b7f73f32141a08fa1d8278d164f","modified":1764001672980},{"_id":"public/medias/featureimages/20.jpg","hash":"61e04e767b2fc70970b8de2e4e7493fef0dd2d4d","modified":1764001672980},{"_id":"public/medias/extra/MCqwnVp.jpeg","hash":"8e04e5e5119942bdf204432b623d79a0d89c06ac","modified":1764001672980},{"_id":"public/medias/extra/TYPpacm.jpeg","hash":"8e7c889d68b8360de298868560ec4fcdabb058f4","modified":1764001672980},{"_id":"public/medias/extra/XC5Trd9.jpeg","hash":"1da7ff148da2dd242d71feb94582aca93c1fed46","modified":1764001672980},{"_id":"public/medias/extra/duXfgC6.jpeg","hash":"7713bd171372760f1aefd1d9797125427b1bcafa","modified":1764001672980},{"_id":"public/medias/extra/m9EOIXp.jpeg","hash":"7fa2eb2e03cf80a3e17cacfc232675cec580ce21","modified":1764001672980},{"_id":"public/medias/extra/jG0hnRG.jpeg","hash":"da8abc0c419adfaeee7c1e5099f8a0fcea21367a","modified":1764001672980},{"_id":"public/medias/extra/xm4QiMj.jpeg","hash":"fbdbb150c822f97fe19e5d75a4ed076a430c5e79","modified":1764001672980},{"_id":"public/medias/featureimages/2.jpg","hash":"1d8863277d744e1a18a2778ac26041bda5b03a98","modified":1764001672980},{"_id":"public/medias/featureimages/25.jpg","hash":"d0668539783fc615f14178644e486a6befb90c0c","modified":1764001672980},{"_id":"public/medias/featureimages/28.jpg","hash":"c73036359640a67a8b17db7ba0e968c088957ab8","modified":1764001672980},{"_id":"public/medias/featureimages/3.jpg","hash":"ceb8e0c195a7fe7420334efa114e98cd0e1c6523","modified":1764001672980},{"_id":"public/medias/banner/0.jpg","hash":"579c7842c852a5e26fb24f6702029638e367ba18","modified":1764001672980},{"_id":"public/medias/extra/DrOnn9n.jpeg","hash":"e3adf8ac0e4b64170f48566b649ef9c5d3276011","modified":1764001672980},{"_id":"public/medias/extra/SrXFZMq.jpeg","hash":"ee24e9412aaddcacce31226a9e4aaa36413db230","modified":1764001672980},{"_id":"public/medias/featureimages/10.jpg","hash":"66de48d963e7f221931e550b2442da0cd40cbaa8","modified":1764001672980},{"_id":"public/medias/featureimages/26.jpg","hash":"c66a4e7a2e670b63759a091f9428ee7f971d7b56","modified":1764001672980},{"_id":"public/medias/featureimages/7.jpg","hash":"bd400da9123424afe7ba6c839be9ad7697c1245b","modified":1764001672980},{"_id":"public/medias/featureimages/6.jpg","hash":"698fc46e97428d73c9d4e3d254e88b9b66fb38cd","modified":1764001672980},{"_id":"public/medias/featureimages/27.jpg","hash":"7ea6f890cc59def8b1c9f393e4ae77cd16c79aad","modified":1764001672980},{"_id":"public/medias/extra/7MW7877.jpeg","hash":"653f5ba0b86be4f95ef11424fe7e9c153ae2a2dd","modified":1764001672980},{"_id":"public/medias/extra/pZgQqm9.jpeg","hash":"1c19bdc86c144072be47f69e5181627585d420c7","modified":1764001672980},{"_id":"public/medias/featureimages/11.jpg","hash":"2b30186c6d78ed76fa5f278be57290c1bd22c96a","modified":1764001672980},{"_id":"public/medias/featureimages/1.jpg","hash":"f1d720039d654d693c32150c06c78cfc3663b0b4","modified":1764001672980},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1764001672980},{"_id":"public/medias/featureimages/14.jpg","hash":"8ed1f7012ccc5e11c609438f1477a05ef823e1c2","modified":1764001672980},{"_id":"public/medias/music/avatars/The 4nd Melody of the Night.jpg","hash":"98cb79003c240df73e2693cbdba2d933ca4ef369","modified":1764001672980},{"_id":"public/medias/music/avatars/Sky Castle.jpeg","hash":"5a66376c272972114e76ea55f07dc9a169c701e1","modified":1764001672980},{"_id":"public/medias/banner/1.jpg","hash":"52cd0c8aa4c5ee6405689dd076668e3e3436b920","modified":1764001672980},{"_id":"public/medias/featureimages/22.jpg","hash":"1549546a7da979f756da717d8cca04ec90d2caef","modified":1764001672980},{"_id":"public/medias/featureimages/29.jpg","hash":"c70569889c0260d8a0ffb667d708022473fc4235","modified":1764001672980},{"_id":"public/medias/featureimages/8.jpg","hash":"f81e97edf705ab45b989b2b15d6a13c005ccaa32","modified":1764001672980},{"_id":"public/medias/featureimages/23.jpg","hash":"c145d49cf05ad810b4dc980717260934828719d6","modified":1764001672980},{"_id":"public/medias/banner/6.jpg","hash":"75742dd0a63ab7d9e37765a7fc699608d8f263c1","modified":1764001672980},{"_id":"public/medias/logo.png","hash":"db5f912d634625c8c12e966ca5f75f5dc4692cb4","modified":1764001672980},{"_id":"public/medias/featureimages/9.jpg","hash":"cd54b116609f5741cc7db0f7f49bf56ac356ddfb","modified":1764001672980},{"_id":"public/medias/banner/4.jpg","hash":"e570bc765b06dde03391f170973f11c3e9b7b819","modified":1764001672980},{"_id":"public/medias/extra/555.jpg","hash":"449be5b5dc89c44459d8801caf3eaad8c64aeb51","modified":1764001672980},{"_id":"public/medias/featureimages/4.jpg","hash":"e06afe32a867f7a6e861618e0b5ac9d93cd71d05","modified":1764001672980},{"_id":"public/medias/featureimages/17.jpg","hash":"449be5b5dc89c44459d8801caf3eaad8c64aeb51","modified":1764001672980},{"_id":"public/medias/featureimages/19.jpg","hash":"b7a0fa17ae2e7732e17e5ea797e7306afab22b0d","modified":1764001672980},{"_id":"public/medias/featureimages/24.jpg","hash":"ae2951e58e38e47a4ca309a041258ac1f63a163f","modified":1764001672980},{"_id":"public/medias/banner/3.jpg","hash":"59cd7277a61f00d8edd3d02e644bb28cd8877b97","modified":1764001672980},{"_id":"public/medias/banner/5.jpg","hash":"7c8b5f0801b7a9af9e33bf9095d17ba4689df11a","modified":1764001672980},{"_id":"public/medias/avatars/avatar.jpg","hash":"9e8b7d41368b75b37906a73b844ef5a12ca28dbb","modified":1764001672980},{"_id":"public/medias/music/The 2nd Melody of the Night.mp3","hash":"a4451bfbba2e157e4e449469a599dec84f436dae","modified":1764001672980},{"_id":"public/medias/music/The 4nd Melody of the Night.mp3","hash":"30862b1df21eab8d135b3c7afa6b80e15f3e039c","modified":1764001672980},{"_id":"public/medias/banner/2.jpg","hash":"7420bd4a4248510ea1c0c4a8645616dac62ea9a3","modified":1764001672980},{"_id":"public/medias/music/Sky Castle.mp4","hash":"f965956d37b3d9b6d687a9125cc6f37e2884006d","modified":1764001672980},{"_id":"public/medias/music/Reflections of the Moon on Erquan.mp3","hash":"798985dca4fbbd3b9466a72648fb6978999559a0","modified":1764001672980}],"Category":[{"name":"Neuroscience","_id":"cuidJJUg_gLKGDcvftEODIHfk"},{"name":"programming","_id":"cuidDwwpPs-d4gZKLi8mrtF9V"},{"name":"daily life","_id":"cuiduzx55enbrKre-OXPbdRVj"},{"name":"discussion","_id":"cuid1Hok2e5rxFsJ0dJZjro7-"},{"name":"Traveling","_id":"cuidnENRJiZWMH9NOT9ZBprYh"},{"name":"Neuroscience programming","_id":"cuidv205CRCP2040jPeycN4Fj"},{"name":"Neruroscience programming","_id":"cuidwy15ZiBdA6fv5oDluj7zW"},{"name":"life","_id":"cuidXmj04GE7n1skmj0tWW_xv"}],"Data":[{"_id":"musics","data":[{"name":"The 2nd Melody of the Night","artist":"Shi Jing","url":"/medias/music/The 2nd Melody of the Night.mp3","cover":"/medias/music/avatars/The 2nd Melody of the Night.jpg"},{"name":"The 4nd Melody of the Night","artist":"Shi Jing","url":"/medias/music/The 4nd Melody of the Night.mp3","cover":"/medias/music/avatars/The 4nd Melody of the Night.jpg"},{"name":"Sky Castle","artist":"Joe Hisaishi","url":"/medias/music/Sky Castle.mp4","cover":"/medias/music/avatars/Sky Castle.jpeg"}]}],"Page":[{"title":"categories","date":"2019-07-19T15:39:20.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-07-19 16:39:20\ntype: \"categories\"\nlayout: \"categories\"\n---","updated":"2022-08-24T17:08:39.391Z","path":"categories/index.html","comments":1,"_id":"cuidarVF-lti5_IylceaRdzIU","content":"","excerpt":"","more":""},{"title":"archives","date":"2019-07-19T15:39:20.000Z","type":"archives","layout":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-07-19 16:39:20\ntype: \"archives\"\nlayout: \"archives\"\n---","updated":"2022-08-24T17:08:39.390Z","path":"archives/index.html","comments":1,"_id":"cuidW97xWI1JZQeMEeEWI4GQn","content":"","excerpt":"","more":""},{"title":"404","date":"2019-07-19T15:41:10.000Z","type":"404","layout":"404","description":"You came to a borderlands without knowledge","_content":"","source":"404.md","raw":"---\ntitle: 404\ndate: 2019-07-19 16:41:10\ntype: \"404\"\nlayout: \"404\"\ndescription: \"You came to a borderlands without knowledge\"\n---\n","updated":"2022-08-24T17:08:39.277Z","path":"404.html","comments":1,"_id":"cuid3C1JOjpIzCbGtJpMEGY9Z","content":"","excerpt":"","more":""},{"title":"contact","date":"2019-07-26T16:17:02.000Z","type":"contact","layout":"contact","_content":"\n# Contact me at: \n\nGitHub: <a href=\"https://github.com/ReveRoyl\">ReveRoyl</a>\n\nemail: <a href=\"mailto:k21116947@kcl.ac.uk\">k21116947@kcl.ac.uk</a>\n\nFacebook: <a href=\"https://www.facebook.com/people/Lei-Luo/100045483159494/\">Lei Luo</a>\n\nTwitter: <a href=\"https://twitter.com/ReveRoyl\">ReveRoyl</a>\n\nLink: <a href=\"https://www.linkedin.com/in/luo-lei-264207199/\">Lei Luo</a>\n\n","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2019-07-26 17:17:02\ntype: \"contact\"\nlayout: \"contact\"\n---\n\n# Contact me at: \n\nGitHub: <a href=\"https://github.com/ReveRoyl\">ReveRoyl</a>\n\nemail: <a href=\"mailto:k21116947@kcl.ac.uk\">k21116947@kcl.ac.uk</a>\n\nFacebook: <a href=\"https://www.facebook.com/people/Lei-Luo/100045483159494/\">Lei Luo</a>\n\nTwitter: <a href=\"https://twitter.com/ReveRoyl\">ReveRoyl</a>\n\nLink: <a href=\"https://www.linkedin.com/in/luo-lei-264207199/\">Lei Luo</a>\n\n","updated":"2022-08-25T13:14:14.230Z","path":"contact/index.html","comments":1,"_id":"cuidBDIVPy5KXpDkXJBBgkTVU","content":"<h1 id=\"Contact-me-at\"><a href=\"#Contact-me-at\" class=\"headerlink\" title=\"Contact me at:\"></a>Contact me at:</h1><p>GitHub: <a href=\"https://github.com/ReveRoyl\">ReveRoyl</a></p>\n<p>email: <a href=\"mailto:k21116947@kcl.ac.uk\">k21116947@kcl.ac.uk</a></p>\n<p>Facebook: <a href=\"https://www.facebook.com/people/Lei-Luo/100045483159494/\">Lei Luo</a></p>\n<p>Twitter: <a href=\"https://twitter.com/ReveRoyl\">ReveRoyl</a></p>\n<p>Link: <a href=\"https://www.linkedin.com/in/luo-lei-264207199/\">Lei Luo</a></p>\n","excerpt":"","more":"<h1 id=\"Contact-me-at\"><a href=\"#Contact-me-at\" class=\"headerlink\" title=\"Contact me at:\"></a>Contact me at:</h1><p>GitHub: <a href=\"https://github.com/ReveRoyl\">ReveRoyl</a></p>\n<p>email: <a href=\"mailto:k21116947@kcl.ac.uk\">k21116947@kcl.ac.uk</a></p>\n<p>Facebook: <a href=\"https://www.facebook.com/people/Lei-Luo/100045483159494/\">Lei Luo</a></p>\n<p>Twitter: <a href=\"https://twitter.com/ReveRoyl\">ReveRoyl</a></p>\n<p>Link: <a href=\"https://www.linkedin.com/in/luo-lei-264207199/\">Lei Luo</a></p>\n"},{"title":"about","date":"2022-07-19T15:41:10.000Z","type":"about","layout":"about","mathjax":true,"_content":"\n# About me ([CV.pdf](./CV_Lei_Luo.pdf)) \n\n**Lei Luo** \n\n+86 18105509928[ 丨k21116947@kcl.ac.uk ](mailto:%E4%B8%A8k21116947@kcl.ac.uk) 20 Glenfilnlas way, SE5 0PW, London https://reveroyl.github.io/ \n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2022-07-19 16:41:10\ntype: \"about\"\nlayout: \"about\"\nmathjax: true\n---\n\n# About me ([CV.pdf](./CV_Lei_Luo.pdf)) \n\n**Lei Luo** \n\n+86 18105509928[ 丨k21116947@kcl.ac.uk ](mailto:%E4%B8%A8k21116947@kcl.ac.uk) 20 Glenfilnlas way, SE5 0PW, London https://reveroyl.github.io/ \n","updated":"2025-11-24T16:27:32.270Z","path":"about/index.html","comments":1,"_id":"cuidBhlgrC3XULYMhzlxYH51C","content":"<h1 id=\"About-me-CV-pdf\"><a href=\"#About-me-CV-pdf\" class=\"headerlink\" title=\"About me (CV.pdf)\"></a>About me (<a href=\"./CV_Lei_Luo.pdf\">CV.pdf</a>)</h1><p><strong>Lei Luo</strong> </p>\n<p>+86 18105509928<a href=\"mailto:%E4%B8%A8k21116947@kcl.ac.uk\"> 丨k21116947@kcl.ac.uk </a> 20 Glenfilnlas way, SE5 0PW, London <a href=\"https://reveroyl.github.io/\">https://reveroyl.github.io/</a> </p>\n","excerpt":"","more":"<h1 id=\"About-me-CV-pdf\"><a href=\"#About-me-CV-pdf\" class=\"headerlink\" title=\"About me (CV.pdf)\"></a>About me (<a href=\"./CV_Lei_Luo.pdf\">CV.pdf</a>)</h1><p><strong>Lei Luo</strong> </p>\n<p>+86 18105509928<a href=\"mailto:%E4%B8%A8k21116947@kcl.ac.uk\"> 丨k21116947@kcl.ac.uk </a> 20 Glenfilnlas way, SE5 0PW, London <a href=\"https://reveroyl.github.io/\">https://reveroyl.github.io/</a> </p>\n"},{"title":"tags","date":"2022-02-16T00:04:27.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2022-02-16 00:04:27\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2022-08-24T17:08:39.392Z","path":"tags/index.html","comments":1,"_id":"cuid8vFqKQwOxNgoi1osdBNPg","content":"","excerpt":"","more":""}],"Post":[{"title":"Lecture Notes 01/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-01T10:00:00.000Z","password":null,"summary":null,"_content":"\n# Mock abstract exam\n\n## Part 1\n\n### What is the main aim of the research reported in this paper? \n\nDefine method and clarify why this method is used in the study\n\ngive background information on aim \n\n### What are the main findings of this research? How could the authors further investigate them?\n\nstate the main finding\n\n\n\nDiscuss future research in the context of the current research\n\n### Are the authors’ conclusions supported by the data? Discuss possible confounding variables. \n\nstate if the data support the conclusion.\n\nfully consider all confounding variables\n\n### The authors report there was no significant main effect of stimulation, with an associated p-value of p = 0.97. What would the conclusion be if the *p*-value was 0.50? \n\nanswer the question but provide context\n\nshow off your additional knowledge of the subject\n\nUsing your own words, describe the following:\n\n## Part 2 \n\n### The results obtained in this paper. Include in your answer a brief indication of the methods used\n\nState the major findings. 30 marks.\n\nGive key details of the methods\n\n\n\nthink more broadly -replication crisis in cognitive neuroscience is relevant here\n\n\n\n### The significance of the results for understanding cognitive neuroscience\n\n\n\n---\n\n# Neural underpinnings of cognitive ageing\n\n## Objectives\n\nWhat is cognitive ageing and when does cognitive decline begin?\n\n## Cognitive decline\n\nindividual- differences approaches to studying the neural basis of cognitive ageing\n\n![cross-sectional and longitudinal ageing](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261740132.png)\n\n**Why do cross-sectional and longitudinal ageing studies give different results?**\n\n1. Cohort differences (the Flynn Effect)\n• Problem for cross-sectional studies\n2. Nonrandom attrition\n• Problem for longitudinal studies\n3. Practice effects\n• Problem for longitudinal studies\n\n## Neural underpinnings\n\n**Average brain changes between 73 and 76**\n\n- Grey matter volume: -.07 SDs/year\n- Normal-appearing white matter volume: -.10 SDs/year\n- White matter hyperintensity volume: +.11 SDs/year\n- General fractional anisotropy: -.09 SDs/year\n- General mean diffusivity: +.34 SDs/year\n\n## Coupled brain/cognitive changes - summary\n\n- Volume declines across the lifespan\n- Of volumetric results, best cognitive predictor/coupling is often white matter hyperintensities (pathology)\n- White matter microstructure changes alongside fluid intelligence\n- Some unexpected results (no coupled change between white matter and processing speed)\n  - Larger studies required\n\n## Next steps\n\n- Increase power\n\n  - Larger, longer studies with additional waves?\n\n- Get specific\n\n  - Brain networks rather than broad measures?\n\n  - Spatial interaction of hyperintensities and healthy white matter?\n\n- Find predictors\n\n  - Early-life rather than old-age?\n\n- Add genetics\n\n  - Polygenic scores to predict brain or cognitive changes?","source":"_posts/01_03_22.md","raw":"---\ntitle: Lecture Notes 01/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-01 10:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n# Mock abstract exam\n\n## Part 1\n\n### What is the main aim of the research reported in this paper? \n\nDefine method and clarify why this method is used in the study\n\ngive background information on aim \n\n### What are the main findings of this research? How could the authors further investigate them?\n\nstate the main finding\n\n\n\nDiscuss future research in the context of the current research\n\n### Are the authors’ conclusions supported by the data? Discuss possible confounding variables. \n\nstate if the data support the conclusion.\n\nfully consider all confounding variables\n\n### The authors report there was no significant main effect of stimulation, with an associated p-value of p = 0.97. What would the conclusion be if the *p*-value was 0.50? \n\nanswer the question but provide context\n\nshow off your additional knowledge of the subject\n\nUsing your own words, describe the following:\n\n## Part 2 \n\n### The results obtained in this paper. Include in your answer a brief indication of the methods used\n\nState the major findings. 30 marks.\n\nGive key details of the methods\n\n\n\nthink more broadly -replication crisis in cognitive neuroscience is relevant here\n\n\n\n### The significance of the results for understanding cognitive neuroscience\n\n\n\n---\n\n# Neural underpinnings of cognitive ageing\n\n## Objectives\n\nWhat is cognitive ageing and when does cognitive decline begin?\n\n## Cognitive decline\n\nindividual- differences approaches to studying the neural basis of cognitive ageing\n\n![cross-sectional and longitudinal ageing](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261740132.png)\n\n**Why do cross-sectional and longitudinal ageing studies give different results?**\n\n1. Cohort differences (the Flynn Effect)\n• Problem for cross-sectional studies\n2. Nonrandom attrition\n• Problem for longitudinal studies\n3. Practice effects\n• Problem for longitudinal studies\n\n## Neural underpinnings\n\n**Average brain changes between 73 and 76**\n\n- Grey matter volume: -.07 SDs/year\n- Normal-appearing white matter volume: -.10 SDs/year\n- White matter hyperintensity volume: +.11 SDs/year\n- General fractional anisotropy: -.09 SDs/year\n- General mean diffusivity: +.34 SDs/year\n\n## Coupled brain/cognitive changes - summary\n\n- Volume declines across the lifespan\n- Of volumetric results, best cognitive predictor/coupling is often white matter hyperintensities (pathology)\n- White matter microstructure changes alongside fluid intelligence\n- Some unexpected results (no coupled change between white matter and processing speed)\n  - Larger studies required\n\n## Next steps\n\n- Increase power\n\n  - Larger, longer studies with additional waves?\n\n- Get specific\n\n  - Brain networks rather than broad measures?\n\n  - Spatial interaction of hyperintensities and healthy white matter?\n\n- Find predictors\n\n  - Early-life rather than old-age?\n\n- Add genetics\n\n  - Polygenic scores to predict brain or cognitive changes?","slug":"01_03_22","published":1,"updated":"2022-08-24T17:08:39.283Z","comments":1,"layout":"post","photos":[],"_id":"cuidscvgjRq-3L0XlaOzAQ7qL","content":"<h1 id=\"Mock-abstract-exam\"><a href=\"#Mock-abstract-exam\" class=\"headerlink\" title=\"Mock abstract exam\"></a>Mock abstract exam</h1><h2 id=\"Part-1\"><a href=\"#Part-1\" class=\"headerlink\" title=\"Part 1\"></a>Part 1</h2><h3 id=\"What-is-the-main-aim-of-the-research-reported-in-this-paper\"><a href=\"#What-is-the-main-aim-of-the-research-reported-in-this-paper\" class=\"headerlink\" title=\"What is the main aim of the research reported in this paper?\"></a>What is the main aim of the research reported in this paper?</h3><p>Define method and clarify why this method is used in the study</p>\n<p>give background information on aim </p>\n<h3 id=\"What-are-the-main-findings-of-this-research-How-could-the-authors-further-investigate-them\"><a href=\"#What-are-the-main-findings-of-this-research-How-could-the-authors-further-investigate-them\" class=\"headerlink\" title=\"What are the main findings of this research? How could the authors further investigate them?\"></a>What are the main findings of this research? How could the authors further investigate them?</h3><p>state the main finding</p>\n<p>Discuss future research in the context of the current research</p>\n<h3 id=\"Are-the-authors’-conclusions-supported-by-the-data-Discuss-possible-confounding-variables\"><a href=\"#Are-the-authors’-conclusions-supported-by-the-data-Discuss-possible-confounding-variables\" class=\"headerlink\" title=\"Are the authors’ conclusions supported by the data? Discuss possible confounding variables.\"></a>Are the authors’ conclusions supported by the data? Discuss possible confounding variables.</h3><p>state if the data support the conclusion.</p>\n<p>fully consider all confounding variables</p>\n<h3 id=\"The-authors-report-there-was-no-significant-main-effect-of-stimulation-with-an-associated-p-value-of-p-0-97-What-would-the-conclusion-be-if-the-p-value-was-0-50\"><a href=\"#The-authors-report-there-was-no-significant-main-effect-of-stimulation-with-an-associated-p-value-of-p-0-97-What-would-the-conclusion-be-if-the-p-value-was-0-50\" class=\"headerlink\" title=\"The authors report there was no significant main effect of stimulation, with an associated p-value of p = 0.97. What would the conclusion be if the p-value was 0.50?\"></a>The authors report there was no significant main effect of stimulation, with an associated p-value of p = 0.97. What would the conclusion be if the <em>p</em>-value was 0.50?</h3><p>answer the question but provide context</p>\n<p>show off your additional knowledge of the subject</p>\n<p>Using your own words, describe the following:</p>\n<h2 id=\"Part-2\"><a href=\"#Part-2\" class=\"headerlink\" title=\"Part 2\"></a>Part 2</h2><h3 id=\"The-results-obtained-in-this-paper-Include-in-your-answer-a-brief-indication-of-the-methods-used\"><a href=\"#The-results-obtained-in-this-paper-Include-in-your-answer-a-brief-indication-of-the-methods-used\" class=\"headerlink\" title=\"The results obtained in this paper. Include in your answer a brief indication of the methods used\"></a>The results obtained in this paper. Include in your answer a brief indication of the methods used</h3><p>State the major findings. 30 marks.</p>\n<p>Give key details of the methods</p>\n<p>think more broadly -replication crisis in cognitive neuroscience is relevant here</p>\n<h3 id=\"The-significance-of-the-results-for-understanding-cognitive-neuroscience\"><a href=\"#The-significance-of-the-results-for-understanding-cognitive-neuroscience\" class=\"headerlink\" title=\"The significance of the results for understanding cognitive neuroscience\"></a>The significance of the results for understanding cognitive neuroscience</h3><hr>\n<h1 id=\"Neural-underpinnings-of-cognitive-ageing\"><a href=\"#Neural-underpinnings-of-cognitive-ageing\" class=\"headerlink\" title=\"Neural underpinnings of cognitive ageing\"></a>Neural underpinnings of cognitive ageing</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><p>What is cognitive ageing and when does cognitive decline begin?</p>\n<h2 id=\"Cognitive-decline\"><a href=\"#Cognitive-decline\" class=\"headerlink\" title=\"Cognitive decline\"></a>Cognitive decline</h2><p>individual- differences approaches to studying the neural basis of cognitive ageing</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261740132.png\" alt=\"cross-sectional and longitudinal ageing\"></p>\n<p><strong>Why do cross-sectional and longitudinal ageing studies give different results?</strong></p>\n<ol>\n<li>Cohort differences (the Flynn Effect)<br>• Problem for cross-sectional studies</li>\n<li>Nonrandom attrition<br>• Problem for longitudinal studies</li>\n<li>Practice effects<br>• Problem for longitudinal studies</li>\n</ol>\n<h2 id=\"Neural-underpinnings\"><a href=\"#Neural-underpinnings\" class=\"headerlink\" title=\"Neural underpinnings\"></a>Neural underpinnings</h2><p><strong>Average brain changes between 73 and 76</strong></p>\n<ul>\n<li>Grey matter volume: -.07 SDs/year</li>\n<li>Normal-appearing white matter volume: -.10 SDs/year</li>\n<li>White matter hyperintensity volume: +.11 SDs/year</li>\n<li>General fractional anisotropy: -.09 SDs/year</li>\n<li>General mean diffusivity: +.34 SDs/year</li>\n</ul>\n<h2 id=\"Coupled-brain-cognitive-changes-summary\"><a href=\"#Coupled-brain-cognitive-changes-summary\" class=\"headerlink\" title=\"Coupled brain/cognitive changes - summary\"></a>Coupled brain/cognitive changes - summary</h2><ul>\n<li>Volume declines across the lifespan</li>\n<li>Of volumetric results, best cognitive predictor/coupling is often white matter hyperintensities (pathology)</li>\n<li>White matter microstructure changes alongside fluid intelligence</li>\n<li>Some unexpected results (no coupled change between white matter and processing speed)<ul>\n<li>Larger studies required</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Next-steps\"><a href=\"#Next-steps\" class=\"headerlink\" title=\"Next steps\"></a>Next steps</h2><ul>\n<li><p>Increase power</p>\n<ul>\n<li>Larger, longer studies with additional waves?</li>\n</ul>\n</li>\n<li><p>Get specific</p>\n<ul>\n<li><p>Brain networks rather than broad measures?</p>\n</li>\n<li><p>Spatial interaction of hyperintensities and healthy white matter?</p>\n</li>\n</ul>\n</li>\n<li><p>Find predictors</p>\n<ul>\n<li>Early-life rather than old-age?</li>\n</ul>\n</li>\n<li><p>Add genetics</p>\n<ul>\n<li>Polygenic scores to predict brain or cognitive changes?</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"Mock-abstract-exam\"><a href=\"#Mock-abstract-exam\" class=\"headerlink\" title=\"Mock abstract exam\"></a>Mock abstract exam</h1><h2 id=\"Part-1\"><a href=\"#Part-1\" class=\"headerlink\" title=\"Part 1\"></a>Part 1</h2><h3 id=\"What-is-the-main-aim-of-the-research-reported-in-this-paper\"><a href=\"#What-is-the-main-aim-of-the-research-reported-in-this-paper\" class=\"headerlink\" title=\"What is the main aim of the research reported in this paper?\"></a>What is the main aim of the research reported in this paper?</h3><p>Define method and clarify why this method is used in the study</p>\n<p>give background information on aim </p>\n<h3 id=\"What-are-the-main-findings-of-this-research-How-could-the-authors-further-investigate-them\"><a href=\"#What-are-the-main-findings-of-this-research-How-could-the-authors-further-investigate-them\" class=\"headerlink\" title=\"What are the main findings of this research? How could the authors further investigate them?\"></a>What are the main findings of this research? How could the authors further investigate them?</h3><p>state the main finding</p>\n<p>Discuss future research in the context of the current research</p>\n<h3 id=\"Are-the-authors’-conclusions-supported-by-the-data-Discuss-possible-confounding-variables\"><a href=\"#Are-the-authors’-conclusions-supported-by-the-data-Discuss-possible-confounding-variables\" class=\"headerlink\" title=\"Are the authors’ conclusions supported by the data? Discuss possible confounding variables.\"></a>Are the authors’ conclusions supported by the data? Discuss possible confounding variables.</h3><p>state if the data support the conclusion.</p>\n<p>fully consider all confounding variables</p>\n<h3 id=\"The-authors-report-there-was-no-significant-main-effect-of-stimulation-with-an-associated-p-value-of-p-0-97-What-would-the-conclusion-be-if-the-p-value-was-0-50\"><a href=\"#The-authors-report-there-was-no-significant-main-effect-of-stimulation-with-an-associated-p-value-of-p-0-97-What-would-the-conclusion-be-if-the-p-value-was-0-50\" class=\"headerlink\" title=\"The authors report there was no significant main effect of stimulation, with an associated p-value of p = 0.97. What would the conclusion be if the p-value was 0.50?\"></a>The authors report there was no significant main effect of stimulation, with an associated p-value of p = 0.97. What would the conclusion be if the <em>p</em>-value was 0.50?</h3><p>answer the question but provide context</p>\n<p>show off your additional knowledge of the subject</p>\n<p>Using your own words, describe the following:</p>\n<h2 id=\"Part-2\"><a href=\"#Part-2\" class=\"headerlink\" title=\"Part 2\"></a>Part 2</h2><h3 id=\"The-results-obtained-in-this-paper-Include-in-your-answer-a-brief-indication-of-the-methods-used\"><a href=\"#The-results-obtained-in-this-paper-Include-in-your-answer-a-brief-indication-of-the-methods-used\" class=\"headerlink\" title=\"The results obtained in this paper. Include in your answer a brief indication of the methods used\"></a>The results obtained in this paper. Include in your answer a brief indication of the methods used</h3><p>State the major findings. 30 marks.</p>\n<p>Give key details of the methods</p>\n<p>think more broadly -replication crisis in cognitive neuroscience is relevant here</p>\n<h3 id=\"The-significance-of-the-results-for-understanding-cognitive-neuroscience\"><a href=\"#The-significance-of-the-results-for-understanding-cognitive-neuroscience\" class=\"headerlink\" title=\"The significance of the results for understanding cognitive neuroscience\"></a>The significance of the results for understanding cognitive neuroscience</h3><hr>\n<h1 id=\"Neural-underpinnings-of-cognitive-ageing\"><a href=\"#Neural-underpinnings-of-cognitive-ageing\" class=\"headerlink\" title=\"Neural underpinnings of cognitive ageing\"></a>Neural underpinnings of cognitive ageing</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><p>What is cognitive ageing and when does cognitive decline begin?</p>\n<h2 id=\"Cognitive-decline\"><a href=\"#Cognitive-decline\" class=\"headerlink\" title=\"Cognitive decline\"></a>Cognitive decline</h2><p>individual- differences approaches to studying the neural basis of cognitive ageing</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261740132.png\" alt=\"cross-sectional and longitudinal ageing\"></p>\n<p><strong>Why do cross-sectional and longitudinal ageing studies give different results?</strong></p>\n<ol>\n<li>Cohort differences (the Flynn Effect)<br>• Problem for cross-sectional studies</li>\n<li>Nonrandom attrition<br>• Problem for longitudinal studies</li>\n<li>Practice effects<br>• Problem for longitudinal studies</li>\n</ol>\n<h2 id=\"Neural-underpinnings\"><a href=\"#Neural-underpinnings\" class=\"headerlink\" title=\"Neural underpinnings\"></a>Neural underpinnings</h2><p><strong>Average brain changes between 73 and 76</strong></p>\n<ul>\n<li>Grey matter volume: -.07 SDs/year</li>\n<li>Normal-appearing white matter volume: -.10 SDs/year</li>\n<li>White matter hyperintensity volume: +.11 SDs/year</li>\n<li>General fractional anisotropy: -.09 SDs/year</li>\n<li>General mean diffusivity: +.34 SDs/year</li>\n</ul>\n<h2 id=\"Coupled-brain-cognitive-changes-summary\"><a href=\"#Coupled-brain-cognitive-changes-summary\" class=\"headerlink\" title=\"Coupled brain/cognitive changes - summary\"></a>Coupled brain/cognitive changes - summary</h2><ul>\n<li>Volume declines across the lifespan</li>\n<li>Of volumetric results, best cognitive predictor/coupling is often white matter hyperintensities (pathology)</li>\n<li>White matter microstructure changes alongside fluid intelligence</li>\n<li>Some unexpected results (no coupled change between white matter and processing speed)<ul>\n<li>Larger studies required</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Next-steps\"><a href=\"#Next-steps\" class=\"headerlink\" title=\"Next steps\"></a>Next steps</h2><ul>\n<li><p>Increase power</p>\n<ul>\n<li>Larger, longer studies with additional waves?</li>\n</ul>\n</li>\n<li><p>Get specific</p>\n<ul>\n<li><p>Brain networks rather than broad measures?</p>\n</li>\n<li><p>Spatial interaction of hyperintensities and healthy white matter?</p>\n</li>\n</ul>\n</li>\n<li><p>Find predictors</p>\n<ul>\n<li>Early-life rather than old-age?</li>\n</ul>\n</li>\n<li><p>Add genetics</p>\n<ul>\n<li>Polygenic scores to predict brain or cognitive changes?</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Lecture Notes 07/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-07T12:00:00.000Z","password":null,"summary":null,"_content":"\n\n\n***\n\nthe angular momentum denoted as I and can be 1/2, 1, 3/2 ...\n\n\n\nThe frequency of precession (the frequency of our signals) is\ngoverned by the ‘Larmor’ formula\n\n𝜔 = 𝛾 𝐵\n\nwhere:\nω: is the Larmor frequency of precession\nγ: is gyromagnetic ratio\n(a constant for each nucleus)\nB: is the amplitude of the magnetic field\t\n\n\n\nQ: homogeneous magnetic field does not exist. How do we eliminate this detection error?\n\n![image-20220207113547829](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071135914.png)\n\nA: in a small zone. \n\n\n\nthe MRI data acquires information from the inverse domain of the object, organ, patient, etc. It is called ‘k-space’\n\n\n\n## Learning objectives (part I):\n\n### • Understand the phenomenon of Nuclear Magnetic Resonance (NMR) and how we detect NMR signals\n\nThe nucleus of a stuff as a whole has angular monument. Under a magnetic field, they behave as magnets, experience precession (A comparatively slow rotation of axis of rotation of a spinning body about a line intersecting the spin axis. The smooth, slow circling is precession, whereas the uneven wobbling is nutation. The frequency is given by ‘Larmor’ formula 𝜔 = 𝛾 𝐵).\n\nWe detect NMR signals with resonance. The spins will absorb the energy (radio-frequency waves) with an equal frequency to precession (Nuclear Magnetic Resonance). When we stop giving the energy, the nuclei will emit the energy. Thus we can detect. However, the direct detection is impossible because of the main external field. The trick is to rotate net nuclear magnetization with a small  perpendicular magnetic field (oscillating at 𝜔, i.e. on resonance). Then we turn it off when magnetization rotate by 90deg. During the rotating-back stage, a current will be induced in our induction coil enabling us to detect.  \n\n### • Understand what is a magnetic field gradient\n\n### • Understand how Magnetic Field Gradients can be used to make Magnetic Resonance signals dependent on position\n\n### • Understand how this process is used to generate images\n\n***\n\n\n\n***\n\nfMRI and structural images are often 16-bit\n\n| 8 bit  | char  |\n| ------ | ----- |\n| 16 bit | short |\n| 32 bit | float |\n\nNifTI is the standard format for MR image (,nii)\n\n### There are three applications of image registration\n\n1. **Head-motion correction** (aka realignment): keep all images the same shape and size, we only want to move it (translations) or rotate it (rotations)- This is termed “**Rigid Body Registration**”\n\n2. For distinct participants, **Co-registration** is necessary,\n\n![image-20220207155747063](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071557403.png)\n\n3. Another approach is **normalization**.\n   1. Affine transformations\n   2. Non-linear wraps\n\n\n\n","source":"_posts/07_02_22.md","raw":"---\ntitle: Lecture Notes 07/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-07 12:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n\n\n***\n\nthe angular momentum denoted as I and can be 1/2, 1, 3/2 ...\n\n\n\nThe frequency of precession (the frequency of our signals) is\ngoverned by the ‘Larmor’ formula\n\n𝜔 = 𝛾 𝐵\n\nwhere:\nω: is the Larmor frequency of precession\nγ: is gyromagnetic ratio\n(a constant for each nucleus)\nB: is the amplitude of the magnetic field\t\n\n\n\nQ: homogeneous magnetic field does not exist. How do we eliminate this detection error?\n\n![image-20220207113547829](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071135914.png)\n\nA: in a small zone. \n\n\n\nthe MRI data acquires information from the inverse domain of the object, organ, patient, etc. It is called ‘k-space’\n\n\n\n## Learning objectives (part I):\n\n### • Understand the phenomenon of Nuclear Magnetic Resonance (NMR) and how we detect NMR signals\n\nThe nucleus of a stuff as a whole has angular monument. Under a magnetic field, they behave as magnets, experience precession (A comparatively slow rotation of axis of rotation of a spinning body about a line intersecting the spin axis. The smooth, slow circling is precession, whereas the uneven wobbling is nutation. The frequency is given by ‘Larmor’ formula 𝜔 = 𝛾 𝐵).\n\nWe detect NMR signals with resonance. The spins will absorb the energy (radio-frequency waves) with an equal frequency to precession (Nuclear Magnetic Resonance). When we stop giving the energy, the nuclei will emit the energy. Thus we can detect. However, the direct detection is impossible because of the main external field. The trick is to rotate net nuclear magnetization with a small  perpendicular magnetic field (oscillating at 𝜔, i.e. on resonance). Then we turn it off when magnetization rotate by 90deg. During the rotating-back stage, a current will be induced in our induction coil enabling us to detect.  \n\n### • Understand what is a magnetic field gradient\n\n### • Understand how Magnetic Field Gradients can be used to make Magnetic Resonance signals dependent on position\n\n### • Understand how this process is used to generate images\n\n***\n\n\n\n***\n\nfMRI and structural images are often 16-bit\n\n| 8 bit  | char  |\n| ------ | ----- |\n| 16 bit | short |\n| 32 bit | float |\n\nNifTI is the standard format for MR image (,nii)\n\n### There are three applications of image registration\n\n1. **Head-motion correction** (aka realignment): keep all images the same shape and size, we only want to move it (translations) or rotate it (rotations)- This is termed “**Rigid Body Registration**”\n\n2. For distinct participants, **Co-registration** is necessary,\n\n![image-20220207155747063](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071557403.png)\n\n3. Another approach is **normalization**.\n   1. Affine transformations\n   2. Non-linear wraps\n\n\n\n","slug":"07_02_22","published":1,"updated":"2022-08-24T17:08:39.290Z","comments":1,"layout":"post","photos":[],"_id":"cuidqeYB5bdsfvTR2qBJXoPE_","content":"<hr>\n<p>the angular momentum denoted as I and can be 1/2, 1, 3/2 …</p>\n<p>The frequency of precession (the frequency of our signals) is<br>governed by the ‘Larmor’ formula</p>\n<p>𝜔 = 𝛾 𝐵</p>\n<p>where:<br>ω: is the Larmor frequency of precession<br>γ: is gyromagnetic ratio<br>(a constant for each nucleus)<br>B: is the amplitude of the magnetic field    </p>\n<p>Q: homogeneous magnetic field does not exist. How do we eliminate this detection error?</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071135914.png\" alt=\"image-20220207113547829\"></p>\n<p>A: in a small zone. </p>\n<p>the MRI data acquires information from the inverse domain of the object, organ, patient, etc. It is called ‘k-space’</p>\n<h2 id=\"Learning-objectives-part-I\"><a href=\"#Learning-objectives-part-I\" class=\"headerlink\" title=\"Learning objectives (part I):\"></a>Learning objectives (part I):</h2><h3 id=\"•-Understand-the-phenomenon-of-Nuclear-Magnetic-Resonance-NMR-and-how-we-detect-NMR-signals\"><a href=\"#•-Understand-the-phenomenon-of-Nuclear-Magnetic-Resonance-NMR-and-how-we-detect-NMR-signals\" class=\"headerlink\" title=\"• Understand the phenomenon of Nuclear Magnetic Resonance (NMR) and how we detect NMR signals\"></a>• Understand the phenomenon of Nuclear Magnetic Resonance (NMR) and how we detect NMR signals</h3><p>The nucleus of a stuff as a whole has angular monument. Under a magnetic field, they behave as magnets, experience precession (A comparatively slow rotation of axis of rotation of a spinning body about a line intersecting the spin axis. The smooth, slow circling is precession, whereas the uneven wobbling is nutation. The frequency is given by ‘Larmor’ formula 𝜔 = 𝛾 𝐵).</p>\n<p>We detect NMR signals with resonance. The spins will absorb the energy (radio-frequency waves) with an equal frequency to precession (Nuclear Magnetic Resonance). When we stop giving the energy, the nuclei will emit the energy. Thus we can detect. However, the direct detection is impossible because of the main external field. The trick is to rotate net nuclear magnetization with a small  perpendicular magnetic field (oscillating at 𝜔, i.e. on resonance). Then we turn it off when magnetization rotate by 90deg. During the rotating-back stage, a current will be induced in our induction coil enabling us to detect.  </p>\n<h3 id=\"•-Understand-what-is-a-magnetic-field-gradient\"><a href=\"#•-Understand-what-is-a-magnetic-field-gradient\" class=\"headerlink\" title=\"• Understand what is a magnetic field gradient\"></a>• Understand what is a magnetic field gradient</h3><h3 id=\"•-Understand-how-Magnetic-Field-Gradients-can-be-used-to-make-Magnetic-Resonance-signals-dependent-on-position\"><a href=\"#•-Understand-how-Magnetic-Field-Gradients-can-be-used-to-make-Magnetic-Resonance-signals-dependent-on-position\" class=\"headerlink\" title=\"• Understand how Magnetic Field Gradients can be used to make Magnetic Resonance signals dependent on position\"></a>• Understand how Magnetic Field Gradients can be used to make Magnetic Resonance signals dependent on position</h3><h3 id=\"•-Understand-how-this-process-is-used-to-generate-images\"><a href=\"#•-Understand-how-this-process-is-used-to-generate-images\" class=\"headerlink\" title=\"• Understand how this process is used to generate images\"></a>• Understand how this process is used to generate images</h3><hr>\n<hr>\n<p>fMRI and structural images are often 16-bit</p>\n<table>\n<thead>\n<tr>\n<th>8 bit</th>\n<th>char</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>16 bit</td>\n<td>short</td>\n</tr>\n<tr>\n<td>32 bit</td>\n<td>float</td>\n</tr>\n</tbody></table>\n<p>NifTI is the standard format for MR image (,nii)</p>\n<h3 id=\"There-are-three-applications-of-image-registration\"><a href=\"#There-are-three-applications-of-image-registration\" class=\"headerlink\" title=\"There are three applications of image registration\"></a>There are three applications of image registration</h3><ol>\n<li><p><strong>Head-motion correction</strong> (aka realignment): keep all images the same shape and size, we only want to move it (translations) or rotate it (rotations)- This is termed “<strong>Rigid Body Registration</strong>”</p>\n</li>\n<li><p>For distinct participants, <strong>Co-registration</strong> is necessary,</p>\n</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071557403.png\" alt=\"image-20220207155747063\"></p>\n<ol start=\"3\">\n<li>Another approach is <strong>normalization</strong>.<ol>\n<li>Affine transformations</li>\n<li>Non-linear wraps</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<hr>\n<p>the angular momentum denoted as I and can be 1/2, 1, 3/2 …</p>\n<p>The frequency of precession (the frequency of our signals) is<br>governed by the ‘Larmor’ formula</p>\n<p>𝜔 = 𝛾 𝐵</p>\n<p>where:<br>ω: is the Larmor frequency of precession<br>γ: is gyromagnetic ratio<br>(a constant for each nucleus)<br>B: is the amplitude of the magnetic field    </p>\n<p>Q: homogeneous magnetic field does not exist. How do we eliminate this detection error?</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071135914.png\" alt=\"image-20220207113547829\"></p>\n<p>A: in a small zone. </p>\n<p>the MRI data acquires information from the inverse domain of the object, organ, patient, etc. It is called ‘k-space’</p>\n<h2 id=\"Learning-objectives-part-I\"><a href=\"#Learning-objectives-part-I\" class=\"headerlink\" title=\"Learning objectives (part I):\"></a>Learning objectives (part I):</h2><h3 id=\"•-Understand-the-phenomenon-of-Nuclear-Magnetic-Resonance-NMR-and-how-we-detect-NMR-signals\"><a href=\"#•-Understand-the-phenomenon-of-Nuclear-Magnetic-Resonance-NMR-and-how-we-detect-NMR-signals\" class=\"headerlink\" title=\"• Understand the phenomenon of Nuclear Magnetic Resonance (NMR) and how we detect NMR signals\"></a>• Understand the phenomenon of Nuclear Magnetic Resonance (NMR) and how we detect NMR signals</h3><p>The nucleus of a stuff as a whole has angular monument. Under a magnetic field, they behave as magnets, experience precession (A comparatively slow rotation of axis of rotation of a spinning body about a line intersecting the spin axis. The smooth, slow circling is precession, whereas the uneven wobbling is nutation. The frequency is given by ‘Larmor’ formula 𝜔 = 𝛾 𝐵).</p>\n<p>We detect NMR signals with resonance. The spins will absorb the energy (radio-frequency waves) with an equal frequency to precession (Nuclear Magnetic Resonance). When we stop giving the energy, the nuclei will emit the energy. Thus we can detect. However, the direct detection is impossible because of the main external field. The trick is to rotate net nuclear magnetization with a small  perpendicular magnetic field (oscillating at 𝜔, i.e. on resonance). Then we turn it off when magnetization rotate by 90deg. During the rotating-back stage, a current will be induced in our induction coil enabling us to detect.  </p>\n<h3 id=\"•-Understand-what-is-a-magnetic-field-gradient\"><a href=\"#•-Understand-what-is-a-magnetic-field-gradient\" class=\"headerlink\" title=\"• Understand what is a magnetic field gradient\"></a>• Understand what is a magnetic field gradient</h3><h3 id=\"•-Understand-how-Magnetic-Field-Gradients-can-be-used-to-make-Magnetic-Resonance-signals-dependent-on-position\"><a href=\"#•-Understand-how-Magnetic-Field-Gradients-can-be-used-to-make-Magnetic-Resonance-signals-dependent-on-position\" class=\"headerlink\" title=\"• Understand how Magnetic Field Gradients can be used to make Magnetic Resonance signals dependent on position\"></a>• Understand how Magnetic Field Gradients can be used to make Magnetic Resonance signals dependent on position</h3><h3 id=\"•-Understand-how-this-process-is-used-to-generate-images\"><a href=\"#•-Understand-how-this-process-is-used-to-generate-images\" class=\"headerlink\" title=\"• Understand how this process is used to generate images\"></a>• Understand how this process is used to generate images</h3><hr>\n<hr>\n<p>fMRI and structural images are often 16-bit</p>\n<table>\n<thead>\n<tr>\n<th>8 bit</th>\n<th>char</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>16 bit</td>\n<td>short</td>\n</tr>\n<tr>\n<td>32 bit</td>\n<td>float</td>\n</tr>\n</tbody></table>\n<p>NifTI is the standard format for MR image (,nii)</p>\n<h3 id=\"There-are-three-applications-of-image-registration\"><a href=\"#There-are-three-applications-of-image-registration\" class=\"headerlink\" title=\"There are three applications of image registration\"></a>There are three applications of image registration</h3><ol>\n<li><p><strong>Head-motion correction</strong> (aka realignment): keep all images the same shape and size, we only want to move it (translations) or rotate it (rotations)- This is termed “<strong>Rigid Body Registration</strong>”</p>\n</li>\n<li><p>For distinct participants, <strong>Co-registration</strong> is necessary,</p>\n</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202071557403.png\" alt=\"image-20220207155747063\"></p>\n<ol start=\"3\">\n<li>Another approach is <strong>normalization</strong>.<ol>\n<li>Affine transformations</li>\n<li>Non-linear wraps</li>\n</ol>\n</li>\n</ol>\n"},{"title":"Lecture Notes 07/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-07T12:30:00.000Z","password":null,"summary":null,"_content":"\n# Mocap\n\n## Objective\n\n1. Name the key principle that has remained unchanged in the history of motion capture\n\n2. Explain key terminology relating to motion capture\n\n3. Identify the types of motion capture systems available and outline advantages and disadvantages\n\n4. Describe some applications of motion capture, in particular in Psychology\n\n5. Using an inertial system, describe the process of data collection and data processing\n\n\nHow can we describe movement?\n\nWe can use: lively vs agitated\n\nbut not precise and reliable\n\nDefinition of motion capture: Recording the motion as 3d data for analysis, playback and remapping\n\n![Mocap process](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071255552.png)\n\nusually interchangeably \n\n## A few keywords\n\nrigid object\n\nDegree of freedom (DOF): numbers of dimensions that are tracked: position & orientation = 3 directions +3 orientations =6 DOF\n\nKinematic model\n\nSample rate: how often (per second are data collected). Note that any analyses of movement from a recording/video (e.g. markerless MoCap) is constrained to the framerate of the video.\n\n![movement model](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071313781.png)\n\n\n\nA co-lab link https://tinyurl.com/5h2yb6n2\n\n---\n\n# Neuroimaging of ASD II (COGNITIVE NEUROSCIENCE OF AUTISM SPECTRUM DISORDERS)\n\n## Objectives\n\n1. Classify the main diagnostic criteria of autism spectrum disorders (ASD)\n2. Describe different factors of heterogeneity in ASD\n3. Explain and summarise current as well as future strategies to overcome the problem of individual variability in ASD using cognitive neuroscientific approaches\n\n## Autism spectrum disorders (ASD)\n\nPrevalence: 1% of more than 5.5 million in EU; Gender ratio: 4:1 male to female.\n\nDiagnosis: Neurodevelopment diagnosis.\n\n\n\nIndividual variability among clinical and cognitive symptoms\n\nNeuroimaging findings across the lifespan\n\n![Diagnostic and statistical manual of mental disorders](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261816229.png)\n\n![image-20220326181947701](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261819751.png)\n\nExcitotoxicity in brains of individuals with ASD due to an excess of Glutamate\n\nGlutamate and/or Gamma aminobutyric acid (GABA) markers could become a biomarker for ASD\n\n![biomarker for ASD](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071600591.png)\n\nLONGITUDINAL EUROPEAN AUTISM PROJECT (LEAP)\n\nAIMS-2-TRIALS AND LEAP\n\n![AIMS-2-TRIALS AND LEAP](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071606554.png)\n\n## Summary\n\n**ASD**\n\n- Relatively common and dimensional condition\n- Lifelong condition\n- Underdiagnosed in females\n- Typically accompanied by co-occurring mental health conditions\n- Multi-factorial risk factors and causes\n- Neurodevelopmental disorder\n\n**Clinical and research approaches have changed accordingly**\n\n- Greater awareness of heterogeneity\n- Increasing emphasis on large sample size\n- Use of autism trait measures with subclinical groups\n\n**Neuroimaging research**\n\n- Revealed brain phenotypes associated with ASD across the lifespan\n- Evidence for brain overgrowth, alterations in brain volume, structural and functional patterns\n\n**Future research**\n\n- Lack of understanding of the underlying neurobiological mechanisms -No evidence in treatment yet\n- Use of new technology to include individuals with ASD with intellectual and/or language impairments\n- Address the historical imbalance in participant gender\n- Study ASD in low and middle income countries\n- Balance big data with deep phenotyping as well as prediction tools for predicting diagnostic and dimensional outcomes\n\n# Vocabulary\n\n**PDD:** pervasive developmental disorder\n\n**RRBIs:** Restricted and repetitive behavioural interests\n","source":"_posts/07_03_22.md","raw":"---\ntitle: Lecture Notes 07/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-07 12:30\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n# Mocap\n\n## Objective\n\n1. Name the key principle that has remained unchanged in the history of motion capture\n\n2. Explain key terminology relating to motion capture\n\n3. Identify the types of motion capture systems available and outline advantages and disadvantages\n\n4. Describe some applications of motion capture, in particular in Psychology\n\n5. Using an inertial system, describe the process of data collection and data processing\n\n\nHow can we describe movement?\n\nWe can use: lively vs agitated\n\nbut not precise and reliable\n\nDefinition of motion capture: Recording the motion as 3d data for analysis, playback and remapping\n\n![Mocap process](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071255552.png)\n\nusually interchangeably \n\n## A few keywords\n\nrigid object\n\nDegree of freedom (DOF): numbers of dimensions that are tracked: position & orientation = 3 directions +3 orientations =6 DOF\n\nKinematic model\n\nSample rate: how often (per second are data collected). Note that any analyses of movement from a recording/video (e.g. markerless MoCap) is constrained to the framerate of the video.\n\n![movement model](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071313781.png)\n\n\n\nA co-lab link https://tinyurl.com/5h2yb6n2\n\n---\n\n# Neuroimaging of ASD II (COGNITIVE NEUROSCIENCE OF AUTISM SPECTRUM DISORDERS)\n\n## Objectives\n\n1. Classify the main diagnostic criteria of autism spectrum disorders (ASD)\n2. Describe different factors of heterogeneity in ASD\n3. Explain and summarise current as well as future strategies to overcome the problem of individual variability in ASD using cognitive neuroscientific approaches\n\n## Autism spectrum disorders (ASD)\n\nPrevalence: 1% of more than 5.5 million in EU; Gender ratio: 4:1 male to female.\n\nDiagnosis: Neurodevelopment diagnosis.\n\n\n\nIndividual variability among clinical and cognitive symptoms\n\nNeuroimaging findings across the lifespan\n\n![Diagnostic and statistical manual of mental disorders](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261816229.png)\n\n![image-20220326181947701](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261819751.png)\n\nExcitotoxicity in brains of individuals with ASD due to an excess of Glutamate\n\nGlutamate and/or Gamma aminobutyric acid (GABA) markers could become a biomarker for ASD\n\n![biomarker for ASD](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071600591.png)\n\nLONGITUDINAL EUROPEAN AUTISM PROJECT (LEAP)\n\nAIMS-2-TRIALS AND LEAP\n\n![AIMS-2-TRIALS AND LEAP](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071606554.png)\n\n## Summary\n\n**ASD**\n\n- Relatively common and dimensional condition\n- Lifelong condition\n- Underdiagnosed in females\n- Typically accompanied by co-occurring mental health conditions\n- Multi-factorial risk factors and causes\n- Neurodevelopmental disorder\n\n**Clinical and research approaches have changed accordingly**\n\n- Greater awareness of heterogeneity\n- Increasing emphasis on large sample size\n- Use of autism trait measures with subclinical groups\n\n**Neuroimaging research**\n\n- Revealed brain phenotypes associated with ASD across the lifespan\n- Evidence for brain overgrowth, alterations in brain volume, structural and functional patterns\n\n**Future research**\n\n- Lack of understanding of the underlying neurobiological mechanisms -No evidence in treatment yet\n- Use of new technology to include individuals with ASD with intellectual and/or language impairments\n- Address the historical imbalance in participant gender\n- Study ASD in low and middle income countries\n- Balance big data with deep phenotyping as well as prediction tools for predicting diagnostic and dimensional outcomes\n\n# Vocabulary\n\n**PDD:** pervasive developmental disorder\n\n**RRBIs:** Restricted and repetitive behavioural interests\n","slug":"07_03_22","published":1,"updated":"2022-08-24T17:08:39.296Z","comments":1,"layout":"post","photos":[],"_id":"cuidpYPNBSBD6hB-cvuTJocRY","content":"<h1 id=\"Mocap\"><a href=\"#Mocap\" class=\"headerlink\" title=\"Mocap\"></a>Mocap</h1><h2 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective\"></a>Objective</h2><ol>\n<li><p>Name the key principle that has remained unchanged in the history of motion capture</p>\n</li>\n<li><p>Explain key terminology relating to motion capture</p>\n</li>\n<li><p>Identify the types of motion capture systems available and outline advantages and disadvantages</p>\n</li>\n<li><p>Describe some applications of motion capture, in particular in Psychology</p>\n</li>\n<li><p>Using an inertial system, describe the process of data collection and data processing</p>\n</li>\n</ol>\n<p>How can we describe movement?</p>\n<p>We can use: lively vs agitated</p>\n<p>but not precise and reliable</p>\n<p>Definition of motion capture: Recording the motion as 3d data for analysis, playback and remapping</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071255552.png\" alt=\"Mocap process\"></p>\n<p>usually interchangeably </p>\n<h2 id=\"A-few-keywords\"><a href=\"#A-few-keywords\" class=\"headerlink\" title=\"A few keywords\"></a>A few keywords</h2><p>rigid object</p>\n<p>Degree of freedom (DOF): numbers of dimensions that are tracked: position &amp; orientation = 3 directions +3 orientations =6 DOF</p>\n<p>Kinematic model</p>\n<p>Sample rate: how often (per second are data collected). Note that any analyses of movement from a recording/video (e.g. markerless MoCap) is constrained to the framerate of the video.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071313781.png\" alt=\"movement model\"></p>\n<p>A co-lab link <a href=\"https://tinyurl.com/5h2yb6n2\">https://tinyurl.com/5h2yb6n2</a></p>\n<hr>\n<h1 id=\"Neuroimaging-of-ASD-II-COGNITIVE-NEUROSCIENCE-OF-AUTISM-SPECTRUM-DISORDERS\"><a href=\"#Neuroimaging-of-ASD-II-COGNITIVE-NEUROSCIENCE-OF-AUTISM-SPECTRUM-DISORDERS\" class=\"headerlink\" title=\"Neuroimaging of ASD II (COGNITIVE NEUROSCIENCE OF AUTISM SPECTRUM DISORDERS)\"></a>Neuroimaging of ASD II (COGNITIVE NEUROSCIENCE OF AUTISM SPECTRUM DISORDERS)</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>Classify the main diagnostic criteria of autism spectrum disorders (ASD)</li>\n<li>Describe different factors of heterogeneity in ASD</li>\n<li>Explain and summarise current as well as future strategies to overcome the problem of individual variability in ASD using cognitive neuroscientific approaches</li>\n</ol>\n<h2 id=\"Autism-spectrum-disorders-ASD\"><a href=\"#Autism-spectrum-disorders-ASD\" class=\"headerlink\" title=\"Autism spectrum disorders (ASD)\"></a>Autism spectrum disorders (ASD)</h2><p>Prevalence: 1% of more than 5.5 million in EU; Gender ratio: 4:1 male to female.</p>\n<p>Diagnosis: Neurodevelopment diagnosis.</p>\n<p>Individual variability among clinical and cognitive symptoms</p>\n<p>Neuroimaging findings across the lifespan</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261816229.png\" alt=\"Diagnostic and statistical manual of mental disorders\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261819751.png\" alt=\"image-20220326181947701\"></p>\n<p>Excitotoxicity in brains of individuals with ASD due to an excess of Glutamate</p>\n<p>Glutamate and/or Gamma aminobutyric acid (GABA) markers could become a biomarker for ASD</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071600591.png\" alt=\"biomarker for ASD\"></p>\n<p>LONGITUDINAL EUROPEAN AUTISM PROJECT (LEAP)</p>\n<p>AIMS-2-TRIALS AND LEAP</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071606554.png\" alt=\"AIMS-2-TRIALS AND LEAP\"></p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p><strong>ASD</strong></p>\n<ul>\n<li>Relatively common and dimensional condition</li>\n<li>Lifelong condition</li>\n<li>Underdiagnosed in females</li>\n<li>Typically accompanied by co-occurring mental health conditions</li>\n<li>Multi-factorial risk factors and causes</li>\n<li>Neurodevelopmental disorder</li>\n</ul>\n<p><strong>Clinical and research approaches have changed accordingly</strong></p>\n<ul>\n<li>Greater awareness of heterogeneity</li>\n<li>Increasing emphasis on large sample size</li>\n<li>Use of autism trait measures with subclinical groups</li>\n</ul>\n<p><strong>Neuroimaging research</strong></p>\n<ul>\n<li>Revealed brain phenotypes associated with ASD across the lifespan</li>\n<li>Evidence for brain overgrowth, alterations in brain volume, structural and functional patterns</li>\n</ul>\n<p><strong>Future research</strong></p>\n<ul>\n<li>Lack of understanding of the underlying neurobiological mechanisms -No evidence in treatment yet</li>\n<li>Use of new technology to include individuals with ASD with intellectual and/or language impairments</li>\n<li>Address the historical imbalance in participant gender</li>\n<li>Study ASD in low and middle income countries</li>\n<li>Balance big data with deep phenotyping as well as prediction tools for predicting diagnostic and dimensional outcomes</li>\n</ul>\n<h1 id=\"Vocabulary\"><a href=\"#Vocabulary\" class=\"headerlink\" title=\"Vocabulary\"></a>Vocabulary</h1><p><strong>PDD:</strong> pervasive developmental disorder</p>\n<p><strong>RRBIs:</strong> Restricted and repetitive behavioural interests</p>\n","excerpt":"","more":"<h1 id=\"Mocap\"><a href=\"#Mocap\" class=\"headerlink\" title=\"Mocap\"></a>Mocap</h1><h2 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective\"></a>Objective</h2><ol>\n<li><p>Name the key principle that has remained unchanged in the history of motion capture</p>\n</li>\n<li><p>Explain key terminology relating to motion capture</p>\n</li>\n<li><p>Identify the types of motion capture systems available and outline advantages and disadvantages</p>\n</li>\n<li><p>Describe some applications of motion capture, in particular in Psychology</p>\n</li>\n<li><p>Using an inertial system, describe the process of data collection and data processing</p>\n</li>\n</ol>\n<p>How can we describe movement?</p>\n<p>We can use: lively vs agitated</p>\n<p>but not precise and reliable</p>\n<p>Definition of motion capture: Recording the motion as 3d data for analysis, playback and remapping</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071255552.png\" alt=\"Mocap process\"></p>\n<p>usually interchangeably </p>\n<h2 id=\"A-few-keywords\"><a href=\"#A-few-keywords\" class=\"headerlink\" title=\"A few keywords\"></a>A few keywords</h2><p>rigid object</p>\n<p>Degree of freedom (DOF): numbers of dimensions that are tracked: position &amp; orientation = 3 directions +3 orientations =6 DOF</p>\n<p>Kinematic model</p>\n<p>Sample rate: how often (per second are data collected). Note that any analyses of movement from a recording/video (e.g. markerless MoCap) is constrained to the framerate of the video.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071313781.png\" alt=\"movement model\"></p>\n<p>A co-lab link <a href=\"https://tinyurl.com/5h2yb6n2\">https://tinyurl.com/5h2yb6n2</a></p>\n<hr>\n<h1 id=\"Neuroimaging-of-ASD-II-COGNITIVE-NEUROSCIENCE-OF-AUTISM-SPECTRUM-DISORDERS\"><a href=\"#Neuroimaging-of-ASD-II-COGNITIVE-NEUROSCIENCE-OF-AUTISM-SPECTRUM-DISORDERS\" class=\"headerlink\" title=\"Neuroimaging of ASD II (COGNITIVE NEUROSCIENCE OF AUTISM SPECTRUM DISORDERS)\"></a>Neuroimaging of ASD II (COGNITIVE NEUROSCIENCE OF AUTISM SPECTRUM DISORDERS)</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>Classify the main diagnostic criteria of autism spectrum disorders (ASD)</li>\n<li>Describe different factors of heterogeneity in ASD</li>\n<li>Explain and summarise current as well as future strategies to overcome the problem of individual variability in ASD using cognitive neuroscientific approaches</li>\n</ol>\n<h2 id=\"Autism-spectrum-disorders-ASD\"><a href=\"#Autism-spectrum-disorders-ASD\" class=\"headerlink\" title=\"Autism spectrum disorders (ASD)\"></a>Autism spectrum disorders (ASD)</h2><p>Prevalence: 1% of more than 5.5 million in EU; Gender ratio: 4:1 male to female.</p>\n<p>Diagnosis: Neurodevelopment diagnosis.</p>\n<p>Individual variability among clinical and cognitive symptoms</p>\n<p>Neuroimaging findings across the lifespan</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261816229.png\" alt=\"Diagnostic and statistical manual of mental disorders\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261819751.png\" alt=\"image-20220326181947701\"></p>\n<p>Excitotoxicity in brains of individuals with ASD due to an excess of Glutamate</p>\n<p>Glutamate and/or Gamma aminobutyric acid (GABA) markers could become a biomarker for ASD</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071600591.png\" alt=\"biomarker for ASD\"></p>\n<p>LONGITUDINAL EUROPEAN AUTISM PROJECT (LEAP)</p>\n<p>AIMS-2-TRIALS AND LEAP</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203071606554.png\" alt=\"AIMS-2-TRIALS AND LEAP\"></p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p><strong>ASD</strong></p>\n<ul>\n<li>Relatively common and dimensional condition</li>\n<li>Lifelong condition</li>\n<li>Underdiagnosed in females</li>\n<li>Typically accompanied by co-occurring mental health conditions</li>\n<li>Multi-factorial risk factors and causes</li>\n<li>Neurodevelopmental disorder</li>\n</ul>\n<p><strong>Clinical and research approaches have changed accordingly</strong></p>\n<ul>\n<li>Greater awareness of heterogeneity</li>\n<li>Increasing emphasis on large sample size</li>\n<li>Use of autism trait measures with subclinical groups</li>\n</ul>\n<p><strong>Neuroimaging research</strong></p>\n<ul>\n<li>Revealed brain phenotypes associated with ASD across the lifespan</li>\n<li>Evidence for brain overgrowth, alterations in brain volume, structural and functional patterns</li>\n</ul>\n<p><strong>Future research</strong></p>\n<ul>\n<li>Lack of understanding of the underlying neurobiological mechanisms -No evidence in treatment yet</li>\n<li>Use of new technology to include individuals with ASD with intellectual and/or language impairments</li>\n<li>Address the historical imbalance in participant gender</li>\n<li>Study ASD in low and middle income countries</li>\n<li>Balance big data with deep phenotyping as well as prediction tools for predicting diagnostic and dimensional outcomes</li>\n</ul>\n<h1 id=\"Vocabulary\"><a href=\"#Vocabulary\" class=\"headerlink\" title=\"Vocabulary\"></a>Vocabulary</h1><p><strong>PDD:</strong> pervasive developmental disorder</p>\n<p><strong>RRBIs:</strong> Restricted and repetitive behavioural interests</p>\n"},{"title":"Lecture Notes 10/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-10T20:00:00.000Z","password":null,"summary":null,"_content":"\n### Experimental design\n\n1. #### categorical design\n\n   distinct types of stimuli or the timing, participant instructions\n\n2. #### factorial design\n\n   usually 2 pairs of controlled factors\n\n3. #### parametric design\n\n   modify the control variables\n\n   \n### Timing of stimuli\n\n1. #### block design\n\n   Block some variables\n\n   ##### pros\n\n   most commonly used\n\n   statistically the most powerful\n\n   ##### cons\n\n   can be **predicable**, lead to rapid habituation or anticipation (reduced response)\n\n   **cannot** **extract** specific stimulus brain response\n\n   some design **cannot** be modelled as a **block**\n\n   can be affected by cumulative effects (context)\n\n2. #### event-related design\n\n   Each stimulus is individual epoch (can be associated with discrete events)\n\n   ##### pros\n\n   parallel behavioural studies\n\n   greater flexibility (more complex)\n\n   ##### cons\n\n   related designs require a greater understanding of fMRI because the design (more complex)\n\n   less statistical power (can be reduced to extend the scanning time)\n\n3. mixed design\n\n   mix the two above design together\n\n\n\n***\n\n   Structural MRI: Focus on analysis with Voxel Based Morphometry (**VBM**)\n\n   ![image-20220210111218622](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101112736.png)\n\n![image-20220210111635460](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101116502.png)\n\n### Spatial Normalization\n\ntransform a brain image into a standard brain coordinate system \n\n**SPM** (Statistical Parametric Mapping) spatial normalisation\n\n### Segmentation\n\nWe do not use intensity threshold to segment for the following reasons:\n\nUser intervention to decide what lever to threshold\n\nBias field correction (an MRI artefact which causes slow changes in image intensity across the brain)\n\nImage noise (random regions of white matter have low levels of intensity which may be classified as grey matter)\n\nModulation can increase the contrast ratio (an analogy: just like the reverse of using a rolling pin on pastry)\n\n![image-20220210114715754](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147787.png)\n\nNormalised:\n\n![image-20220210114705364](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147398.png)\n\nModulated:\n\n![image-20220210114635501](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101146535.png)\n\n(form left to right: Grey, White and CSF (Cerebrospinal fluid))\n\n### Smoothing\n\nTake into account variations in structural anatomy\n\nTo reduce noise\n\nTo increase the normality of the data\n\nSmoothing amount is measured as FWHM (A common smoothing kernel for VBM is 8-12mm)\n\n","source":"_posts/10_02_22.md","raw":"---\ntitle: Lecture Notes 10/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-10 20:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n### Experimental design\n\n1. #### categorical design\n\n   distinct types of stimuli or the timing, participant instructions\n\n2. #### factorial design\n\n   usually 2 pairs of controlled factors\n\n3. #### parametric design\n\n   modify the control variables\n\n   \n### Timing of stimuli\n\n1. #### block design\n\n   Block some variables\n\n   ##### pros\n\n   most commonly used\n\n   statistically the most powerful\n\n   ##### cons\n\n   can be **predicable**, lead to rapid habituation or anticipation (reduced response)\n\n   **cannot** **extract** specific stimulus brain response\n\n   some design **cannot** be modelled as a **block**\n\n   can be affected by cumulative effects (context)\n\n2. #### event-related design\n\n   Each stimulus is individual epoch (can be associated with discrete events)\n\n   ##### pros\n\n   parallel behavioural studies\n\n   greater flexibility (more complex)\n\n   ##### cons\n\n   related designs require a greater understanding of fMRI because the design (more complex)\n\n   less statistical power (can be reduced to extend the scanning time)\n\n3. mixed design\n\n   mix the two above design together\n\n\n\n***\n\n   Structural MRI: Focus on analysis with Voxel Based Morphometry (**VBM**)\n\n   ![image-20220210111218622](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101112736.png)\n\n![image-20220210111635460](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101116502.png)\n\n### Spatial Normalization\n\ntransform a brain image into a standard brain coordinate system \n\n**SPM** (Statistical Parametric Mapping) spatial normalisation\n\n### Segmentation\n\nWe do not use intensity threshold to segment for the following reasons:\n\nUser intervention to decide what lever to threshold\n\nBias field correction (an MRI artefact which causes slow changes in image intensity across the brain)\n\nImage noise (random regions of white matter have low levels of intensity which may be classified as grey matter)\n\nModulation can increase the contrast ratio (an analogy: just like the reverse of using a rolling pin on pastry)\n\n![image-20220210114715754](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147787.png)\n\nNormalised:\n\n![image-20220210114705364](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147398.png)\n\nModulated:\n\n![image-20220210114635501](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101146535.png)\n\n(form left to right: Grey, White and CSF (Cerebrospinal fluid))\n\n### Smoothing\n\nTake into account variations in structural anatomy\n\nTo reduce noise\n\nTo increase the normality of the data\n\nSmoothing amount is measured as FWHM (A common smoothing kernel for VBM is 8-12mm)\n\n","slug":"10_02_22","published":1,"updated":"2022-08-24T17:08:39.303Z","comments":1,"layout":"post","photos":[],"_id":"cuidYc8Hw8WXB62O-lyFdi_YJ","content":"<h3 id=\"Experimental-design\"><a href=\"#Experimental-design\" class=\"headerlink\" title=\"Experimental design\"></a>Experimental design</h3><ol>\n<li><h4 id=\"categorical-design\"><a href=\"#categorical-design\" class=\"headerlink\" title=\"categorical design\"></a>categorical design</h4><p>distinct types of stimuli or the timing, participant instructions</p>\n</li>\n<li><h4 id=\"factorial-design\"><a href=\"#factorial-design\" class=\"headerlink\" title=\"factorial design\"></a>factorial design</h4><p>usually 2 pairs of controlled factors</p>\n</li>\n<li><h4 id=\"parametric-design\"><a href=\"#parametric-design\" class=\"headerlink\" title=\"parametric design\"></a>parametric design</h4><p>modify the control variables</p>\n</li>\n</ol>\n<h3 id=\"Timing-of-stimuli\"><a href=\"#Timing-of-stimuli\" class=\"headerlink\" title=\"Timing of stimuli\"></a>Timing of stimuli</h3><ol>\n<li><h4 id=\"block-design\"><a href=\"#block-design\" class=\"headerlink\" title=\"block design\"></a>block design</h4><p>Block some variables</p>\n<h5 id=\"pros\"><a href=\"#pros\" class=\"headerlink\" title=\"pros\"></a>pros</h5><p>most commonly used</p>\n<p>statistically the most powerful</p>\n<h5 id=\"cons\"><a href=\"#cons\" class=\"headerlink\" title=\"cons\"></a>cons</h5><p>can be <strong>predicable</strong>, lead to rapid habituation or anticipation (reduced response)</p>\n<p><strong>cannot</strong> <strong>extract</strong> specific stimulus brain response</p>\n<p>some design <strong>cannot</strong> be modelled as a <strong>block</strong></p>\n<p>can be affected by cumulative effects (context)</p>\n</li>\n<li><h4 id=\"event-related-design\"><a href=\"#event-related-design\" class=\"headerlink\" title=\"event-related design\"></a>event-related design</h4><p>Each stimulus is individual epoch (can be associated with discrete events)</p>\n<h5 id=\"pros-1\"><a href=\"#pros-1\" class=\"headerlink\" title=\"pros\"></a>pros</h5><p>parallel behavioural studies</p>\n<p>greater flexibility (more complex)</p>\n<h5 id=\"cons-1\"><a href=\"#cons-1\" class=\"headerlink\" title=\"cons\"></a>cons</h5><p>related designs require a greater understanding of fMRI because the design (more complex)</p>\n<p>less statistical power (can be reduced to extend the scanning time)</p>\n</li>\n<li><p>mixed design</p>\n<p>mix the two above design together</p>\n</li>\n</ol>\n<hr>\n<p>   Structural MRI: Focus on analysis with Voxel Based Morphometry (<strong>VBM</strong>)</p>\n<p>   <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101112736.png\" alt=\"image-20220210111218622\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101116502.png\" alt=\"image-20220210111635460\"></p>\n<h3 id=\"Spatial-Normalization\"><a href=\"#Spatial-Normalization\" class=\"headerlink\" title=\"Spatial Normalization\"></a>Spatial Normalization</h3><p>transform a brain image into a standard brain coordinate system </p>\n<p><strong>SPM</strong> (Statistical Parametric Mapping) spatial normalisation</p>\n<h3 id=\"Segmentation\"><a href=\"#Segmentation\" class=\"headerlink\" title=\"Segmentation\"></a>Segmentation</h3><p>We do not use intensity threshold to segment for the following reasons:</p>\n<p>User intervention to decide what lever to threshold</p>\n<p>Bias field correction (an MRI artefact which causes slow changes in image intensity across the brain)</p>\n<p>Image noise (random regions of white matter have low levels of intensity which may be classified as grey matter)</p>\n<p>Modulation can increase the contrast ratio (an analogy: just like the reverse of using a rolling pin on pastry)</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147787.png\" alt=\"image-20220210114715754\"></p>\n<p>Normalised:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147398.png\" alt=\"image-20220210114705364\"></p>\n<p>Modulated:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101146535.png\" alt=\"image-20220210114635501\"></p>\n<p>(form left to right: Grey, White and CSF (Cerebrospinal fluid))</p>\n<h3 id=\"Smoothing\"><a href=\"#Smoothing\" class=\"headerlink\" title=\"Smoothing\"></a>Smoothing</h3><p>Take into account variations in structural anatomy</p>\n<p>To reduce noise</p>\n<p>To increase the normality of the data</p>\n<p>Smoothing amount is measured as FWHM (A common smoothing kernel for VBM is 8-12mm)</p>\n","excerpt":"","more":"<h3 id=\"Experimental-design\"><a href=\"#Experimental-design\" class=\"headerlink\" title=\"Experimental design\"></a>Experimental design</h3><ol>\n<li><h4 id=\"categorical-design\"><a href=\"#categorical-design\" class=\"headerlink\" title=\"categorical design\"></a>categorical design</h4><p>distinct types of stimuli or the timing, participant instructions</p>\n</li>\n<li><h4 id=\"factorial-design\"><a href=\"#factorial-design\" class=\"headerlink\" title=\"factorial design\"></a>factorial design</h4><p>usually 2 pairs of controlled factors</p>\n</li>\n<li><h4 id=\"parametric-design\"><a href=\"#parametric-design\" class=\"headerlink\" title=\"parametric design\"></a>parametric design</h4><p>modify the control variables</p>\n</li>\n</ol>\n<h3 id=\"Timing-of-stimuli\"><a href=\"#Timing-of-stimuli\" class=\"headerlink\" title=\"Timing of stimuli\"></a>Timing of stimuli</h3><ol>\n<li><h4 id=\"block-design\"><a href=\"#block-design\" class=\"headerlink\" title=\"block design\"></a>block design</h4><p>Block some variables</p>\n<h5 id=\"pros\"><a href=\"#pros\" class=\"headerlink\" title=\"pros\"></a>pros</h5><p>most commonly used</p>\n<p>statistically the most powerful</p>\n<h5 id=\"cons\"><a href=\"#cons\" class=\"headerlink\" title=\"cons\"></a>cons</h5><p>can be <strong>predicable</strong>, lead to rapid habituation or anticipation (reduced response)</p>\n<p><strong>cannot</strong> <strong>extract</strong> specific stimulus brain response</p>\n<p>some design <strong>cannot</strong> be modelled as a <strong>block</strong></p>\n<p>can be affected by cumulative effects (context)</p>\n</li>\n<li><h4 id=\"event-related-design\"><a href=\"#event-related-design\" class=\"headerlink\" title=\"event-related design\"></a>event-related design</h4><p>Each stimulus is individual epoch (can be associated with discrete events)</p>\n<h5 id=\"pros-1\"><a href=\"#pros-1\" class=\"headerlink\" title=\"pros\"></a>pros</h5><p>parallel behavioural studies</p>\n<p>greater flexibility (more complex)</p>\n<h5 id=\"cons-1\"><a href=\"#cons-1\" class=\"headerlink\" title=\"cons\"></a>cons</h5><p>related designs require a greater understanding of fMRI because the design (more complex)</p>\n<p>less statistical power (can be reduced to extend the scanning time)</p>\n</li>\n<li><p>mixed design</p>\n<p>mix the two above design together</p>\n</li>\n</ol>\n<hr>\n<p>   Structural MRI: Focus on analysis with Voxel Based Morphometry (<strong>VBM</strong>)</p>\n<p>   <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101112736.png\" alt=\"image-20220210111218622\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101116502.png\" alt=\"image-20220210111635460\"></p>\n<h3 id=\"Spatial-Normalization\"><a href=\"#Spatial-Normalization\" class=\"headerlink\" title=\"Spatial Normalization\"></a>Spatial Normalization</h3><p>transform a brain image into a standard brain coordinate system </p>\n<p><strong>SPM</strong> (Statistical Parametric Mapping) spatial normalisation</p>\n<h3 id=\"Segmentation\"><a href=\"#Segmentation\" class=\"headerlink\" title=\"Segmentation\"></a>Segmentation</h3><p>We do not use intensity threshold to segment for the following reasons:</p>\n<p>User intervention to decide what lever to threshold</p>\n<p>Bias field correction (an MRI artefact which causes slow changes in image intensity across the brain)</p>\n<p>Image noise (random regions of white matter have low levels of intensity which may be classified as grey matter)</p>\n<p>Modulation can increase the contrast ratio (an analogy: just like the reverse of using a rolling pin on pastry)</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147787.png\" alt=\"image-20220210114715754\"></p>\n<p>Normalised:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101147398.png\" alt=\"image-20220210114705364\"></p>\n<p>Modulated:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202101146535.png\" alt=\"image-20220210114635501\"></p>\n<p>(form left to right: Grey, White and CSF (Cerebrospinal fluid))</p>\n<h3 id=\"Smoothing\"><a href=\"#Smoothing\" class=\"headerlink\" title=\"Smoothing\"></a>Smoothing</h3><p>Take into account variations in structural anatomy</p>\n<p>To reduce noise</p>\n<p>To increase the normality of the data</p>\n<p>Smoothing amount is measured as FWHM (A common smoothing kernel for VBM is 8-12mm)</p>\n"},{"title":"Lecture Notes 02/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-02T09:30:00.000Z","password":null,"summary":null,"_content":"\n## PsychoPy\n\nThere is a online version: https://pavlovia.org/\n\nChoose the units as height so that we do not need to set it every time\n\n ![image-20220302102011091](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021020152.png)\n\nuntick the \"save csv file\" (to avoid saving a new csv file every single time; can tick it if needed) ![image-20220302102419605](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021024639.png)\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/02_03_22.md","raw":"---\ntitle: Lecture Notes 02/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-02 9:30\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n## PsychoPy\n\nThere is a online version: https://pavlovia.org/\n\nChoose the units as height so that we do not need to set it every time\n\n ![image-20220302102011091](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021020152.png)\n\nuntick the \"save csv file\" (to avoid saving a new csv file every single time; can tick it if needed) ![image-20220302102419605](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021024639.png)\n\n\n\n\n\n\n\n\n\n\n\n","slug":"02_03_22","published":1,"updated":"2022-08-24T17:08:39.284Z","comments":1,"layout":"post","photos":[],"_id":"cuidy5NiOES34NBq7_wzlCwQZ","content":"<h2 id=\"PsychoPy\"><a href=\"#PsychoPy\" class=\"headerlink\" title=\"PsychoPy\"></a>PsychoPy</h2><p>There is a online version: <a href=\"https://pavlovia.org/\">https://pavlovia.org/</a></p>\n<p>Choose the units as height so that we do not need to set it every time</p>\n<p> <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021020152.png\" alt=\"image-20220302102011091\"></p>\n<p>untick the “save csv file” (to avoid saving a new csv file every single time; can tick it if needed) <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021024639.png\" alt=\"image-20220302102419605\"></p>\n","excerpt":"","more":"<h2 id=\"PsychoPy\"><a href=\"#PsychoPy\" class=\"headerlink\" title=\"PsychoPy\"></a>PsychoPy</h2><p>There is a online version: <a href=\"https://pavlovia.org/\">https://pavlovia.org/</a></p>\n<p>Choose the units as height so that we do not need to set it every time</p>\n<p> <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021020152.png\" alt=\"image-20220302102011091\"></p>\n<p>untick the “save csv file” (to avoid saving a new csv file every single time; can tick it if needed) <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203021024639.png\" alt=\"image-20220302102419605\"></p>\n"},{"title":"Lecture Notes 03/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-03T11:00:00.000Z","password":null,"summary":null,"_content":"\n## Introduction of schizophrenia\n\n**Classic definition:** Schizophrenia is a severe, chronic mental disorder characterized by disturbances in thought, perception and behaviour. (DSM-5)\n\n### To describe the symptoms of schizophrenia\n\nGeneral 3 kinds of symptoms: \n\n1. **Positive Symptoms:** \n\n   hallucinations (sensory perception, can be visual or auditory); Delusions (Beliefs that conflict with reality, can be persecutory, erotomanic, somatic, grandiose)\n\n2. **Negative Symptoms:** \n\n   Ø Flat affect- restricted range of expressed emotions.\n   Ø Alogia - poverty of speech.\n   Ø Avolition - loss of motivation/an inability to initiate and persist in goal-directed activities.\n   Ø Anhedonia - lack of pleasure/interest in doing things.\n   Ø Social withdrawal.\n\n3. **Cognitive Symptoms**\n\n### To understand the general course of schizophrenia\n\n   Ø Approx. 20% of patients achieve a full recovery and 20% a ‘social’ recovery.\n   Ø Majority of patients experience multiple psychotic episodes.\n   Ø Cycles of relapsing and remitting.\n   Ø Subsequent episodes are often harder to recover from or recovery is less quick.\n   Ø Residual symptoms and functional decline.\n   Ø Term ‘chronic’ schizophrenia.\n   Ø Important to treat effectively and as early as possible!\n   Ø Duration of untreated psychosis (DUP) is a major predictor of outcome.\n   Ø Focus towards prevention strategies.\n\n### To detail some of the cognitive deficits that are characteristic of schizophrenia\n\n![image-20220303112919352](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031129442.png)\n\nGeneral 7 types of deficits\n\n1. Verbal fluency: e.g., producing words from a category\n2. Attention/ vigilance: e.g., psychomotor vigilance task\n3. Visual learning/ memory: e.g., delayed match to sample task\n4. Verbal learning/ memory: e.g., auditory verbal learning task\n5. Social learning: e.g., reward learning task\n6. Working memory: e.g., n-back task\n7. Reasoning/ problem solving: e.g., tower of London task\n\n## Brain dysfunction in schizophrenia (neuroimaging methods and hypotheses)\n\n### To describe the key hypotheses of schizophrenia\n\nThere are a number of key hypotheses that aim to explain the causes of schizophrenia including dopamine, salience, glutamate, disconnection, neurodevelopmental (to name a few!). Each have their strengths and weaknesses.\t\n\n**Evidence**:\n\nDopamine and reward learning\n\nRPE (<u>reward prediction error</u>) signalling\n\nMR spectroscopy\n\nThe dysconnectivity hypothesis\n\nNeurodevelopmental hypothesis\n\nStructural MRI\n\n### To describe the key hypotheses of schizophrenia\n\nSchizophrenia is characterized by widespread brain dysfunction including structural, functional and alterations in neurotransmitter systems.\n\n### To detail some of the neuroimaging methods used to understand these brain dysfunctions\n\nNeuroimaging modalities such as fMRI, MRI, MRS, PET can help us to understand these brain dysfunctions (and many more e.g., EEG, MEG…).\n\n## Heterogeneity problem (symptoms, classification, cognition, treatment response and new approaches to dealing with this).\n\n### To describe the problem of heterogeneity in schizophrenia.\n\nHeterogeneity (large interindividual differences) is a large problem in schizophrenia research and has slowed progress towards new treatments and prevention strategies.\n\n### To understand treatment resistance as an example of heterogeneity in schizophrenia.\n\nAntipsychotic treatment response in schizophrenia is an example of a form of heterogeneity that may be better understood as two subtypes of the disorder\n\n### To detail some of the new approaches to this problem.\n\nNew approaches that move away from the classic diagnostic criteria may aid in new developments and towards precision medicine\n\n\n\n---\n\n## Autism\n\n### What is Autism?\n\n\n\n### Development of the diagnostic concept\n\n1925 Grunya Efimovna Sukhareva, a Soviet child psychiatrist, published descriptions of ‘schizoid psychopathy’\n\n1967 ICD-8 ‘Infantile autism’ under Schizophrenia DSM-I and II: ‘Childhood schizophrenia’\n\n1978 ICD-9: ‘Autistic disorder’ a childhood psychosis\n\n1980 DSM-III: ‘Infantile autism’ a ‘Pervasive Developmental Disorder’\n\n1993 ICD-10: ‘Autistic disorder’\n\n1994 DSM-IV: ‘Autistic disorder’, ‘Asperger disorder’, ‘PDD-NOS’\n\n2013 DSM-5: ‘Autism Spectrum Disorder’\n\n### Is autism increasing?\n\n![image-20220303142326485](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031423765.png)\n\nRussell, G., et al., 2021. Child Psychology Psychiatry, 2021, DOI: (10.1111/jcpp.13505)\n\n### Levels of description: biological, behavioural, cognitive\n\n#### Psychological \n\nAutism is… highly heritable\n\nAutism is… a differently wired brain\n\nAutism is… a disorder of social communication\n\nAutism is... a different way of processing the world\n\n#### Cognitive\n\nNo single explanation at the Cognitive level\n\n![image-20220303143027214](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031430264.png)\n\n### Current and future issues\n\n\n\n### Conclusions\n\nAutistic people have always been with us; autism is not rare\n\nThe concept/diagnosis of ‘autism’ is relatively new and has evolved\n\nMuch research is underway into the biological causes; heterogeneity an obstacle\n\nThe diagnosis remains behavioural; is it serving older people and women well?\n\nAutism is rarely ‘pure’; additional problems are good treatment targets\n\nNeurotypicals need to increase empathy, acceptance, and respect for difference","source":"_posts/03_03_22.md","raw":"---\ntitle: Lecture Notes 03/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-03 11:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n## Introduction of schizophrenia\n\n**Classic definition:** Schizophrenia is a severe, chronic mental disorder characterized by disturbances in thought, perception and behaviour. (DSM-5)\n\n### To describe the symptoms of schizophrenia\n\nGeneral 3 kinds of symptoms: \n\n1. **Positive Symptoms:** \n\n   hallucinations (sensory perception, can be visual or auditory); Delusions (Beliefs that conflict with reality, can be persecutory, erotomanic, somatic, grandiose)\n\n2. **Negative Symptoms:** \n\n   Ø Flat affect- restricted range of expressed emotions.\n   Ø Alogia - poverty of speech.\n   Ø Avolition - loss of motivation/an inability to initiate and persist in goal-directed activities.\n   Ø Anhedonia - lack of pleasure/interest in doing things.\n   Ø Social withdrawal.\n\n3. **Cognitive Symptoms**\n\n### To understand the general course of schizophrenia\n\n   Ø Approx. 20% of patients achieve a full recovery and 20% a ‘social’ recovery.\n   Ø Majority of patients experience multiple psychotic episodes.\n   Ø Cycles of relapsing and remitting.\n   Ø Subsequent episodes are often harder to recover from or recovery is less quick.\n   Ø Residual symptoms and functional decline.\n   Ø Term ‘chronic’ schizophrenia.\n   Ø Important to treat effectively and as early as possible!\n   Ø Duration of untreated psychosis (DUP) is a major predictor of outcome.\n   Ø Focus towards prevention strategies.\n\n### To detail some of the cognitive deficits that are characteristic of schizophrenia\n\n![image-20220303112919352](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031129442.png)\n\nGeneral 7 types of deficits\n\n1. Verbal fluency: e.g., producing words from a category\n2. Attention/ vigilance: e.g., psychomotor vigilance task\n3. Visual learning/ memory: e.g., delayed match to sample task\n4. Verbal learning/ memory: e.g., auditory verbal learning task\n5. Social learning: e.g., reward learning task\n6. Working memory: e.g., n-back task\n7. Reasoning/ problem solving: e.g., tower of London task\n\n## Brain dysfunction in schizophrenia (neuroimaging methods and hypotheses)\n\n### To describe the key hypotheses of schizophrenia\n\nThere are a number of key hypotheses that aim to explain the causes of schizophrenia including dopamine, salience, glutamate, disconnection, neurodevelopmental (to name a few!). Each have their strengths and weaknesses.\t\n\n**Evidence**:\n\nDopamine and reward learning\n\nRPE (<u>reward prediction error</u>) signalling\n\nMR spectroscopy\n\nThe dysconnectivity hypothesis\n\nNeurodevelopmental hypothesis\n\nStructural MRI\n\n### To describe the key hypotheses of schizophrenia\n\nSchizophrenia is characterized by widespread brain dysfunction including structural, functional and alterations in neurotransmitter systems.\n\n### To detail some of the neuroimaging methods used to understand these brain dysfunctions\n\nNeuroimaging modalities such as fMRI, MRI, MRS, PET can help us to understand these brain dysfunctions (and many more e.g., EEG, MEG…).\n\n## Heterogeneity problem (symptoms, classification, cognition, treatment response and new approaches to dealing with this).\n\n### To describe the problem of heterogeneity in schizophrenia.\n\nHeterogeneity (large interindividual differences) is a large problem in schizophrenia research and has slowed progress towards new treatments and prevention strategies.\n\n### To understand treatment resistance as an example of heterogeneity in schizophrenia.\n\nAntipsychotic treatment response in schizophrenia is an example of a form of heterogeneity that may be better understood as two subtypes of the disorder\n\n### To detail some of the new approaches to this problem.\n\nNew approaches that move away from the classic diagnostic criteria may aid in new developments and towards precision medicine\n\n\n\n---\n\n## Autism\n\n### What is Autism?\n\n\n\n### Development of the diagnostic concept\n\n1925 Grunya Efimovna Sukhareva, a Soviet child psychiatrist, published descriptions of ‘schizoid psychopathy’\n\n1967 ICD-8 ‘Infantile autism’ under Schizophrenia DSM-I and II: ‘Childhood schizophrenia’\n\n1978 ICD-9: ‘Autistic disorder’ a childhood psychosis\n\n1980 DSM-III: ‘Infantile autism’ a ‘Pervasive Developmental Disorder’\n\n1993 ICD-10: ‘Autistic disorder’\n\n1994 DSM-IV: ‘Autistic disorder’, ‘Asperger disorder’, ‘PDD-NOS’\n\n2013 DSM-5: ‘Autism Spectrum Disorder’\n\n### Is autism increasing?\n\n![image-20220303142326485](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031423765.png)\n\nRussell, G., et al., 2021. Child Psychology Psychiatry, 2021, DOI: (10.1111/jcpp.13505)\n\n### Levels of description: biological, behavioural, cognitive\n\n#### Psychological \n\nAutism is… highly heritable\n\nAutism is… a differently wired brain\n\nAutism is… a disorder of social communication\n\nAutism is... a different way of processing the world\n\n#### Cognitive\n\nNo single explanation at the Cognitive level\n\n![image-20220303143027214](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031430264.png)\n\n### Current and future issues\n\n\n\n### Conclusions\n\nAutistic people have always been with us; autism is not rare\n\nThe concept/diagnosis of ‘autism’ is relatively new and has evolved\n\nMuch research is underway into the biological causes; heterogeneity an obstacle\n\nThe diagnosis remains behavioural; is it serving older people and women well?\n\nAutism is rarely ‘pure’; additional problems are good treatment targets\n\nNeurotypicals need to increase empathy, acceptance, and respect for difference","slug":"03_03_22","published":1,"updated":"2022-08-24T17:08:39.290Z","comments":1,"layout":"post","photos":[],"_id":"cuid4_mmUHVSUB1ArVFwpvSeR","content":"<h2 id=\"Introduction-of-schizophrenia\"><a href=\"#Introduction-of-schizophrenia\" class=\"headerlink\" title=\"Introduction of schizophrenia\"></a>Introduction of schizophrenia</h2><p><strong>Classic definition:</strong> Schizophrenia is a severe, chronic mental disorder characterized by disturbances in thought, perception and behaviour. (DSM-5)</p>\n<h3 id=\"To-describe-the-symptoms-of-schizophrenia\"><a href=\"#To-describe-the-symptoms-of-schizophrenia\" class=\"headerlink\" title=\"To describe the symptoms of schizophrenia\"></a>To describe the symptoms of schizophrenia</h3><p>General 3 kinds of symptoms: </p>\n<ol>\n<li><p><strong>Positive Symptoms:</strong> </p>\n<p>hallucinations (sensory perception, can be visual or auditory); Delusions (Beliefs that conflict with reality, can be persecutory, erotomanic, somatic, grandiose)</p>\n</li>\n<li><p><strong>Negative Symptoms:</strong> </p>\n<p>Ø Flat affect- restricted range of expressed emotions.<br>Ø Alogia - poverty of speech.<br>Ø Avolition - loss of motivation/an inability to initiate and persist in goal-directed activities.<br>Ø Anhedonia - lack of pleasure/interest in doing things.<br>Ø Social withdrawal.</p>\n</li>\n<li><p><strong>Cognitive Symptoms</strong></p>\n</li>\n</ol>\n<h3 id=\"To-understand-the-general-course-of-schizophrenia\"><a href=\"#To-understand-the-general-course-of-schizophrenia\" class=\"headerlink\" title=\"To understand the general course of schizophrenia\"></a>To understand the general course of schizophrenia</h3><p>   Ø Approx. 20% of patients achieve a full recovery and 20% a ‘social’ recovery.<br>   Ø Majority of patients experience multiple psychotic episodes.<br>   Ø Cycles of relapsing and remitting.<br>   Ø Subsequent episodes are often harder to recover from or recovery is less quick.<br>   Ø Residual symptoms and functional decline.<br>   Ø Term ‘chronic’ schizophrenia.<br>   Ø Important to treat effectively and as early as possible!<br>   Ø Duration of untreated psychosis (DUP) is a major predictor of outcome.<br>   Ø Focus towards prevention strategies.</p>\n<h3 id=\"To-detail-some-of-the-cognitive-deficits-that-are-characteristic-of-schizophrenia\"><a href=\"#To-detail-some-of-the-cognitive-deficits-that-are-characteristic-of-schizophrenia\" class=\"headerlink\" title=\"To detail some of the cognitive deficits that are characteristic of schizophrenia\"></a>To detail some of the cognitive deficits that are characteristic of schizophrenia</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031129442.png\" alt=\"image-20220303112919352\"></p>\n<p>General 7 types of deficits</p>\n<ol>\n<li>Verbal fluency: e.g., producing words from a category</li>\n<li>Attention/ vigilance: e.g., psychomotor vigilance task</li>\n<li>Visual learning/ memory: e.g., delayed match to sample task</li>\n<li>Verbal learning/ memory: e.g., auditory verbal learning task</li>\n<li>Social learning: e.g., reward learning task</li>\n<li>Working memory: e.g., n-back task</li>\n<li>Reasoning/ problem solving: e.g., tower of London task</li>\n</ol>\n<h2 id=\"Brain-dysfunction-in-schizophrenia-neuroimaging-methods-and-hypotheses\"><a href=\"#Brain-dysfunction-in-schizophrenia-neuroimaging-methods-and-hypotheses\" class=\"headerlink\" title=\"Brain dysfunction in schizophrenia (neuroimaging methods and hypotheses)\"></a>Brain dysfunction in schizophrenia (neuroimaging methods and hypotheses)</h2><h3 id=\"To-describe-the-key-hypotheses-of-schizophrenia\"><a href=\"#To-describe-the-key-hypotheses-of-schizophrenia\" class=\"headerlink\" title=\"To describe the key hypotheses of schizophrenia\"></a>To describe the key hypotheses of schizophrenia</h3><p>There are a number of key hypotheses that aim to explain the causes of schizophrenia including dopamine, salience, glutamate, disconnection, neurodevelopmental (to name a few!). Each have their strengths and weaknesses.    </p>\n<p><strong>Evidence</strong>:</p>\n<p>Dopamine and reward learning</p>\n<p>RPE (<u>reward prediction error</u>) signalling</p>\n<p>MR spectroscopy</p>\n<p>The dysconnectivity hypothesis</p>\n<p>Neurodevelopmental hypothesis</p>\n<p>Structural MRI</p>\n<h3 id=\"To-describe-the-key-hypotheses-of-schizophrenia-1\"><a href=\"#To-describe-the-key-hypotheses-of-schizophrenia-1\" class=\"headerlink\" title=\"To describe the key hypotheses of schizophrenia\"></a>To describe the key hypotheses of schizophrenia</h3><p>Schizophrenia is characterized by widespread brain dysfunction including structural, functional and alterations in neurotransmitter systems.</p>\n<h3 id=\"To-detail-some-of-the-neuroimaging-methods-used-to-understand-these-brain-dysfunctions\"><a href=\"#To-detail-some-of-the-neuroimaging-methods-used-to-understand-these-brain-dysfunctions\" class=\"headerlink\" title=\"To detail some of the neuroimaging methods used to understand these brain dysfunctions\"></a>To detail some of the neuroimaging methods used to understand these brain dysfunctions</h3><p>Neuroimaging modalities such as fMRI, MRI, MRS, PET can help us to understand these brain dysfunctions (and many more e.g., EEG, MEG…).</p>\n<h2 id=\"Heterogeneity-problem-symptoms-classification-cognition-treatment-response-and-new-approaches-to-dealing-with-this\"><a href=\"#Heterogeneity-problem-symptoms-classification-cognition-treatment-response-and-new-approaches-to-dealing-with-this\" class=\"headerlink\" title=\"Heterogeneity problem (symptoms, classification, cognition, treatment response and new approaches to dealing with this).\"></a>Heterogeneity problem (symptoms, classification, cognition, treatment response and new approaches to dealing with this).</h2><h3 id=\"To-describe-the-problem-of-heterogeneity-in-schizophrenia\"><a href=\"#To-describe-the-problem-of-heterogeneity-in-schizophrenia\" class=\"headerlink\" title=\"To describe the problem of heterogeneity in schizophrenia.\"></a>To describe the problem of heterogeneity in schizophrenia.</h3><p>Heterogeneity (large interindividual differences) is a large problem in schizophrenia research and has slowed progress towards new treatments and prevention strategies.</p>\n<h3 id=\"To-understand-treatment-resistance-as-an-example-of-heterogeneity-in-schizophrenia\"><a href=\"#To-understand-treatment-resistance-as-an-example-of-heterogeneity-in-schizophrenia\" class=\"headerlink\" title=\"To understand treatment resistance as an example of heterogeneity in schizophrenia.\"></a>To understand treatment resistance as an example of heterogeneity in schizophrenia.</h3><p>Antipsychotic treatment response in schizophrenia is an example of a form of heterogeneity that may be better understood as two subtypes of the disorder</p>\n<h3 id=\"To-detail-some-of-the-new-approaches-to-this-problem\"><a href=\"#To-detail-some-of-the-new-approaches-to-this-problem\" class=\"headerlink\" title=\"To detail some of the new approaches to this problem.\"></a>To detail some of the new approaches to this problem.</h3><p>New approaches that move away from the classic diagnostic criteria may aid in new developments and towards precision medicine</p>\n<hr>\n<h2 id=\"Autism\"><a href=\"#Autism\" class=\"headerlink\" title=\"Autism\"></a>Autism</h2><h3 id=\"What-is-Autism\"><a href=\"#What-is-Autism\" class=\"headerlink\" title=\"What is Autism?\"></a>What is Autism?</h3><h3 id=\"Development-of-the-diagnostic-concept\"><a href=\"#Development-of-the-diagnostic-concept\" class=\"headerlink\" title=\"Development of the diagnostic concept\"></a>Development of the diagnostic concept</h3><p>1925 Grunya Efimovna Sukhareva, a Soviet child psychiatrist, published descriptions of ‘schizoid psychopathy’</p>\n<p>1967 ICD-8 ‘Infantile autism’ under Schizophrenia DSM-I and II: ‘Childhood schizophrenia’</p>\n<p>1978 ICD-9: ‘Autistic disorder’ a childhood psychosis</p>\n<p>1980 DSM-III: ‘Infantile autism’ a ‘Pervasive Developmental Disorder’</p>\n<p>1993 ICD-10: ‘Autistic disorder’</p>\n<p>1994 DSM-IV: ‘Autistic disorder’, ‘Asperger disorder’, ‘PDD-NOS’</p>\n<p>2013 DSM-5: ‘Autism Spectrum Disorder’</p>\n<h3 id=\"Is-autism-increasing\"><a href=\"#Is-autism-increasing\" class=\"headerlink\" title=\"Is autism increasing?\"></a>Is autism increasing?</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031423765.png\" alt=\"image-20220303142326485\"></p>\n<p>Russell, G., et al., 2021. Child Psychology Psychiatry, 2021, DOI: (10.1111/jcpp.13505)</p>\n<h3 id=\"Levels-of-description-biological-behavioural-cognitive\"><a href=\"#Levels-of-description-biological-behavioural-cognitive\" class=\"headerlink\" title=\"Levels of description: biological, behavioural, cognitive\"></a>Levels of description: biological, behavioural, cognitive</h3><h4 id=\"Psychological\"><a href=\"#Psychological\" class=\"headerlink\" title=\"Psychological\"></a>Psychological</h4><p>Autism is… highly heritable</p>\n<p>Autism is… a differently wired brain</p>\n<p>Autism is… a disorder of social communication</p>\n<p>Autism is… a different way of processing the world</p>\n<h4 id=\"Cognitive\"><a href=\"#Cognitive\" class=\"headerlink\" title=\"Cognitive\"></a>Cognitive</h4><p>No single explanation at the Cognitive level</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031430264.png\" alt=\"image-20220303143027214\"></p>\n<h3 id=\"Current-and-future-issues\"><a href=\"#Current-and-future-issues\" class=\"headerlink\" title=\"Current and future issues\"></a>Current and future issues</h3><h3 id=\"Conclusions\"><a href=\"#Conclusions\" class=\"headerlink\" title=\"Conclusions\"></a>Conclusions</h3><p>Autistic people have always been with us; autism is not rare</p>\n<p>The concept/diagnosis of ‘autism’ is relatively new and has evolved</p>\n<p>Much research is underway into the biological causes; heterogeneity an obstacle</p>\n<p>The diagnosis remains behavioural; is it serving older people and women well?</p>\n<p>Autism is rarely ‘pure’; additional problems are good treatment targets</p>\n<p>Neurotypicals need to increase empathy, acceptance, and respect for difference</p>\n","excerpt":"","more":"<h2 id=\"Introduction-of-schizophrenia\"><a href=\"#Introduction-of-schizophrenia\" class=\"headerlink\" title=\"Introduction of schizophrenia\"></a>Introduction of schizophrenia</h2><p><strong>Classic definition:</strong> Schizophrenia is a severe, chronic mental disorder characterized by disturbances in thought, perception and behaviour. (DSM-5)</p>\n<h3 id=\"To-describe-the-symptoms-of-schizophrenia\"><a href=\"#To-describe-the-symptoms-of-schizophrenia\" class=\"headerlink\" title=\"To describe the symptoms of schizophrenia\"></a>To describe the symptoms of schizophrenia</h3><p>General 3 kinds of symptoms: </p>\n<ol>\n<li><p><strong>Positive Symptoms:</strong> </p>\n<p>hallucinations (sensory perception, can be visual or auditory); Delusions (Beliefs that conflict with reality, can be persecutory, erotomanic, somatic, grandiose)</p>\n</li>\n<li><p><strong>Negative Symptoms:</strong> </p>\n<p>Ø Flat affect- restricted range of expressed emotions.<br>Ø Alogia - poverty of speech.<br>Ø Avolition - loss of motivation/an inability to initiate and persist in goal-directed activities.<br>Ø Anhedonia - lack of pleasure/interest in doing things.<br>Ø Social withdrawal.</p>\n</li>\n<li><p><strong>Cognitive Symptoms</strong></p>\n</li>\n</ol>\n<h3 id=\"To-understand-the-general-course-of-schizophrenia\"><a href=\"#To-understand-the-general-course-of-schizophrenia\" class=\"headerlink\" title=\"To understand the general course of schizophrenia\"></a>To understand the general course of schizophrenia</h3><p>   Ø Approx. 20% of patients achieve a full recovery and 20% a ‘social’ recovery.<br>   Ø Majority of patients experience multiple psychotic episodes.<br>   Ø Cycles of relapsing and remitting.<br>   Ø Subsequent episodes are often harder to recover from or recovery is less quick.<br>   Ø Residual symptoms and functional decline.<br>   Ø Term ‘chronic’ schizophrenia.<br>   Ø Important to treat effectively and as early as possible!<br>   Ø Duration of untreated psychosis (DUP) is a major predictor of outcome.<br>   Ø Focus towards prevention strategies.</p>\n<h3 id=\"To-detail-some-of-the-cognitive-deficits-that-are-characteristic-of-schizophrenia\"><a href=\"#To-detail-some-of-the-cognitive-deficits-that-are-characteristic-of-schizophrenia\" class=\"headerlink\" title=\"To detail some of the cognitive deficits that are characteristic of schizophrenia\"></a>To detail some of the cognitive deficits that are characteristic of schizophrenia</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031129442.png\" alt=\"image-20220303112919352\"></p>\n<p>General 7 types of deficits</p>\n<ol>\n<li>Verbal fluency: e.g., producing words from a category</li>\n<li>Attention/ vigilance: e.g., psychomotor vigilance task</li>\n<li>Visual learning/ memory: e.g., delayed match to sample task</li>\n<li>Verbal learning/ memory: e.g., auditory verbal learning task</li>\n<li>Social learning: e.g., reward learning task</li>\n<li>Working memory: e.g., n-back task</li>\n<li>Reasoning/ problem solving: e.g., tower of London task</li>\n</ol>\n<h2 id=\"Brain-dysfunction-in-schizophrenia-neuroimaging-methods-and-hypotheses\"><a href=\"#Brain-dysfunction-in-schizophrenia-neuroimaging-methods-and-hypotheses\" class=\"headerlink\" title=\"Brain dysfunction in schizophrenia (neuroimaging methods and hypotheses)\"></a>Brain dysfunction in schizophrenia (neuroimaging methods and hypotheses)</h2><h3 id=\"To-describe-the-key-hypotheses-of-schizophrenia\"><a href=\"#To-describe-the-key-hypotheses-of-schizophrenia\" class=\"headerlink\" title=\"To describe the key hypotheses of schizophrenia\"></a>To describe the key hypotheses of schizophrenia</h3><p>There are a number of key hypotheses that aim to explain the causes of schizophrenia including dopamine, salience, glutamate, disconnection, neurodevelopmental (to name a few!). Each have their strengths and weaknesses.    </p>\n<p><strong>Evidence</strong>:</p>\n<p>Dopamine and reward learning</p>\n<p>RPE (<u>reward prediction error</u>) signalling</p>\n<p>MR spectroscopy</p>\n<p>The dysconnectivity hypothesis</p>\n<p>Neurodevelopmental hypothesis</p>\n<p>Structural MRI</p>\n<h3 id=\"To-describe-the-key-hypotheses-of-schizophrenia-1\"><a href=\"#To-describe-the-key-hypotheses-of-schizophrenia-1\" class=\"headerlink\" title=\"To describe the key hypotheses of schizophrenia\"></a>To describe the key hypotheses of schizophrenia</h3><p>Schizophrenia is characterized by widespread brain dysfunction including structural, functional and alterations in neurotransmitter systems.</p>\n<h3 id=\"To-detail-some-of-the-neuroimaging-methods-used-to-understand-these-brain-dysfunctions\"><a href=\"#To-detail-some-of-the-neuroimaging-methods-used-to-understand-these-brain-dysfunctions\" class=\"headerlink\" title=\"To detail some of the neuroimaging methods used to understand these brain dysfunctions\"></a>To detail some of the neuroimaging methods used to understand these brain dysfunctions</h3><p>Neuroimaging modalities such as fMRI, MRI, MRS, PET can help us to understand these brain dysfunctions (and many more e.g., EEG, MEG…).</p>\n<h2 id=\"Heterogeneity-problem-symptoms-classification-cognition-treatment-response-and-new-approaches-to-dealing-with-this\"><a href=\"#Heterogeneity-problem-symptoms-classification-cognition-treatment-response-and-new-approaches-to-dealing-with-this\" class=\"headerlink\" title=\"Heterogeneity problem (symptoms, classification, cognition, treatment response and new approaches to dealing with this).\"></a>Heterogeneity problem (symptoms, classification, cognition, treatment response and new approaches to dealing with this).</h2><h3 id=\"To-describe-the-problem-of-heterogeneity-in-schizophrenia\"><a href=\"#To-describe-the-problem-of-heterogeneity-in-schizophrenia\" class=\"headerlink\" title=\"To describe the problem of heterogeneity in schizophrenia.\"></a>To describe the problem of heterogeneity in schizophrenia.</h3><p>Heterogeneity (large interindividual differences) is a large problem in schizophrenia research and has slowed progress towards new treatments and prevention strategies.</p>\n<h3 id=\"To-understand-treatment-resistance-as-an-example-of-heterogeneity-in-schizophrenia\"><a href=\"#To-understand-treatment-resistance-as-an-example-of-heterogeneity-in-schizophrenia\" class=\"headerlink\" title=\"To understand treatment resistance as an example of heterogeneity in schizophrenia.\"></a>To understand treatment resistance as an example of heterogeneity in schizophrenia.</h3><p>Antipsychotic treatment response in schizophrenia is an example of a form of heterogeneity that may be better understood as two subtypes of the disorder</p>\n<h3 id=\"To-detail-some-of-the-new-approaches-to-this-problem\"><a href=\"#To-detail-some-of-the-new-approaches-to-this-problem\" class=\"headerlink\" title=\"To detail some of the new approaches to this problem.\"></a>To detail some of the new approaches to this problem.</h3><p>New approaches that move away from the classic diagnostic criteria may aid in new developments and towards precision medicine</p>\n<hr>\n<h2 id=\"Autism\"><a href=\"#Autism\" class=\"headerlink\" title=\"Autism\"></a>Autism</h2><h3 id=\"What-is-Autism\"><a href=\"#What-is-Autism\" class=\"headerlink\" title=\"What is Autism?\"></a>What is Autism?</h3><h3 id=\"Development-of-the-diagnostic-concept\"><a href=\"#Development-of-the-diagnostic-concept\" class=\"headerlink\" title=\"Development of the diagnostic concept\"></a>Development of the diagnostic concept</h3><p>1925 Grunya Efimovna Sukhareva, a Soviet child psychiatrist, published descriptions of ‘schizoid psychopathy’</p>\n<p>1967 ICD-8 ‘Infantile autism’ under Schizophrenia DSM-I and II: ‘Childhood schizophrenia’</p>\n<p>1978 ICD-9: ‘Autistic disorder’ a childhood psychosis</p>\n<p>1980 DSM-III: ‘Infantile autism’ a ‘Pervasive Developmental Disorder’</p>\n<p>1993 ICD-10: ‘Autistic disorder’</p>\n<p>1994 DSM-IV: ‘Autistic disorder’, ‘Asperger disorder’, ‘PDD-NOS’</p>\n<p>2013 DSM-5: ‘Autism Spectrum Disorder’</p>\n<h3 id=\"Is-autism-increasing\"><a href=\"#Is-autism-increasing\" class=\"headerlink\" title=\"Is autism increasing?\"></a>Is autism increasing?</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031423765.png\" alt=\"image-20220303142326485\"></p>\n<p>Russell, G., et al., 2021. Child Psychology Psychiatry, 2021, DOI: (10.1111/jcpp.13505)</p>\n<h3 id=\"Levels-of-description-biological-behavioural-cognitive\"><a href=\"#Levels-of-description-biological-behavioural-cognitive\" class=\"headerlink\" title=\"Levels of description: biological, behavioural, cognitive\"></a>Levels of description: biological, behavioural, cognitive</h3><h4 id=\"Psychological\"><a href=\"#Psychological\" class=\"headerlink\" title=\"Psychological\"></a>Psychological</h4><p>Autism is… highly heritable</p>\n<p>Autism is… a differently wired brain</p>\n<p>Autism is… a disorder of social communication</p>\n<p>Autism is… a different way of processing the world</p>\n<h4 id=\"Cognitive\"><a href=\"#Cognitive\" class=\"headerlink\" title=\"Cognitive\"></a>Cognitive</h4><p>No single explanation at the Cognitive level</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203031430264.png\" alt=\"image-20220303143027214\"></p>\n<h3 id=\"Current-and-future-issues\"><a href=\"#Current-and-future-issues\" class=\"headerlink\" title=\"Current and future issues\"></a>Current and future issues</h3><h3 id=\"Conclusions\"><a href=\"#Conclusions\" class=\"headerlink\" title=\"Conclusions\"></a>Conclusions</h3><p>Autistic people have always been with us; autism is not rare</p>\n<p>The concept/diagnosis of ‘autism’ is relatively new and has evolved</p>\n<p>Much research is underway into the biological causes; heterogeneity an obstacle</p>\n<p>The diagnosis remains behavioural; is it serving older people and women well?</p>\n<p>Autism is rarely ‘pure’; additional problems are good treatment targets</p>\n<p>Neurotypicals need to increase empathy, acceptance, and respect for difference</p>\n"},{"title":"Lecture Notes 08/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-08T12:00:00.000Z","password":null,"summary":null,"_content":"\n- ## review basic concepts about neuronal activity\n\n  Two ways to propagate information: 1. electrical potential; 2. chemical neurotransmitters\n\n  Generation of signals (both) only require kinetic energy already available\n\n- ## discuss the mechanisms that lead to spontaneous electrical activity in neurons\n\n  \n\n- ## discuss basic concepts about neuro-transmitter function\n\n  Restoration of electro-chemical potential requires a huge amount of **additional** energy that can only be met by increases in metabolism\n\n  Reuptake and recycling requires a lot of additional energy from increases in metabolism\n\n- ## discuss the energy requirements for neuronal and synaptic activity\n\n  There are only a small amount of glycogen in brain so that a vast supply of oxygen and glucose delivered by a highly specialized vascular network is necessary\n\n- ## discuss the control of blood flow in brain tissue and its relevance\n\n  **Increases** in neuronal activity are always accompanied by a **local** increase in **regional Cerebral Blood Flow** (CBF)\n\n\n\n***\n\n\n\n- ## Understand the physical principles of Blood Oxygen Level Dependent (BOLD) contrast\n\n  Paramagnetic deoxyhemoglobin in venous blood is a naturally occurring contrast agent (Ogawa, 1990)\n\n  \n\n- ## The BOLD contrast depends on the relationship between three processes:\n\n- ### (b) the magnetic properties of the haemoglobin in the blood\n\n- ### (a) the increase in blood flow triggered by the increase in cellular activity\n\n- ### (c) the mismatch between the increase in blood flow and the increase in oxygen metabolism\n\n  BOLD contrast depends on the relationship between CBF (Cerebral Blood Flow) and CMRO2 (Cerebral metabolic rate of oxygen)\n\n  increases in CBF, CMR~gluc~ and CMR~O2~ comes as a result of increases in neuronal activity\n\n  However, paradoxically: the oxygen extraction fraction (E) (E = (oxygen consumed) / (oxygen delivered)) **DECREASES** with **INCREASES** in neuronal activity. \n\n  Increased neuronal activity leads to a **DECREASE** in the concentration of de-oxyhaemoglobin in venous space\n\n  Why does this reactive hyperemia occur? One explanation is to transport oxygenated haemoglobin\n\n   \n\n  ***\n\n  \n\n  ## • Understand the basic methods used to assess drug effects with MRI\n\n  \n\n  ## • Appreciate the utility of phMRI\n\n  ## • Understand the key differences in PET and MRI for drug effects\n\n  PET is much more expensive even though MRI is expensive\n\n  ![image-20220208141412291](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081414374.png)\n\n  ## • To be able to identify major confounds\n\n  ![image-20220208143638212](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081436286.png)\n\n  ## • To be able to describe solutions to confounds\n\n\n\n***\n\n\n\nWe may meet some problems with building and using BOLD predictors\n\n1. The BOLD response is delayed, has dispersed/wide and variable shape\n2. BOLD signals include substantial amount of low-frequency noise\n   1. \n\n\n\n## • The assumptions underpinning the flexible modelling of the BOLD response\n\n\n\n## • How autocorrelation violates the assumptions underlying out parameter estimation and how we can correct for it.\n\n## • The differences between fixed-effects, random effects and mixed effects models\n\n## • About a common methods of multiple comparisons correction is implemented for neuroimaging?\n\n## • The differences between parametric and non-parametric analyses.","source":"_posts/08_02_22.md","raw":"---\ntitle: Lecture Notes 08/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-08 12:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n\n---\n\n- ## review basic concepts about neuronal activity\n\n  Two ways to propagate information: 1. electrical potential; 2. chemical neurotransmitters\n\n  Generation of signals (both) only require kinetic energy already available\n\n- ## discuss the mechanisms that lead to spontaneous electrical activity in neurons\n\n  \n\n- ## discuss basic concepts about neuro-transmitter function\n\n  Restoration of electro-chemical potential requires a huge amount of **additional** energy that can only be met by increases in metabolism\n\n  Reuptake and recycling requires a lot of additional energy from increases in metabolism\n\n- ## discuss the energy requirements for neuronal and synaptic activity\n\n  There are only a small amount of glycogen in brain so that a vast supply of oxygen and glucose delivered by a highly specialized vascular network is necessary\n\n- ## discuss the control of blood flow in brain tissue and its relevance\n\n  **Increases** in neuronal activity are always accompanied by a **local** increase in **regional Cerebral Blood Flow** (CBF)\n\n\n\n***\n\n\n\n- ## Understand the physical principles of Blood Oxygen Level Dependent (BOLD) contrast\n\n  Paramagnetic deoxyhemoglobin in venous blood is a naturally occurring contrast agent (Ogawa, 1990)\n\n  \n\n- ## The BOLD contrast depends on the relationship between three processes:\n\n- ### (b) the magnetic properties of the haemoglobin in the blood\n\n- ### (a) the increase in blood flow triggered by the increase in cellular activity\n\n- ### (c) the mismatch between the increase in blood flow and the increase in oxygen metabolism\n\n  BOLD contrast depends on the relationship between CBF (Cerebral Blood Flow) and CMRO2 (Cerebral metabolic rate of oxygen)\n\n  increases in CBF, CMR~gluc~ and CMR~O2~ comes as a result of increases in neuronal activity\n\n  However, paradoxically: the oxygen extraction fraction (E) (E = (oxygen consumed) / (oxygen delivered)) **DECREASES** with **INCREASES** in neuronal activity. \n\n  Increased neuronal activity leads to a **DECREASE** in the concentration of de-oxyhaemoglobin in venous space\n\n  Why does this reactive hyperemia occur? One explanation is to transport oxygenated haemoglobin\n\n   \n\n  ***\n\n  \n\n  ## • Understand the basic methods used to assess drug effects with MRI\n\n  \n\n  ## • Appreciate the utility of phMRI\n\n  ## • Understand the key differences in PET and MRI for drug effects\n\n  PET is much more expensive even though MRI is expensive\n\n  ![image-20220208141412291](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081414374.png)\n\n  ## • To be able to identify major confounds\n\n  ![image-20220208143638212](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081436286.png)\n\n  ## • To be able to describe solutions to confounds\n\n\n\n***\n\n\n\nWe may meet some problems with building and using BOLD predictors\n\n1. The BOLD response is delayed, has dispersed/wide and variable shape\n2. BOLD signals include substantial amount of low-frequency noise\n   1. \n\n\n\n## • The assumptions underpinning the flexible modelling of the BOLD response\n\n\n\n## • How autocorrelation violates the assumptions underlying out parameter estimation and how we can correct for it.\n\n## • The differences between fixed-effects, random effects and mixed effects models\n\n## • About a common methods of multiple comparisons correction is implemented for neuroimaging?\n\n## • The differences between parametric and non-parametric analyses.","slug":"08_02_22","published":1,"updated":"2022-08-24T17:08:39.296Z","comments":1,"layout":"post","photos":[],"_id":"cuidsTPW2bWerHF6I4gAPJ42b","content":"<ul>\n<li><h2 id=\"review-basic-concepts-about-neuronal-activity\"><a href=\"#review-basic-concepts-about-neuronal-activity\" class=\"headerlink\" title=\"review basic concepts about neuronal activity\"></a>review basic concepts about neuronal activity</h2><p>Two ways to propagate information: 1. electrical potential; 2. chemical neurotransmitters</p>\n<p>Generation of signals (both) only require kinetic energy already available</p>\n</li>\n<li><h2 id=\"discuss-the-mechanisms-that-lead-to-spontaneous-electrical-activity-in-neurons\"><a href=\"#discuss-the-mechanisms-that-lead-to-spontaneous-electrical-activity-in-neurons\" class=\"headerlink\" title=\"discuss the mechanisms that lead to spontaneous electrical activity in neurons\"></a>discuss the mechanisms that lead to spontaneous electrical activity in neurons</h2></li>\n</ul>\n<ul>\n<li><h2 id=\"discuss-basic-concepts-about-neuro-transmitter-function\"><a href=\"#discuss-basic-concepts-about-neuro-transmitter-function\" class=\"headerlink\" title=\"discuss basic concepts about neuro-transmitter function\"></a>discuss basic concepts about neuro-transmitter function</h2><p>Restoration of electro-chemical potential requires a huge amount of <strong>additional</strong> energy that can only be met by increases in metabolism</p>\n<p>Reuptake and recycling requires a lot of additional energy from increases in metabolism</p>\n</li>\n<li><h2 id=\"discuss-the-energy-requirements-for-neuronal-and-synaptic-activity\"><a href=\"#discuss-the-energy-requirements-for-neuronal-and-synaptic-activity\" class=\"headerlink\" title=\"discuss the energy requirements for neuronal and synaptic activity\"></a>discuss the energy requirements for neuronal and synaptic activity</h2><p>There are only a small amount of glycogen in brain so that a vast supply of oxygen and glucose delivered by a highly specialized vascular network is necessary</p>\n</li>\n<li><h2 id=\"discuss-the-control-of-blood-flow-in-brain-tissue-and-its-relevance\"><a href=\"#discuss-the-control-of-blood-flow-in-brain-tissue-and-its-relevance\" class=\"headerlink\" title=\"discuss the control of blood flow in brain tissue and its relevance\"></a>discuss the control of blood flow in brain tissue and its relevance</h2><p><strong>Increases</strong> in neuronal activity are always accompanied by a <strong>local</strong> increase in <strong>regional Cerebral Blood Flow</strong> (CBF)</p>\n</li>\n</ul>\n<hr>\n<ul>\n<li><h2 id=\"Understand-the-physical-principles-of-Blood-Oxygen-Level-Dependent-BOLD-contrast\"><a href=\"#Understand-the-physical-principles-of-Blood-Oxygen-Level-Dependent-BOLD-contrast\" class=\"headerlink\" title=\"Understand the physical principles of Blood Oxygen Level Dependent (BOLD) contrast\"></a>Understand the physical principles of Blood Oxygen Level Dependent (BOLD) contrast</h2><p>Paramagnetic deoxyhemoglobin in venous blood is a naturally occurring contrast agent (Ogawa, 1990)</p>\n</li>\n</ul>\n<ul>\n<li><h2 id=\"The-BOLD-contrast-depends-on-the-relationship-between-three-processes\"><a href=\"#The-BOLD-contrast-depends-on-the-relationship-between-three-processes\" class=\"headerlink\" title=\"The BOLD contrast depends on the relationship between three processes:\"></a>The BOLD contrast depends on the relationship between three processes:</h2></li>\n<li><h3 id=\"b-the-magnetic-properties-of-the-haemoglobin-in-the-blood\"><a href=\"#b-the-magnetic-properties-of-the-haemoglobin-in-the-blood\" class=\"headerlink\" title=\"(b) the magnetic properties of the haemoglobin in the blood\"></a>(b) the magnetic properties of the haemoglobin in the blood</h3></li>\n<li><h3 id=\"a-the-increase-in-blood-flow-triggered-by-the-increase-in-cellular-activity\"><a href=\"#a-the-increase-in-blood-flow-triggered-by-the-increase-in-cellular-activity\" class=\"headerlink\" title=\"(a) the increase in blood flow triggered by the increase in cellular activity\"></a>(a) the increase in blood flow triggered by the increase in cellular activity</h3></li>\n<li><h3 id=\"c-the-mismatch-between-the-increase-in-blood-flow-and-the-increase-in-oxygen-metabolism\"><a href=\"#c-the-mismatch-between-the-increase-in-blood-flow-and-the-increase-in-oxygen-metabolism\" class=\"headerlink\" title=\"(c) the mismatch between the increase in blood flow and the increase in oxygen metabolism\"></a>(c) the mismatch between the increase in blood flow and the increase in oxygen metabolism</h3><p>BOLD contrast depends on the relationship between CBF (Cerebral Blood Flow) and CMRO2 (Cerebral metabolic rate of oxygen)</p>\n<p>increases in CBF, CMR<del>gluc</del> and CMR<del>O2</del> comes as a result of increases in neuronal activity</p>\n<p>However, paradoxically: the oxygen extraction fraction (E) (E = (oxygen consumed) / (oxygen delivered)) <strong>DECREASES</strong> with <strong>INCREASES</strong> in neuronal activity. </p>\n<p>Increased neuronal activity leads to a <strong>DECREASE</strong> in the concentration of de-oxyhaemoglobin in venous space</p>\n<p>Why does this reactive hyperemia occur? One explanation is to transport oxygenated haemoglobin</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"•-Understand-the-basic-methods-used-to-assess-drug-effects-with-MRI\"><a href=\"#•-Understand-the-basic-methods-used-to-assess-drug-effects-with-MRI\" class=\"headerlink\" title=\"• Understand the basic methods used to assess drug effects with MRI\"></a>• Understand the basic methods used to assess drug effects with MRI</h2><h2 id=\"•-Appreciate-the-utility-of-phMRI\"><a href=\"#•-Appreciate-the-utility-of-phMRI\" class=\"headerlink\" title=\"• Appreciate the utility of phMRI\"></a>• Appreciate the utility of phMRI</h2><h2 id=\"•-Understand-the-key-differences-in-PET-and-MRI-for-drug-effects\"><a href=\"#•-Understand-the-key-differences-in-PET-and-MRI-for-drug-effects\" class=\"headerlink\" title=\"• Understand the key differences in PET and MRI for drug effects\"></a>• Understand the key differences in PET and MRI for drug effects</h2><p>  PET is much more expensive even though MRI is expensive</p>\n<p>  <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081414374.png\" alt=\"image-20220208141412291\"></p>\n<h2 id=\"•-To-be-able-to-identify-major-confounds\"><a href=\"#•-To-be-able-to-identify-major-confounds\" class=\"headerlink\" title=\"• To be able to identify major confounds\"></a>• To be able to identify major confounds</h2><p>  <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081436286.png\" alt=\"image-20220208143638212\"></p>\n<h2 id=\"•-To-be-able-to-describe-solutions-to-confounds\"><a href=\"#•-To-be-able-to-describe-solutions-to-confounds\" class=\"headerlink\" title=\"• To be able to describe solutions to confounds\"></a>• To be able to describe solutions to confounds</h2><hr>\n<p>We may meet some problems with building and using BOLD predictors</p>\n<ol>\n<li>The BOLD response is delayed, has dispersed/wide and variable shape</li>\n<li>BOLD signals include substantial amount of low-frequency noise<ol>\n<li></li>\n</ol>\n</li>\n</ol>\n<h2 id=\"•-The-assumptions-underpinning-the-flexible-modelling-of-the-BOLD-response\"><a href=\"#•-The-assumptions-underpinning-the-flexible-modelling-of-the-BOLD-response\" class=\"headerlink\" title=\"• The assumptions underpinning the flexible modelling of the BOLD response\"></a>• The assumptions underpinning the flexible modelling of the BOLD response</h2><h2 id=\"•-How-autocorrelation-violates-the-assumptions-underlying-out-parameter-estimation-and-how-we-can-correct-for-it\"><a href=\"#•-How-autocorrelation-violates-the-assumptions-underlying-out-parameter-estimation-and-how-we-can-correct-for-it\" class=\"headerlink\" title=\"• How autocorrelation violates the assumptions underlying out parameter estimation and how we can correct for it.\"></a>• How autocorrelation violates the assumptions underlying out parameter estimation and how we can correct for it.</h2><h2 id=\"•-The-differences-between-fixed-effects-random-effects-and-mixed-effects-models\"><a href=\"#•-The-differences-between-fixed-effects-random-effects-and-mixed-effects-models\" class=\"headerlink\" title=\"• The differences between fixed-effects, random effects and mixed effects models\"></a>• The differences between fixed-effects, random effects and mixed effects models</h2><h2 id=\"•-About-a-common-methods-of-multiple-comparisons-correction-is-implemented-for-neuroimaging\"><a href=\"#•-About-a-common-methods-of-multiple-comparisons-correction-is-implemented-for-neuroimaging\" class=\"headerlink\" title=\"• About a common methods of multiple comparisons correction is implemented for neuroimaging?\"></a>• About a common methods of multiple comparisons correction is implemented for neuroimaging?</h2><h2 id=\"•-The-differences-between-parametric-and-non-parametric-analyses\"><a href=\"#•-The-differences-between-parametric-and-non-parametric-analyses\" class=\"headerlink\" title=\"• The differences between parametric and non-parametric analyses.\"></a>• The differences between parametric and non-parametric analyses.</h2>","excerpt":"","more":"<ul>\n<li><h2 id=\"review-basic-concepts-about-neuronal-activity\"><a href=\"#review-basic-concepts-about-neuronal-activity\" class=\"headerlink\" title=\"review basic concepts about neuronal activity\"></a>review basic concepts about neuronal activity</h2><p>Two ways to propagate information: 1. electrical potential; 2. chemical neurotransmitters</p>\n<p>Generation of signals (both) only require kinetic energy already available</p>\n</li>\n<li><h2 id=\"discuss-the-mechanisms-that-lead-to-spontaneous-electrical-activity-in-neurons\"><a href=\"#discuss-the-mechanisms-that-lead-to-spontaneous-electrical-activity-in-neurons\" class=\"headerlink\" title=\"discuss the mechanisms that lead to spontaneous electrical activity in neurons\"></a>discuss the mechanisms that lead to spontaneous electrical activity in neurons</h2></li>\n</ul>\n<ul>\n<li><h2 id=\"discuss-basic-concepts-about-neuro-transmitter-function\"><a href=\"#discuss-basic-concepts-about-neuro-transmitter-function\" class=\"headerlink\" title=\"discuss basic concepts about neuro-transmitter function\"></a>discuss basic concepts about neuro-transmitter function</h2><p>Restoration of electro-chemical potential requires a huge amount of <strong>additional</strong> energy that can only be met by increases in metabolism</p>\n<p>Reuptake and recycling requires a lot of additional energy from increases in metabolism</p>\n</li>\n<li><h2 id=\"discuss-the-energy-requirements-for-neuronal-and-synaptic-activity\"><a href=\"#discuss-the-energy-requirements-for-neuronal-and-synaptic-activity\" class=\"headerlink\" title=\"discuss the energy requirements for neuronal and synaptic activity\"></a>discuss the energy requirements for neuronal and synaptic activity</h2><p>There are only a small amount of glycogen in brain so that a vast supply of oxygen and glucose delivered by a highly specialized vascular network is necessary</p>\n</li>\n<li><h2 id=\"discuss-the-control-of-blood-flow-in-brain-tissue-and-its-relevance\"><a href=\"#discuss-the-control-of-blood-flow-in-brain-tissue-and-its-relevance\" class=\"headerlink\" title=\"discuss the control of blood flow in brain tissue and its relevance\"></a>discuss the control of blood flow in brain tissue and its relevance</h2><p><strong>Increases</strong> in neuronal activity are always accompanied by a <strong>local</strong> increase in <strong>regional Cerebral Blood Flow</strong> (CBF)</p>\n</li>\n</ul>\n<hr>\n<ul>\n<li><h2 id=\"Understand-the-physical-principles-of-Blood-Oxygen-Level-Dependent-BOLD-contrast\"><a href=\"#Understand-the-physical-principles-of-Blood-Oxygen-Level-Dependent-BOLD-contrast\" class=\"headerlink\" title=\"Understand the physical principles of Blood Oxygen Level Dependent (BOLD) contrast\"></a>Understand the physical principles of Blood Oxygen Level Dependent (BOLD) contrast</h2><p>Paramagnetic deoxyhemoglobin in venous blood is a naturally occurring contrast agent (Ogawa, 1990)</p>\n</li>\n</ul>\n<ul>\n<li><h2 id=\"The-BOLD-contrast-depends-on-the-relationship-between-three-processes\"><a href=\"#The-BOLD-contrast-depends-on-the-relationship-between-three-processes\" class=\"headerlink\" title=\"The BOLD contrast depends on the relationship between three processes:\"></a>The BOLD contrast depends on the relationship between three processes:</h2></li>\n<li><h3 id=\"b-the-magnetic-properties-of-the-haemoglobin-in-the-blood\"><a href=\"#b-the-magnetic-properties-of-the-haemoglobin-in-the-blood\" class=\"headerlink\" title=\"(b) the magnetic properties of the haemoglobin in the blood\"></a>(b) the magnetic properties of the haemoglobin in the blood</h3></li>\n<li><h3 id=\"a-the-increase-in-blood-flow-triggered-by-the-increase-in-cellular-activity\"><a href=\"#a-the-increase-in-blood-flow-triggered-by-the-increase-in-cellular-activity\" class=\"headerlink\" title=\"(a) the increase in blood flow triggered by the increase in cellular activity\"></a>(a) the increase in blood flow triggered by the increase in cellular activity</h3></li>\n<li><h3 id=\"c-the-mismatch-between-the-increase-in-blood-flow-and-the-increase-in-oxygen-metabolism\"><a href=\"#c-the-mismatch-between-the-increase-in-blood-flow-and-the-increase-in-oxygen-metabolism\" class=\"headerlink\" title=\"(c) the mismatch between the increase in blood flow and the increase in oxygen metabolism\"></a>(c) the mismatch between the increase in blood flow and the increase in oxygen metabolism</h3><p>BOLD contrast depends on the relationship between CBF (Cerebral Blood Flow) and CMRO2 (Cerebral metabolic rate of oxygen)</p>\n<p>increases in CBF, CMR<del>gluc</del> and CMR<del>O2</del> comes as a result of increases in neuronal activity</p>\n<p>However, paradoxically: the oxygen extraction fraction (E) (E = (oxygen consumed) / (oxygen delivered)) <strong>DECREASES</strong> with <strong>INCREASES</strong> in neuronal activity. </p>\n<p>Increased neuronal activity leads to a <strong>DECREASE</strong> in the concentration of de-oxyhaemoglobin in venous space</p>\n<p>Why does this reactive hyperemia occur? One explanation is to transport oxygenated haemoglobin</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"•-Understand-the-basic-methods-used-to-assess-drug-effects-with-MRI\"><a href=\"#•-Understand-the-basic-methods-used-to-assess-drug-effects-with-MRI\" class=\"headerlink\" title=\"• Understand the basic methods used to assess drug effects with MRI\"></a>• Understand the basic methods used to assess drug effects with MRI</h2><h2 id=\"•-Appreciate-the-utility-of-phMRI\"><a href=\"#•-Appreciate-the-utility-of-phMRI\" class=\"headerlink\" title=\"• Appreciate the utility of phMRI\"></a>• Appreciate the utility of phMRI</h2><h2 id=\"•-Understand-the-key-differences-in-PET-and-MRI-for-drug-effects\"><a href=\"#•-Understand-the-key-differences-in-PET-and-MRI-for-drug-effects\" class=\"headerlink\" title=\"• Understand the key differences in PET and MRI for drug effects\"></a>• Understand the key differences in PET and MRI for drug effects</h2><p>  PET is much more expensive even though MRI is expensive</p>\n<p>  <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081414374.png\" alt=\"image-20220208141412291\"></p>\n<h2 id=\"•-To-be-able-to-identify-major-confounds\"><a href=\"#•-To-be-able-to-identify-major-confounds\" class=\"headerlink\" title=\"• To be able to identify major confounds\"></a>• To be able to identify major confounds</h2><p>  <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202081436286.png\" alt=\"image-20220208143638212\"></p>\n<h2 id=\"•-To-be-able-to-describe-solutions-to-confounds\"><a href=\"#•-To-be-able-to-describe-solutions-to-confounds\" class=\"headerlink\" title=\"• To be able to describe solutions to confounds\"></a>• To be able to describe solutions to confounds</h2><hr>\n<p>We may meet some problems with building and using BOLD predictors</p>\n<ol>\n<li>The BOLD response is delayed, has dispersed/wide and variable shape</li>\n<li>BOLD signals include substantial amount of low-frequency noise<ol>\n<li></li>\n</ol>\n</li>\n</ol>\n<h2 id=\"•-The-assumptions-underpinning-the-flexible-modelling-of-the-BOLD-response\"><a href=\"#•-The-assumptions-underpinning-the-flexible-modelling-of-the-BOLD-response\" class=\"headerlink\" title=\"• The assumptions underpinning the flexible modelling of the BOLD response\"></a>• The assumptions underpinning the flexible modelling of the BOLD response</h2><h2 id=\"•-How-autocorrelation-violates-the-assumptions-underlying-out-parameter-estimation-and-how-we-can-correct-for-it\"><a href=\"#•-How-autocorrelation-violates-the-assumptions-underlying-out-parameter-estimation-and-how-we-can-correct-for-it\" class=\"headerlink\" title=\"• How autocorrelation violates the assumptions underlying out parameter estimation and how we can correct for it.\"></a>• How autocorrelation violates the assumptions underlying out parameter estimation and how we can correct for it.</h2><h2 id=\"•-The-differences-between-fixed-effects-random-effects-and-mixed-effects-models\"><a href=\"#•-The-differences-between-fixed-effects-random-effects-and-mixed-effects-models\" class=\"headerlink\" title=\"• The differences between fixed-effects, random effects and mixed effects models\"></a>• The differences between fixed-effects, random effects and mixed effects models</h2><h2 id=\"•-About-a-common-methods-of-multiple-comparisons-correction-is-implemented-for-neuroimaging\"><a href=\"#•-About-a-common-methods-of-multiple-comparisons-correction-is-implemented-for-neuroimaging\" class=\"headerlink\" title=\"• About a common methods of multiple comparisons correction is implemented for neuroimaging?\"></a>• About a common methods of multiple comparisons correction is implemented for neuroimaging?</h2><h2 id=\"•-The-differences-between-parametric-and-non-parametric-analyses\"><a href=\"#•-The-differences-between-parametric-and-non-parametric-analyses\" class=\"headerlink\" title=\"• The differences between parametric and non-parametric analyses.\"></a>• The differences between parametric and non-parametric analyses.</h2>"},{"title":"Lecture Notes 08/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-08T10:00:00.000Z","password":null,"summary":null,"_content":"\n# EEG Oscillations\n\nThere are different ways to measure oscillations![different methods to measure oscillations](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081018999.png)\n\nLFP: local field potential\n\nEEG: electroencephalography\n\nEcoG: Electrocorticography\n\nMEG is not commonly used because it is expensive\n\n## FASTFOURIER TRANSFORM (FFT): Delta, Theta, Alpha, Beta, Gamma\n\nA Fourier transform (FT) is a mathematical transform that decomposes functions depending on **space** or **time** into functions depending on spatial frequency or temporal frequency.\n\n![image-20220308102128935](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081040845.png)\n\nDelta 1 – 3.5 Hz\n\n- Most strongly associated with slow wave sleep in healthy adults, and seen in young infants\n- In an awake person, can be related to brain pathology, e.g. stroke, brain trauma, brain infection\n- The slow fluctuations need to be distinguished from artifacts with similar temporal activity, e.g. respiration, perspiration\n\nTheta 3.5 – 7.5 Hz\n\n- Whole brain theta linked to arousal, sleep \n- In conflict tasks FM theta represents processes involved in the timing of cognitive synchronisation -packaging of information for communication in the cortex, e.g. theta-gamma coupling\n- Theta waves (6 Hz) studied in “place cells” by O’Keefe and Nadel in rat hippocampus\n\nAlpha 7.5 – 12.5 Hz\n\n- Strong, clear and characteristic wave observable even in raw data e.g. “Berger’s wave”\n- Produced when quietly sitting in relaxed position, enhanced with eyes closed\n- Generally, mental activity is associated with reduced alpha power\n\nBeta 12.5 – ~30 Hz (or low/high)\n\n- Two subtypes of beta oscillations:\n1. Regular oscillations around 20 Hz – related to benzodiazepine\n      administration, sensorimotor activity\n\n  2. Less rhythmic oscillations between 14 and 30 Hz greatest during\n      mental thought and activity, such as completing a cognitive task\n\n- Evidence for existence of multiple beta rhythms\n\nGamma 30 Hz+\n\n## Conclusions\n\n1. Oscillations are part of how the brain organises perception, cognition and action\n2. We can measure brain oscillations using various methods: EEG is the most accessible and non-invasive\n3. Brain oscillations are altered in a number of brain and mental health conditions\n4. Stimulating oscillations via entrainment may have therapeutic benefits for various disorders, including dementia\n5. Brain oscillations and their measurement opens up new possibilities for brain machine/computer interfaces, which hold exciting therapeutic possibilities for those affected by neural degeneration or brain injury\n\n\n\n---\n\n# Bayesian optimisation machine learning (Machine Learning Applied to Neurosciences)\n\n## Optimization\n\n### learning objectives\n\n1. Distinguishing between Artificial Intelligence and Machine Learning;\n2. Develop an understanding of how machines learn from data;\n3. Understanding the concepts of bias and variance and how to balance them;\n4. Understanding the advantages and shortcomings of using Machine Learning for modelling the brain and behaviour\n\nAI and ML are different concepts: AI encapsulates ML:\n\n![AI encapsulates ML](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081144280.png)\n\nIn Machine Learning models learn from experience. In supervised learning\nthey use their errors to adapt their behaviour;\n\n### Supervised learning\n\n\n\n![Supervised learning](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081157396.png)\n\nClassification (focuses on predicting a label) & Regression (focuses on predicting a quantity)\n\n### Unsupervised learning\n\n![Unsupervised learning](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158374.png)\n\nExample of unsupervised learning – K-means clustering\n\nhttps://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n\n### Reinforcement learning\n\n![Reinforcement learning](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158238.png)\n\nHowever the fitting can be underfitting or overfitting\n\n| Underfitting                                                 | overfitting                                                  |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| model has limited flexibility to learn the true signal.<br/>high bias.<br/>solution :increase number of features. | model is too complex and is fitting to noise instead of the signal.<br/>high variance.<br/>solutions:<br/>1. increase number of samples;<br/>2. separate training and test sets;<br/>3. constrain the parameters to reduce complexity (regularization). |\n\n![Underfitting vs overfitting](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081207107.png)\n\nWhat happens as we train a model:\n\n![image-20220308121253647](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081212722.png)\n\nWhen fitting a model, one should avoid errors of bias and variance by using a\ntraining, a validation and a test set.\n\nThere have been some interesting results in modelling the brain with machine\nlearning but it still has some limitations.\n\n**Clinical implementation pros and cons:**\n\nPros:\n\n- high precision\n- allows almost immediate diagnosis\n- can scale to places with scarcity of resources\n\nCons:\n\n- lack of explainibility\n- problem with generalisation\n\nBayesian optimization is a method to find the maximum of expensive functions\n\n## Conclusion:\n\n- AI and ML are different concepts: AI encapsulates ML;\n- In Machine Learning models learn from experience. In supervised learning they use their errors to adapt their behaviour;\n- When fitting a model, one should avoid errors of bias and variance by using a training, a validation and a test set;\n- There have been some interesting results in modelling the brain with machine learning but it still has some limitations.\n\n---\n\n# Clinical application of fMRI feedback\n\n## Objective\n\n- To understand what real-time fMRI (rtfMRI) is and how it differs from conventional fMRI\n- To learn how and where rtfMRI can be implemented\n- To know some of the applications of rtfMRI\n- To understand neurofeedback in the context of rtfMRI\n- To know some of the applications of neurofeedback with real-time fMRI\n\n## Real time fMRI (rtfMRI)\n\n![Conventional fMRI](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409628.png)\n\n**What makes the results real-time**\n\n![Option 1](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409773.png)\n\n![Option 2](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081410689.png)\n\n### Optimising the pre-processing \n\nMost of the usual pre processing options have been adapted to run in real time.\n\nBut most often limited to real time motion correction and some form of temporal smoothing (detrending)\n\n**What can make the fMRI steps run faster:**\n\nAll the fMRI steps can be made to run faster:\n\n1. Image acquisition\n2. Image reconstruction\n3. Pre-processing\n4. Statistical analysis\n\n### Application s of real-time fMRI:\n\n1. Quality control\n2. Branching protocols\n3. Presurgical mapping\n4. Neurofeedback\n\n**Real time fMRI for quality control:**\n\n- Real-time fMRI makes it possible to detect problems as they happen\n- You can stop/restart the scan if needed (e.g., when participant is not doing the task or moving too much)\n- Especially important for (rare) patients, children or elderly who may not come back\n- Test and tweak experimental protocol during scan\n- Change difficulty / stimulation levels\n- Test different hardware\n- Detect non-desirable cognitive strategies (e.g., verbal strategy during pictorial delayed matched to sample (DMTS) task)\n- Cut task short when analysis results are stable\n- Can lead to reduced costs, anxiety, habituation, and boredom\n\n## Neurofeedback\n\nBiofeedback is employed to control body functions which are not generally directly accessible, or which cannot be evaluated. \n\nBiofeedback is called neurofeedback when it is about the control of brain functions.\n\n**Implementation of neurofeedback with rtfMRI:**\n\n![Option 1](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081433572.png)\n\n![Option 2](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081434417.png)\n\nReal time fMRI Neurofeedback may improve chronic **Tinnitus**: DOI: 0.007/s00330-009-1595-z\n\n**Stroke**: DOI: 10.1177/1545968311418345 \n\nBrain Computer Interface (BCI)\n\n---\n\n# Neuroscience of fear, anxiety and defence\n\n## Learning objectives\n\n1. Understand the relationship between defensive behaviour and\nthe situation.\n2. Understand how anti-anxiety drugs can be used to study\ndefensive behaviour.\n3. Understand how abstract stimuli affect anxiety.\n\n## Anxiety\n\n### Definition\n\nJeffrey Gray’s definition: whatever is affected by anti-anxiety drugs. This is not a circular argument because he found these drugs also affect punishment-related behaviour in rodents, increasing approach to locations or stimuli that have been associated with painful electric shock.\n\nExtended and refined by Philip Corr and Neil McNaughton: This has resulted in the key theory of defensive direction, which splits general punishment/threat sensitivity into sensitivity to threats that require approach  (anxiety-proneness) and sensitivity to threats that need not be approached\n(fear-proneness).\n\nSøren Kierkegaard, The Concept of Anxiety (1844): Anxiety informs us of our choices, our self-awareness and personal responsibility, and brings us from a state of un-self-conscious immediacy to self-conscious reflection.\n\n**How can we test abstract anxiety objectively?**\n\nThe moral dilemma task\n\n![Lorazepam studies](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302004197.png)\n\n## Summary\n\nThis research (Adam Perkins) shows that the same anti-anxiety drug affects responses to threat and moral judgment, suggesting that the same brain systems underlie both processes and that previously abstract philosophical concepts may be explained in functional, evolutionary terms.\n\n\n\n# Vocabularies\n\n**Entrainment**:  the process of making something have the same pattern or rhythm as something else\n\n**BCI**: brain computer interface\n\n**Lorazepam**: a drug of the benzodiazepine group, used especially to treat anxiety.\n","source":"_posts/08_03_22.md","raw":"---\ntitle: Lecture Notes 08/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-08 10:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n# EEG Oscillations\n\nThere are different ways to measure oscillations![different methods to measure oscillations](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081018999.png)\n\nLFP: local field potential\n\nEEG: electroencephalography\n\nEcoG: Electrocorticography\n\nMEG is not commonly used because it is expensive\n\n## FASTFOURIER TRANSFORM (FFT): Delta, Theta, Alpha, Beta, Gamma\n\nA Fourier transform (FT) is a mathematical transform that decomposes functions depending on **space** or **time** into functions depending on spatial frequency or temporal frequency.\n\n![image-20220308102128935](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081040845.png)\n\nDelta 1 – 3.5 Hz\n\n- Most strongly associated with slow wave sleep in healthy adults, and seen in young infants\n- In an awake person, can be related to brain pathology, e.g. stroke, brain trauma, brain infection\n- The slow fluctuations need to be distinguished from artifacts with similar temporal activity, e.g. respiration, perspiration\n\nTheta 3.5 – 7.5 Hz\n\n- Whole brain theta linked to arousal, sleep \n- In conflict tasks FM theta represents processes involved in the timing of cognitive synchronisation -packaging of information for communication in the cortex, e.g. theta-gamma coupling\n- Theta waves (6 Hz) studied in “place cells” by O’Keefe and Nadel in rat hippocampus\n\nAlpha 7.5 – 12.5 Hz\n\n- Strong, clear and characteristic wave observable even in raw data e.g. “Berger’s wave”\n- Produced when quietly sitting in relaxed position, enhanced with eyes closed\n- Generally, mental activity is associated with reduced alpha power\n\nBeta 12.5 – ~30 Hz (or low/high)\n\n- Two subtypes of beta oscillations:\n1. Regular oscillations around 20 Hz – related to benzodiazepine\n      administration, sensorimotor activity\n\n  2. Less rhythmic oscillations between 14 and 30 Hz greatest during\n      mental thought and activity, such as completing a cognitive task\n\n- Evidence for existence of multiple beta rhythms\n\nGamma 30 Hz+\n\n## Conclusions\n\n1. Oscillations are part of how the brain organises perception, cognition and action\n2. We can measure brain oscillations using various methods: EEG is the most accessible and non-invasive\n3. Brain oscillations are altered in a number of brain and mental health conditions\n4. Stimulating oscillations via entrainment may have therapeutic benefits for various disorders, including dementia\n5. Brain oscillations and their measurement opens up new possibilities for brain machine/computer interfaces, which hold exciting therapeutic possibilities for those affected by neural degeneration or brain injury\n\n\n\n---\n\n# Bayesian optimisation machine learning (Machine Learning Applied to Neurosciences)\n\n## Optimization\n\n### learning objectives\n\n1. Distinguishing between Artificial Intelligence and Machine Learning;\n2. Develop an understanding of how machines learn from data;\n3. Understanding the concepts of bias and variance and how to balance them;\n4. Understanding the advantages and shortcomings of using Machine Learning for modelling the brain and behaviour\n\nAI and ML are different concepts: AI encapsulates ML:\n\n![AI encapsulates ML](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081144280.png)\n\nIn Machine Learning models learn from experience. In supervised learning\nthey use their errors to adapt their behaviour;\n\n### Supervised learning\n\n\n\n![Supervised learning](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081157396.png)\n\nClassification (focuses on predicting a label) & Regression (focuses on predicting a quantity)\n\n### Unsupervised learning\n\n![Unsupervised learning](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158374.png)\n\nExample of unsupervised learning – K-means clustering\n\nhttps://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n\n### Reinforcement learning\n\n![Reinforcement learning](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158238.png)\n\nHowever the fitting can be underfitting or overfitting\n\n| Underfitting                                                 | overfitting                                                  |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| model has limited flexibility to learn the true signal.<br/>high bias.<br/>solution :increase number of features. | model is too complex and is fitting to noise instead of the signal.<br/>high variance.<br/>solutions:<br/>1. increase number of samples;<br/>2. separate training and test sets;<br/>3. constrain the parameters to reduce complexity (regularization). |\n\n![Underfitting vs overfitting](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081207107.png)\n\nWhat happens as we train a model:\n\n![image-20220308121253647](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081212722.png)\n\nWhen fitting a model, one should avoid errors of bias and variance by using a\ntraining, a validation and a test set.\n\nThere have been some interesting results in modelling the brain with machine\nlearning but it still has some limitations.\n\n**Clinical implementation pros and cons:**\n\nPros:\n\n- high precision\n- allows almost immediate diagnosis\n- can scale to places with scarcity of resources\n\nCons:\n\n- lack of explainibility\n- problem with generalisation\n\nBayesian optimization is a method to find the maximum of expensive functions\n\n## Conclusion:\n\n- AI and ML are different concepts: AI encapsulates ML;\n- In Machine Learning models learn from experience. In supervised learning they use their errors to adapt their behaviour;\n- When fitting a model, one should avoid errors of bias and variance by using a training, a validation and a test set;\n- There have been some interesting results in modelling the brain with machine learning but it still has some limitations.\n\n---\n\n# Clinical application of fMRI feedback\n\n## Objective\n\n- To understand what real-time fMRI (rtfMRI) is and how it differs from conventional fMRI\n- To learn how and where rtfMRI can be implemented\n- To know some of the applications of rtfMRI\n- To understand neurofeedback in the context of rtfMRI\n- To know some of the applications of neurofeedback with real-time fMRI\n\n## Real time fMRI (rtfMRI)\n\n![Conventional fMRI](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409628.png)\n\n**What makes the results real-time**\n\n![Option 1](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409773.png)\n\n![Option 2](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081410689.png)\n\n### Optimising the pre-processing \n\nMost of the usual pre processing options have been adapted to run in real time.\n\nBut most often limited to real time motion correction and some form of temporal smoothing (detrending)\n\n**What can make the fMRI steps run faster:**\n\nAll the fMRI steps can be made to run faster:\n\n1. Image acquisition\n2. Image reconstruction\n3. Pre-processing\n4. Statistical analysis\n\n### Application s of real-time fMRI:\n\n1. Quality control\n2. Branching protocols\n3. Presurgical mapping\n4. Neurofeedback\n\n**Real time fMRI for quality control:**\n\n- Real-time fMRI makes it possible to detect problems as they happen\n- You can stop/restart the scan if needed (e.g., when participant is not doing the task or moving too much)\n- Especially important for (rare) patients, children or elderly who may not come back\n- Test and tweak experimental protocol during scan\n- Change difficulty / stimulation levels\n- Test different hardware\n- Detect non-desirable cognitive strategies (e.g., verbal strategy during pictorial delayed matched to sample (DMTS) task)\n- Cut task short when analysis results are stable\n- Can lead to reduced costs, anxiety, habituation, and boredom\n\n## Neurofeedback\n\nBiofeedback is employed to control body functions which are not generally directly accessible, or which cannot be evaluated. \n\nBiofeedback is called neurofeedback when it is about the control of brain functions.\n\n**Implementation of neurofeedback with rtfMRI:**\n\n![Option 1](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081433572.png)\n\n![Option 2](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081434417.png)\n\nReal time fMRI Neurofeedback may improve chronic **Tinnitus**: DOI: 0.007/s00330-009-1595-z\n\n**Stroke**: DOI: 10.1177/1545968311418345 \n\nBrain Computer Interface (BCI)\n\n---\n\n# Neuroscience of fear, anxiety and defence\n\n## Learning objectives\n\n1. Understand the relationship between defensive behaviour and\nthe situation.\n2. Understand how anti-anxiety drugs can be used to study\ndefensive behaviour.\n3. Understand how abstract stimuli affect anxiety.\n\n## Anxiety\n\n### Definition\n\nJeffrey Gray’s definition: whatever is affected by anti-anxiety drugs. This is not a circular argument because he found these drugs also affect punishment-related behaviour in rodents, increasing approach to locations or stimuli that have been associated with painful electric shock.\n\nExtended and refined by Philip Corr and Neil McNaughton: This has resulted in the key theory of defensive direction, which splits general punishment/threat sensitivity into sensitivity to threats that require approach  (anxiety-proneness) and sensitivity to threats that need not be approached\n(fear-proneness).\n\nSøren Kierkegaard, The Concept of Anxiety (1844): Anxiety informs us of our choices, our self-awareness and personal responsibility, and brings us from a state of un-self-conscious immediacy to self-conscious reflection.\n\n**How can we test abstract anxiety objectively?**\n\nThe moral dilemma task\n\n![Lorazepam studies](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302004197.png)\n\n## Summary\n\nThis research (Adam Perkins) shows that the same anti-anxiety drug affects responses to threat and moral judgment, suggesting that the same brain systems underlie both processes and that previously abstract philosophical concepts may be explained in functional, evolutionary terms.\n\n\n\n# Vocabularies\n\n**Entrainment**:  the process of making something have the same pattern or rhythm as something else\n\n**BCI**: brain computer interface\n\n**Lorazepam**: a drug of the benzodiazepine group, used especially to treat anxiety.\n","slug":"08_03_22","published":1,"updated":"2022-08-24T17:08:39.302Z","comments":1,"layout":"post","photos":[],"_id":"cuidj2nhGs_L6P79IJY8t-7aG","content":"<h1 id=\"EEG-Oscillations\"><a href=\"#EEG-Oscillations\" class=\"headerlink\" title=\"EEG Oscillations\"></a>EEG Oscillations</h1><p>There are different ways to measure oscillations<img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081018999.png\" alt=\"different methods to measure oscillations\"></p>\n<p>LFP: local field potential</p>\n<p>EEG: electroencephalography</p>\n<p>EcoG: Electrocorticography</p>\n<p>MEG is not commonly used because it is expensive</p>\n<h2 id=\"FASTFOURIER-TRANSFORM-FFT-Delta-Theta-Alpha-Beta-Gamma\"><a href=\"#FASTFOURIER-TRANSFORM-FFT-Delta-Theta-Alpha-Beta-Gamma\" class=\"headerlink\" title=\"FASTFOURIER TRANSFORM (FFT): Delta, Theta, Alpha, Beta, Gamma\"></a>FASTFOURIER TRANSFORM (FFT): Delta, Theta, Alpha, Beta, Gamma</h2><p>A Fourier transform (FT) is a mathematical transform that decomposes functions depending on <strong>space</strong> or <strong>time</strong> into functions depending on spatial frequency or temporal frequency.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081040845.png\" alt=\"image-20220308102128935\"></p>\n<p>Delta 1 – 3.5 Hz</p>\n<ul>\n<li>Most strongly associated with slow wave sleep in healthy adults, and seen in young infants</li>\n<li>In an awake person, can be related to brain pathology, e.g. stroke, brain trauma, brain infection</li>\n<li>The slow fluctuations need to be distinguished from artifacts with similar temporal activity, e.g. respiration, perspiration</li>\n</ul>\n<p>Theta 3.5 – 7.5 Hz</p>\n<ul>\n<li>Whole brain theta linked to arousal, sleep </li>\n<li>In conflict tasks FM theta represents processes involved in the timing of cognitive synchronisation -packaging of information for communication in the cortex, e.g. theta-gamma coupling</li>\n<li>Theta waves (6 Hz) studied in “place cells” by O’Keefe and Nadel in rat hippocampus</li>\n</ul>\n<p>Alpha 7.5 – 12.5 Hz</p>\n<ul>\n<li>Strong, clear and characteristic wave observable even in raw data e.g. “Berger’s wave”</li>\n<li>Produced when quietly sitting in relaxed position, enhanced with eyes closed</li>\n<li>Generally, mental activity is associated with reduced alpha power</li>\n</ul>\n<p>Beta 12.5 – ~30 Hz (or low/high)</p>\n<ul>\n<li>Two subtypes of beta oscillations:</li>\n</ul>\n<ol>\n<li><p>Regular oscillations around 20 Hz – related to benzodiazepine<br>   administration, sensorimotor activity</p>\n<ol start=\"2\">\n<li>Less rhythmic oscillations between 14 and 30 Hz greatest during<br>mental thought and activity, such as completing a cognitive task</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li>Evidence for existence of multiple beta rhythms</li>\n</ul>\n<p>Gamma 30 Hz+</p>\n<h2 id=\"Conclusions\"><a href=\"#Conclusions\" class=\"headerlink\" title=\"Conclusions\"></a>Conclusions</h2><ol>\n<li>Oscillations are part of how the brain organises perception, cognition and action</li>\n<li>We can measure brain oscillations using various methods: EEG is the most accessible and non-invasive</li>\n<li>Brain oscillations are altered in a number of brain and mental health conditions</li>\n<li>Stimulating oscillations via entrainment may have therapeutic benefits for various disorders, including dementia</li>\n<li>Brain oscillations and their measurement opens up new possibilities for brain machine/computer interfaces, which hold exciting therapeutic possibilities for those affected by neural degeneration or brain injury</li>\n</ol>\n<hr>\n<h1 id=\"Bayesian-optimisation-machine-learning-Machine-Learning-Applied-to-Neurosciences\"><a href=\"#Bayesian-optimisation-machine-learning-Machine-Learning-Applied-to-Neurosciences\" class=\"headerlink\" title=\"Bayesian optimisation machine learning (Machine Learning Applied to Neurosciences)\"></a>Bayesian optimisation machine learning (Machine Learning Applied to Neurosciences)</h1><h2 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h2><h3 id=\"learning-objectives\"><a href=\"#learning-objectives\" class=\"headerlink\" title=\"learning objectives\"></a>learning objectives</h3><ol>\n<li>Distinguishing between Artificial Intelligence and Machine Learning;</li>\n<li>Develop an understanding of how machines learn from data;</li>\n<li>Understanding the concepts of bias and variance and how to balance them;</li>\n<li>Understanding the advantages and shortcomings of using Machine Learning for modelling the brain and behaviour</li>\n</ol>\n<p>AI and ML are different concepts: AI encapsulates ML:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081144280.png\" alt=\"AI encapsulates ML\"></p>\n<p>In Machine Learning models learn from experience. In supervised learning<br>they use their errors to adapt their behaviour;</p>\n<h3 id=\"Supervised-learning\"><a href=\"#Supervised-learning\" class=\"headerlink\" title=\"Supervised learning\"></a>Supervised learning</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081157396.png\" alt=\"Supervised learning\"></p>\n<p>Classification (focuses on predicting a label) &amp; Regression (focuses on predicting a quantity)</p>\n<h3 id=\"Unsupervised-learning\"><a href=\"#Unsupervised-learning\" class=\"headerlink\" title=\"Unsupervised learning\"></a>Unsupervised learning</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158374.png\" alt=\"Unsupervised learning\"></p>\n<p>Example of unsupervised learning – K-means clustering</p>\n<p><a href=\"https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\">https://www.naftaliharris.com/blog/visualizing-k-means-clustering/</a></p>\n<h3 id=\"Reinforcement-learning\"><a href=\"#Reinforcement-learning\" class=\"headerlink\" title=\"Reinforcement learning\"></a>Reinforcement learning</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158238.png\" alt=\"Reinforcement learning\"></p>\n<p>However the fitting can be underfitting or overfitting</p>\n<table>\n<thead>\n<tr>\n<th>Underfitting</th>\n<th>overfitting</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>model has limited flexibility to learn the true signal.<br/>high bias.<br/>solution :increase number of features.</td>\n<td>model is too complex and is fitting to noise instead of the signal.<br/>high variance.<br/>solutions:<br/>1. increase number of samples;<br/>2. separate training and test sets;<br/>3. constrain the parameters to reduce complexity (regularization).</td>\n</tr>\n</tbody></table>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081207107.png\" alt=\"Underfitting vs overfitting\"></p>\n<p>What happens as we train a model:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081212722.png\" alt=\"image-20220308121253647\"></p>\n<p>When fitting a model, one should avoid errors of bias and variance by using a<br>training, a validation and a test set.</p>\n<p>There have been some interesting results in modelling the brain with machine<br>learning but it still has some limitations.</p>\n<p><strong>Clinical implementation pros and cons:</strong></p>\n<p>Pros:</p>\n<ul>\n<li>high precision</li>\n<li>allows almost immediate diagnosis</li>\n<li>can scale to places with scarcity of resources</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>lack of explainibility</li>\n<li>problem with generalisation</li>\n</ul>\n<p>Bayesian optimization is a method to find the maximum of expensive functions</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion:\"></a>Conclusion:</h2><ul>\n<li>AI and ML are different concepts: AI encapsulates ML;</li>\n<li>In Machine Learning models learn from experience. In supervised learning they use their errors to adapt their behaviour;</li>\n<li>When fitting a model, one should avoid errors of bias and variance by using a training, a validation and a test set;</li>\n<li>There have been some interesting results in modelling the brain with machine learning but it still has some limitations.</li>\n</ul>\n<hr>\n<h1 id=\"Clinical-application-of-fMRI-feedback\"><a href=\"#Clinical-application-of-fMRI-feedback\" class=\"headerlink\" title=\"Clinical application of fMRI feedback\"></a>Clinical application of fMRI feedback</h1><h2 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective\"></a>Objective</h2><ul>\n<li>To understand what real-time fMRI (rtfMRI) is and how it differs from conventional fMRI</li>\n<li>To learn how and where rtfMRI can be implemented</li>\n<li>To know some of the applications of rtfMRI</li>\n<li>To understand neurofeedback in the context of rtfMRI</li>\n<li>To know some of the applications of neurofeedback with real-time fMRI</li>\n</ul>\n<h2 id=\"Real-time-fMRI-rtfMRI\"><a href=\"#Real-time-fMRI-rtfMRI\" class=\"headerlink\" title=\"Real time fMRI (rtfMRI)\"></a>Real time fMRI (rtfMRI)</h2><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409628.png\" alt=\"Conventional fMRI\"></p>\n<p><strong>What makes the results real-time</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409773.png\" alt=\"Option 1\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081410689.png\" alt=\"Option 2\"></p>\n<h3 id=\"Optimising-the-pre-processing\"><a href=\"#Optimising-the-pre-processing\" class=\"headerlink\" title=\"Optimising the pre-processing\"></a>Optimising the pre-processing</h3><p>Most of the usual pre processing options have been adapted to run in real time.</p>\n<p>But most often limited to real time motion correction and some form of temporal smoothing (detrending)</p>\n<p><strong>What can make the fMRI steps run faster:</strong></p>\n<p>All the fMRI steps can be made to run faster:</p>\n<ol>\n<li>Image acquisition</li>\n<li>Image reconstruction</li>\n<li>Pre-processing</li>\n<li>Statistical analysis</li>\n</ol>\n<h3 id=\"Application-s-of-real-time-fMRI\"><a href=\"#Application-s-of-real-time-fMRI\" class=\"headerlink\" title=\"Application s of real-time fMRI:\"></a>Application s of real-time fMRI:</h3><ol>\n<li>Quality control</li>\n<li>Branching protocols</li>\n<li>Presurgical mapping</li>\n<li>Neurofeedback</li>\n</ol>\n<p><strong>Real time fMRI for quality control:</strong></p>\n<ul>\n<li>Real-time fMRI makes it possible to detect problems as they happen</li>\n<li>You can stop/restart the scan if needed (e.g., when participant is not doing the task or moving too much)</li>\n<li>Especially important for (rare) patients, children or elderly who may not come back</li>\n<li>Test and tweak experimental protocol during scan</li>\n<li>Change difficulty / stimulation levels</li>\n<li>Test different hardware</li>\n<li>Detect non-desirable cognitive strategies (e.g., verbal strategy during pictorial delayed matched to sample (DMTS) task)</li>\n<li>Cut task short when analysis results are stable</li>\n<li>Can lead to reduced costs, anxiety, habituation, and boredom</li>\n</ul>\n<h2 id=\"Neurofeedback\"><a href=\"#Neurofeedback\" class=\"headerlink\" title=\"Neurofeedback\"></a>Neurofeedback</h2><p>Biofeedback is employed to control body functions which are not generally directly accessible, or which cannot be evaluated. </p>\n<p>Biofeedback is called neurofeedback when it is about the control of brain functions.</p>\n<p><strong>Implementation of neurofeedback with rtfMRI:</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081433572.png\" alt=\"Option 1\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081434417.png\" alt=\"Option 2\"></p>\n<p>Real time fMRI Neurofeedback may improve chronic <strong>Tinnitus</strong>: DOI: 0.007/s00330-009-1595-z</p>\n<p><strong>Stroke</strong>: DOI: 10.1177/1545968311418345 </p>\n<p>Brain Computer Interface (BCI)</p>\n<hr>\n<h1 id=\"Neuroscience-of-fear-anxiety-and-defence\"><a href=\"#Neuroscience-of-fear-anxiety-and-defence\" class=\"headerlink\" title=\"Neuroscience of fear, anxiety and defence\"></a>Neuroscience of fear, anxiety and defence</h1><h2 id=\"Learning-objectives\"><a href=\"#Learning-objectives\" class=\"headerlink\" title=\"Learning objectives\"></a>Learning objectives</h2><ol>\n<li>Understand the relationship between defensive behaviour and<br>the situation.</li>\n<li>Understand how anti-anxiety drugs can be used to study<br>defensive behaviour.</li>\n<li>Understand how abstract stimuli affect anxiety.</li>\n</ol>\n<h2 id=\"Anxiety\"><a href=\"#Anxiety\" class=\"headerlink\" title=\"Anxiety\"></a>Anxiety</h2><h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>Jeffrey Gray’s definition: whatever is affected by anti-anxiety drugs. This is not a circular argument because he found these drugs also affect punishment-related behaviour in rodents, increasing approach to locations or stimuli that have been associated with painful electric shock.</p>\n<p>Extended and refined by Philip Corr and Neil McNaughton: This has resulted in the key theory of defensive direction, which splits general punishment/threat sensitivity into sensitivity to threats that require approach  (anxiety-proneness) and sensitivity to threats that need not be approached<br>(fear-proneness).</p>\n<p>Søren Kierkegaard, The Concept of Anxiety (1844): Anxiety informs us of our choices, our self-awareness and personal responsibility, and brings us from a state of un-self-conscious immediacy to self-conscious reflection.</p>\n<p><strong>How can we test abstract anxiety objectively?</strong></p>\n<p>The moral dilemma task</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302004197.png\" alt=\"Lorazepam studies\"></p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>This research (Adam Perkins) shows that the same anti-anxiety drug affects responses to threat and moral judgment, suggesting that the same brain systems underlie both processes and that previously abstract philosophical concepts may be explained in functional, evolutionary terms.</p>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>Entrainment</strong>:  the process of making something have the same pattern or rhythm as something else</p>\n<p><strong>BCI</strong>: brain computer interface</p>\n<p><strong>Lorazepam</strong>: a drug of the benzodiazepine group, used especially to treat anxiety.</p>\n","excerpt":"","more":"<h1 id=\"EEG-Oscillations\"><a href=\"#EEG-Oscillations\" class=\"headerlink\" title=\"EEG Oscillations\"></a>EEG Oscillations</h1><p>There are different ways to measure oscillations<img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081018999.png\" alt=\"different methods to measure oscillations\"></p>\n<p>LFP: local field potential</p>\n<p>EEG: electroencephalography</p>\n<p>EcoG: Electrocorticography</p>\n<p>MEG is not commonly used because it is expensive</p>\n<h2 id=\"FASTFOURIER-TRANSFORM-FFT-Delta-Theta-Alpha-Beta-Gamma\"><a href=\"#FASTFOURIER-TRANSFORM-FFT-Delta-Theta-Alpha-Beta-Gamma\" class=\"headerlink\" title=\"FASTFOURIER TRANSFORM (FFT): Delta, Theta, Alpha, Beta, Gamma\"></a>FASTFOURIER TRANSFORM (FFT): Delta, Theta, Alpha, Beta, Gamma</h2><p>A Fourier transform (FT) is a mathematical transform that decomposes functions depending on <strong>space</strong> or <strong>time</strong> into functions depending on spatial frequency or temporal frequency.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081040845.png\" alt=\"image-20220308102128935\"></p>\n<p>Delta 1 – 3.5 Hz</p>\n<ul>\n<li>Most strongly associated with slow wave sleep in healthy adults, and seen in young infants</li>\n<li>In an awake person, can be related to brain pathology, e.g. stroke, brain trauma, brain infection</li>\n<li>The slow fluctuations need to be distinguished from artifacts with similar temporal activity, e.g. respiration, perspiration</li>\n</ul>\n<p>Theta 3.5 – 7.5 Hz</p>\n<ul>\n<li>Whole brain theta linked to arousal, sleep </li>\n<li>In conflict tasks FM theta represents processes involved in the timing of cognitive synchronisation -packaging of information for communication in the cortex, e.g. theta-gamma coupling</li>\n<li>Theta waves (6 Hz) studied in “place cells” by O’Keefe and Nadel in rat hippocampus</li>\n</ul>\n<p>Alpha 7.5 – 12.5 Hz</p>\n<ul>\n<li>Strong, clear and characteristic wave observable even in raw data e.g. “Berger’s wave”</li>\n<li>Produced when quietly sitting in relaxed position, enhanced with eyes closed</li>\n<li>Generally, mental activity is associated with reduced alpha power</li>\n</ul>\n<p>Beta 12.5 – ~30 Hz (or low/high)</p>\n<ul>\n<li>Two subtypes of beta oscillations:</li>\n</ul>\n<ol>\n<li><p>Regular oscillations around 20 Hz – related to benzodiazepine<br>   administration, sensorimotor activity</p>\n<ol start=\"2\">\n<li>Less rhythmic oscillations between 14 and 30 Hz greatest during<br>mental thought and activity, such as completing a cognitive task</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li>Evidence for existence of multiple beta rhythms</li>\n</ul>\n<p>Gamma 30 Hz+</p>\n<h2 id=\"Conclusions\"><a href=\"#Conclusions\" class=\"headerlink\" title=\"Conclusions\"></a>Conclusions</h2><ol>\n<li>Oscillations are part of how the brain organises perception, cognition and action</li>\n<li>We can measure brain oscillations using various methods: EEG is the most accessible and non-invasive</li>\n<li>Brain oscillations are altered in a number of brain and mental health conditions</li>\n<li>Stimulating oscillations via entrainment may have therapeutic benefits for various disorders, including dementia</li>\n<li>Brain oscillations and their measurement opens up new possibilities for brain machine/computer interfaces, which hold exciting therapeutic possibilities for those affected by neural degeneration or brain injury</li>\n</ol>\n<hr>\n<h1 id=\"Bayesian-optimisation-machine-learning-Machine-Learning-Applied-to-Neurosciences\"><a href=\"#Bayesian-optimisation-machine-learning-Machine-Learning-Applied-to-Neurosciences\" class=\"headerlink\" title=\"Bayesian optimisation machine learning (Machine Learning Applied to Neurosciences)\"></a>Bayesian optimisation machine learning (Machine Learning Applied to Neurosciences)</h1><h2 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h2><h3 id=\"learning-objectives\"><a href=\"#learning-objectives\" class=\"headerlink\" title=\"learning objectives\"></a>learning objectives</h3><ol>\n<li>Distinguishing between Artificial Intelligence and Machine Learning;</li>\n<li>Develop an understanding of how machines learn from data;</li>\n<li>Understanding the concepts of bias and variance and how to balance them;</li>\n<li>Understanding the advantages and shortcomings of using Machine Learning for modelling the brain and behaviour</li>\n</ol>\n<p>AI and ML are different concepts: AI encapsulates ML:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081144280.png\" alt=\"AI encapsulates ML\"></p>\n<p>In Machine Learning models learn from experience. In supervised learning<br>they use their errors to adapt their behaviour;</p>\n<h3 id=\"Supervised-learning\"><a href=\"#Supervised-learning\" class=\"headerlink\" title=\"Supervised learning\"></a>Supervised learning</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081157396.png\" alt=\"Supervised learning\"></p>\n<p>Classification (focuses on predicting a label) &amp; Regression (focuses on predicting a quantity)</p>\n<h3 id=\"Unsupervised-learning\"><a href=\"#Unsupervised-learning\" class=\"headerlink\" title=\"Unsupervised learning\"></a>Unsupervised learning</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158374.png\" alt=\"Unsupervised learning\"></p>\n<p>Example of unsupervised learning – K-means clustering</p>\n<p><a href=\"https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\">https://www.naftaliharris.com/blog/visualizing-k-means-clustering/</a></p>\n<h3 id=\"Reinforcement-learning\"><a href=\"#Reinforcement-learning\" class=\"headerlink\" title=\"Reinforcement learning\"></a>Reinforcement learning</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081158238.png\" alt=\"Reinforcement learning\"></p>\n<p>However the fitting can be underfitting or overfitting</p>\n<table>\n<thead>\n<tr>\n<th>Underfitting</th>\n<th>overfitting</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>model has limited flexibility to learn the true signal.<br/>high bias.<br/>solution :increase number of features.</td>\n<td>model is too complex and is fitting to noise instead of the signal.<br/>high variance.<br/>solutions:<br/>1. increase number of samples;<br/>2. separate training and test sets;<br/>3. constrain the parameters to reduce complexity (regularization).</td>\n</tr>\n</tbody></table>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081207107.png\" alt=\"Underfitting vs overfitting\"></p>\n<p>What happens as we train a model:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081212722.png\" alt=\"image-20220308121253647\"></p>\n<p>When fitting a model, one should avoid errors of bias and variance by using a<br>training, a validation and a test set.</p>\n<p>There have been some interesting results in modelling the brain with machine<br>learning but it still has some limitations.</p>\n<p><strong>Clinical implementation pros and cons:</strong></p>\n<p>Pros:</p>\n<ul>\n<li>high precision</li>\n<li>allows almost immediate diagnosis</li>\n<li>can scale to places with scarcity of resources</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>lack of explainibility</li>\n<li>problem with generalisation</li>\n</ul>\n<p>Bayesian optimization is a method to find the maximum of expensive functions</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion:\"></a>Conclusion:</h2><ul>\n<li>AI and ML are different concepts: AI encapsulates ML;</li>\n<li>In Machine Learning models learn from experience. In supervised learning they use their errors to adapt their behaviour;</li>\n<li>When fitting a model, one should avoid errors of bias and variance by using a training, a validation and a test set;</li>\n<li>There have been some interesting results in modelling the brain with machine learning but it still has some limitations.</li>\n</ul>\n<hr>\n<h1 id=\"Clinical-application-of-fMRI-feedback\"><a href=\"#Clinical-application-of-fMRI-feedback\" class=\"headerlink\" title=\"Clinical application of fMRI feedback\"></a>Clinical application of fMRI feedback</h1><h2 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective\"></a>Objective</h2><ul>\n<li>To understand what real-time fMRI (rtfMRI) is and how it differs from conventional fMRI</li>\n<li>To learn how and where rtfMRI can be implemented</li>\n<li>To know some of the applications of rtfMRI</li>\n<li>To understand neurofeedback in the context of rtfMRI</li>\n<li>To know some of the applications of neurofeedback with real-time fMRI</li>\n</ul>\n<h2 id=\"Real-time-fMRI-rtfMRI\"><a href=\"#Real-time-fMRI-rtfMRI\" class=\"headerlink\" title=\"Real time fMRI (rtfMRI)\"></a>Real time fMRI (rtfMRI)</h2><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409628.png\" alt=\"Conventional fMRI\"></p>\n<p><strong>What makes the results real-time</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081409773.png\" alt=\"Option 1\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081410689.png\" alt=\"Option 2\"></p>\n<h3 id=\"Optimising-the-pre-processing\"><a href=\"#Optimising-the-pre-processing\" class=\"headerlink\" title=\"Optimising the pre-processing\"></a>Optimising the pre-processing</h3><p>Most of the usual pre processing options have been adapted to run in real time.</p>\n<p>But most often limited to real time motion correction and some form of temporal smoothing (detrending)</p>\n<p><strong>What can make the fMRI steps run faster:</strong></p>\n<p>All the fMRI steps can be made to run faster:</p>\n<ol>\n<li>Image acquisition</li>\n<li>Image reconstruction</li>\n<li>Pre-processing</li>\n<li>Statistical analysis</li>\n</ol>\n<h3 id=\"Application-s-of-real-time-fMRI\"><a href=\"#Application-s-of-real-time-fMRI\" class=\"headerlink\" title=\"Application s of real-time fMRI:\"></a>Application s of real-time fMRI:</h3><ol>\n<li>Quality control</li>\n<li>Branching protocols</li>\n<li>Presurgical mapping</li>\n<li>Neurofeedback</li>\n</ol>\n<p><strong>Real time fMRI for quality control:</strong></p>\n<ul>\n<li>Real-time fMRI makes it possible to detect problems as they happen</li>\n<li>You can stop/restart the scan if needed (e.g., when participant is not doing the task or moving too much)</li>\n<li>Especially important for (rare) patients, children or elderly who may not come back</li>\n<li>Test and tweak experimental protocol during scan</li>\n<li>Change difficulty / stimulation levels</li>\n<li>Test different hardware</li>\n<li>Detect non-desirable cognitive strategies (e.g., verbal strategy during pictorial delayed matched to sample (DMTS) task)</li>\n<li>Cut task short when analysis results are stable</li>\n<li>Can lead to reduced costs, anxiety, habituation, and boredom</li>\n</ul>\n<h2 id=\"Neurofeedback\"><a href=\"#Neurofeedback\" class=\"headerlink\" title=\"Neurofeedback\"></a>Neurofeedback</h2><p>Biofeedback is employed to control body functions which are not generally directly accessible, or which cannot be evaluated. </p>\n<p>Biofeedback is called neurofeedback when it is about the control of brain functions.</p>\n<p><strong>Implementation of neurofeedback with rtfMRI:</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081433572.png\" alt=\"Option 1\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203081434417.png\" alt=\"Option 2\"></p>\n<p>Real time fMRI Neurofeedback may improve chronic <strong>Tinnitus</strong>: DOI: 0.007/s00330-009-1595-z</p>\n<p><strong>Stroke</strong>: DOI: 10.1177/1545968311418345 </p>\n<p>Brain Computer Interface (BCI)</p>\n<hr>\n<h1 id=\"Neuroscience-of-fear-anxiety-and-defence\"><a href=\"#Neuroscience-of-fear-anxiety-and-defence\" class=\"headerlink\" title=\"Neuroscience of fear, anxiety and defence\"></a>Neuroscience of fear, anxiety and defence</h1><h2 id=\"Learning-objectives\"><a href=\"#Learning-objectives\" class=\"headerlink\" title=\"Learning objectives\"></a>Learning objectives</h2><ol>\n<li>Understand the relationship between defensive behaviour and<br>the situation.</li>\n<li>Understand how anti-anxiety drugs can be used to study<br>defensive behaviour.</li>\n<li>Understand how abstract stimuli affect anxiety.</li>\n</ol>\n<h2 id=\"Anxiety\"><a href=\"#Anxiety\" class=\"headerlink\" title=\"Anxiety\"></a>Anxiety</h2><h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>Jeffrey Gray’s definition: whatever is affected by anti-anxiety drugs. This is not a circular argument because he found these drugs also affect punishment-related behaviour in rodents, increasing approach to locations or stimuli that have been associated with painful electric shock.</p>\n<p>Extended and refined by Philip Corr and Neil McNaughton: This has resulted in the key theory of defensive direction, which splits general punishment/threat sensitivity into sensitivity to threats that require approach  (anxiety-proneness) and sensitivity to threats that need not be approached<br>(fear-proneness).</p>\n<p>Søren Kierkegaard, The Concept of Anxiety (1844): Anxiety informs us of our choices, our self-awareness and personal responsibility, and brings us from a state of un-self-conscious immediacy to self-conscious reflection.</p>\n<p><strong>How can we test abstract anxiety objectively?</strong></p>\n<p>The moral dilemma task</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302004197.png\" alt=\"Lorazepam studies\"></p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>This research (Adam Perkins) shows that the same anti-anxiety drug affects responses to threat and moral judgment, suggesting that the same brain systems underlie both processes and that previously abstract philosophical concepts may be explained in functional, evolutionary terms.</p>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>Entrainment</strong>:  the process of making something have the same pattern or rhythm as something else</p>\n<p><strong>BCI</strong>: brain computer interface</p>\n<p><strong>Lorazepam</strong>: a drug of the benzodiazepine group, used especially to treat anxiety.</p>\n"},{"title":"Lecture Notes 09/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-09T18:00:00.000Z","password":null,"summary":null,"_content":"\n## Abstract\n\nquick overviews (**What you have done**) avoid to use 'I will'\n\nkey words\n\n### How\n\nthe key is structure\n\n| Background/introduction | 25%  |\n| ----------------------- | ---- |\n| Method                  | 25%  |\n| conclusion              | 35%  |\n| results                 | 15%  |\n\n#### Background/introduction  \n\ngive starting point, get the salient points across\n\nbe tailored to the level that you expect the audience have\n\n##### Aim/objective\n\nmost important part\n\nshort, relevant, specific and measurable\n\n#### Methods\n\nvariable (can be in detail or succinctly depending on the projects)\n\noutcome measure and how to measure (secondary one can be absence if there is a word limitation)\n\nstatistical method, how it is important\n\n#### Results\n\nrelevant values (like p-values; in correlation, like r value)\n\n#### Conclusions/implications\n\nstudied' contribution\n\nTake-home message\n\nit is good to relate it back to the aim \n\nno specific number\n\ncan add future direction\n\n## Task\n\n### Background/introduction \n\nThe previous research has stated that social cues could play an important role in one's socioemotional regulation. In this study, the longitudinal associations between children and parents are verified to serve as a potential social buffer to adolescent behavioral and neurobiological regulation and ameliorate false alarms and brain activation toward affective cues.\n\n51 adolescents with ages ranging between 31 and 35 months were classified into secure group and insecure group by a modified 17-minute Strange Situation procedure. We then analyzed the data of behaviour and fMRI from those adolescents when they were completing social go-nogo tasks, compared the conditions of presence of their parents and the adolescents alone without parents.\n\nIn false alarm test, appetitive group shows significant difference between secure and insecure. Aversive model indicates that secure adolescents alone have better behavioral regulation and with parental presence there are promotion in insecure adolescents' regulation. \n\nFindings show the presence of a parent promote regulation for insecure adolescents in aversive social contexts. Further supported by the reduction of hyperactivity in brain regions associated with socioemotional processing in the presence of a parent. \n\n","source":"_posts/09_02_22.md","raw":"---\ntitle: Lecture Notes 09/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-09 18:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n\n---\n\n## Abstract\n\nquick overviews (**What you have done**) avoid to use 'I will'\n\nkey words\n\n### How\n\nthe key is structure\n\n| Background/introduction | 25%  |\n| ----------------------- | ---- |\n| Method                  | 25%  |\n| conclusion              | 35%  |\n| results                 | 15%  |\n\n#### Background/introduction  \n\ngive starting point, get the salient points across\n\nbe tailored to the level that you expect the audience have\n\n##### Aim/objective\n\nmost important part\n\nshort, relevant, specific and measurable\n\n#### Methods\n\nvariable (can be in detail or succinctly depending on the projects)\n\noutcome measure and how to measure (secondary one can be absence if there is a word limitation)\n\nstatistical method, how it is important\n\n#### Results\n\nrelevant values (like p-values; in correlation, like r value)\n\n#### Conclusions/implications\n\nstudied' contribution\n\nTake-home message\n\nit is good to relate it back to the aim \n\nno specific number\n\ncan add future direction\n\n## Task\n\n### Background/introduction \n\nThe previous research has stated that social cues could play an important role in one's socioemotional regulation. In this study, the longitudinal associations between children and parents are verified to serve as a potential social buffer to adolescent behavioral and neurobiological regulation and ameliorate false alarms and brain activation toward affective cues.\n\n51 adolescents with ages ranging between 31 and 35 months were classified into secure group and insecure group by a modified 17-minute Strange Situation procedure. We then analyzed the data of behaviour and fMRI from those adolescents when they were completing social go-nogo tasks, compared the conditions of presence of their parents and the adolescents alone without parents.\n\nIn false alarm test, appetitive group shows significant difference between secure and insecure. Aversive model indicates that secure adolescents alone have better behavioral regulation and with parental presence there are promotion in insecure adolescents' regulation. \n\nFindings show the presence of a parent promote regulation for insecure adolescents in aversive social contexts. Further supported by the reduction of hyperactivity in brain regions associated with socioemotional processing in the presence of a parent. \n\n","slug":"09_02_22","published":1,"updated":"2022-08-24T17:08:39.302Z","comments":1,"layout":"post","photos":[],"_id":"cuidaWoIZsWDeYPrpvltEEuBO","content":"<h2 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h2><p>quick overviews (<strong>What you have done</strong>) avoid to use ‘I will’</p>\n<p>key words</p>\n<h3 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h3><p>the key is structure</p>\n<table>\n<thead>\n<tr>\n<th>Background/introduction</th>\n<th>25%</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Method</td>\n<td>25%</td>\n</tr>\n<tr>\n<td>conclusion</td>\n<td>35%</td>\n</tr>\n<tr>\n<td>results</td>\n<td>15%</td>\n</tr>\n</tbody></table>\n<h4 id=\"Background-introduction\"><a href=\"#Background-introduction\" class=\"headerlink\" title=\"Background/introduction\"></a>Background/introduction</h4><p>give starting point, get the salient points across</p>\n<p>be tailored to the level that you expect the audience have</p>\n<h5 id=\"Aim-objective\"><a href=\"#Aim-objective\" class=\"headerlink\" title=\"Aim/objective\"></a>Aim/objective</h5><p>most important part</p>\n<p>short, relevant, specific and measurable</p>\n<h4 id=\"Methods\"><a href=\"#Methods\" class=\"headerlink\" title=\"Methods\"></a>Methods</h4><p>variable (can be in detail or succinctly depending on the projects)</p>\n<p>outcome measure and how to measure (secondary one can be absence if there is a word limitation)</p>\n<p>statistical method, how it is important</p>\n<h4 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h4><p>relevant values (like p-values; in correlation, like r value)</p>\n<h4 id=\"Conclusions-implications\"><a href=\"#Conclusions-implications\" class=\"headerlink\" title=\"Conclusions/implications\"></a>Conclusions/implications</h4><p>studied’ contribution</p>\n<p>Take-home message</p>\n<p>it is good to relate it back to the aim </p>\n<p>no specific number</p>\n<p>can add future direction</p>\n<h2 id=\"Task\"><a href=\"#Task\" class=\"headerlink\" title=\"Task\"></a>Task</h2><h3 id=\"Background-introduction-1\"><a href=\"#Background-introduction-1\" class=\"headerlink\" title=\"Background/introduction\"></a>Background/introduction</h3><p>The previous research has stated that social cues could play an important role in one’s socioemotional regulation. In this study, the longitudinal associations between children and parents are verified to serve as a potential social buffer to adolescent behavioral and neurobiological regulation and ameliorate false alarms and brain activation toward affective cues.</p>\n<p>51 adolescents with ages ranging between 31 and 35 months were classified into secure group and insecure group by a modified 17-minute Strange Situation procedure. We then analyzed the data of behaviour and fMRI from those adolescents when they were completing social go-nogo tasks, compared the conditions of presence of their parents and the adolescents alone without parents.</p>\n<p>In false alarm test, appetitive group shows significant difference between secure and insecure. Aversive model indicates that secure adolescents alone have better behavioral regulation and with parental presence there are promotion in insecure adolescents’ regulation. </p>\n<p>Findings show the presence of a parent promote regulation for insecure adolescents in aversive social contexts. Further supported by the reduction of hyperactivity in brain regions associated with socioemotional processing in the presence of a parent. </p>\n","excerpt":"","more":"<h2 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h2><p>quick overviews (<strong>What you have done</strong>) avoid to use ‘I will’</p>\n<p>key words</p>\n<h3 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h3><p>the key is structure</p>\n<table>\n<thead>\n<tr>\n<th>Background/introduction</th>\n<th>25%</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Method</td>\n<td>25%</td>\n</tr>\n<tr>\n<td>conclusion</td>\n<td>35%</td>\n</tr>\n<tr>\n<td>results</td>\n<td>15%</td>\n</tr>\n</tbody></table>\n<h4 id=\"Background-introduction\"><a href=\"#Background-introduction\" class=\"headerlink\" title=\"Background/introduction\"></a>Background/introduction</h4><p>give starting point, get the salient points across</p>\n<p>be tailored to the level that you expect the audience have</p>\n<h5 id=\"Aim-objective\"><a href=\"#Aim-objective\" class=\"headerlink\" title=\"Aim/objective\"></a>Aim/objective</h5><p>most important part</p>\n<p>short, relevant, specific and measurable</p>\n<h4 id=\"Methods\"><a href=\"#Methods\" class=\"headerlink\" title=\"Methods\"></a>Methods</h4><p>variable (can be in detail or succinctly depending on the projects)</p>\n<p>outcome measure and how to measure (secondary one can be absence if there is a word limitation)</p>\n<p>statistical method, how it is important</p>\n<h4 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h4><p>relevant values (like p-values; in correlation, like r value)</p>\n<h4 id=\"Conclusions-implications\"><a href=\"#Conclusions-implications\" class=\"headerlink\" title=\"Conclusions/implications\"></a>Conclusions/implications</h4><p>studied’ contribution</p>\n<p>Take-home message</p>\n<p>it is good to relate it back to the aim </p>\n<p>no specific number</p>\n<p>can add future direction</p>\n<h2 id=\"Task\"><a href=\"#Task\" class=\"headerlink\" title=\"Task\"></a>Task</h2><h3 id=\"Background-introduction-1\"><a href=\"#Background-introduction-1\" class=\"headerlink\" title=\"Background/introduction\"></a>Background/introduction</h3><p>The previous research has stated that social cues could play an important role in one’s socioemotional regulation. In this study, the longitudinal associations between children and parents are verified to serve as a potential social buffer to adolescent behavioral and neurobiological regulation and ameliorate false alarms and brain activation toward affective cues.</p>\n<p>51 adolescents with ages ranging between 31 and 35 months were classified into secure group and insecure group by a modified 17-minute Strange Situation procedure. We then analyzed the data of behaviour and fMRI from those adolescents when they were completing social go-nogo tasks, compared the conditions of presence of their parents and the adolescents alone without parents.</p>\n<p>In false alarm test, appetitive group shows significant difference between secure and insecure. Aversive model indicates that secure adolescents alone have better behavioral regulation and with parental presence there are promotion in insecure adolescents’ regulation. </p>\n<p>Findings show the presence of a parent promote regulation for insecure adolescents in aversive social contexts. Further supported by the reduction of hyperactivity in brain regions associated with socioemotional processing in the presence of a parent. </p>\n"},{"title":"Lecture Notes 10/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-10T13:00:00.000Z","password":null,"summary":null,"_content":"# Mind wandering in ADHD\n\n## Objectives\n\n1.\tTo understand the mind wandering (MW) hypothesis of attention deficit/hyperactivity disorder(ADHD), (theoretical implications).\n2.\tTo understand the neural basis of mind wandering in ADHD.\n3.\tTo understand the clinical implication(s) of mind wandering in ADHD.\n\n## ADHD\n\nADHD: a common neurodevelopmental disorder, characterised by inattentive and hyperactive/impulsive behaviours which interfere with everyday functioning (Fayyad et al., 2007; Polanczyk et al., 2007).\n\nADHD diagnosis: DIVA Inattention, DIVA Hyperactivity\n\n[^Fayyad et al., 2007; Polanczyk et al., 2007]: https://rationalwiki.org/wiki/Attention-deficit_hyperactivity_disorder\n\n**Mind wandering hypothesis of ADHD:**\n\nA dysfunctional and later absent interaction between the four major networks (default mode, executive control network and salience network) is proposed to underlie different aspects of cognitive and behavioural impairment associated with MW in ADHD.\n\n![Mind Wandering hypothesis](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101317221.png)\n\n**Context regulation hypothesis:**\n\nAn ability to reduce frequency of MW under high demand compared low demand conditions in order to allow an adequate performance of the primary task.\n\n## MW frequency and context regulation of MW in ADHD\n\n### Model\n\n![Mind wandering task](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302011196.png)\n\n\n\n### Procedure\n\n1. Aims\n2. Sample\n3. Validity Results\n4. results\n   1. Mind Wandering Frequency results: 1-back/WM and 0-back/CRT\n   2. Cognitive performance Mind wandering task: Mean reaction time, Reaction time variability, Accuracy (Error rate), \n   3. Cognitive performance Sustained attention task: Mean reaction time, Reaction time variability, Error rate\n5. Conclusion\n6. Future research\n\nThe slides are good protocol for investigating a novel field.\n\n---\n\n# Neurocognitive development in early childhood\n\n## Learning outcomes:\n\n1. Describe typical and atypical infant neurocognitive development\n2. Select appropriate neurocognitive methods for assessing infant development\n3. Understand the dynamic interaction between genes and environment in early brain development.\n4. Critically evaluate research on early neurocognitive development and interpret it within theoretical frameworks\n\n## Neurocognitive development\n\nThere are two stages during wiring the brain: Synapse formation and synaptic pruning\n\n![Wiring the brain](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302037568.png)\n\n**Frameworks for understanding human functional brain development**\n\n| Maturational: domain specificity (intrinsic)                 | Skill learning: expertise (extrinsic)                        | Interactive specialisation                                   |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Maturation of brain regions; mature = adult level of functioning (one-off event) | Brain regions active in infants during onset of new skills are similar to those involved in complex skill acquisition in adults | Changes in specialisation of brain regions occur as they interact with each other |\n| Regions ‘added in’ during development                        | e.g. PFC engaged in simple tasks early in development        | Brain development involves a process of organising interactions between brain regions |\n| Contrast with neuroanatomical development?                   |                                                              | New behaviour/skills associated with network changes         |\n\n**Methods for early neurodevelopment:**\n\n- Behavioural and cognitive tasks\n- Eye-tracking\n- EEG (ERPs and frequency measures)\n- fMRI\n- fNIRS\n\nComparison of brain imaging techniques\n\n![Comparison of brain imaging techniques](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101450571.png)\n\n## Case study: face processing\n\n- Studies demonstrate exceptionally early sensitivity to social stimuli informing cognitive neuroscience\n\n- Atypical processing of faces and gaze in autistic individuals, which is:\n\n  - Shown in infants who have a higher likelihood of being diagnosed with autism\n\n  - Early marker of likelihood for a later diagnosis and symptoms of autism\n  - Atypical patterns of specialisation\n\n- **Development of the cerebral cortex involves both predetermined genetic influences and activity-dependent processes**\n\n- **If certain synaptic connections are not laid down early in life, they are less likely to become established later in life. Once pruning has occurred and number of neurons stabilizes, the function might also “freeze” at a particular level.**\n\n# Vocabulary\n\n**CRT**: context regulation\n\n**ERPs**: Event-related potentials\n","source":"_posts/10_03_22.md","raw":"---\n\ntitle: Lecture Notes 10/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-10 13:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n# Mind wandering in ADHD\n\n## Objectives\n\n1.\tTo understand the mind wandering (MW) hypothesis of attention deficit/hyperactivity disorder(ADHD), (theoretical implications).\n2.\tTo understand the neural basis of mind wandering in ADHD.\n3.\tTo understand the clinical implication(s) of mind wandering in ADHD.\n\n## ADHD\n\nADHD: a common neurodevelopmental disorder, characterised by inattentive and hyperactive/impulsive behaviours which interfere with everyday functioning (Fayyad et al., 2007; Polanczyk et al., 2007).\n\nADHD diagnosis: DIVA Inattention, DIVA Hyperactivity\n\n[^Fayyad et al., 2007; Polanczyk et al., 2007]: https://rationalwiki.org/wiki/Attention-deficit_hyperactivity_disorder\n\n**Mind wandering hypothesis of ADHD:**\n\nA dysfunctional and later absent interaction between the four major networks (default mode, executive control network and salience network) is proposed to underlie different aspects of cognitive and behavioural impairment associated with MW in ADHD.\n\n![Mind Wandering hypothesis](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101317221.png)\n\n**Context regulation hypothesis:**\n\nAn ability to reduce frequency of MW under high demand compared low demand conditions in order to allow an adequate performance of the primary task.\n\n## MW frequency and context regulation of MW in ADHD\n\n### Model\n\n![Mind wandering task](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302011196.png)\n\n\n\n### Procedure\n\n1. Aims\n2. Sample\n3. Validity Results\n4. results\n   1. Mind Wandering Frequency results: 1-back/WM and 0-back/CRT\n   2. Cognitive performance Mind wandering task: Mean reaction time, Reaction time variability, Accuracy (Error rate), \n   3. Cognitive performance Sustained attention task: Mean reaction time, Reaction time variability, Error rate\n5. Conclusion\n6. Future research\n\nThe slides are good protocol for investigating a novel field.\n\n---\n\n# Neurocognitive development in early childhood\n\n## Learning outcomes:\n\n1. Describe typical and atypical infant neurocognitive development\n2. Select appropriate neurocognitive methods for assessing infant development\n3. Understand the dynamic interaction between genes and environment in early brain development.\n4. Critically evaluate research on early neurocognitive development and interpret it within theoretical frameworks\n\n## Neurocognitive development\n\nThere are two stages during wiring the brain: Synapse formation and synaptic pruning\n\n![Wiring the brain](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302037568.png)\n\n**Frameworks for understanding human functional brain development**\n\n| Maturational: domain specificity (intrinsic)                 | Skill learning: expertise (extrinsic)                        | Interactive specialisation                                   |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Maturation of brain regions; mature = adult level of functioning (one-off event) | Brain regions active in infants during onset of new skills are similar to those involved in complex skill acquisition in adults | Changes in specialisation of brain regions occur as they interact with each other |\n| Regions ‘added in’ during development                        | e.g. PFC engaged in simple tasks early in development        | Brain development involves a process of organising interactions between brain regions |\n| Contrast with neuroanatomical development?                   |                                                              | New behaviour/skills associated with network changes         |\n\n**Methods for early neurodevelopment:**\n\n- Behavioural and cognitive tasks\n- Eye-tracking\n- EEG (ERPs and frequency measures)\n- fMRI\n- fNIRS\n\nComparison of brain imaging techniques\n\n![Comparison of brain imaging techniques](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101450571.png)\n\n## Case study: face processing\n\n- Studies demonstrate exceptionally early sensitivity to social stimuli informing cognitive neuroscience\n\n- Atypical processing of faces and gaze in autistic individuals, which is:\n\n  - Shown in infants who have a higher likelihood of being diagnosed with autism\n\n  - Early marker of likelihood for a later diagnosis and symptoms of autism\n  - Atypical patterns of specialisation\n\n- **Development of the cerebral cortex involves both predetermined genetic influences and activity-dependent processes**\n\n- **If certain synaptic connections are not laid down early in life, they are less likely to become established later in life. Once pruning has occurred and number of neurons stabilizes, the function might also “freeze” at a particular level.**\n\n# Vocabulary\n\n**CRT**: context regulation\n\n**ERPs**: Event-related potentials\n","slug":"10_03_22","published":1,"updated":"2022-08-24T17:08:39.307Z","comments":1,"layout":"post","photos":[],"_id":"cuidLK1QHhP_PgqMkCA1qSkSQ","content":"<h1 id=\"Mind-wandering-in-ADHD\"><a href=\"#Mind-wandering-in-ADHD\" class=\"headerlink\" title=\"Mind wandering in ADHD\"></a>Mind wandering in ADHD</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>To understand the mind wandering (MW) hypothesis of attention deficit/hyperactivity disorder(ADHD), (theoretical implications).</li>\n<li>To understand the neural basis of mind wandering in ADHD.</li>\n<li>To understand the clinical implication(s) of mind wandering in ADHD.</li>\n</ol>\n<h2 id=\"ADHD\"><a href=\"#ADHD\" class=\"headerlink\" title=\"ADHD\"></a>ADHD</h2><p>ADHD: a common neurodevelopmental disorder, characterised by inattentive and hyperactive/impulsive behaviours which interfere with everyday functioning (Fayyad et al., 2007; Polanczyk et al., 2007).</p>\n<p>ADHD diagnosis: DIVA Inattention, DIVA Hyperactivity</p>\n<p><strong>Mind wandering hypothesis of ADHD:</strong></p>\n<p>A dysfunctional and later absent interaction between the four major networks (default mode, executive control network and salience network) is proposed to underlie different aspects of cognitive and behavioural impairment associated with MW in ADHD.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101317221.png\" alt=\"Mind Wandering hypothesis\"></p>\n<p><strong>Context regulation hypothesis:</strong></p>\n<p>An ability to reduce frequency of MW under high demand compared low demand conditions in order to allow an adequate performance of the primary task.</p>\n<h2 id=\"MW-frequency-and-context-regulation-of-MW-in-ADHD\"><a href=\"#MW-frequency-and-context-regulation-of-MW-in-ADHD\" class=\"headerlink\" title=\"MW frequency and context regulation of MW in ADHD\"></a>MW frequency and context regulation of MW in ADHD</h2><h3 id=\"Model\"><a href=\"#Model\" class=\"headerlink\" title=\"Model\"></a>Model</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302011196.png\" alt=\"Mind wandering task\"></p>\n<h3 id=\"Procedure\"><a href=\"#Procedure\" class=\"headerlink\" title=\"Procedure\"></a>Procedure</h3><ol>\n<li>Aims</li>\n<li>Sample</li>\n<li>Validity Results</li>\n<li>results<ol>\n<li>Mind Wandering Frequency results: 1-back/WM and 0-back/CRT</li>\n<li>Cognitive performance Mind wandering task: Mean reaction time, Reaction time variability, Accuracy (Error rate), </li>\n<li>Cognitive performance Sustained attention task: Mean reaction time, Reaction time variability, Error rate</li>\n</ol>\n</li>\n<li>Conclusion</li>\n<li>Future research</li>\n</ol>\n<p>The slides are good protocol for investigating a novel field.</p>\n<hr>\n<h1 id=\"Neurocognitive-development-in-early-childhood\"><a href=\"#Neurocognitive-development-in-early-childhood\" class=\"headerlink\" title=\"Neurocognitive development in early childhood\"></a>Neurocognitive development in early childhood</h1><h2 id=\"Learning-outcomes\"><a href=\"#Learning-outcomes\" class=\"headerlink\" title=\"Learning outcomes:\"></a>Learning outcomes:</h2><ol>\n<li>Describe typical and atypical infant neurocognitive development</li>\n<li>Select appropriate neurocognitive methods for assessing infant development</li>\n<li>Understand the dynamic interaction between genes and environment in early brain development.</li>\n<li>Critically evaluate research on early neurocognitive development and interpret it within theoretical frameworks</li>\n</ol>\n<h2 id=\"Neurocognitive-development\"><a href=\"#Neurocognitive-development\" class=\"headerlink\" title=\"Neurocognitive development\"></a>Neurocognitive development</h2><p>There are two stages during wiring the brain: Synapse formation and synaptic pruning</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302037568.png\" alt=\"Wiring the brain\"></p>\n<p><strong>Frameworks for understanding human functional brain development</strong></p>\n<table>\n<thead>\n<tr>\n<th>Maturational: domain specificity (intrinsic)</th>\n<th>Skill learning: expertise (extrinsic)</th>\n<th>Interactive specialisation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Maturation of brain regions; mature = adult level of functioning (one-off event)</td>\n<td>Brain regions active in infants during onset of new skills are similar to those involved in complex skill acquisition in adults</td>\n<td>Changes in specialisation of brain regions occur as they interact with each other</td>\n</tr>\n<tr>\n<td>Regions ‘added in’ during development</td>\n<td>e.g. PFC engaged in simple tasks early in development</td>\n<td>Brain development involves a process of organising interactions between brain regions</td>\n</tr>\n<tr>\n<td>Contrast with neuroanatomical development?</td>\n<td></td>\n<td>New behaviour/skills associated with network changes</td>\n</tr>\n</tbody></table>\n<p><strong>Methods for early neurodevelopment:</strong></p>\n<ul>\n<li>Behavioural and cognitive tasks</li>\n<li>Eye-tracking</li>\n<li>EEG (ERPs and frequency measures)</li>\n<li>fMRI</li>\n<li>fNIRS</li>\n</ul>\n<p>Comparison of brain imaging techniques</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101450571.png\" alt=\"Comparison of brain imaging techniques\"></p>\n<h2 id=\"Case-study-face-processing\"><a href=\"#Case-study-face-processing\" class=\"headerlink\" title=\"Case study: face processing\"></a>Case study: face processing</h2><ul>\n<li><p>Studies demonstrate exceptionally early sensitivity to social stimuli informing cognitive neuroscience</p>\n</li>\n<li><p>Atypical processing of faces and gaze in autistic individuals, which is:</p>\n<ul>\n<li><p>Shown in infants who have a higher likelihood of being diagnosed with autism</p>\n</li>\n<li><p>Early marker of likelihood for a later diagnosis and symptoms of autism</p>\n</li>\n<li><p>Atypical patterns of specialisation</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Development of the cerebral cortex involves both predetermined genetic influences and activity-dependent processes</strong></p>\n</li>\n<li><p><strong>If certain synaptic connections are not laid down early in life, they are less likely to become established later in life. Once pruning has occurred and number of neurons stabilizes, the function might also “freeze” at a particular level.</strong></p>\n</li>\n</ul>\n<h1 id=\"Vocabulary\"><a href=\"#Vocabulary\" class=\"headerlink\" title=\"Vocabulary\"></a>Vocabulary</h1><p><strong>CRT</strong>: context regulation</p>\n<p><strong>ERPs</strong>: Event-related potentials</p>\n","excerpt":"","more":"<h1 id=\"Mind-wandering-in-ADHD\"><a href=\"#Mind-wandering-in-ADHD\" class=\"headerlink\" title=\"Mind wandering in ADHD\"></a>Mind wandering in ADHD</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>To understand the mind wandering (MW) hypothesis of attention deficit/hyperactivity disorder(ADHD), (theoretical implications).</li>\n<li>To understand the neural basis of mind wandering in ADHD.</li>\n<li>To understand the clinical implication(s) of mind wandering in ADHD.</li>\n</ol>\n<h2 id=\"ADHD\"><a href=\"#ADHD\" class=\"headerlink\" title=\"ADHD\"></a>ADHD</h2><p>ADHD: a common neurodevelopmental disorder, characterised by inattentive and hyperactive/impulsive behaviours which interfere with everyday functioning (Fayyad et al., 2007; Polanczyk et al., 2007).</p>\n<p>ADHD diagnosis: DIVA Inattention, DIVA Hyperactivity</p>\n<p><strong>Mind wandering hypothesis of ADHD:</strong></p>\n<p>A dysfunctional and later absent interaction between the four major networks (default mode, executive control network and salience network) is proposed to underlie different aspects of cognitive and behavioural impairment associated with MW in ADHD.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101317221.png\" alt=\"Mind Wandering hypothesis\"></p>\n<p><strong>Context regulation hypothesis:</strong></p>\n<p>An ability to reduce frequency of MW under high demand compared low demand conditions in order to allow an adequate performance of the primary task.</p>\n<h2 id=\"MW-frequency-and-context-regulation-of-MW-in-ADHD\"><a href=\"#MW-frequency-and-context-regulation-of-MW-in-ADHD\" class=\"headerlink\" title=\"MW frequency and context regulation of MW in ADHD\"></a>MW frequency and context regulation of MW in ADHD</h2><h3 id=\"Model\"><a href=\"#Model\" class=\"headerlink\" title=\"Model\"></a>Model</h3><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302011196.png\" alt=\"Mind wandering task\"></p>\n<h3 id=\"Procedure\"><a href=\"#Procedure\" class=\"headerlink\" title=\"Procedure\"></a>Procedure</h3><ol>\n<li>Aims</li>\n<li>Sample</li>\n<li>Validity Results</li>\n<li>results<ol>\n<li>Mind Wandering Frequency results: 1-back/WM and 0-back/CRT</li>\n<li>Cognitive performance Mind wandering task: Mean reaction time, Reaction time variability, Accuracy (Error rate), </li>\n<li>Cognitive performance Sustained attention task: Mean reaction time, Reaction time variability, Error rate</li>\n</ol>\n</li>\n<li>Conclusion</li>\n<li>Future research</li>\n</ol>\n<p>The slides are good protocol for investigating a novel field.</p>\n<hr>\n<h1 id=\"Neurocognitive-development-in-early-childhood\"><a href=\"#Neurocognitive-development-in-early-childhood\" class=\"headerlink\" title=\"Neurocognitive development in early childhood\"></a>Neurocognitive development in early childhood</h1><h2 id=\"Learning-outcomes\"><a href=\"#Learning-outcomes\" class=\"headerlink\" title=\"Learning outcomes:\"></a>Learning outcomes:</h2><ol>\n<li>Describe typical and atypical infant neurocognitive development</li>\n<li>Select appropriate neurocognitive methods for assessing infant development</li>\n<li>Understand the dynamic interaction between genes and environment in early brain development.</li>\n<li>Critically evaluate research on early neurocognitive development and interpret it within theoretical frameworks</li>\n</ol>\n<h2 id=\"Neurocognitive-development\"><a href=\"#Neurocognitive-development\" class=\"headerlink\" title=\"Neurocognitive development\"></a>Neurocognitive development</h2><p>There are two stages during wiring the brain: Synapse formation and synaptic pruning</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302037568.png\" alt=\"Wiring the brain\"></p>\n<p><strong>Frameworks for understanding human functional brain development</strong></p>\n<table>\n<thead>\n<tr>\n<th>Maturational: domain specificity (intrinsic)</th>\n<th>Skill learning: expertise (extrinsic)</th>\n<th>Interactive specialisation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Maturation of brain regions; mature = adult level of functioning (one-off event)</td>\n<td>Brain regions active in infants during onset of new skills are similar to those involved in complex skill acquisition in adults</td>\n<td>Changes in specialisation of brain regions occur as they interact with each other</td>\n</tr>\n<tr>\n<td>Regions ‘added in’ during development</td>\n<td>e.g. PFC engaged in simple tasks early in development</td>\n<td>Brain development involves a process of organising interactions between brain regions</td>\n</tr>\n<tr>\n<td>Contrast with neuroanatomical development?</td>\n<td></td>\n<td>New behaviour/skills associated with network changes</td>\n</tr>\n</tbody></table>\n<p><strong>Methods for early neurodevelopment:</strong></p>\n<ul>\n<li>Behavioural and cognitive tasks</li>\n<li>Eye-tracking</li>\n<li>EEG (ERPs and frequency measures)</li>\n<li>fMRI</li>\n<li>fNIRS</li>\n</ul>\n<p>Comparison of brain imaging techniques</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203101450571.png\" alt=\"Comparison of brain imaging techniques\"></p>\n<h2 id=\"Case-study-face-processing\"><a href=\"#Case-study-face-processing\" class=\"headerlink\" title=\"Case study: face processing\"></a>Case study: face processing</h2><ul>\n<li><p>Studies demonstrate exceptionally early sensitivity to social stimuli informing cognitive neuroscience</p>\n</li>\n<li><p>Atypical processing of faces and gaze in autistic individuals, which is:</p>\n<ul>\n<li><p>Shown in infants who have a higher likelihood of being diagnosed with autism</p>\n</li>\n<li><p>Early marker of likelihood for a later diagnosis and symptoms of autism</p>\n</li>\n<li><p>Atypical patterns of specialisation</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Development of the cerebral cortex involves both predetermined genetic influences and activity-dependent processes</strong></p>\n</li>\n<li><p><strong>If certain synaptic connections are not laid down early in life, they are less likely to become established later in life. Once pruning has occurred and number of neurons stabilizes, the function might also “freeze” at a particular level.</strong></p>\n</li>\n</ul>\n<h1 id=\"Vocabulary\"><a href=\"#Vocabulary\" class=\"headerlink\" title=\"Vocabulary\"></a>Vocabulary</h1><p><strong>CRT</strong>: context regulation</p>\n<p><strong>ERPs</strong>: Event-related potentials</p>\n"},{"title":"Lecture Notes 11/03/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-11T10:00:00.000Z","password":null,"summary":null,"_content":"# What can functional connectivity tell us about cognition and behaviour?\n\n## Objective\n\n- Describe different approaches to studying human functional connectivity\n- Outline the organisation of the brain into intrinsic connectivity networks, \n  and their relationship to cognition\n- Provide examples of methods to study links between functional connectivity and behaviour & cognition\n\n**Functional connectivity construction:**\n\n![Functional connectivity construction](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302234794.png)\n\n**Options in functional connectivity construction:**\n\n![Options in functional connectivity construction](C:\\Users\\Makka Papa\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220330223524083.png)\n\nFunctional (MRI) data pitfalls: head motion (& other artefacts)\n\nData base for meta-analyses of fMRI data: neurosynth.org; brainmap.org\n\n## Summary\n\n![Summary](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302242338.png)\n\n---\n\n# Frontier of brain imaging\n\nMyelin mapping using mcDESPOT\n\n3D motion correction -PROMO\n\n\n\nLooping star (Wiesinger rt al. 2018 MRM): **silent**\n\n\n\n<u>Baby in Uterus</u>\n\n\n\nMAttia Veronese - ^18^F-DOPA PET imaging: Brain Chemistry\n\nFernando Zelaya - Perfusion MR imaging: Brain Physiology  Quantitative whole brain imaging of cerebral blood flow\n\n\n\n\n\n\n\nInforming treatment development in ADHD\n\nExisting treatment: Methylphenidate\n\nPotential new medication: Atomoxetine\n\n\n\n[Portable MR][https://www.kcl.ac.uk/news/europes-first-game-changing-portable-mri-machine-arrives-at-kings-health-partners]\n\n\n\nAdam Hampshire the Great British Intelligence Test 2020 \n\n\n\n\n\nImbalance in catecholaminergic functional circuits might underlie cognitive fatigue in multiple sclerosis\n\n---\n\n# Cognitive neuroscience of cognitive control\n\n## Cognitive control functions\n\n- Motor response inhibition: the ability to inhibit a prepotent motor response\n  - Go/no-go task\n  - Stop task\n- Interfere nee inhibition: the ability to inhibit a prepotent tendency to respond to an\n  interfering stimulus/overriding a conflicting motor response\n  - Simon task\n  - Eriksen Flanker task\n  - Colour-Word Stroop task\n- Cognitive flexibility: the ability to inhibit a response that is no longer appropriate &\n  reengage 1n a new response\n  - Wisconsin Card Sorting task\n  - Other switching tasks; STOP-Change task\n\nTDCS is cheaper than TMS\n\n## Overall conclusions\n\n1. Lateral & medial fronto-striatal areas mediate cognitive control\n   - R IFG, pre-SMA, caudate, subthal. nucleus for motor inhibition\n   - R & L IFG, caudate, ACC for interference inhibition\n   - R & L DLPFC/IFG, R & L IPL, basal ganglia for switching\n   - Anterior insula is crucial for saliency processing\n2. There is progressive increase in activation of areas that mediate <u>development</u> (not sure)\n   - these functions from childhood to adulthood\n   - R IFG, SMA, caudate, subthalamic nucleus for inhibition\n   - R & L IFG, caudate, ACC for interference inhibition\n   - L & R IFG, L & R IPL, basal ganglia for switching\n3. ADHD patients have functional deficits in these areas\n   - R IFG/ AI, SMA/ ACC, caudate, thal for motor/interference inh.\n   - R & L IFG, basal ganglia for switching\n   - =>likely a delay of neurofunctional maturation?\n\n# Vocabulary\n\nIFG: inferior frontal gyrus\n\nAG: angular gyrus (PL)\n\nMFG: medial frontal gyrus (DLPFC)\t","source":"_posts/11_03_22.md","raw":"---\ntitle: Lecture Notes 11/03/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-11 10:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n# What can functional connectivity tell us about cognition and behaviour?\n\n## Objective\n\n- Describe different approaches to studying human functional connectivity\n- Outline the organisation of the brain into intrinsic connectivity networks, \n  and their relationship to cognition\n- Provide examples of methods to study links between functional connectivity and behaviour & cognition\n\n**Functional connectivity construction:**\n\n![Functional connectivity construction](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302234794.png)\n\n**Options in functional connectivity construction:**\n\n![Options in functional connectivity construction](C:\\Users\\Makka Papa\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220330223524083.png)\n\nFunctional (MRI) data pitfalls: head motion (& other artefacts)\n\nData base for meta-analyses of fMRI data: neurosynth.org; brainmap.org\n\n## Summary\n\n![Summary](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302242338.png)\n\n---\n\n# Frontier of brain imaging\n\nMyelin mapping using mcDESPOT\n\n3D motion correction -PROMO\n\n\n\nLooping star (Wiesinger rt al. 2018 MRM): **silent**\n\n\n\n<u>Baby in Uterus</u>\n\n\n\nMAttia Veronese - ^18^F-DOPA PET imaging: Brain Chemistry\n\nFernando Zelaya - Perfusion MR imaging: Brain Physiology  Quantitative whole brain imaging of cerebral blood flow\n\n\n\n\n\n\n\nInforming treatment development in ADHD\n\nExisting treatment: Methylphenidate\n\nPotential new medication: Atomoxetine\n\n\n\n[Portable MR][https://www.kcl.ac.uk/news/europes-first-game-changing-portable-mri-machine-arrives-at-kings-health-partners]\n\n\n\nAdam Hampshire the Great British Intelligence Test 2020 \n\n\n\n\n\nImbalance in catecholaminergic functional circuits might underlie cognitive fatigue in multiple sclerosis\n\n---\n\n# Cognitive neuroscience of cognitive control\n\n## Cognitive control functions\n\n- Motor response inhibition: the ability to inhibit a prepotent motor response\n  - Go/no-go task\n  - Stop task\n- Interfere nee inhibition: the ability to inhibit a prepotent tendency to respond to an\n  interfering stimulus/overriding a conflicting motor response\n  - Simon task\n  - Eriksen Flanker task\n  - Colour-Word Stroop task\n- Cognitive flexibility: the ability to inhibit a response that is no longer appropriate &\n  reengage 1n a new response\n  - Wisconsin Card Sorting task\n  - Other switching tasks; STOP-Change task\n\nTDCS is cheaper than TMS\n\n## Overall conclusions\n\n1. Lateral & medial fronto-striatal areas mediate cognitive control\n   - R IFG, pre-SMA, caudate, subthal. nucleus for motor inhibition\n   - R & L IFG, caudate, ACC for interference inhibition\n   - R & L DLPFC/IFG, R & L IPL, basal ganglia for switching\n   - Anterior insula is crucial for saliency processing\n2. There is progressive increase in activation of areas that mediate <u>development</u> (not sure)\n   - these functions from childhood to adulthood\n   - R IFG, SMA, caudate, subthalamic nucleus for inhibition\n   - R & L IFG, caudate, ACC for interference inhibition\n   - L & R IFG, L & R IPL, basal ganglia for switching\n3. ADHD patients have functional deficits in these areas\n   - R IFG/ AI, SMA/ ACC, caudate, thal for motor/interference inh.\n   - R & L IFG, basal ganglia for switching\n   - =>likely a delay of neurofunctional maturation?\n\n# Vocabulary\n\nIFG: inferior frontal gyrus\n\nAG: angular gyrus (PL)\n\nMFG: medial frontal gyrus (DLPFC)\t","slug":"11_03_22","published":1,"updated":"2022-08-24T17:08:39.312Z","comments":1,"layout":"post","photos":[],"_id":"cuid-WhXtxrRREjIOJSKv5i7u","content":"<h1 id=\"What-can-functional-connectivity-tell-us-about-cognition-and-behaviour\"><a href=\"#What-can-functional-connectivity-tell-us-about-cognition-and-behaviour\" class=\"headerlink\" title=\"What can functional connectivity tell us about cognition and behaviour?\"></a>What can functional connectivity tell us about cognition and behaviour?</h1><h2 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective\"></a>Objective</h2><ul>\n<li>Describe different approaches to studying human functional connectivity</li>\n<li>Outline the organisation of the brain into intrinsic connectivity networks,<br>and their relationship to cognition</li>\n<li>Provide examples of methods to study links between functional connectivity and behaviour &amp; cognition</li>\n</ul>\n<p><strong>Functional connectivity construction:</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302234794.png\" alt=\"Functional connectivity construction\"></p>\n<p><strong>Options in functional connectivity construction:</strong></p>\n<p>![Options in functional connectivity construction](C:\\Users\\Makka Papa\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220330223524083.png)</p>\n<p>Functional (MRI) data pitfalls: head motion (&amp; other artefacts)</p>\n<p>Data base for meta-analyses of fMRI data: neurosynth.org; brainmap.org</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302242338.png\" alt=\"Summary\"></p>\n<hr>\n<h1 id=\"Frontier-of-brain-imaging\"><a href=\"#Frontier-of-brain-imaging\" class=\"headerlink\" title=\"Frontier of brain imaging\"></a>Frontier of brain imaging</h1><p>Myelin mapping using mcDESPOT</p>\n<p>3D motion correction -PROMO</p>\n<p>Looping star (Wiesinger rt al. 2018 MRM): <strong>silent</strong></p>\n<p><u>Baby in Uterus</u></p>\n<p>MAttia Veronese - ^18^F-DOPA PET imaging: Brain Chemistry</p>\n<p>Fernando Zelaya - Perfusion MR imaging: Brain Physiology  Quantitative whole brain imaging of cerebral blood flow</p>\n<p>Informing treatment development in ADHD</p>\n<p>Existing treatment: Methylphenidate</p>\n<p>Potential new medication: Atomoxetine</p>\n<p>[Portable MR][<a href=\"https://www.kcl.ac.uk/news/europes-first-game-changing-portable-mri-machine-arrives-at-kings-health-partners]\">https://www.kcl.ac.uk/news/europes-first-game-changing-portable-mri-machine-arrives-at-kings-health-partners]</a></p>\n<p>Adam Hampshire the Great British Intelligence Test 2020 </p>\n<p>Imbalance in catecholaminergic functional circuits might underlie cognitive fatigue in multiple sclerosis</p>\n<hr>\n<h1 id=\"Cognitive-neuroscience-of-cognitive-control\"><a href=\"#Cognitive-neuroscience-of-cognitive-control\" class=\"headerlink\" title=\"Cognitive neuroscience of cognitive control\"></a>Cognitive neuroscience of cognitive control</h1><h2 id=\"Cognitive-control-functions\"><a href=\"#Cognitive-control-functions\" class=\"headerlink\" title=\"Cognitive control functions\"></a>Cognitive control functions</h2><ul>\n<li>Motor response inhibition: the ability to inhibit a prepotent motor response<ul>\n<li>Go/no-go task</li>\n<li>Stop task</li>\n</ul>\n</li>\n<li>Interfere nee inhibition: the ability to inhibit a prepotent tendency to respond to an<br>interfering stimulus/overriding a conflicting motor response<ul>\n<li>Simon task</li>\n<li>Eriksen Flanker task</li>\n<li>Colour-Word Stroop task</li>\n</ul>\n</li>\n<li>Cognitive flexibility: the ability to inhibit a response that is no longer appropriate &amp;<br>reengage 1n a new response<ul>\n<li>Wisconsin Card Sorting task</li>\n<li>Other switching tasks; STOP-Change task</li>\n</ul>\n</li>\n</ul>\n<p>TDCS is cheaper than TMS</p>\n<h2 id=\"Overall-conclusions\"><a href=\"#Overall-conclusions\" class=\"headerlink\" title=\"Overall conclusions\"></a>Overall conclusions</h2><ol>\n<li>Lateral &amp; medial fronto-striatal areas mediate cognitive control<ul>\n<li>R IFG, pre-SMA, caudate, subthal. nucleus for motor inhibition</li>\n<li>R &amp; L IFG, caudate, ACC for interference inhibition</li>\n<li>R &amp; L DLPFC/IFG, R &amp; L IPL, basal ganglia for switching</li>\n<li>Anterior insula is crucial for saliency processing</li>\n</ul>\n</li>\n<li>There is progressive increase in activation of areas that mediate <u>development</u> (not sure)<ul>\n<li>these functions from childhood to adulthood</li>\n<li>R IFG, SMA, caudate, subthalamic nucleus for inhibition</li>\n<li>R &amp; L IFG, caudate, ACC for interference inhibition</li>\n<li>L &amp; R IFG, L &amp; R IPL, basal ganglia for switching</li>\n</ul>\n</li>\n<li>ADHD patients have functional deficits in these areas<ul>\n<li>R IFG/ AI, SMA/ ACC, caudate, thal for motor/interference inh.</li>\n<li>R &amp; L IFG, basal ganglia for switching</li>\n<li>=&gt;likely a delay of neurofunctional maturation?</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Vocabulary\"><a href=\"#Vocabulary\" class=\"headerlink\" title=\"Vocabulary\"></a>Vocabulary</h1><p>IFG: inferior frontal gyrus</p>\n<p>AG: angular gyrus (PL)</p>\n<p>MFG: medial frontal gyrus (DLPFC)    </p>\n","excerpt":"","more":"<h1 id=\"What-can-functional-connectivity-tell-us-about-cognition-and-behaviour\"><a href=\"#What-can-functional-connectivity-tell-us-about-cognition-and-behaviour\" class=\"headerlink\" title=\"What can functional connectivity tell us about cognition and behaviour?\"></a>What can functional connectivity tell us about cognition and behaviour?</h1><h2 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective\"></a>Objective</h2><ul>\n<li>Describe different approaches to studying human functional connectivity</li>\n<li>Outline the organisation of the brain into intrinsic connectivity networks,<br>and their relationship to cognition</li>\n<li>Provide examples of methods to study links between functional connectivity and behaviour &amp; cognition</li>\n</ul>\n<p><strong>Functional connectivity construction:</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302234794.png\" alt=\"Functional connectivity construction\"></p>\n<p><strong>Options in functional connectivity construction:</strong></p>\n<p>![Options in functional connectivity construction](C:\\Users\\Makka Papa\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220330223524083.png)</p>\n<p>Functional (MRI) data pitfalls: head motion (&amp; other artefacts)</p>\n<p>Data base for meta-analyses of fMRI data: neurosynth.org; brainmap.org</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203302242338.png\" alt=\"Summary\"></p>\n<hr>\n<h1 id=\"Frontier-of-brain-imaging\"><a href=\"#Frontier-of-brain-imaging\" class=\"headerlink\" title=\"Frontier of brain imaging\"></a>Frontier of brain imaging</h1><p>Myelin mapping using mcDESPOT</p>\n<p>3D motion correction -PROMO</p>\n<p>Looping star (Wiesinger rt al. 2018 MRM): <strong>silent</strong></p>\n<p><u>Baby in Uterus</u></p>\n<p>MAttia Veronese - ^18^F-DOPA PET imaging: Brain Chemistry</p>\n<p>Fernando Zelaya - Perfusion MR imaging: Brain Physiology  Quantitative whole brain imaging of cerebral blood flow</p>\n<p>Informing treatment development in ADHD</p>\n<p>Existing treatment: Methylphenidate</p>\n<p>Potential new medication: Atomoxetine</p>\n<p>[Portable MR][<a href=\"https://www.kcl.ac.uk/news/europes-first-game-changing-portable-mri-machine-arrives-at-kings-health-partners]\">https://www.kcl.ac.uk/news/europes-first-game-changing-portable-mri-machine-arrives-at-kings-health-partners]</a></p>\n<p>Adam Hampshire the Great British Intelligence Test 2020 </p>\n<p>Imbalance in catecholaminergic functional circuits might underlie cognitive fatigue in multiple sclerosis</p>\n<hr>\n<h1 id=\"Cognitive-neuroscience-of-cognitive-control\"><a href=\"#Cognitive-neuroscience-of-cognitive-control\" class=\"headerlink\" title=\"Cognitive neuroscience of cognitive control\"></a>Cognitive neuroscience of cognitive control</h1><h2 id=\"Cognitive-control-functions\"><a href=\"#Cognitive-control-functions\" class=\"headerlink\" title=\"Cognitive control functions\"></a>Cognitive control functions</h2><ul>\n<li>Motor response inhibition: the ability to inhibit a prepotent motor response<ul>\n<li>Go/no-go task</li>\n<li>Stop task</li>\n</ul>\n</li>\n<li>Interfere nee inhibition: the ability to inhibit a prepotent tendency to respond to an<br>interfering stimulus/overriding a conflicting motor response<ul>\n<li>Simon task</li>\n<li>Eriksen Flanker task</li>\n<li>Colour-Word Stroop task</li>\n</ul>\n</li>\n<li>Cognitive flexibility: the ability to inhibit a response that is no longer appropriate &amp;<br>reengage 1n a new response<ul>\n<li>Wisconsin Card Sorting task</li>\n<li>Other switching tasks; STOP-Change task</li>\n</ul>\n</li>\n</ul>\n<p>TDCS is cheaper than TMS</p>\n<h2 id=\"Overall-conclusions\"><a href=\"#Overall-conclusions\" class=\"headerlink\" title=\"Overall conclusions\"></a>Overall conclusions</h2><ol>\n<li>Lateral &amp; medial fronto-striatal areas mediate cognitive control<ul>\n<li>R IFG, pre-SMA, caudate, subthal. nucleus for motor inhibition</li>\n<li>R &amp; L IFG, caudate, ACC for interference inhibition</li>\n<li>R &amp; L DLPFC/IFG, R &amp; L IPL, basal ganglia for switching</li>\n<li>Anterior insula is crucial for saliency processing</li>\n</ul>\n</li>\n<li>There is progressive increase in activation of areas that mediate <u>development</u> (not sure)<ul>\n<li>these functions from childhood to adulthood</li>\n<li>R IFG, SMA, caudate, subthalamic nucleus for inhibition</li>\n<li>R &amp; L IFG, caudate, ACC for interference inhibition</li>\n<li>L &amp; R IFG, L &amp; R IPL, basal ganglia for switching</li>\n</ul>\n</li>\n<li>ADHD patients have functional deficits in these areas<ul>\n<li>R IFG/ AI, SMA/ ACC, caudate, thal for motor/interference inh.</li>\n<li>R &amp; L IFG, basal ganglia for switching</li>\n<li>=&gt;likely a delay of neurofunctional maturation?</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Vocabulary\"><a href=\"#Vocabulary\" class=\"headerlink\" title=\"Vocabulary\"></a>Vocabulary</h1><p>IFG: inferior frontal gyrus</p>\n<p>AG: angular gyrus (PL)</p>\n<p>MFG: medial frontal gyrus (DLPFC)    </p>\n"},{"title":"Lecture Notes 14/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-14T12:00:00.000Z","password":null,"summary":null,"_content":"\n# Face processing and its disorders\n\n## Learning objectives\n\nUnderstand the cognitive and neural basis of face perception\n\nUnderstand differential processes involved in holistic and configural processing\n\nUnderstand how differences between familiar and unfamiliar faces provide a basis for understanding how faces are learnt\n\nUnderstand cases of face processing deficits in various disorders (prosopagnosia, ASD)\n\n## Basic of face perception and theories\n\nThere are generally two types of coding: holistic processing, configural progressing.\n\n### Evidence\n\nEvidences for holistic coding: Inversion Effects \\(Yin, 1969), The Thatcher Effect \\(Thomson,1980), The composite and part whole effect \\(Young et al., 1987, Tanaka & Farah, 1993).\n\n**Inversion effect**\n\n![Inversion effect](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549192.png)\n\nFace perception is disproportionately impaired by inversion. The argument: upright and inverted faces are processed in qualitatively different ways. The argument: upright and inverted faces are processed in qualitatively different ways\n\n**Thatcher effect**\n\n![Thatcher effect](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549409.png)\n\nit becomes more difficult to detect local feature changes in an upside-down face \n\nnot face specific (Wong et al., 2010; Johnston et al., 2014).\n\n**The composite face effect**\n\n![The composite face effect](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171554805.png)\n\nwhen the top half of one face was aligned with the bottom half of another, the resulting composite arrangement induced the perception of a novel facial configuration; the presence of the bottom half altered the appearance of the top half, and *vice versa* (Young, Hellawell and Hay, 1987) \n\nbut it is not observed for other objects like cars (e.g., Cassia et al., 2009).\n\n## Theories\n\nAre faces special \\(different from objects) ? \n\n### Evidence \n\nBehavioural evidence\n\nInversion impairs facial recognition to a greater extent than object recognition (e.g. Yin, 1969; Diamond & Carey, 1987). \n\nComposite effects observed for faces, but not other objects like cars (e.g., Cassia et al., 2009). \n\nInversion effects for objects of expertise (Diamond & Carey, 1986; Gauthier & Tarr, 1997).\n\nThatcher effect not face specific (Wong et al., 2010; Johnston et al., 2014). \n\nComposite effects for objects of expertise (Anstis, 2005; Richler et al., 2009 Gauthier et al., 2003)\n\n\n\n## Brain\n\n**FMRI evidence**\n\n![FMRI evidence](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202141329236.png)\n\nmost findings show normal activation, perhaps an issue of WM myelination\n\n**EEG evidence**\n\nless selectivity in N170 (N170 is the component associated to the neural processing of faces), no inversion effects, standard repetition suppression effects\n\n**CAUSAL evidence – TMS/BRAIN STIM**\n\n**TMS** to the OFA disrupts face perception abilities (Pitcher et al., 2007), but also inverted faces (Pitcher et al., 2011).\n\n**tDCS **of OFA enhances the perception of both faces and objects (Barbieri et al., 2016).\n\n## Failure\n\nPROSOPAGNOSIA (ACQUIRED PROSOPAGNOSIA and DEVELOPMENTAL PROSOPAGNOSIA)\n\n### Diagnosis\n\nFormal diagnosis not defined by DSM-V. Standard batteries rely on subjective self-report questionnaires and objective behavioural tests.\n\nThe twenty-item Prosopagnosia Index (PI20)\n\n\n\nThere a conflict between **domain-specific** and **domain general**\n\n## NEURAL ACCOUNTS\n\n### Findings\n\n**functional**\n\nThe impairment in DP may arise not from a dysfunction of the core areas, but from a failure to propagate signals between areas of the network. \n\n**structural**\n\nThe reduced grey matter volume is found in DPs in inferior temporal lobe, STS, FFA, associated with face recognition performance. \n\nreduced grey matter volume, potential connectivity issues between core and extended regions\n\n**Genetics**\n\ninherited aspect to face recognition abilities\n\n\n\n## Summary\n\nFaces are thought to be processed holistically, but controversy still remains.\n\nWhether faces are processed by dedicated perceptual and neural mechanisms remains unclear, different from objects but possibly not objects of expertise.\n\nEvidence of specificity from neural and behavioural studies, but difficulty dissociating faces from objects of expertise.\n\nTwo types of prosopagnosia can account for vast majority of individual differences in perception ability, but testing methods are slow and variable.\n\nNeural accounts go far in explaining the heterogeneity of the ability, but many questions about familiarity, viewpoint, propagation of signal, etc. remain.\n\n\n\n# Vocabularies\n\n**Prosopagnosia**: the condition of not being able to recognize the faces of people who are know to you, often caused by damage to the brain \n\n---\n\n# Permalink for lecture slides \n\n[Face processing and its disorders](https://github.com/ReveRoyl/Lecture-slides/blob/305c4b4701b37289e1f4d53d7a5e745cecc8037c/MSc/B7.14%20Face%20processing%20and%20its%20disorders%20(14%20Feb%202022).pdf)\n\n","source":"_posts/14_02_22.md","raw":"---\ntitle: Lecture Notes 14/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-14 12:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n\n---\n\n# Face processing and its disorders\n\n## Learning objectives\n\nUnderstand the cognitive and neural basis of face perception\n\nUnderstand differential processes involved in holistic and configural processing\n\nUnderstand how differences between familiar and unfamiliar faces provide a basis for understanding how faces are learnt\n\nUnderstand cases of face processing deficits in various disorders (prosopagnosia, ASD)\n\n## Basic of face perception and theories\n\nThere are generally two types of coding: holistic processing, configural progressing.\n\n### Evidence\n\nEvidences for holistic coding: Inversion Effects \\(Yin, 1969), The Thatcher Effect \\(Thomson,1980), The composite and part whole effect \\(Young et al., 1987, Tanaka & Farah, 1993).\n\n**Inversion effect**\n\n![Inversion effect](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549192.png)\n\nFace perception is disproportionately impaired by inversion. The argument: upright and inverted faces are processed in qualitatively different ways. The argument: upright and inverted faces are processed in qualitatively different ways\n\n**Thatcher effect**\n\n![Thatcher effect](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549409.png)\n\nit becomes more difficult to detect local feature changes in an upside-down face \n\nnot face specific (Wong et al., 2010; Johnston et al., 2014).\n\n**The composite face effect**\n\n![The composite face effect](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171554805.png)\n\nwhen the top half of one face was aligned with the bottom half of another, the resulting composite arrangement induced the perception of a novel facial configuration; the presence of the bottom half altered the appearance of the top half, and *vice versa* (Young, Hellawell and Hay, 1987) \n\nbut it is not observed for other objects like cars (e.g., Cassia et al., 2009).\n\n## Theories\n\nAre faces special \\(different from objects) ? \n\n### Evidence \n\nBehavioural evidence\n\nInversion impairs facial recognition to a greater extent than object recognition (e.g. Yin, 1969; Diamond & Carey, 1987). \n\nComposite effects observed for faces, but not other objects like cars (e.g., Cassia et al., 2009). \n\nInversion effects for objects of expertise (Diamond & Carey, 1986; Gauthier & Tarr, 1997).\n\nThatcher effect not face specific (Wong et al., 2010; Johnston et al., 2014). \n\nComposite effects for objects of expertise (Anstis, 2005; Richler et al., 2009 Gauthier et al., 2003)\n\n\n\n## Brain\n\n**FMRI evidence**\n\n![FMRI evidence](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202141329236.png)\n\nmost findings show normal activation, perhaps an issue of WM myelination\n\n**EEG evidence**\n\nless selectivity in N170 (N170 is the component associated to the neural processing of faces), no inversion effects, standard repetition suppression effects\n\n**CAUSAL evidence – TMS/BRAIN STIM**\n\n**TMS** to the OFA disrupts face perception abilities (Pitcher et al., 2007), but also inverted faces (Pitcher et al., 2011).\n\n**tDCS **of OFA enhances the perception of both faces and objects (Barbieri et al., 2016).\n\n## Failure\n\nPROSOPAGNOSIA (ACQUIRED PROSOPAGNOSIA and DEVELOPMENTAL PROSOPAGNOSIA)\n\n### Diagnosis\n\nFormal diagnosis not defined by DSM-V. Standard batteries rely on subjective self-report questionnaires and objective behavioural tests.\n\nThe twenty-item Prosopagnosia Index (PI20)\n\n\n\nThere a conflict between **domain-specific** and **domain general**\n\n## NEURAL ACCOUNTS\n\n### Findings\n\n**functional**\n\nThe impairment in DP may arise not from a dysfunction of the core areas, but from a failure to propagate signals between areas of the network. \n\n**structural**\n\nThe reduced grey matter volume is found in DPs in inferior temporal lobe, STS, FFA, associated with face recognition performance. \n\nreduced grey matter volume, potential connectivity issues between core and extended regions\n\n**Genetics**\n\ninherited aspect to face recognition abilities\n\n\n\n## Summary\n\nFaces are thought to be processed holistically, but controversy still remains.\n\nWhether faces are processed by dedicated perceptual and neural mechanisms remains unclear, different from objects but possibly not objects of expertise.\n\nEvidence of specificity from neural and behavioural studies, but difficulty dissociating faces from objects of expertise.\n\nTwo types of prosopagnosia can account for vast majority of individual differences in perception ability, but testing methods are slow and variable.\n\nNeural accounts go far in explaining the heterogeneity of the ability, but many questions about familiarity, viewpoint, propagation of signal, etc. remain.\n\n\n\n# Vocabularies\n\n**Prosopagnosia**: the condition of not being able to recognize the faces of people who are know to you, often caused by damage to the brain \n\n---\n\n# Permalink for lecture slides \n\n[Face processing and its disorders](https://github.com/ReveRoyl/Lecture-slides/blob/305c4b4701b37289e1f4d53d7a5e745cecc8037c/MSc/B7.14%20Face%20processing%20and%20its%20disorders%20(14%20Feb%202022).pdf)\n\n","slug":"14_02_22","published":1,"updated":"2022-08-24T17:08:39.320Z","comments":1,"layout":"post","photos":[],"_id":"cuidu0miNSUXIO3CJyT3-PELI","content":"<h1 id=\"Face-processing-and-its-disorders\"><a href=\"#Face-processing-and-its-disorders\" class=\"headerlink\" title=\"Face processing and its disorders\"></a>Face processing and its disorders</h1><h2 id=\"Learning-objectives\"><a href=\"#Learning-objectives\" class=\"headerlink\" title=\"Learning objectives\"></a>Learning objectives</h2><p>Understand the cognitive and neural basis of face perception</p>\n<p>Understand differential processes involved in holistic and configural processing</p>\n<p>Understand how differences between familiar and unfamiliar faces provide a basis for understanding how faces are learnt</p>\n<p>Understand cases of face processing deficits in various disorders (prosopagnosia, ASD)</p>\n<h2 id=\"Basic-of-face-perception-and-theories\"><a href=\"#Basic-of-face-perception-and-theories\" class=\"headerlink\" title=\"Basic of face perception and theories\"></a>Basic of face perception and theories</h2><p>There are generally two types of coding: holistic processing, configural progressing.</p>\n<h3 id=\"Evidence\"><a href=\"#Evidence\" class=\"headerlink\" title=\"Evidence\"></a>Evidence</h3><p>Evidences for holistic coding: Inversion Effects (Yin, 1969), The Thatcher Effect (Thomson,1980), The composite and part whole effect (Young et al., 1987, Tanaka &amp; Farah, 1993).</p>\n<p><strong>Inversion effect</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549192.png\" alt=\"Inversion effect\"></p>\n<p>Face perception is disproportionately impaired by inversion. The argument: upright and inverted faces are processed in qualitatively different ways. The argument: upright and inverted faces are processed in qualitatively different ways</p>\n<p><strong>Thatcher effect</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549409.png\" alt=\"Thatcher effect\"></p>\n<p>it becomes more difficult to detect local feature changes in an upside-down face </p>\n<p>not face specific (Wong et al., 2010; Johnston et al., 2014).</p>\n<p><strong>The composite face effect</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171554805.png\" alt=\"The composite face effect\"></p>\n<p>when the top half of one face was aligned with the bottom half of another, the resulting composite arrangement induced the perception of a novel facial configuration; the presence of the bottom half altered the appearance of the top half, and <em>vice versa</em> (Young, Hellawell and Hay, 1987) </p>\n<p>but it is not observed for other objects like cars (e.g., Cassia et al., 2009).</p>\n<h2 id=\"Theories\"><a href=\"#Theories\" class=\"headerlink\" title=\"Theories\"></a>Theories</h2><p>Are faces special (different from objects) ? </p>\n<h3 id=\"Evidence-1\"><a href=\"#Evidence-1\" class=\"headerlink\" title=\"Evidence\"></a>Evidence</h3><p>Behavioural evidence</p>\n<p>Inversion impairs facial recognition to a greater extent than object recognition (e.g. Yin, 1969; Diamond &amp; Carey, 1987). </p>\n<p>Composite effects observed for faces, but not other objects like cars (e.g., Cassia et al., 2009). </p>\n<p>Inversion effects for objects of expertise (Diamond &amp; Carey, 1986; Gauthier &amp; Tarr, 1997).</p>\n<p>Thatcher effect not face specific (Wong et al., 2010; Johnston et al., 2014). </p>\n<p>Composite effects for objects of expertise (Anstis, 2005; Richler et al., 2009 Gauthier et al., 2003)</p>\n<h2 id=\"Brain\"><a href=\"#Brain\" class=\"headerlink\" title=\"Brain\"></a>Brain</h2><p><strong>FMRI evidence</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202141329236.png\" alt=\"FMRI evidence\"></p>\n<p>most findings show normal activation, perhaps an issue of WM myelination</p>\n<p><strong>EEG evidence</strong></p>\n<p>less selectivity in N170 (N170 is the component associated to the neural processing of faces), no inversion effects, standard repetition suppression effects</p>\n<p><strong>CAUSAL evidence – TMS/BRAIN STIM</strong></p>\n<p><strong>TMS</strong> to the OFA disrupts face perception abilities (Pitcher et al., 2007), but also inverted faces (Pitcher et al., 2011).</p>\n<p>*<em>tDCS *</em>of OFA enhances the perception of both faces and objects (Barbieri et al., 2016).</p>\n<h2 id=\"Failure\"><a href=\"#Failure\" class=\"headerlink\" title=\"Failure\"></a>Failure</h2><p>PROSOPAGNOSIA (ACQUIRED PROSOPAGNOSIA and DEVELOPMENTAL PROSOPAGNOSIA)</p>\n<h3 id=\"Diagnosis\"><a href=\"#Diagnosis\" class=\"headerlink\" title=\"Diagnosis\"></a>Diagnosis</h3><p>Formal diagnosis not defined by DSM-V. Standard batteries rely on subjective self-report questionnaires and objective behavioural tests.</p>\n<p>The twenty-item Prosopagnosia Index (PI20)</p>\n<p>There a conflict between <strong>domain-specific</strong> and <strong>domain general</strong></p>\n<h2 id=\"NEURAL-ACCOUNTS\"><a href=\"#NEURAL-ACCOUNTS\" class=\"headerlink\" title=\"NEURAL ACCOUNTS\"></a>NEURAL ACCOUNTS</h2><h3 id=\"Findings\"><a href=\"#Findings\" class=\"headerlink\" title=\"Findings\"></a>Findings</h3><p><strong>functional</strong></p>\n<p>The impairment in DP may arise not from a dysfunction of the core areas, but from a failure to propagate signals between areas of the network. </p>\n<p><strong>structural</strong></p>\n<p>The reduced grey matter volume is found in DPs in inferior temporal lobe, STS, FFA, associated with face recognition performance. </p>\n<p>reduced grey matter volume, potential connectivity issues between core and extended regions</p>\n<p><strong>Genetics</strong></p>\n<p>inherited aspect to face recognition abilities</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Faces are thought to be processed holistically, but controversy still remains.</p>\n<p>Whether faces are processed by dedicated perceptual and neural mechanisms remains unclear, different from objects but possibly not objects of expertise.</p>\n<p>Evidence of specificity from neural and behavioural studies, but difficulty dissociating faces from objects of expertise.</p>\n<p>Two types of prosopagnosia can account for vast majority of individual differences in perception ability, but testing methods are slow and variable.</p>\n<p>Neural accounts go far in explaining the heterogeneity of the ability, but many questions about familiarity, viewpoint, propagation of signal, etc. remain.</p>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>Prosopagnosia</strong>: the condition of not being able to recognize the faces of people who are know to you, often caused by damage to the brain </p>\n<hr>\n<h1 id=\"Permalink-for-lecture-slides\"><a href=\"#Permalink-for-lecture-slides\" class=\"headerlink\" title=\"Permalink for lecture slides\"></a>Permalink for lecture slides</h1><p><a href=\"https://github.com/ReveRoyl/Lecture-slides/blob/305c4b4701b37289e1f4d53d7a5e745cecc8037c/MSc/B7.14%20Face%20processing%20and%20its%20disorders%20(14%20Feb%202022).pdf\">Face processing and its disorders</a></p>\n","excerpt":"","more":"<h1 id=\"Face-processing-and-its-disorders\"><a href=\"#Face-processing-and-its-disorders\" class=\"headerlink\" title=\"Face processing and its disorders\"></a>Face processing and its disorders</h1><h2 id=\"Learning-objectives\"><a href=\"#Learning-objectives\" class=\"headerlink\" title=\"Learning objectives\"></a>Learning objectives</h2><p>Understand the cognitive and neural basis of face perception</p>\n<p>Understand differential processes involved in holistic and configural processing</p>\n<p>Understand how differences between familiar and unfamiliar faces provide a basis for understanding how faces are learnt</p>\n<p>Understand cases of face processing deficits in various disorders (prosopagnosia, ASD)</p>\n<h2 id=\"Basic-of-face-perception-and-theories\"><a href=\"#Basic-of-face-perception-and-theories\" class=\"headerlink\" title=\"Basic of face perception and theories\"></a>Basic of face perception and theories</h2><p>There are generally two types of coding: holistic processing, configural progressing.</p>\n<h3 id=\"Evidence\"><a href=\"#Evidence\" class=\"headerlink\" title=\"Evidence\"></a>Evidence</h3><p>Evidences for holistic coding: Inversion Effects (Yin, 1969), The Thatcher Effect (Thomson,1980), The composite and part whole effect (Young et al., 1987, Tanaka &amp; Farah, 1993).</p>\n<p><strong>Inversion effect</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549192.png\" alt=\"Inversion effect\"></p>\n<p>Face perception is disproportionately impaired by inversion. The argument: upright and inverted faces are processed in qualitatively different ways. The argument: upright and inverted faces are processed in qualitatively different ways</p>\n<p><strong>Thatcher effect</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171549409.png\" alt=\"Thatcher effect\"></p>\n<p>it becomes more difficult to detect local feature changes in an upside-down face </p>\n<p>not face specific (Wong et al., 2010; Johnston et al., 2014).</p>\n<p><strong>The composite face effect</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171554805.png\" alt=\"The composite face effect\"></p>\n<p>when the top half of one face was aligned with the bottom half of another, the resulting composite arrangement induced the perception of a novel facial configuration; the presence of the bottom half altered the appearance of the top half, and <em>vice versa</em> (Young, Hellawell and Hay, 1987) </p>\n<p>but it is not observed for other objects like cars (e.g., Cassia et al., 2009).</p>\n<h2 id=\"Theories\"><a href=\"#Theories\" class=\"headerlink\" title=\"Theories\"></a>Theories</h2><p>Are faces special (different from objects) ? </p>\n<h3 id=\"Evidence-1\"><a href=\"#Evidence-1\" class=\"headerlink\" title=\"Evidence\"></a>Evidence</h3><p>Behavioural evidence</p>\n<p>Inversion impairs facial recognition to a greater extent than object recognition (e.g. Yin, 1969; Diamond &amp; Carey, 1987). </p>\n<p>Composite effects observed for faces, but not other objects like cars (e.g., Cassia et al., 2009). </p>\n<p>Inversion effects for objects of expertise (Diamond &amp; Carey, 1986; Gauthier &amp; Tarr, 1997).</p>\n<p>Thatcher effect not face specific (Wong et al., 2010; Johnston et al., 2014). </p>\n<p>Composite effects for objects of expertise (Anstis, 2005; Richler et al., 2009 Gauthier et al., 2003)</p>\n<h2 id=\"Brain\"><a href=\"#Brain\" class=\"headerlink\" title=\"Brain\"></a>Brain</h2><p><strong>FMRI evidence</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202141329236.png\" alt=\"FMRI evidence\"></p>\n<p>most findings show normal activation, perhaps an issue of WM myelination</p>\n<p><strong>EEG evidence</strong></p>\n<p>less selectivity in N170 (N170 is the component associated to the neural processing of faces), no inversion effects, standard repetition suppression effects</p>\n<p><strong>CAUSAL evidence – TMS/BRAIN STIM</strong></p>\n<p><strong>TMS</strong> to the OFA disrupts face perception abilities (Pitcher et al., 2007), but also inverted faces (Pitcher et al., 2011).</p>\n<p>*<em>tDCS *</em>of OFA enhances the perception of both faces and objects (Barbieri et al., 2016).</p>\n<h2 id=\"Failure\"><a href=\"#Failure\" class=\"headerlink\" title=\"Failure\"></a>Failure</h2><p>PROSOPAGNOSIA (ACQUIRED PROSOPAGNOSIA and DEVELOPMENTAL PROSOPAGNOSIA)</p>\n<h3 id=\"Diagnosis\"><a href=\"#Diagnosis\" class=\"headerlink\" title=\"Diagnosis\"></a>Diagnosis</h3><p>Formal diagnosis not defined by DSM-V. Standard batteries rely on subjective self-report questionnaires and objective behavioural tests.</p>\n<p>The twenty-item Prosopagnosia Index (PI20)</p>\n<p>There a conflict between <strong>domain-specific</strong> and <strong>domain general</strong></p>\n<h2 id=\"NEURAL-ACCOUNTS\"><a href=\"#NEURAL-ACCOUNTS\" class=\"headerlink\" title=\"NEURAL ACCOUNTS\"></a>NEURAL ACCOUNTS</h2><h3 id=\"Findings\"><a href=\"#Findings\" class=\"headerlink\" title=\"Findings\"></a>Findings</h3><p><strong>functional</strong></p>\n<p>The impairment in DP may arise not from a dysfunction of the core areas, but from a failure to propagate signals between areas of the network. </p>\n<p><strong>structural</strong></p>\n<p>The reduced grey matter volume is found in DPs in inferior temporal lobe, STS, FFA, associated with face recognition performance. </p>\n<p>reduced grey matter volume, potential connectivity issues between core and extended regions</p>\n<p><strong>Genetics</strong></p>\n<p>inherited aspect to face recognition abilities</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Faces are thought to be processed holistically, but controversy still remains.</p>\n<p>Whether faces are processed by dedicated perceptual and neural mechanisms remains unclear, different from objects but possibly not objects of expertise.</p>\n<p>Evidence of specificity from neural and behavioural studies, but difficulty dissociating faces from objects of expertise.</p>\n<p>Two types of prosopagnosia can account for vast majority of individual differences in perception ability, but testing methods are slow and variable.</p>\n<p>Neural accounts go far in explaining the heterogeneity of the ability, but many questions about familiarity, viewpoint, propagation of signal, etc. remain.</p>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>Prosopagnosia</strong>: the condition of not being able to recognize the faces of people who are know to you, often caused by damage to the brain </p>\n<hr>\n<h1 id=\"Permalink-for-lecture-slides\"><a href=\"#Permalink-for-lecture-slides\" class=\"headerlink\" title=\"Permalink for lecture slides\"></a>Permalink for lecture slides</h1><p><a href=\"https://github.com/ReveRoyl/Lecture-slides/blob/305c4b4701b37289e1f4d53d7a5e745cecc8037c/MSc/B7.14%20Face%20processing%20and%20its%20disorders%20(14%20Feb%202022).pdf\">Face processing and its disorders</a></p>\n"},{"title":"Backup blog source files","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-03-13T19:09:00.000Z","password":null,"summary":null,"_content":"# Backup blog source files\n\nFirst create a new branch under the github blog repository `hexo`, then `git clone` to local，take `.git`folder out, and place it in the blog root directory.\n\nThen `git checkout -b hexo` to switch to hexo branch, \n\nSubsequently, use `git add .` \n\nNext, `git commit -m \"xxx\"` , the xxx can be any note information.\n\nAfterwards, use `git push origin hexo` to submit.\n\n","source":"_posts/13_03_22Backup blog source files.md","raw":"---\ntitle: Backup blog source files\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-03-13 19:09:00\npassword:\nsummary:\ntags:\n- blog building\ncategories:\n- programming\n---\n# Backup blog source files\n\nFirst create a new branch under the github blog repository `hexo`, then `git clone` to local，take `.git`folder out, and place it in the blog root directory.\n\nThen `git checkout -b hexo` to switch to hexo branch, \n\nSubsequently, use `git add .` \n\nNext, `git commit -m \"xxx\"` , the xxx can be any note information.\n\nAfterwards, use `git push origin hexo` to submit.\n\n","slug":"13_03_22Backup blog source files","published":1,"updated":"2022-08-24T17:08:39.316Z","comments":1,"layout":"post","photos":[],"_id":"cuidEnRcQxLEpgtCzp0yR467K","content":"<h1 id=\"Backup-blog-source-files\"><a href=\"#Backup-blog-source-files\" class=\"headerlink\" title=\"Backup blog source files\"></a>Backup blog source files</h1><p>First create a new branch under the github blog repository <code>hexo</code>, then <code>git clone</code> to local，take <code>.git</code>folder out, and place it in the blog root directory.</p>\n<p>Then <code>git checkout -b hexo</code> to switch to hexo branch, </p>\n<p>Subsequently, use <code>git add .</code> </p>\n<p>Next, <code>git commit -m &quot;xxx&quot;</code> , the xxx can be any note information.</p>\n<p>Afterwards, use <code>git push origin hexo</code> to submit.</p>\n","excerpt":"","more":"<h1 id=\"Backup-blog-source-files\"><a href=\"#Backup-blog-source-files\" class=\"headerlink\" title=\"Backup blog source files\"></a>Backup blog source files</h1><p>First create a new branch under the github blog repository <code>hexo</code>, then <code>git clone</code> to local，take <code>.git</code>folder out, and place it in the blog root directory.</p>\n<p>Then <code>git checkout -b hexo</code> to switch to hexo branch, </p>\n<p>Subsequently, use <code>git add .</code> </p>\n<p>Next, <code>git commit -m &quot;xxx&quot;</code> , the xxx can be any note information.</p>\n<p>Afterwards, use <code>git push origin hexo</code> to submit.</p>\n"},{"title":"Lecture Notes 15/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-15T16:00:00.000Z","password":null,"summary":null,"_content":"\n# Cognitive and neural effects of drugs of abuse\n\n## Concept of Drug dependence\n\n![Concept of Drug Dependence](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171841445.png)PFC (prefrontal cortex) is the \"executive centre\" for planning and decision making. \n\n![PFC integrates glutamate and dopamine inputs](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171840809.png)\n\nIt involves **attention **salient information and **working memory**; PFC integrates **glutamate** and **dopamine** inputs  \n\nAssociation between cognitive domain and brain region\n\n![Association between cognitive domain and brain region](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202151810239.png)\n\n### 5-CSRTT\n\nThe **Five-choice serial-reaction time task** is a laboratory behavioural task used in psychological research to assess visuospatial attention and motor impulsivity in animals\n\n![5-CSRTT](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171849458.png)\n\nThe 5CSRTT requires the animal to correctly identify which of the five apertures has been briefly illuminated, via a nose poke, in order to receive a sugar reward\n\nAssesses **sustained** attention, **divided** attention and **selective** attention.\n\n### Animal models of Impulsive behaviour (ADHD)\n\n1. Stop-Signal Reaction Time Task\n2. Five-Choice Serial Reaction Time Task\n3. Delay-Discounting Paradigm: Delay discounting refers to the tendency for individuals to prefer immediate rewards over rewards received after a delay, even if the magnitude of the delayed reward is larger (Kirby et al., 1999; Berns et al., 2007) 延迟满足\n\nThere are similarities between patients with ventromedial prefrontal/orbitofrontal cortex (VMPC) damage and drug addicts.\n\n### Tools to assess decision\n\nIowa gambling task\n\n## Summary\n\n1. Acute administration of stimulants can enhance performance - may be one of the reasons for self-administering the drug – ‘functional reinforcement’.\n2. The acute withdrawal from these abused substances can transiently disrupt cognitive control functions such as attentional selection.\n3. These observations of impaired performance have been observed in subjects dependent on nicotine, cocaine and heroin.\n\n# Vocabularies\n\n**exacerbate**: make (a problem, bad situation, or negative feeling) worse.\n\n**ensue**: to happen after something else, especially as a result of it.\n\n**deleterious**: harmful\n\n**PFC**: Prefrontal cortex, executive centre’ for planning and decision making\n\n**withdrawal symptoms:** 戒断反应\n\n**consensus:** a generally accepted opinion or decision among a group of people\n\n**VMPC:** ventromedial prefrontal/orbitofrontal cortex\n\n\n\n\n\n\n\n","source":"_posts/15_02_22.md","raw":"---\ntitle: Lecture Notes 15/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-15 16:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n# Cognitive and neural effects of drugs of abuse\n\n## Concept of Drug dependence\n\n![Concept of Drug Dependence](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171841445.png)PFC (prefrontal cortex) is the \"executive centre\" for planning and decision making. \n\n![PFC integrates glutamate and dopamine inputs](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171840809.png)\n\nIt involves **attention **salient information and **working memory**; PFC integrates **glutamate** and **dopamine** inputs  \n\nAssociation between cognitive domain and brain region\n\n![Association between cognitive domain and brain region](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202151810239.png)\n\n### 5-CSRTT\n\nThe **Five-choice serial-reaction time task** is a laboratory behavioural task used in psychological research to assess visuospatial attention and motor impulsivity in animals\n\n![5-CSRTT](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171849458.png)\n\nThe 5CSRTT requires the animal to correctly identify which of the five apertures has been briefly illuminated, via a nose poke, in order to receive a sugar reward\n\nAssesses **sustained** attention, **divided** attention and **selective** attention.\n\n### Animal models of Impulsive behaviour (ADHD)\n\n1. Stop-Signal Reaction Time Task\n2. Five-Choice Serial Reaction Time Task\n3. Delay-Discounting Paradigm: Delay discounting refers to the tendency for individuals to prefer immediate rewards over rewards received after a delay, even if the magnitude of the delayed reward is larger (Kirby et al., 1999; Berns et al., 2007) 延迟满足\n\nThere are similarities between patients with ventromedial prefrontal/orbitofrontal cortex (VMPC) damage and drug addicts.\n\n### Tools to assess decision\n\nIowa gambling task\n\n## Summary\n\n1. Acute administration of stimulants can enhance performance - may be one of the reasons for self-administering the drug – ‘functional reinforcement’.\n2. The acute withdrawal from these abused substances can transiently disrupt cognitive control functions such as attentional selection.\n3. These observations of impaired performance have been observed in subjects dependent on nicotine, cocaine and heroin.\n\n# Vocabularies\n\n**exacerbate**: make (a problem, bad situation, or negative feeling) worse.\n\n**ensue**: to happen after something else, especially as a result of it.\n\n**deleterious**: harmful\n\n**PFC**: Prefrontal cortex, executive centre’ for planning and decision making\n\n**withdrawal symptoms:** 戒断反应\n\n**consensus:** a generally accepted opinion or decision among a group of people\n\n**VMPC:** ventromedial prefrontal/orbitofrontal cortex\n\n\n\n\n\n\n\n","slug":"15_02_22","published":1,"updated":"2022-08-24T17:08:39.327Z","comments":1,"layout":"post","photos":[],"_id":"cuidvmREG4e5FI5IOVsZYUYGl","content":"<h1 id=\"Cognitive-and-neural-effects-of-drugs-of-abuse\"><a href=\"#Cognitive-and-neural-effects-of-drugs-of-abuse\" class=\"headerlink\" title=\"Cognitive and neural effects of drugs of abuse\"></a>Cognitive and neural effects of drugs of abuse</h1><h2 id=\"Concept-of-Drug-dependence\"><a href=\"#Concept-of-Drug-dependence\" class=\"headerlink\" title=\"Concept of Drug dependence\"></a>Concept of Drug dependence</h2><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171841445.png\" alt=\"Concept of Drug Dependence\">PFC (prefrontal cortex) is the “executive centre” for planning and decision making. </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171840809.png\" alt=\"PFC integrates glutamate and dopamine inputs\"></p>\n<p>It involves <strong>attention *<em>salient information and *</em>working memory</strong>; PFC integrates <strong>glutamate</strong> and <strong>dopamine</strong> inputs  </p>\n<p>Association between cognitive domain and brain region</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202151810239.png\" alt=\"Association between cognitive domain and brain region\"></p>\n<h3 id=\"5-CSRTT\"><a href=\"#5-CSRTT\" class=\"headerlink\" title=\"5-CSRTT\"></a>5-CSRTT</h3><p>The <strong>Five-choice serial-reaction time task</strong> is a laboratory behavioural task used in psychological research to assess visuospatial attention and motor impulsivity in animals</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171849458.png\" alt=\"5-CSRTT\"></p>\n<p>The 5CSRTT requires the animal to correctly identify which of the five apertures has been briefly illuminated, via a nose poke, in order to receive a sugar reward</p>\n<p>Assesses <strong>sustained</strong> attention, <strong>divided</strong> attention and <strong>selective</strong> attention.</p>\n<h3 id=\"Animal-models-of-Impulsive-behaviour-ADHD\"><a href=\"#Animal-models-of-Impulsive-behaviour-ADHD\" class=\"headerlink\" title=\"Animal models of Impulsive behaviour (ADHD)\"></a>Animal models of Impulsive behaviour (ADHD)</h3><ol>\n<li>Stop-Signal Reaction Time Task</li>\n<li>Five-Choice Serial Reaction Time Task</li>\n<li>Delay-Discounting Paradigm: Delay discounting refers to the tendency for individuals to prefer immediate rewards over rewards received after a delay, even if the magnitude of the delayed reward is larger (Kirby et al., 1999; Berns et al., 2007) 延迟满足</li>\n</ol>\n<p>There are similarities between patients with ventromedial prefrontal/orbitofrontal cortex (VMPC) damage and drug addicts.</p>\n<h3 id=\"Tools-to-assess-decision\"><a href=\"#Tools-to-assess-decision\" class=\"headerlink\" title=\"Tools to assess decision\"></a>Tools to assess decision</h3><p>Iowa gambling task</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><ol>\n<li>Acute administration of stimulants can enhance performance - may be one of the reasons for self-administering the drug – ‘functional reinforcement’.</li>\n<li>The acute withdrawal from these abused substances can transiently disrupt cognitive control functions such as attentional selection.</li>\n<li>These observations of impaired performance have been observed in subjects dependent on nicotine, cocaine and heroin.</li>\n</ol>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>exacerbate</strong>: make (a problem, bad situation, or negative feeling) worse.</p>\n<p><strong>ensue</strong>: to happen after something else, especially as a result of it.</p>\n<p><strong>deleterious</strong>: harmful</p>\n<p><strong>PFC</strong>: Prefrontal cortex, executive centre’ for planning and decision making</p>\n<p><strong>withdrawal symptoms:</strong> 戒断反应</p>\n<p><strong>consensus:</strong> a generally accepted opinion or decision among a group of people</p>\n<p><strong>VMPC:</strong> ventromedial prefrontal/orbitofrontal cortex</p>\n","excerpt":"","more":"<h1 id=\"Cognitive-and-neural-effects-of-drugs-of-abuse\"><a href=\"#Cognitive-and-neural-effects-of-drugs-of-abuse\" class=\"headerlink\" title=\"Cognitive and neural effects of drugs of abuse\"></a>Cognitive and neural effects of drugs of abuse</h1><h2 id=\"Concept-of-Drug-dependence\"><a href=\"#Concept-of-Drug-dependence\" class=\"headerlink\" title=\"Concept of Drug dependence\"></a>Concept of Drug dependence</h2><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171841445.png\" alt=\"Concept of Drug Dependence\">PFC (prefrontal cortex) is the “executive centre” for planning and decision making. </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171840809.png\" alt=\"PFC integrates glutamate and dopamine inputs\"></p>\n<p>It involves <strong>attention *<em>salient information and *</em>working memory</strong>; PFC integrates <strong>glutamate</strong> and <strong>dopamine</strong> inputs  </p>\n<p>Association between cognitive domain and brain region</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202151810239.png\" alt=\"Association between cognitive domain and brain region\"></p>\n<h3 id=\"5-CSRTT\"><a href=\"#5-CSRTT\" class=\"headerlink\" title=\"5-CSRTT\"></a>5-CSRTT</h3><p>The <strong>Five-choice serial-reaction time task</strong> is a laboratory behavioural task used in psychological research to assess visuospatial attention and motor impulsivity in animals</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203171849458.png\" alt=\"5-CSRTT\"></p>\n<p>The 5CSRTT requires the animal to correctly identify which of the five apertures has been briefly illuminated, via a nose poke, in order to receive a sugar reward</p>\n<p>Assesses <strong>sustained</strong> attention, <strong>divided</strong> attention and <strong>selective</strong> attention.</p>\n<h3 id=\"Animal-models-of-Impulsive-behaviour-ADHD\"><a href=\"#Animal-models-of-Impulsive-behaviour-ADHD\" class=\"headerlink\" title=\"Animal models of Impulsive behaviour (ADHD)\"></a>Animal models of Impulsive behaviour (ADHD)</h3><ol>\n<li>Stop-Signal Reaction Time Task</li>\n<li>Five-Choice Serial Reaction Time Task</li>\n<li>Delay-Discounting Paradigm: Delay discounting refers to the tendency for individuals to prefer immediate rewards over rewards received after a delay, even if the magnitude of the delayed reward is larger (Kirby et al., 1999; Berns et al., 2007) 延迟满足</li>\n</ol>\n<p>There are similarities between patients with ventromedial prefrontal/orbitofrontal cortex (VMPC) damage and drug addicts.</p>\n<h3 id=\"Tools-to-assess-decision\"><a href=\"#Tools-to-assess-decision\" class=\"headerlink\" title=\"Tools to assess decision\"></a>Tools to assess decision</h3><p>Iowa gambling task</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><ol>\n<li>Acute administration of stimulants can enhance performance - may be one of the reasons for self-administering the drug – ‘functional reinforcement’.</li>\n<li>The acute withdrawal from these abused substances can transiently disrupt cognitive control functions such as attentional selection.</li>\n<li>These observations of impaired performance have been observed in subjects dependent on nicotine, cocaine and heroin.</li>\n</ol>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>exacerbate</strong>: make (a problem, bad situation, or negative feeling) worse.</p>\n<p><strong>ensue</strong>: to happen after something else, especially as a result of it.</p>\n<p><strong>deleterious</strong>: harmful</p>\n<p><strong>PFC</strong>: Prefrontal cortex, executive centre’ for planning and decision making</p>\n<p><strong>withdrawal symptoms:</strong> 戒断反应</p>\n<p><strong>consensus:</strong> a generally accepted opinion or decision among a group of people</p>\n<p><strong>VMPC:</strong> ventromedial prefrontal/orbitofrontal cortex</p>\n"},{"title":"Lecture Notes 16/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-16T19:00:00.000Z","password":null,"summary":null,"_content":"\n## Cognitive process can be measured\n\nattention and planning \n\n## What need be be discussed\n\n### 1. definition\n\nattention: focusing, sustaining \n\nplanning: organize behaviour \n\n### 2. examples\n\n#### Stroop test (computerized version: The Hampshire tree task): \n\nActivated brain region: ACC and dPFC \n\nit takes around double time to speak out the right colour for colour-paired words than unpaired ones\n\n\n\nThe tower of Hannoi \n\nTower of London\n\n### 3. methodology\n\ntest barriers: e.g. BADS\n\nsingle assessments\n\nbrain functional and structural rather than clinical factors (researchers rather than clinicians)\n\n\n\n## Validity and reliability:\n\n ","source":"_posts/16_02_22.md","raw":"---\ntitle: Lecture Notes 16/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-16 19:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n## Cognitive process can be measured\n\nattention and planning \n\n## What need be be discussed\n\n### 1. definition\n\nattention: focusing, sustaining \n\nplanning: organize behaviour \n\n### 2. examples\n\n#### Stroop test (computerized version: The Hampshire tree task): \n\nActivated brain region: ACC and dPFC \n\nit takes around double time to speak out the right colour for colour-paired words than unpaired ones\n\n\n\nThe tower of Hannoi \n\nTower of London\n\n### 3. methodology\n\ntest barriers: e.g. BADS\n\nsingle assessments\n\nbrain functional and structural rather than clinical factors (researchers rather than clinicians)\n\n\n\n## Validity and reliability:\n\n ","slug":"16_02_22","published":1,"updated":"2022-08-24T17:08:39.327Z","comments":1,"layout":"post","photos":[],"_id":"cuid5hrjeIfxgRbgYkDZELIn_","content":"<h2 id=\"Cognitive-process-can-be-measured\"><a href=\"#Cognitive-process-can-be-measured\" class=\"headerlink\" title=\"Cognitive process can be measured\"></a>Cognitive process can be measured</h2><p>attention and planning </p>\n<h2 id=\"What-need-be-be-discussed\"><a href=\"#What-need-be-be-discussed\" class=\"headerlink\" title=\"What need be be discussed\"></a>What need be be discussed</h2><h3 id=\"1-definition\"><a href=\"#1-definition\" class=\"headerlink\" title=\"1. definition\"></a>1. definition</h3><p>attention: focusing, sustaining </p>\n<p>planning: organize behaviour </p>\n<h3 id=\"2-examples\"><a href=\"#2-examples\" class=\"headerlink\" title=\"2. examples\"></a>2. examples</h3><h4 id=\"Stroop-test-computerized-version-The-Hampshire-tree-task\"><a href=\"#Stroop-test-computerized-version-The-Hampshire-tree-task\" class=\"headerlink\" title=\"Stroop test (computerized version: The Hampshire tree task):\"></a>Stroop test (computerized version: The Hampshire tree task):</h4><p>Activated brain region: ACC and dPFC </p>\n<p>it takes around double time to speak out the right colour for colour-paired words than unpaired ones</p>\n<p>The tower of Hannoi </p>\n<p>Tower of London</p>\n<h3 id=\"3-methodology\"><a href=\"#3-methodology\" class=\"headerlink\" title=\"3. methodology\"></a>3. methodology</h3><p>test barriers: e.g. BADS</p>\n<p>single assessments</p>\n<p>brain functional and structural rather than clinical factors (researchers rather than clinicians)</p>\n<h2 id=\"Validity-and-reliability\"><a href=\"#Validity-and-reliability\" class=\"headerlink\" title=\"Validity and reliability:\"></a>Validity and reliability:</h2>","excerpt":"","more":"<h2 id=\"Cognitive-process-can-be-measured\"><a href=\"#Cognitive-process-can-be-measured\" class=\"headerlink\" title=\"Cognitive process can be measured\"></a>Cognitive process can be measured</h2><p>attention and planning </p>\n<h2 id=\"What-need-be-be-discussed\"><a href=\"#What-need-be-be-discussed\" class=\"headerlink\" title=\"What need be be discussed\"></a>What need be be discussed</h2><h3 id=\"1-definition\"><a href=\"#1-definition\" class=\"headerlink\" title=\"1. definition\"></a>1. definition</h3><p>attention: focusing, sustaining </p>\n<p>planning: organize behaviour </p>\n<h3 id=\"2-examples\"><a href=\"#2-examples\" class=\"headerlink\" title=\"2. examples\"></a>2. examples</h3><h4 id=\"Stroop-test-computerized-version-The-Hampshire-tree-task\"><a href=\"#Stroop-test-computerized-version-The-Hampshire-tree-task\" class=\"headerlink\" title=\"Stroop test (computerized version: The Hampshire tree task):\"></a>Stroop test (computerized version: The Hampshire tree task):</h4><p>Activated brain region: ACC and dPFC </p>\n<p>it takes around double time to speak out the right colour for colour-paired words than unpaired ones</p>\n<p>The tower of Hannoi </p>\n<p>Tower of London</p>\n<h3 id=\"3-methodology\"><a href=\"#3-methodology\" class=\"headerlink\" title=\"3. methodology\"></a>3. methodology</h3><p>test barriers: e.g. BADS</p>\n<p>single assessments</p>\n<p>brain functional and structural rather than clinical factors (researchers rather than clinicians)</p>\n<h2 id=\"Validity-and-reliability\"><a href=\"#Validity-and-reliability\" class=\"headerlink\" title=\"Validity and reliability:\"></a>Validity and reliability:</h2>"},{"title":"Lecture Notes 17/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-17T15:00:00.000Z","password":null,"summary":null,"_content":"\n# Emotion processing: gaze and arousal mechanisms \n\n## Objectives\n\n1. Gain familiarity with prevailing and novel accounts of **atypical emotion processing** in autism.\n2. Understand **methodological problems** associated with the study of typical and atypical socioemotional processing.\n3. Understand how to derive research questions and hypotheses from theory to experiment design and become familiarised with relevant analytical approaches.\n\n## Introduction of Autism\n\n### The Autism Triade\n\n1. Impairments in social interaction and communication;\n2. Repetitive and restricted patterns of behaviour;\n3. Lack of socio-emotional reciprocity, impaired emotion\n\n\n\n![Social processing models](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203251835454.png)\n\nFast-track modulator model\n\n1. Fast pathway for face detection, tuned to low spatial frequency \n2. Subcortical route\n3. support biases to faces even in newborns\n\n![Fast track modulator model](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203252116487.png)\n\n### Atypical gaze\n\nFor atypical gaze\n\n- Reduced orientation or increased gaze aversion.\n- Gaze contingent paradigms.\n- Hyperarousal to direct eye-contact.\n- Blunt arousal correlates with reduced orientation.\n\nAgainst atypical gaze\n\n- Either no support for atypical gaze or atypical gaze was not necessarily predictive of accuracy.\n- Frequency tagging + eyetracking – similar neural dynamics.\n- Meta-analysis.\n\n## Summary\n\n1. Gaze and physiological mechanisms underlying socioemotional processing in autism are highly heterogeneous.\n2. Methodological factors: task, context, analytical approaches, measures.\n3. Individual differences and comorbidity (e.g., alexithymia, anxiety).\n4. Different theoretical approaches (normative models vs. developmental models, individual difference models).\n\n---\n\n# Neuroscience of perception and imagery\n\n## Objectives\n\n1. Phenomenological continuum of sensory experience\n2. Neurobiology of imagery and perception\n3. Theoretical models\n\n### sensory experience\n\n1. Perception\n2. Phenomenological\n3. continuum\n4. Imagery\n5. Volitional\n6. Pareidolia\n7. Illusion\n8. Hallucination\n9. Metamorphopsia\n10. Eidetic imagery\n11. Afterimage\n12. Synaesthesia\n13. Pseudohallucination\n14. Flashback imagery\n\nVeridical percept:\n\nExternal; outside voluntary control; vivid\n\nImagery percept:\n\nMind's eye; volitional; vague\n\nSome phenomena: Dream, Illusion, Pareidolia, Hallucination, Clinical illusions: Metamorphopsia, Eidetic imagery, After image, Synaesthesia, Pseudohallucination, Flashback imagery\n\nPerception and imagery are different and happens in different brain areas.\n\n![image-20220217144413570](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171444678.png)\n\nThe perception occurs in occipital lobe. The imaginary occurs in frontal parietal\n\n![image-20220217145445781](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171454844.png)\n\nQuestion: What if the abstract idea can be understood if one lack the ability for imaginary?\n\nAnswer: Ture, you can still make a prediction. \n\n\n\n---\n\n# Running a neurotech company\n\nTip 1: Embrace academic interdisciplinarity \n\nTip 2: Look before you leap\n\nTip 3: Advanced academic leaning is a great training ground for entrepreneurs and leader just be sure to step out of the \"Ivory tower\"\n\nTip 4: Find a real world problem to solve\t\n\n![image-20220217165946716](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171659887.png)\n\n![image-20220217170402216](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171704273.png)\n\n\n\n\n\n---\n\n## Watermark (an update for the blog)\n\nEvery time I finish writing an article, I can run `python3 watermark.py postname` to add a watermark. If I want to add a watermark to all articles in the first run, I can run `python3 watermark.py all`\n\n\n\n# Vocabularies\n\n**alexithymia:** the inability to recognize or describe one's own emotions.\n\n**Prevailing:** existing at a particular time; current; popular\n\n**comorbidity:** the simultaneous presence of two or more diseases or medical conditions in a patient.\n\n**Perception:** the ability to see, hear, or become aware of something through the senses.\n\n**Imagery:** visually descriptive or figurative language, especially in a literary work.\n\n","source":"_posts/17_02_22.md","raw":"---\ntitle: Lecture Notes 17/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-17 15:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n# Emotion processing: gaze and arousal mechanisms \n\n## Objectives\n\n1. Gain familiarity with prevailing and novel accounts of **atypical emotion processing** in autism.\n2. Understand **methodological problems** associated with the study of typical and atypical socioemotional processing.\n3. Understand how to derive research questions and hypotheses from theory to experiment design and become familiarised with relevant analytical approaches.\n\n## Introduction of Autism\n\n### The Autism Triade\n\n1. Impairments in social interaction and communication;\n2. Repetitive and restricted patterns of behaviour;\n3. Lack of socio-emotional reciprocity, impaired emotion\n\n\n\n![Social processing models](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203251835454.png)\n\nFast-track modulator model\n\n1. Fast pathway for face detection, tuned to low spatial frequency \n2. Subcortical route\n3. support biases to faces even in newborns\n\n![Fast track modulator model](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203252116487.png)\n\n### Atypical gaze\n\nFor atypical gaze\n\n- Reduced orientation or increased gaze aversion.\n- Gaze contingent paradigms.\n- Hyperarousal to direct eye-contact.\n- Blunt arousal correlates with reduced orientation.\n\nAgainst atypical gaze\n\n- Either no support for atypical gaze or atypical gaze was not necessarily predictive of accuracy.\n- Frequency tagging + eyetracking – similar neural dynamics.\n- Meta-analysis.\n\n## Summary\n\n1. Gaze and physiological mechanisms underlying socioemotional processing in autism are highly heterogeneous.\n2. Methodological factors: task, context, analytical approaches, measures.\n3. Individual differences and comorbidity (e.g., alexithymia, anxiety).\n4. Different theoretical approaches (normative models vs. developmental models, individual difference models).\n\n---\n\n# Neuroscience of perception and imagery\n\n## Objectives\n\n1. Phenomenological continuum of sensory experience\n2. Neurobiology of imagery and perception\n3. Theoretical models\n\n### sensory experience\n\n1. Perception\n2. Phenomenological\n3. continuum\n4. Imagery\n5. Volitional\n6. Pareidolia\n7. Illusion\n8. Hallucination\n9. Metamorphopsia\n10. Eidetic imagery\n11. Afterimage\n12. Synaesthesia\n13. Pseudohallucination\n14. Flashback imagery\n\nVeridical percept:\n\nExternal; outside voluntary control; vivid\n\nImagery percept:\n\nMind's eye; volitional; vague\n\nSome phenomena: Dream, Illusion, Pareidolia, Hallucination, Clinical illusions: Metamorphopsia, Eidetic imagery, After image, Synaesthesia, Pseudohallucination, Flashback imagery\n\nPerception and imagery are different and happens in different brain areas.\n\n![image-20220217144413570](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171444678.png)\n\nThe perception occurs in occipital lobe. The imaginary occurs in frontal parietal\n\n![image-20220217145445781](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171454844.png)\n\nQuestion: What if the abstract idea can be understood if one lack the ability for imaginary?\n\nAnswer: Ture, you can still make a prediction. \n\n\n\n---\n\n# Running a neurotech company\n\nTip 1: Embrace academic interdisciplinarity \n\nTip 2: Look before you leap\n\nTip 3: Advanced academic leaning is a great training ground for entrepreneurs and leader just be sure to step out of the \"Ivory tower\"\n\nTip 4: Find a real world problem to solve\t\n\n![image-20220217165946716](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171659887.png)\n\n![image-20220217170402216](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171704273.png)\n\n\n\n\n\n---\n\n## Watermark (an update for the blog)\n\nEvery time I finish writing an article, I can run `python3 watermark.py postname` to add a watermark. If I want to add a watermark to all articles in the first run, I can run `python3 watermark.py all`\n\n\n\n# Vocabularies\n\n**alexithymia:** the inability to recognize or describe one's own emotions.\n\n**Prevailing:** existing at a particular time; current; popular\n\n**comorbidity:** the simultaneous presence of two or more diseases or medical conditions in a patient.\n\n**Perception:** the ability to see, hear, or become aware of something through the senses.\n\n**Imagery:** visually descriptive or figurative language, especially in a literary work.\n\n","slug":"17_02_22","published":1,"updated":"2022-08-24T17:08:39.331Z","comments":1,"layout":"post","photos":[],"_id":"cuidqjYPyoZYrZ42vdH7X5zDC","content":"<h1 id=\"Emotion-processing-gaze-and-arousal-mechanisms\"><a href=\"#Emotion-processing-gaze-and-arousal-mechanisms\" class=\"headerlink\" title=\"Emotion processing: gaze and arousal mechanisms\"></a>Emotion processing: gaze and arousal mechanisms</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>Gain familiarity with prevailing and novel accounts of <strong>atypical emotion processing</strong> in autism.</li>\n<li>Understand <strong>methodological problems</strong> associated with the study of typical and atypical socioemotional processing.</li>\n<li>Understand how to derive research questions and hypotheses from theory to experiment design and become familiarised with relevant analytical approaches.</li>\n</ol>\n<h2 id=\"Introduction-of-Autism\"><a href=\"#Introduction-of-Autism\" class=\"headerlink\" title=\"Introduction of Autism\"></a>Introduction of Autism</h2><h3 id=\"The-Autism-Triade\"><a href=\"#The-Autism-Triade\" class=\"headerlink\" title=\"The Autism Triade\"></a>The Autism Triade</h3><ol>\n<li>Impairments in social interaction and communication;</li>\n<li>Repetitive and restricted patterns of behaviour;</li>\n<li>Lack of socio-emotional reciprocity, impaired emotion</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203251835454.png\" alt=\"Social processing models\"></p>\n<p>Fast-track modulator model</p>\n<ol>\n<li>Fast pathway for face detection, tuned to low spatial frequency </li>\n<li>Subcortical route</li>\n<li>support biases to faces even in newborns</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203252116487.png\" alt=\"Fast track modulator model\"></p>\n<h3 id=\"Atypical-gaze\"><a href=\"#Atypical-gaze\" class=\"headerlink\" title=\"Atypical gaze\"></a>Atypical gaze</h3><p>For atypical gaze</p>\n<ul>\n<li>Reduced orientation or increased gaze aversion.</li>\n<li>Gaze contingent paradigms.</li>\n<li>Hyperarousal to direct eye-contact.</li>\n<li>Blunt arousal correlates with reduced orientation.</li>\n</ul>\n<p>Against atypical gaze</p>\n<ul>\n<li>Either no support for atypical gaze or atypical gaze was not necessarily predictive of accuracy.</li>\n<li>Frequency tagging + eyetracking – similar neural dynamics.</li>\n<li>Meta-analysis.</li>\n</ul>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><ol>\n<li>Gaze and physiological mechanisms underlying socioemotional processing in autism are highly heterogeneous.</li>\n<li>Methodological factors: task, context, analytical approaches, measures.</li>\n<li>Individual differences and comorbidity (e.g., alexithymia, anxiety).</li>\n<li>Different theoretical approaches (normative models vs. developmental models, individual difference models).</li>\n</ol>\n<hr>\n<h1 id=\"Neuroscience-of-perception-and-imagery\"><a href=\"#Neuroscience-of-perception-and-imagery\" class=\"headerlink\" title=\"Neuroscience of perception and imagery\"></a>Neuroscience of perception and imagery</h1><h2 id=\"Objectives-1\"><a href=\"#Objectives-1\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>Phenomenological continuum of sensory experience</li>\n<li>Neurobiology of imagery and perception</li>\n<li>Theoretical models</li>\n</ol>\n<h3 id=\"sensory-experience\"><a href=\"#sensory-experience\" class=\"headerlink\" title=\"sensory experience\"></a>sensory experience</h3><ol>\n<li>Perception</li>\n<li>Phenomenological</li>\n<li>continuum</li>\n<li>Imagery</li>\n<li>Volitional</li>\n<li>Pareidolia</li>\n<li>Illusion</li>\n<li>Hallucination</li>\n<li>Metamorphopsia</li>\n<li>Eidetic imagery</li>\n<li>Afterimage</li>\n<li>Synaesthesia</li>\n<li>Pseudohallucination</li>\n<li>Flashback imagery</li>\n</ol>\n<p>Veridical percept:</p>\n<p>External; outside voluntary control; vivid</p>\n<p>Imagery percept:</p>\n<p>Mind’s eye; volitional; vague</p>\n<p>Some phenomena: Dream, Illusion, Pareidolia, Hallucination, Clinical illusions: Metamorphopsia, Eidetic imagery, After image, Synaesthesia, Pseudohallucination, Flashback imagery</p>\n<p>Perception and imagery are different and happens in different brain areas.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171444678.png\" alt=\"image-20220217144413570\"></p>\n<p>The perception occurs in occipital lobe. The imaginary occurs in frontal parietal</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171454844.png\" alt=\"image-20220217145445781\"></p>\n<p>Question: What if the abstract idea can be understood if one lack the ability for imaginary?</p>\n<p>Answer: Ture, you can still make a prediction. </p>\n<hr>\n<h1 id=\"Running-a-neurotech-company\"><a href=\"#Running-a-neurotech-company\" class=\"headerlink\" title=\"Running a neurotech company\"></a>Running a neurotech company</h1><p>Tip 1: Embrace academic interdisciplinarity </p>\n<p>Tip 2: Look before you leap</p>\n<p>Tip 3: Advanced academic leaning is a great training ground for entrepreneurs and leader just be sure to step out of the “Ivory tower”</p>\n<p>Tip 4: Find a real world problem to solve    </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171659887.png\" alt=\"image-20220217165946716\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171704273.png\" alt=\"image-20220217170402216\"></p>\n<hr>\n<h2 id=\"Watermark-an-update-for-the-blog\"><a href=\"#Watermark-an-update-for-the-blog\" class=\"headerlink\" title=\"Watermark (an update for the blog)\"></a>Watermark (an update for the blog)</h2><p>Every time I finish writing an article, I can run <code>python3 watermark.py postname</code> to add a watermark. If I want to add a watermark to all articles in the first run, I can run <code>python3 watermark.py all</code></p>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>alexithymia:</strong> the inability to recognize or describe one’s own emotions.</p>\n<p><strong>Prevailing:</strong> existing at a particular time; current; popular</p>\n<p><strong>comorbidity:</strong> the simultaneous presence of two or more diseases or medical conditions in a patient.</p>\n<p><strong>Perception:</strong> the ability to see, hear, or become aware of something through the senses.</p>\n<p><strong>Imagery:</strong> visually descriptive or figurative language, especially in a literary work.</p>\n","excerpt":"","more":"<h1 id=\"Emotion-processing-gaze-and-arousal-mechanisms\"><a href=\"#Emotion-processing-gaze-and-arousal-mechanisms\" class=\"headerlink\" title=\"Emotion processing: gaze and arousal mechanisms\"></a>Emotion processing: gaze and arousal mechanisms</h1><h2 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>Gain familiarity with prevailing and novel accounts of <strong>atypical emotion processing</strong> in autism.</li>\n<li>Understand <strong>methodological problems</strong> associated with the study of typical and atypical socioemotional processing.</li>\n<li>Understand how to derive research questions and hypotheses from theory to experiment design and become familiarised with relevant analytical approaches.</li>\n</ol>\n<h2 id=\"Introduction-of-Autism\"><a href=\"#Introduction-of-Autism\" class=\"headerlink\" title=\"Introduction of Autism\"></a>Introduction of Autism</h2><h3 id=\"The-Autism-Triade\"><a href=\"#The-Autism-Triade\" class=\"headerlink\" title=\"The Autism Triade\"></a>The Autism Triade</h3><ol>\n<li>Impairments in social interaction and communication;</li>\n<li>Repetitive and restricted patterns of behaviour;</li>\n<li>Lack of socio-emotional reciprocity, impaired emotion</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203251835454.png\" alt=\"Social processing models\"></p>\n<p>Fast-track modulator model</p>\n<ol>\n<li>Fast pathway for face detection, tuned to low spatial frequency </li>\n<li>Subcortical route</li>\n<li>support biases to faces even in newborns</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203252116487.png\" alt=\"Fast track modulator model\"></p>\n<h3 id=\"Atypical-gaze\"><a href=\"#Atypical-gaze\" class=\"headerlink\" title=\"Atypical gaze\"></a>Atypical gaze</h3><p>For atypical gaze</p>\n<ul>\n<li>Reduced orientation or increased gaze aversion.</li>\n<li>Gaze contingent paradigms.</li>\n<li>Hyperarousal to direct eye-contact.</li>\n<li>Blunt arousal correlates with reduced orientation.</li>\n</ul>\n<p>Against atypical gaze</p>\n<ul>\n<li>Either no support for atypical gaze or atypical gaze was not necessarily predictive of accuracy.</li>\n<li>Frequency tagging + eyetracking – similar neural dynamics.</li>\n<li>Meta-analysis.</li>\n</ul>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><ol>\n<li>Gaze and physiological mechanisms underlying socioemotional processing in autism are highly heterogeneous.</li>\n<li>Methodological factors: task, context, analytical approaches, measures.</li>\n<li>Individual differences and comorbidity (e.g., alexithymia, anxiety).</li>\n<li>Different theoretical approaches (normative models vs. developmental models, individual difference models).</li>\n</ol>\n<hr>\n<h1 id=\"Neuroscience-of-perception-and-imagery\"><a href=\"#Neuroscience-of-perception-and-imagery\" class=\"headerlink\" title=\"Neuroscience of perception and imagery\"></a>Neuroscience of perception and imagery</h1><h2 id=\"Objectives-1\"><a href=\"#Objectives-1\" class=\"headerlink\" title=\"Objectives\"></a>Objectives</h2><ol>\n<li>Phenomenological continuum of sensory experience</li>\n<li>Neurobiology of imagery and perception</li>\n<li>Theoretical models</li>\n</ol>\n<h3 id=\"sensory-experience\"><a href=\"#sensory-experience\" class=\"headerlink\" title=\"sensory experience\"></a>sensory experience</h3><ol>\n<li>Perception</li>\n<li>Phenomenological</li>\n<li>continuum</li>\n<li>Imagery</li>\n<li>Volitional</li>\n<li>Pareidolia</li>\n<li>Illusion</li>\n<li>Hallucination</li>\n<li>Metamorphopsia</li>\n<li>Eidetic imagery</li>\n<li>Afterimage</li>\n<li>Synaesthesia</li>\n<li>Pseudohallucination</li>\n<li>Flashback imagery</li>\n</ol>\n<p>Veridical percept:</p>\n<p>External; outside voluntary control; vivid</p>\n<p>Imagery percept:</p>\n<p>Mind’s eye; volitional; vague</p>\n<p>Some phenomena: Dream, Illusion, Pareidolia, Hallucination, Clinical illusions: Metamorphopsia, Eidetic imagery, After image, Synaesthesia, Pseudohallucination, Flashback imagery</p>\n<p>Perception and imagery are different and happens in different brain areas.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171444678.png\" alt=\"image-20220217144413570\"></p>\n<p>The perception occurs in occipital lobe. The imaginary occurs in frontal parietal</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171454844.png\" alt=\"image-20220217145445781\"></p>\n<p>Question: What if the abstract idea can be understood if one lack the ability for imaginary?</p>\n<p>Answer: Ture, you can still make a prediction. </p>\n<hr>\n<h1 id=\"Running-a-neurotech-company\"><a href=\"#Running-a-neurotech-company\" class=\"headerlink\" title=\"Running a neurotech company\"></a>Running a neurotech company</h1><p>Tip 1: Embrace academic interdisciplinarity </p>\n<p>Tip 2: Look before you leap</p>\n<p>Tip 3: Advanced academic leaning is a great training ground for entrepreneurs and leader just be sure to step out of the “Ivory tower”</p>\n<p>Tip 4: Find a real world problem to solve    </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171659887.png\" alt=\"image-20220217165946716\"></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171704273.png\" alt=\"image-20220217170402216\"></p>\n<hr>\n<h2 id=\"Watermark-an-update-for-the-blog\"><a href=\"#Watermark-an-update-for-the-blog\" class=\"headerlink\" title=\"Watermark (an update for the blog)\"></a>Watermark (an update for the blog)</h2><p>Every time I finish writing an article, I can run <code>python3 watermark.py postname</code> to add a watermark. If I want to add a watermark to all articles in the first run, I can run <code>python3 watermark.py all</code></p>\n<h1 id=\"Vocabularies\"><a href=\"#Vocabularies\" class=\"headerlink\" title=\"Vocabularies\"></a>Vocabularies</h1><p><strong>alexithymia:</strong> the inability to recognize or describe one’s own emotions.</p>\n<p><strong>Prevailing:</strong> existing at a particular time; current; popular</p>\n<p><strong>comorbidity:</strong> the simultaneous presence of two or more diseases or medical conditions in a patient.</p>\n<p><strong>Perception:</strong> the ability to see, hear, or become aware of something through the senses.</p>\n<p><strong>Imagery:</strong> visually descriptive or figurative language, especially in a literary work.</p>\n"},{"title":"Update of theme","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-16T22:41:29.000Z","password":null,"summary":null,"_content":"\n# Update of theme\n\nYesterday, I changed my blog from the jekyll version into hexo version. A new theme suddenly got me. Thus, I decide to change my theme from plane to the volume, from 2d to 3d. Here is my records for the process:\n\n## Install Node.js\n\nBefore install\n\n``` cmd\nnpm ls -g --depth=0   //check if there is a earlier relesaed node installed\n```\nThen download from https://nodejs.org/en/ for a stable version\n\ndowngrade the npm into certain version (if you installed it before):\n\n``` cmd\nnpm install npm@6.14.14 -g\n```\n\nCheck the version:\n\n``` cmd\nC:\\Users\\{yourusername}>node -v\nv12.0.0\nC:\\Users\\{yourusername}>npm -v\n6.9.0\n```\n\nYou may want to restart at last.\n\n**Tips**: At first I installed the latest version, but eventually find it do not support my \".js\" files. After several trails, here is the stable version.\n\n## Version control\n\nHere is a useful distributed revision control tool: Git\n\nhttps://git-scm.com/download/win\n\nFor the last install step, choose `Use Git from the Windows Command Prompt`\n\n## New a repository\n\nNew a initialized (with readme.md) repository in your Github library.\n\n## Install Hexo\n\nCreate a new folder in a suitable place to store your own blog files. For example, my blog files are stored in`D:\\blog`。\n\nRight click in this directory `Git Bash Here`，Open the console window of git, all our later operations will be performed in the git console。\n\nFind this directory and enter `npm i hexo-cli -g`\n\nYou can type down`hexo -v ` to verify if the installation was successful.\n\nThen we need to initialize our website, type down`hexo init`to initialize the folder, and then type down`npm install` to install the necessary components.\n\nUntil now, the local website configuration is also done.\n\nType down `hexo g` to generate a static webpage, then type down `hexo s` to open the local server.\n\nFinally open the browser [http://localhost:4000/](https://link. zhihu.com/?target=http%3A//localhost%3A4000/), you can see your blog\n\nYou can press ctrl+c to shut down the local server.\n\n## Connect Github with local\n\nThis is a important step which can help you deploy your blog to the cloud (I got stuck in this step for a while night).\n\nFirst right-click to open git bash, and then enter the following command:\n\n`git config --global user.name \"{yourusername}\"\ngit config --global user.email \"{youremailaddress}\"`\n\nThe username and email address should be modified according to the information you registered with github.\n\nThen generate the key SSH key:\n\n`ssh-keygen -t rsa -C \"{youremailaddress}\"`\n\nOpen github, click settings under the avatar, then click SSH and GPG keys to create a new SSH with any name.\n\nEnter in git bash`cat ~/.ssh/id_rsa.pub`. Copy the output to the box and click OK to save.\n\nEnter `ssh -T git@github.com`, if your username appears as shown in the figure below, congratulations, you succeed.\n\nOpen the _config.yml file in the root directory of the blog, which is the configuration file of the blog, where you can modify various information related to the blog.\n\nModify the configuration on the last line:\n\n```bash\ndeploy:\n  type: git\n  repository: https://github.com/{yourusername}/{yourusername}.github.io.git\n  branch: master\n```\n**Tips:** Remember to set the branch master as default or you can change the master into main in above code. Because the rule is changed after Nov, 2020: the master branch has been changed into main.  It may be used to avoid the term: \"master slave\".\n\n## write articles, publish articles\n\nFirst, right-click in the blog root directory to open git bash and install an extension \n\n`npm i hexo-deployer-git`\n\nThen enter `hexo new post \"article title\"` to create a new article.\n\nThen open the `D:\\blog\\source\\_posts` directory, you can find that there is an additional folder and a .md file below, one is used to store your pictures and other data, and the other is your article file.\n\nAfter writing the markdown file, enter `hexo g` in the root directory to generate a static web page, then enter `hexo s` to preview the effect locally, and finally enter `hexo d` to upload it to Github. \n\nYou can see the published article in the **github.io** now! (It may need 5 to 10 minutes to deploy depending on the online server)","source":"_posts/16_02_22Update of theme.md","raw":"---\ntitle: Update of theme\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-16 22:41:29\npassword:\nsummary:\ntags:\n- blog building\ncategories:\n- programming\n---\n\n# Update of theme\n\nYesterday, I changed my blog from the jekyll version into hexo version. A new theme suddenly got me. Thus, I decide to change my theme from plane to the volume, from 2d to 3d. Here is my records for the process:\n\n## Install Node.js\n\nBefore install\n\n``` cmd\nnpm ls -g --depth=0   //check if there is a earlier relesaed node installed\n```\nThen download from https://nodejs.org/en/ for a stable version\n\ndowngrade the npm into certain version (if you installed it before):\n\n``` cmd\nnpm install npm@6.14.14 -g\n```\n\nCheck the version:\n\n``` cmd\nC:\\Users\\{yourusername}>node -v\nv12.0.0\nC:\\Users\\{yourusername}>npm -v\n6.9.0\n```\n\nYou may want to restart at last.\n\n**Tips**: At first I installed the latest version, but eventually find it do not support my \".js\" files. After several trails, here is the stable version.\n\n## Version control\n\nHere is a useful distributed revision control tool: Git\n\nhttps://git-scm.com/download/win\n\nFor the last install step, choose `Use Git from the Windows Command Prompt`\n\n## New a repository\n\nNew a initialized (with readme.md) repository in your Github library.\n\n## Install Hexo\n\nCreate a new folder in a suitable place to store your own blog files. For example, my blog files are stored in`D:\\blog`。\n\nRight click in this directory `Git Bash Here`，Open the console window of git, all our later operations will be performed in the git console。\n\nFind this directory and enter `npm i hexo-cli -g`\n\nYou can type down`hexo -v ` to verify if the installation was successful.\n\nThen we need to initialize our website, type down`hexo init`to initialize the folder, and then type down`npm install` to install the necessary components.\n\nUntil now, the local website configuration is also done.\n\nType down `hexo g` to generate a static webpage, then type down `hexo s` to open the local server.\n\nFinally open the browser [http://localhost:4000/](https://link. zhihu.com/?target=http%3A//localhost%3A4000/), you can see your blog\n\nYou can press ctrl+c to shut down the local server.\n\n## Connect Github with local\n\nThis is a important step which can help you deploy your blog to the cloud (I got stuck in this step for a while night).\n\nFirst right-click to open git bash, and then enter the following command:\n\n`git config --global user.name \"{yourusername}\"\ngit config --global user.email \"{youremailaddress}\"`\n\nThe username and email address should be modified according to the information you registered with github.\n\nThen generate the key SSH key:\n\n`ssh-keygen -t rsa -C \"{youremailaddress}\"`\n\nOpen github, click settings under the avatar, then click SSH and GPG keys to create a new SSH with any name.\n\nEnter in git bash`cat ~/.ssh/id_rsa.pub`. Copy the output to the box and click OK to save.\n\nEnter `ssh -T git@github.com`, if your username appears as shown in the figure below, congratulations, you succeed.\n\nOpen the _config.yml file in the root directory of the blog, which is the configuration file of the blog, where you can modify various information related to the blog.\n\nModify the configuration on the last line:\n\n```bash\ndeploy:\n  type: git\n  repository: https://github.com/{yourusername}/{yourusername}.github.io.git\n  branch: master\n```\n**Tips:** Remember to set the branch master as default or you can change the master into main in above code. Because the rule is changed after Nov, 2020: the master branch has been changed into main.  It may be used to avoid the term: \"master slave\".\n\n## write articles, publish articles\n\nFirst, right-click in the blog root directory to open git bash and install an extension \n\n`npm i hexo-deployer-git`\n\nThen enter `hexo new post \"article title\"` to create a new article.\n\nThen open the `D:\\blog\\source\\_posts` directory, you can find that there is an additional folder and a .md file below, one is used to store your pictures and other data, and the other is your article file.\n\nAfter writing the markdown file, enter `hexo g` in the root directory to generate a static web page, then enter `hexo s` to preview the effect locally, and finally enter `hexo d` to upload it to Github. \n\nYou can see the published article in the **github.io** now! (It may need 5 to 10 minutes to deploy depending on the online server)","slug":"16_02_22Update of theme","published":1,"updated":"2022-08-24T17:08:39.327Z","comments":1,"layout":"post","photos":[],"_id":"cuidolZXPGJU01gloewmdu1_C","content":"<h1 id=\"Update-of-theme\"><a href=\"#Update-of-theme\" class=\"headerlink\" title=\"Update of theme\"></a>Update of theme</h1><p>Yesterday, I changed my blog from the jekyll version into hexo version. A new theme suddenly got me. Thus, I decide to change my theme from plane to the volume, from 2d to 3d. Here is my records for the process:</p>\n<h2 id=\"Install-Node-js\"><a href=\"#Install-Node-js\" class=\"headerlink\" title=\"Install Node.js\"></a>Install Node.js</h2><p>Before install</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm ls -g --depth=<span class=\"number\">0</span>   //check <span class=\"keyword\">if</span> there is a earlier relesaed node installed</span><br></pre></td></tr></table></figure>\n<p>Then download from <a href=\"https://nodejs.org/en/\">https://nodejs.org/en/</a> for a stable version</p>\n<p>downgrade the npm into certain version (if you installed it before):</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install npm@<span class=\"number\">6</span>.<span class=\"number\">14</span>.<span class=\"number\">14</span> -g</span><br></pre></td></tr></table></figure>\n\n<p>Check the version:</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">C:\\<span class=\"title\">Users</span>\\&#123;<span class=\"title\">yourusername</span>&#125;&gt;<span class=\"title\">node</span> -<span class=\"title\">v</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">v12</span>.0.0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">C</span>:\\<span class=\"title\">Users</span>\\&#123;<span class=\"title\">yourusername</span>&#125;&gt;<span class=\"title\">npm</span> -<span class=\"title\">v</span></span></span><br><span class=\"line\"><span class=\"function\">6.9.0</span></span><br></pre></td></tr></table></figure>\n\n<p>You may want to restart at last.</p>\n<p><strong>Tips</strong>: At first I installed the latest version, but eventually find it do not support my “.js” files. After several trails, here is the stable version.</p>\n<h2 id=\"Version-control\"><a href=\"#Version-control\" class=\"headerlink\" title=\"Version control\"></a>Version control</h2><p>Here is a useful distributed revision control tool: Git</p>\n<p><a href=\"https://git-scm.com/download/win\">https://git-scm.com/download/win</a></p>\n<p>For the last install step, choose <code>Use Git from the Windows Command Prompt</code></p>\n<h2 id=\"New-a-repository\"><a href=\"#New-a-repository\" class=\"headerlink\" title=\"New a repository\"></a>New a repository</h2><p>New a initialized (with readme.md) repository in your Github library.</p>\n<h2 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h2><p>Create a new folder in a suitable place to store your own blog files. For example, my blog files are stored in<code>D:\\blog</code>。</p>\n<p>Right click in this directory <code>Git Bash Here</code>，Open the console window of git, all our later operations will be performed in the git console。</p>\n<p>Find this directory and enter <code>npm i hexo-cli -g</code></p>\n<p>You can type down<code>hexo -v</code> to verify if the installation was successful.</p>\n<p>Then we need to initialize our website, type down<code>hexo init</code>to initialize the folder, and then type down<code>npm install</code> to install the necessary components.</p>\n<p>Until now, the local website configuration is also done.</p>\n<p>Type down <code>hexo g</code> to generate a static webpage, then type down <code>hexo s</code> to open the local server.</p>\n<p>Finally open the browser [<a href=\"http://localhost:4000/]\">http://localhost:4000/]</a>(<a href=\"https://link\">https://link</a>. zhihu.com/?target=http%3A//localhost%3A4000/), you can see your blog</p>\n<p>You can press ctrl+c to shut down the local server.</p>\n<h2 id=\"Connect-Github-with-local\"><a href=\"#Connect-Github-with-local\" class=\"headerlink\" title=\"Connect Github with local\"></a>Connect Github with local</h2><p>This is a important step which can help you deploy your blog to the cloud (I got stuck in this step for a while night).</p>\n<p>First right-click to open git bash, and then enter the following command:</p>\n<p><code>git config --global user.name &quot;{yourusername}&quot;\ngit config --global user.email &quot;{youremailaddress}&quot;</code></p>\n<p>The username and email address should be modified according to the information you registered with github.</p>\n<p>Then generate the key SSH key:</p>\n<p><code>ssh-keygen -t rsa -C &quot;{youremailaddress}&quot;</code></p>\n<p>Open github, click settings under the avatar, then click SSH and GPG keys to create a new SSH with any name.</p>\n<p>Enter in git bash<code>cat ~/.ssh/id_rsa.pub</code>. Copy the output to the box and click OK to save.</p>\n<p>Enter <code>ssh -T git@github.com</code>, if your username appears as shown in the figure below, congratulations, you succeed.</p>\n<p>Open the _config.yml file in the root directory of the blog, which is the configuration file of the blog, where you can modify various information related to the blog.</p>\n<p>Modify the configuration on the last line:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  <span class=\"built_in\">type</span>: git</span><br><span class=\"line\">  repository: https://github.com/&#123;yourusername&#125;/&#123;yourusername&#125;.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p><strong>Tips:</strong> Remember to set the branch master as default or you can change the master into main in above code. Because the rule is changed after Nov, 2020: the master branch has been changed into main.  It may be used to avoid the term: “master slave”.</p>\n<h2 id=\"write-articles-publish-articles\"><a href=\"#write-articles-publish-articles\" class=\"headerlink\" title=\"write articles, publish articles\"></a>write articles, publish articles</h2><p>First, right-click in the blog root directory to open git bash and install an extension </p>\n<p><code>npm i hexo-deployer-git</code></p>\n<p>Then enter <code>hexo new post &quot;article title&quot;</code> to create a new article.</p>\n<p>Then open the <code>D:\\blog\\source\\_posts</code> directory, you can find that there is an additional folder and a .md file below, one is used to store your pictures and other data, and the other is your article file.</p>\n<p>After writing the markdown file, enter <code>hexo g</code> in the root directory to generate a static web page, then enter <code>hexo s</code> to preview the effect locally, and finally enter <code>hexo d</code> to upload it to Github. </p>\n<p>You can see the published article in the <strong>github.io</strong> now! (It may need 5 to 10 minutes to deploy depending on the online server)</p>\n","excerpt":"","more":"<h1 id=\"Update-of-theme\"><a href=\"#Update-of-theme\" class=\"headerlink\" title=\"Update of theme\"></a>Update of theme</h1><p>Yesterday, I changed my blog from the jekyll version into hexo version. A new theme suddenly got me. Thus, I decide to change my theme from plane to the volume, from 2d to 3d. Here is my records for the process:</p>\n<h2 id=\"Install-Node-js\"><a href=\"#Install-Node-js\" class=\"headerlink\" title=\"Install Node.js\"></a>Install Node.js</h2><p>Before install</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm ls -g --depth=<span class=\"number\">0</span>   //check <span class=\"keyword\">if</span> there is a earlier relesaed node installed</span><br></pre></td></tr></table></figure>\n<p>Then download from <a href=\"https://nodejs.org/en/\">https://nodejs.org/en/</a> for a stable version</p>\n<p>downgrade the npm into certain version (if you installed it before):</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install npm@<span class=\"number\">6</span>.<span class=\"number\">14</span>.<span class=\"number\">14</span> -g</span><br></pre></td></tr></table></figure>\n\n<p>Check the version:</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">C:\\<span class=\"title\">Users</span>\\&#123;<span class=\"title\">yourusername</span>&#125;&gt;<span class=\"title\">node</span> -<span class=\"title\">v</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">v12</span>.0.0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">C</span>:\\<span class=\"title\">Users</span>\\&#123;<span class=\"title\">yourusername</span>&#125;&gt;<span class=\"title\">npm</span> -<span class=\"title\">v</span></span></span><br><span class=\"line\"><span class=\"function\">6.9.0</span></span><br></pre></td></tr></table></figure>\n\n<p>You may want to restart at last.</p>\n<p><strong>Tips</strong>: At first I installed the latest version, but eventually find it do not support my “.js” files. After several trails, here is the stable version.</p>\n<h2 id=\"Version-control\"><a href=\"#Version-control\" class=\"headerlink\" title=\"Version control\"></a>Version control</h2><p>Here is a useful distributed revision control tool: Git</p>\n<p><a href=\"https://git-scm.com/download/win\">https://git-scm.com/download/win</a></p>\n<p>For the last install step, choose <code>Use Git from the Windows Command Prompt</code></p>\n<h2 id=\"New-a-repository\"><a href=\"#New-a-repository\" class=\"headerlink\" title=\"New a repository\"></a>New a repository</h2><p>New a initialized (with readme.md) repository in your Github library.</p>\n<h2 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h2><p>Create a new folder in a suitable place to store your own blog files. For example, my blog files are stored in<code>D:\\blog</code>。</p>\n<p>Right click in this directory <code>Git Bash Here</code>，Open the console window of git, all our later operations will be performed in the git console。</p>\n<p>Find this directory and enter <code>npm i hexo-cli -g</code></p>\n<p>You can type down<code>hexo -v</code> to verify if the installation was successful.</p>\n<p>Then we need to initialize our website, type down<code>hexo init</code>to initialize the folder, and then type down<code>npm install</code> to install the necessary components.</p>\n<p>Until now, the local website configuration is also done.</p>\n<p>Type down <code>hexo g</code> to generate a static webpage, then type down <code>hexo s</code> to open the local server.</p>\n<p>Finally open the browser [<a href=\"http://localhost:4000/]\">http://localhost:4000/]</a>(<a href=\"https://link\">https://link</a>. zhihu.com/?target=http%3A//localhost%3A4000/), you can see your blog</p>\n<p>You can press ctrl+c to shut down the local server.</p>\n<h2 id=\"Connect-Github-with-local\"><a href=\"#Connect-Github-with-local\" class=\"headerlink\" title=\"Connect Github with local\"></a>Connect Github with local</h2><p>This is a important step which can help you deploy your blog to the cloud (I got stuck in this step for a while night).</p>\n<p>First right-click to open git bash, and then enter the following command:</p>\n<p><code>git config --global user.name &quot;{yourusername}&quot;\ngit config --global user.email &quot;{youremailaddress}&quot;</code></p>\n<p>The username and email address should be modified according to the information you registered with github.</p>\n<p>Then generate the key SSH key:</p>\n<p><code>ssh-keygen -t rsa -C &quot;{youremailaddress}&quot;</code></p>\n<p>Open github, click settings under the avatar, then click SSH and GPG keys to create a new SSH with any name.</p>\n<p>Enter in git bash<code>cat ~/.ssh/id_rsa.pub</code>. Copy the output to the box and click OK to save.</p>\n<p>Enter <code>ssh -T git@github.com</code>, if your username appears as shown in the figure below, congratulations, you succeed.</p>\n<p>Open the _config.yml file in the root directory of the blog, which is the configuration file of the blog, where you can modify various information related to the blog.</p>\n<p>Modify the configuration on the last line:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  <span class=\"built_in\">type</span>: git</span><br><span class=\"line\">  repository: https://github.com/&#123;yourusername&#125;/&#123;yourusername&#125;.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p><strong>Tips:</strong> Remember to set the branch master as default or you can change the master into main in above code. Because the rule is changed after Nov, 2020: the master branch has been changed into main.  It may be used to avoid the term: “master slave”.</p>\n<h2 id=\"write-articles-publish-articles\"><a href=\"#write-articles-publish-articles\" class=\"headerlink\" title=\"write articles, publish articles\"></a>write articles, publish articles</h2><p>First, right-click in the blog root directory to open git bash and install an extension </p>\n<p><code>npm i hexo-deployer-git</code></p>\n<p>Then enter <code>hexo new post &quot;article title&quot;</code> to create a new article.</p>\n<p>Then open the <code>D:\\blog\\source\\_posts</code> directory, you can find that there is an additional folder and a .md file below, one is used to store your pictures and other data, and the other is your article file.</p>\n<p>After writing the markdown file, enter <code>hexo g</code> in the root directory to generate a static web page, then enter <code>hexo s</code> to preview the effect locally, and finally enter <code>hexo d</code> to upload it to Github. </p>\n<p>You can see the published article in the <strong>github.io</strong> now! (It may need 5 to 10 minutes to deploy depending on the online server)</p>\n"},{"layout":"post","title":"Half a year in London","date":"2021-12-13T12:00:00.000Z","_content":"\n\n\n时光荏苒，日月穿梭。2021在无数的美好与缺憾的交织之中落下了帷幕。\n\n不知不觉中我已经在伦敦度过了三个月份，从一开始的惊喜感，初到的新鲜感，远离中国的思念感，异国文化的分离感中，我也曾徘徊过，也曾迷茫过。我突然想到毛主席说过，存人失地，人地皆寸。虽然不是同一个意思，但是我似乎从中找到了些许慰藉。渐渐的，在这个以前从未到触及的土地上我也能够适应下来了。或者至少说，存活下来了。\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356022.jpg)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t图 1. 来到英国后第一顿自己做的饭菜\n\n伴随着和别人的沟通交流，语言的障碍不再是最大的阻碍了，我也能很开心地加入到外国朋友的群体中去。从他们的眼睛里，我看到了许多不同文化背景下对同一个问题不同的解读，我学会了更加包容。不过同时，对于有些问题我们难免会有分歧，我也不尝试去说服别人。走自己的路，让别人说去吧。\n\n![image-20220104235653180](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356217.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t图 2. 校园秋景\n\n籴的籴，粜的粜。在这个校园里，我遇到了很多形形色色的人，有人因为见到了病人的痛苦而放弃了对艺术的追求，在30多岁开始学习生物学；有人身患帕金森病而在五十多岁的年纪决定投身到科学研究中尝试挽救自己和他人。每个人都是普通人，每个人的命运不尽相同，而每个人的理想都不普通。\n\n![image-20220104235705742](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042357785.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t图 3. King’s 主校区晚上九点的图书馆\n\n期待接下来的半年会更好吧。\n","source":"_posts/2022-01-04-Lei-half-a-year-in-London.md","raw":"---\nlayout: post\ntitle:  \"Half a year in London\"\ndate:   2021-12-13 12:00\ncategories: daily life\ntags: diary\n---\n\n\n\n时光荏苒，日月穿梭。2021在无数的美好与缺憾的交织之中落下了帷幕。\n\n不知不觉中我已经在伦敦度过了三个月份，从一开始的惊喜感，初到的新鲜感，远离中国的思念感，异国文化的分离感中，我也曾徘徊过，也曾迷茫过。我突然想到毛主席说过，存人失地，人地皆寸。虽然不是同一个意思，但是我似乎从中找到了些许慰藉。渐渐的，在这个以前从未到触及的土地上我也能够适应下来了。或者至少说，存活下来了。\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356022.jpg)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t图 1. 来到英国后第一顿自己做的饭菜\n\n伴随着和别人的沟通交流，语言的障碍不再是最大的阻碍了，我也能很开心地加入到外国朋友的群体中去。从他们的眼睛里，我看到了许多不同文化背景下对同一个问题不同的解读，我学会了更加包容。不过同时，对于有些问题我们难免会有分歧，我也不尝试去说服别人。走自己的路，让别人说去吧。\n\n![image-20220104235653180](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356217.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t图 2. 校园秋景\n\n籴的籴，粜的粜。在这个校园里，我遇到了很多形形色色的人，有人因为见到了病人的痛苦而放弃了对艺术的追求，在30多岁开始学习生物学；有人身患帕金森病而在五十多岁的年纪决定投身到科学研究中尝试挽救自己和他人。每个人都是普通人，每个人的命运不尽相同，而每个人的理想都不普通。\n\n![image-20220104235705742](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042357785.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t图 3. King’s 主校区晚上九点的图书馆\n\n期待接下来的半年会更好吧。\n","slug":"2022-01-04-Lei-half-a-year-in-London","published":1,"updated":"2022-08-24T17:08:39.333Z","comments":1,"photos":[],"_id":"cuidXegoZNSod9Mu480VIkjj4","content":"<p>时光荏苒，日月穿梭。2021在无数的美好与缺憾的交织之中落下了帷幕。</p>\n<p>不知不觉中我已经在伦敦度过了三个月份，从一开始的惊喜感，初到的新鲜感，远离中国的思念感，异国文化的分离感中，我也曾徘徊过，也曾迷茫过。我突然想到毛主席说过，存人失地，人地皆寸。虽然不是同一个意思，但是我似乎从中找到了些许慰藉。渐渐的，在这个以前从未到触及的土地上我也能够适应下来了。或者至少说，存活下来了。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356022.jpg\" alt=\"img\"></p>\n<p>​                                                                                                        图 1. 来到英国后第一顿自己做的饭菜</p>\n<p>伴随着和别人的沟通交流，语言的障碍不再是最大的阻碍了，我也能很开心地加入到外国朋友的群体中去。从他们的眼睛里，我看到了许多不同文化背景下对同一个问题不同的解读，我学会了更加包容。不过同时，对于有些问题我们难免会有分歧，我也不尝试去说服别人。走自己的路，让别人说去吧。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356217.png\" alt=\"image-20220104235653180\"></p>\n<p>​                                                                                                                            图 2. 校园秋景</p>\n<p>籴的籴，粜的粜。在这个校园里，我遇到了很多形形色色的人，有人因为见到了病人的痛苦而放弃了对艺术的追求，在30多岁开始学习生物学；有人身患帕金森病而在五十多岁的年纪决定投身到科学研究中尝试挽救自己和他人。每个人都是普通人，每个人的命运不尽相同，而每个人的理想都不普通。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042357785.png\" alt=\"image-20220104235705742\"></p>\n<p>​                                                                                                        图 3. King’s 主校区晚上九点的图书馆</p>\n<p>期待接下来的半年会更好吧。</p>\n","excerpt":"","more":"<p>时光荏苒，日月穿梭。2021在无数的美好与缺憾的交织之中落下了帷幕。</p>\n<p>不知不觉中我已经在伦敦度过了三个月份，从一开始的惊喜感，初到的新鲜感，远离中国的思念感，异国文化的分离感中，我也曾徘徊过，也曾迷茫过。我突然想到毛主席说过，存人失地，人地皆寸。虽然不是同一个意思，但是我似乎从中找到了些许慰藉。渐渐的，在这个以前从未到触及的土地上我也能够适应下来了。或者至少说，存活下来了。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356022.jpg\" alt=\"img\"></p>\n<p>​                                                                                                        图 1. 来到英国后第一顿自己做的饭菜</p>\n<p>伴随着和别人的沟通交流，语言的障碍不再是最大的阻碍了，我也能很开心地加入到外国朋友的群体中去。从他们的眼睛里，我看到了许多不同文化背景下对同一个问题不同的解读，我学会了更加包容。不过同时，对于有些问题我们难免会有分歧，我也不尝试去说服别人。走自己的路，让别人说去吧。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042356217.png\" alt=\"image-20220104235653180\"></p>\n<p>​                                                                                                                            图 2. 校园秋景</p>\n<p>籴的籴，粜的粜。在这个校园里，我遇到了很多形形色色的人，有人因为见到了病人的痛苦而放弃了对艺术的追求，在30多岁开始学习生物学；有人身患帕金森病而在五十多岁的年纪决定投身到科学研究中尝试挽救自己和他人。每个人都是普通人，每个人的命运不尽相同，而每个人的理想都不普通。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042357785.png\" alt=\"image-20220104235705742\"></p>\n<p>​                                                                                                        图 3. King’s 主校区晚上九点的图书馆</p>\n<p>期待接下来的半年会更好吧。</p>\n"},{"title":"Model species essay","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-11-28T16:59:19.000Z","password":null,"summary":null,"_content":"\n\n\n\nI described the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria\n\n\n\n\n## Body\n\n```describe the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria```\n\nThroughout the history of scientific research, animals have been used countless times. The earliest written record is that Aristotle (384 to 322 BC) and Erasistratus (304 to 258 BC), two early Greek physician-scientists conducted experiments on animals (Cohen and Loew 1984). In recent years, there is some new archaeological evidence to suggest that humans tried to operate a Neolithic surgery performing trepanation on a cow in 3400-3000 BCE (Ramirez and Froment, 2018). No matter what the behind meaning is, this action may be regarded as the first attempt at animal experiments in human history. When it comes to the modern era, as model biology rides on the locomotive of the rapid development of modern science, model animals become an essential topic in biology. August Krogh (1929), the 1920 Nobel Laureate in Physiology and Medicine, famously and succinctly articulated the selection of a model of a naturally occurring species, often known as the comparative approach: “For a large number of problems there will be some animal of choice or a few such animals on which it can be (most) conveniently studied”. Nowadays, the textbook definition of an animal model “as a living organism with an inherited, naturally acquired, or induced disease state that in one or more ways closely mimics the same phenomenon existing in man\" has affected how researchers approach animal models (Wessler, 1976).\n\nFor neuroscience, several factors are supposed to be considered during selecting a model species. The criteria are stated by Davidson et al. (1987) as followed 9 points: 1) suitability as an analogue, 2) information transferability, 3) genetic uniformity, 4) biological background, 5) expense and accessibility, 6) generalizability for an outcome, 7) usability and adaptability of experimental manipulation, 8) environmental status, 9) moral involvement. Considering these criteria, model selection is mostly a matter of personal preference for individual scientists, who must then persuade the rest of the research world that their choice is sound.  Many model animals, such as drosophila, zebrafish, and mice, share physiological, behavioural, and other features with humans, according to modern science. However, these rules have not treated model animals in many details. As far as Wright was concerned in 2002, the goal of an animal model specifies the requirements that it must meet in order to be considered legitimate. As a result, to decide the weights allocated to the different evaluation criteria, any model evaluation approach must consider the goals and needs that a model is designed to meet, as well as the questions it is anticipated to answer. Meanwhile, some argue that specific research should be conducted on intact, live organisms with as little experimental manipulation as feasible to avoid experimenter-induced artefact (Dow, 2007). Otherwise, the experiment, like Schrödinger's cat (Schrödinger, 1935), will undermine the validity of the outcome. In 2009, a more systemic approach (fig 1) was put forward by van der Staay et. al. At the beginning, an ethical question must be asked: whether it is acceptable? The model evaluation process continues with the question of whether the data generated by the model is reliable and repeatable, implying that deficiencies must be reproducible and behavioural dysfunctions must be quantified using reliable procedures. The model's face validity, construct validity is then discussed. After that, if the proposed model has predictive validity becomes another problem to be concerned. All these above validities reach requirements, external validity and generalizability of the model is the final step in the model evaluation cycle. Those standards are important, but as we mentioned before, each independent experiment requires various models. Therefore, we are going to discuss 3 general model animals, mice, zebrafish and drosophila as follows.\n\nIn the past decades, a lot of different types of model animals meeting these criteria were proposed and applied, some of which decay while others show strong vitality. PubMed search results by publication on the date (Fig 2) shows that the mice continue to be the powerhouse for bioscience. The other two model animals have also been used thousands of times. The very first reason why they can be the most common model animals is that they are all affordable, usability and adaptability. There is no doubt that the most significant shift in the last decades has been the dramatic increase in the use of mice in research (McCammon, 2015). Eckardt et al. (2011) argued that the mouse appears to be the most prevalent genetically altered animal model for studying novel therapeutic compounds for various illnesses at the moment, for the following reasons. As for genome conservation, 99 per cent of human genes have homologues in mice (Mouse Genome Sequencing Consortium et al., 2002). Therefore, generalizability for the outcome is doubtless accessible. The use of mouse models to evaluate pharmacological targets and develop effective and safe dose schemes for combination therapies in humans has proven successful. These scenarios all have one thing in common: they don't seek out to fully simulate a disease or disease mechanisms, but rather to gather relevant functional data. In this case, rough modelling refers to an efficient method. As for new models involving the mouse, pathological processes in human-mouse chimaeras can be uncovered by combining cellular and whole-animal techniques. To create human and mouse hybrids, human iPSCs are injected into blastula of a mouse, or tissue from human is implanted into immune-deficient mice that are older (Eckardt et al., 2011). Due to evolutionary similarities and historical reasons, mice are estimated to be the most used species to model human diseases and many other diseases. However, it is not possible to fully replicate all symptoms for one certain strain. The details are also very important when doing experiments, which is why there are specific protocols.\n\nThe mouse is a good model animal with many advantages; however, it is not the only solution or the best choice for some questions. Both the basic macro-organization of the brain and cellular morphology are strikingly comparable in zebrafish and mammalian models, the mouse for example (Kalueff, Stewart & Gerlai, 2014). The intermediate complexity of Danio rerio makes it appropriate for brain study and drug testing. It has a genetic structure that is similar to primates and a physiology that is comparable to mammals. A genetically tractable species with a sequenced genome and a broad toolset for genetic alteration, the zebrafish, like a drosophila. (Elena, 2018). The genomes of zebrafish and mammals are highly similar, with the zebrafish genome containing more than 80% of human disease genes (Howe et al., 2013). McCammon (2015) holds the view that the zebrafish is a human-like animal model that blends experimental tractability with conservation. They are quite inexpensive to keep and maintain, and they generate a high number of embryos. A considerable standard of molecular, cellular, morphological, and developmental conservation, fast temporary hereditary tests, ability for editing gene, imaging of living organism, behaviours with characteristics, multiple-diseases research, and suitability for identifying putative medicines of chemical screening    are among the zebrafish's significant attributes for addressing psychiatric disorders. The zebrafish is an excellent model organism for studying the neurological underpinnings of natural behaviour. This has been made possible by a number of technologies, including new advances in animal monitoring, computational analysis of behaviour, functional imaging of the whole brain, and methods for specific circuits and genetic manipulation. (Orger and De Polavieja 2017). In conclusion, zebrafish genetics is best adapted to large amount transient analyses, especially variant analysis and genetic interactions. However, there are also substantial disadvantages to using zebrafish models in the neuroscience research. Even though combining chemical substances with water is a simple way to do pharmacological manipulations, Chemicals can be quickly metabolized through skin and gills, based on the surface area of a particular fish and gill activity, therefore such experiments couldn't appropriately manage the medication amount taken (Rubinstein, 2006). Furthermore, from the results from Chatterjee and Gerlai (2009), zebrafish pharmacokinetic studies are still limited, and the amount of drug that reaches different target tissues is poorly explored, despite the fact that its presence and amount in the CNS can be confirmed using various chemo-analytical methods such as mass spectroscopy or high-performance liquid chromatography. The above reasons are partly why we introduce an insect as follows.\n\nThere is a smaller and simpler model animal that can be competent for a job the above two animals can't replace. Drosophila melanogaster, a well-known model animal, was famous for the finding of the concept of heritable qualities being carried on chromosomes, as well as many other ground-breaking genetic findings (Morgan 1911). The genome of drosophila was sequenced as the first main for the first time in the modern era (Adams et al., 2000). But why is drosophila a suitable model for neuroscience? Elena et al. (2018) suggest that many of these species are excellent models for understanding the cellular circuits underlying behaviour and physiology, neurotransmission, sensory perception, and plasticity, as well as the cellular basis of learning and memory at the level of the individual cell, due to the simpler organisation of the invertebrate nervous system and the presence of many accessible neurons of surprisingly large sizes at landmark locations throughout the central nervous system. Another benefit of using drosophila as a model is that the life cycle of the fly is quite short. In 10 to 12 days at 25°C, a single viable mating pair can generate hundreds of genetically identical offspring. This is in contrast to standard mouse models, which generate just a few offspring every three to four months (Pandey, 2011). At the gene level, the fly has a number of distinguishing characteristics that make it an appealing model to examine. The genome of drosophila is entirely sequenced and annotated, which encodes for more than 14,000 genes on totally four chromosomes, with three of four carrying the majority of the genome. Almost 75 per cent of genes linked to disease in humans have functioning orthologs in the drosophila, according to estimates (Reiter et al., 2001). Of course, when transferring proteins like A-beta or alpha-synuclein to fruit flies to build a disease model, someone will question: if you transfer a protein that this organism does not have originally at all, there may be some symptoms. But what is the point and whether it is meaningful or not? Moreover, the evolutionary difference between this kind of creature and human beings is too far regarding the rodent. Based on this statement, it is generally believed that the drosophila is suitable for large-scale screening, for instance, RNAi or EMS mutagenesis belonging to reverse or forward screen and the existing resources are abundant. (Pandey 2011) Experiments such as imaging behaviour are easy to operate and easy to raise. There is a big gap, but at least the targets that are worthy of in-depth selection can be screened out in the early stage. However, with the emergence of new technologies such as RNAi in mice (Slobodan 2013), these advantages may gradually weaken, but it is undeniable that some people still make models of such small animals.\n\nAll in all, these model animals do a firm favourite to the development of neuroscience. On the other hand, the contributions to this issue show that a range of less common and, at times, more specialised animal model systems are used to make numerous breakthroughs in neuroscience. Our understanding of evolutionarily conserved core processes and adaptive solutions that are basic to CNS function across phyla has improved thanks to research employing this diverse set of models (Elena 2018). Advances in stimulus delivery, behavioural monitoring, and the measurement and modulation of brain activity have made model animals behaviour more accurate and experimentally accessible in naturalistic settings. The rapid pace of research in this area should result in more quantitative modelling approaches, a better understanding of behaviour ontogeny, and better optical tools, making mice, zebrafish and drosophila an appealing system not only for genetics and development research but also for investigating the neural circuit basis of complex behaviours (Orger and De Polavieja 2017). In neuroscience research, model animals will add a rich and colourful stroke to the annals of history. The next century will be illuminated as more and more new animal models are being designed and put into use. The building of biology is waiting for us to add bricks and mortar. Zebrafish is an ideal species to study the neurobiological basis of natural behaviour.\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n## Figures and Tables\n\n![oKaJMD.png](https://z3.ax1x.com/2021/11/29/oKaJMD.png)\n\n**Figure 1.** assessment for animal models with moral and scientific assessment standards (van der Staay, 2009)\n\n\n\n \n\n![oKadII.png](https://z3.ax1x.com/2021/11/29/oKadII.png)\n\n**Figure 2.** PubMed results by publication indexed on the date, 1950 through 2020. Each species' search phrases contained both the scientific and popular names\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n## Reference\n\nCohen BJ, Loew FM. Laboratory Animal Medicine: Historical Perspectives in Laboratory Animal Medicine 1984 Academic Press, Inc: Orlando, FL, USA; Fox JG, Cohen BJ, Loew FM (eds)\n\nKrogh A. The Progress of Physiology. Science 1929;70:200-4.\n\nChatterjee, D., Gerlai, R., 2009. High precision liquid chromatography analysis of dopaminergic and serotoninergic responses to acute alcohol exposure in zebrafish. Behav Brain Res 200, 208-213\n\nNutton, V. (2021, January 1). Galen. Encyclopedia Britannica. \n\nRamirez Rozzi, F., Froment, A., 2018. Earliest Animal Cranial Surgery: from Cow to Man in the Neolithic. Scientific Reports 8.. doi:10.1038/s41598-018-23914-1\n\nReiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.]\n\nHowe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., Collins, J. E., Humphray, S., McLaren, K., Matthews, L., McLaren, S., Sealy, I., Caccamo, M., Churcher, C., Scott, C., Barrett, J. C., Koch, R., Rauch, G. J., White, S., Chow, W., … Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. Nature, 496(7446), 498–503. https://doi.org/10.1038/nature12111\n\nKalueff, A. V., Stewart, A. M., & Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. Trends in pharmacological sciences, 35(2), 63–75. https://doi.org/10.1016/j.tips.2013.12.002\n\nRubinstein, A.L., 2006. Zebrafish assays for drug toxicity screening. Expert Opin Drug Metab Toxicol 2, 231-240.\n\nEckardt, S., McLaughlin, K. J., & Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. Cell cycle (Georgetown, Tex.), 10(13), 2091–2099. https://doi.org/10.4161/cc.10.13.16360\n\nMouse Genome Sequencing Consortium, Waterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., Agarwala, R., Ainscough, R., Alexandersson, M., An, P., Antonarakis, S. E., Attwood, J., Baertsch, R., Bailey, J., Barlow, K., Beck, S., Berry, E., Birren, B., Bloom, T., … Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. Nature, 420(6915), 520–562. https://doi.org/10.1038/nature01262\n\nMcCammon, J. M., & Sive, H. (2015). Challenges in understanding psychiatric disorders and developing therapeutics: a role for zebrafish. Dis Model Mech, 8(7), 647-656. doi:10.1242/dmm.019620\n\nBeronja, S., Janki, P., Heller, E., Lien, W.-H., Keyes, B. E., Oshimori, N., & Fuchs, E. (2013). RNAi screens in mice identify physiological regulators of oncogenic growth. *Nature, 501*(7466), 185-190. doi:10.1038/nature12464\n\nBovenkerk, B., & Kaldewaij, F. (2014). The Use of Animal Models in Behavioural Neuroscience Research. In (pp. 17-46): Springer Berlin Heidelberg.\n\nDavidson, M. K., Lindsey, J. R., & Davis, J. K. (1987). Requirements and selection of an animal model. *Isr J Med Sci, 23*(6), 551-555. Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/3312096\n\nEckardt, S., McLaughlin, K. J., & Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. *Cell Cycle, 10*(13), 2091-2099. doi:10.4161/cc.10.13.16360\n\nEricsson, A. C., Crim, M. J., & Franklin, C. L. (2013). A brief history of animal modeling. *Mo Med, 110*(3), 201-205. Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/23829102\n\nHajar, R. (2011). The Physician's Little Black Bag. *Heart Views, 12*(1), 42-42. doi:10.4103/1995-705x.153004\n\nHowe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., . . . Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. *Nature, 496*(7446), 498-503. doi:10.1038/nature12111\n\nKalueff, A. V., Stewart, A. M., & Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. *Trends Pharmacol Sci, 35*(2), 63-75. doi:10.1016/j.tips.2013.12.002\n\nOrger, M. B., & De Polavieja, G. G. (2017). Zebrafish Behavior: Opportunities and Challenges. *Annual Review of Neuroscience, 40*(1), 125-147. doi:10.1146/annurev-neuro-071714-033857\n\nPandey, U. B., & Nichols, C. D. (2011). Human Disease Models in Drosophila melanogaster and the Role of the Fly in Therapeutic Drug Discovery. *Pharmacological Reviews, 63*(2), 411-436. doi:10.1124/pr.110.003293\n\nRomanova, E. V., & Sweedler, J. V. (2018). Animal Model Systems in Neuroscience. *ACS Chemical Neuroscience, 9*(8), 1869-1870. doi:10.1021/acschemneuro.8b00380\n\nSaxena, M. (2013). Huntington's Disease Animal Models. doi://dx.doi.org/10.13070/mm.en.3.205\n\nSchrödinger, E. (1935). Die gegenwärtige Situation in der Quantenmechanik. *Naturwissenschaften, 23*(48), 807-812. doi:10.1007/BF01491891\n\nvan der Staay, F. J., Arndt, S. S., & Nordquist, R. E. (2009). Evaluation of animal models of neurobehavioral disorders. *Behavioral and Brain Functions, 5*(1), 11. doi:10.1186/1744-9081-5-11\n\nWaterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., . . . Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. *Nature, 420*(6915), 520-562. doi:10.1038/nature01262\n\nWessler. (1976). Introduction : what is a model? . In *Animal models of thrombosis and hemorrhagic diseases*. \n\nAnimal Model Systems in Neuroscience Elena V. Romanova and Jonathan V. Sweedler ACS Chemical Neuroscience 2018 9 (8), 1869-1870 DOI: 10.1021/acschemneuro.8b00380\n\nWright, C. (2002). Animal models of depression in neuropsychopharmacology qua Feyerabendian philosophy of science. In S. P. Shohov (Ed.), *Advances in psychology research,* Vol. 13, pp. 129–148). Nova Science Publishers.\n\nMorgan, Thomas H. “Random Segregation Versus Coupling in Mendelian Inheritance.” *Science* (1911): 384. http://science.sciencemag.org/content/34/873/384\n\nAdams MD, Celniker SE, Holt RA, Evans CA, Gocayne JD, Amanatides PG, Scherer SE, Li PW, Hoskins RA, Galle RF, et al. (2000) The genome sequence of Drosophila melanogaster. Science 287:2185–2195.\n\nReiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.\n","source":"_posts/2021-11-28-Lei-model-species-essay.md","raw":"---\ntitle: Model species essay\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-11-28 16:59:19\npassword:\nsummary:\ntags:\n- Essay\ncategories:\n- Neuroscience\n---\n\n\n\n\nI described the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria\n\n\n\n\n## Body\n\n```describe the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria```\n\nThroughout the history of scientific research, animals have been used countless times. The earliest written record is that Aristotle (384 to 322 BC) and Erasistratus (304 to 258 BC), two early Greek physician-scientists conducted experiments on animals (Cohen and Loew 1984). In recent years, there is some new archaeological evidence to suggest that humans tried to operate a Neolithic surgery performing trepanation on a cow in 3400-3000 BCE (Ramirez and Froment, 2018). No matter what the behind meaning is, this action may be regarded as the first attempt at animal experiments in human history. When it comes to the modern era, as model biology rides on the locomotive of the rapid development of modern science, model animals become an essential topic in biology. August Krogh (1929), the 1920 Nobel Laureate in Physiology and Medicine, famously and succinctly articulated the selection of a model of a naturally occurring species, often known as the comparative approach: “For a large number of problems there will be some animal of choice or a few such animals on which it can be (most) conveniently studied”. Nowadays, the textbook definition of an animal model “as a living organism with an inherited, naturally acquired, or induced disease state that in one or more ways closely mimics the same phenomenon existing in man\" has affected how researchers approach animal models (Wessler, 1976).\n\nFor neuroscience, several factors are supposed to be considered during selecting a model species. The criteria are stated by Davidson et al. (1987) as followed 9 points: 1) suitability as an analogue, 2) information transferability, 3) genetic uniformity, 4) biological background, 5) expense and accessibility, 6) generalizability for an outcome, 7) usability and adaptability of experimental manipulation, 8) environmental status, 9) moral involvement. Considering these criteria, model selection is mostly a matter of personal preference for individual scientists, who must then persuade the rest of the research world that their choice is sound.  Many model animals, such as drosophila, zebrafish, and mice, share physiological, behavioural, and other features with humans, according to modern science. However, these rules have not treated model animals in many details. As far as Wright was concerned in 2002, the goal of an animal model specifies the requirements that it must meet in order to be considered legitimate. As a result, to decide the weights allocated to the different evaluation criteria, any model evaluation approach must consider the goals and needs that a model is designed to meet, as well as the questions it is anticipated to answer. Meanwhile, some argue that specific research should be conducted on intact, live organisms with as little experimental manipulation as feasible to avoid experimenter-induced artefact (Dow, 2007). Otherwise, the experiment, like Schrödinger's cat (Schrödinger, 1935), will undermine the validity of the outcome. In 2009, a more systemic approach (fig 1) was put forward by van der Staay et. al. At the beginning, an ethical question must be asked: whether it is acceptable? The model evaluation process continues with the question of whether the data generated by the model is reliable and repeatable, implying that deficiencies must be reproducible and behavioural dysfunctions must be quantified using reliable procedures. The model's face validity, construct validity is then discussed. After that, if the proposed model has predictive validity becomes another problem to be concerned. All these above validities reach requirements, external validity and generalizability of the model is the final step in the model evaluation cycle. Those standards are important, but as we mentioned before, each independent experiment requires various models. Therefore, we are going to discuss 3 general model animals, mice, zebrafish and drosophila as follows.\n\nIn the past decades, a lot of different types of model animals meeting these criteria were proposed and applied, some of which decay while others show strong vitality. PubMed search results by publication on the date (Fig 2) shows that the mice continue to be the powerhouse for bioscience. The other two model animals have also been used thousands of times. The very first reason why they can be the most common model animals is that they are all affordable, usability and adaptability. There is no doubt that the most significant shift in the last decades has been the dramatic increase in the use of mice in research (McCammon, 2015). Eckardt et al. (2011) argued that the mouse appears to be the most prevalent genetically altered animal model for studying novel therapeutic compounds for various illnesses at the moment, for the following reasons. As for genome conservation, 99 per cent of human genes have homologues in mice (Mouse Genome Sequencing Consortium et al., 2002). Therefore, generalizability for the outcome is doubtless accessible. The use of mouse models to evaluate pharmacological targets and develop effective and safe dose schemes for combination therapies in humans has proven successful. These scenarios all have one thing in common: they don't seek out to fully simulate a disease or disease mechanisms, but rather to gather relevant functional data. In this case, rough modelling refers to an efficient method. As for new models involving the mouse, pathological processes in human-mouse chimaeras can be uncovered by combining cellular and whole-animal techniques. To create human and mouse hybrids, human iPSCs are injected into blastula of a mouse, or tissue from human is implanted into immune-deficient mice that are older (Eckardt et al., 2011). Due to evolutionary similarities and historical reasons, mice are estimated to be the most used species to model human diseases and many other diseases. However, it is not possible to fully replicate all symptoms for one certain strain. The details are also very important when doing experiments, which is why there are specific protocols.\n\nThe mouse is a good model animal with many advantages; however, it is not the only solution or the best choice for some questions. Both the basic macro-organization of the brain and cellular morphology are strikingly comparable in zebrafish and mammalian models, the mouse for example (Kalueff, Stewart & Gerlai, 2014). The intermediate complexity of Danio rerio makes it appropriate for brain study and drug testing. It has a genetic structure that is similar to primates and a physiology that is comparable to mammals. A genetically tractable species with a sequenced genome and a broad toolset for genetic alteration, the zebrafish, like a drosophila. (Elena, 2018). The genomes of zebrafish and mammals are highly similar, with the zebrafish genome containing more than 80% of human disease genes (Howe et al., 2013). McCammon (2015) holds the view that the zebrafish is a human-like animal model that blends experimental tractability with conservation. They are quite inexpensive to keep and maintain, and they generate a high number of embryos. A considerable standard of molecular, cellular, morphological, and developmental conservation, fast temporary hereditary tests, ability for editing gene, imaging of living organism, behaviours with characteristics, multiple-diseases research, and suitability for identifying putative medicines of chemical screening    are among the zebrafish's significant attributes for addressing psychiatric disorders. The zebrafish is an excellent model organism for studying the neurological underpinnings of natural behaviour. This has been made possible by a number of technologies, including new advances in animal monitoring, computational analysis of behaviour, functional imaging of the whole brain, and methods for specific circuits and genetic manipulation. (Orger and De Polavieja 2017). In conclusion, zebrafish genetics is best adapted to large amount transient analyses, especially variant analysis and genetic interactions. However, there are also substantial disadvantages to using zebrafish models in the neuroscience research. Even though combining chemical substances with water is a simple way to do pharmacological manipulations, Chemicals can be quickly metabolized through skin and gills, based on the surface area of a particular fish and gill activity, therefore such experiments couldn't appropriately manage the medication amount taken (Rubinstein, 2006). Furthermore, from the results from Chatterjee and Gerlai (2009), zebrafish pharmacokinetic studies are still limited, and the amount of drug that reaches different target tissues is poorly explored, despite the fact that its presence and amount in the CNS can be confirmed using various chemo-analytical methods such as mass spectroscopy or high-performance liquid chromatography. The above reasons are partly why we introduce an insect as follows.\n\nThere is a smaller and simpler model animal that can be competent for a job the above two animals can't replace. Drosophila melanogaster, a well-known model animal, was famous for the finding of the concept of heritable qualities being carried on chromosomes, as well as many other ground-breaking genetic findings (Morgan 1911). The genome of drosophila was sequenced as the first main for the first time in the modern era (Adams et al., 2000). But why is drosophila a suitable model for neuroscience? Elena et al. (2018) suggest that many of these species are excellent models for understanding the cellular circuits underlying behaviour and physiology, neurotransmission, sensory perception, and plasticity, as well as the cellular basis of learning and memory at the level of the individual cell, due to the simpler organisation of the invertebrate nervous system and the presence of many accessible neurons of surprisingly large sizes at landmark locations throughout the central nervous system. Another benefit of using drosophila as a model is that the life cycle of the fly is quite short. In 10 to 12 days at 25°C, a single viable mating pair can generate hundreds of genetically identical offspring. This is in contrast to standard mouse models, which generate just a few offspring every three to four months (Pandey, 2011). At the gene level, the fly has a number of distinguishing characteristics that make it an appealing model to examine. The genome of drosophila is entirely sequenced and annotated, which encodes for more than 14,000 genes on totally four chromosomes, with three of four carrying the majority of the genome. Almost 75 per cent of genes linked to disease in humans have functioning orthologs in the drosophila, according to estimates (Reiter et al., 2001). Of course, when transferring proteins like A-beta or alpha-synuclein to fruit flies to build a disease model, someone will question: if you transfer a protein that this organism does not have originally at all, there may be some symptoms. But what is the point and whether it is meaningful or not? Moreover, the evolutionary difference between this kind of creature and human beings is too far regarding the rodent. Based on this statement, it is generally believed that the drosophila is suitable for large-scale screening, for instance, RNAi or EMS mutagenesis belonging to reverse or forward screen and the existing resources are abundant. (Pandey 2011) Experiments such as imaging behaviour are easy to operate and easy to raise. There is a big gap, but at least the targets that are worthy of in-depth selection can be screened out in the early stage. However, with the emergence of new technologies such as RNAi in mice (Slobodan 2013), these advantages may gradually weaken, but it is undeniable that some people still make models of such small animals.\n\nAll in all, these model animals do a firm favourite to the development of neuroscience. On the other hand, the contributions to this issue show that a range of less common and, at times, more specialised animal model systems are used to make numerous breakthroughs in neuroscience. Our understanding of evolutionarily conserved core processes and adaptive solutions that are basic to CNS function across phyla has improved thanks to research employing this diverse set of models (Elena 2018). Advances in stimulus delivery, behavioural monitoring, and the measurement and modulation of brain activity have made model animals behaviour more accurate and experimentally accessible in naturalistic settings. The rapid pace of research in this area should result in more quantitative modelling approaches, a better understanding of behaviour ontogeny, and better optical tools, making mice, zebrafish and drosophila an appealing system not only for genetics and development research but also for investigating the neural circuit basis of complex behaviours (Orger and De Polavieja 2017). In neuroscience research, model animals will add a rich and colourful stroke to the annals of history. The next century will be illuminated as more and more new animal models are being designed and put into use. The building of biology is waiting for us to add bricks and mortar. Zebrafish is an ideal species to study the neurobiological basis of natural behaviour.\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n## Figures and Tables\n\n![oKaJMD.png](https://z3.ax1x.com/2021/11/29/oKaJMD.png)\n\n**Figure 1.** assessment for animal models with moral and scientific assessment standards (van der Staay, 2009)\n\n\n\n \n\n![oKadII.png](https://z3.ax1x.com/2021/11/29/oKadII.png)\n\n**Figure 2.** PubMed results by publication indexed on the date, 1950 through 2020. Each species' search phrases contained both the scientific and popular names\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n## Reference\n\nCohen BJ, Loew FM. Laboratory Animal Medicine: Historical Perspectives in Laboratory Animal Medicine 1984 Academic Press, Inc: Orlando, FL, USA; Fox JG, Cohen BJ, Loew FM (eds)\n\nKrogh A. The Progress of Physiology. Science 1929;70:200-4.\n\nChatterjee, D., Gerlai, R., 2009. High precision liquid chromatography analysis of dopaminergic and serotoninergic responses to acute alcohol exposure in zebrafish. Behav Brain Res 200, 208-213\n\nNutton, V. (2021, January 1). Galen. Encyclopedia Britannica. \n\nRamirez Rozzi, F., Froment, A., 2018. Earliest Animal Cranial Surgery: from Cow to Man in the Neolithic. Scientific Reports 8.. doi:10.1038/s41598-018-23914-1\n\nReiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.]\n\nHowe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., Collins, J. E., Humphray, S., McLaren, K., Matthews, L., McLaren, S., Sealy, I., Caccamo, M., Churcher, C., Scott, C., Barrett, J. C., Koch, R., Rauch, G. J., White, S., Chow, W., … Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. Nature, 496(7446), 498–503. https://doi.org/10.1038/nature12111\n\nKalueff, A. V., Stewart, A. M., & Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. Trends in pharmacological sciences, 35(2), 63–75. https://doi.org/10.1016/j.tips.2013.12.002\n\nRubinstein, A.L., 2006. Zebrafish assays for drug toxicity screening. Expert Opin Drug Metab Toxicol 2, 231-240.\n\nEckardt, S., McLaughlin, K. J., & Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. Cell cycle (Georgetown, Tex.), 10(13), 2091–2099. https://doi.org/10.4161/cc.10.13.16360\n\nMouse Genome Sequencing Consortium, Waterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., Agarwala, R., Ainscough, R., Alexandersson, M., An, P., Antonarakis, S. E., Attwood, J., Baertsch, R., Bailey, J., Barlow, K., Beck, S., Berry, E., Birren, B., Bloom, T., … Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. Nature, 420(6915), 520–562. https://doi.org/10.1038/nature01262\n\nMcCammon, J. M., & Sive, H. (2015). Challenges in understanding psychiatric disorders and developing therapeutics: a role for zebrafish. Dis Model Mech, 8(7), 647-656. doi:10.1242/dmm.019620\n\nBeronja, S., Janki, P., Heller, E., Lien, W.-H., Keyes, B. E., Oshimori, N., & Fuchs, E. (2013). RNAi screens in mice identify physiological regulators of oncogenic growth. *Nature, 501*(7466), 185-190. doi:10.1038/nature12464\n\nBovenkerk, B., & Kaldewaij, F. (2014). The Use of Animal Models in Behavioural Neuroscience Research. In (pp. 17-46): Springer Berlin Heidelberg.\n\nDavidson, M. K., Lindsey, J. R., & Davis, J. K. (1987). Requirements and selection of an animal model. *Isr J Med Sci, 23*(6), 551-555. Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/3312096\n\nEckardt, S., McLaughlin, K. J., & Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. *Cell Cycle, 10*(13), 2091-2099. doi:10.4161/cc.10.13.16360\n\nEricsson, A. C., Crim, M. J., & Franklin, C. L. (2013). A brief history of animal modeling. *Mo Med, 110*(3), 201-205. Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/23829102\n\nHajar, R. (2011). The Physician's Little Black Bag. *Heart Views, 12*(1), 42-42. doi:10.4103/1995-705x.153004\n\nHowe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., . . . Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. *Nature, 496*(7446), 498-503. doi:10.1038/nature12111\n\nKalueff, A. V., Stewart, A. M., & Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. *Trends Pharmacol Sci, 35*(2), 63-75. doi:10.1016/j.tips.2013.12.002\n\nOrger, M. B., & De Polavieja, G. G. (2017). Zebrafish Behavior: Opportunities and Challenges. *Annual Review of Neuroscience, 40*(1), 125-147. doi:10.1146/annurev-neuro-071714-033857\n\nPandey, U. B., & Nichols, C. D. (2011). Human Disease Models in Drosophila melanogaster and the Role of the Fly in Therapeutic Drug Discovery. *Pharmacological Reviews, 63*(2), 411-436. doi:10.1124/pr.110.003293\n\nRomanova, E. V., & Sweedler, J. V. (2018). Animal Model Systems in Neuroscience. *ACS Chemical Neuroscience, 9*(8), 1869-1870. doi:10.1021/acschemneuro.8b00380\n\nSaxena, M. (2013). Huntington's Disease Animal Models. doi://dx.doi.org/10.13070/mm.en.3.205\n\nSchrödinger, E. (1935). Die gegenwärtige Situation in der Quantenmechanik. *Naturwissenschaften, 23*(48), 807-812. doi:10.1007/BF01491891\n\nvan der Staay, F. J., Arndt, S. S., & Nordquist, R. E. (2009). Evaluation of animal models of neurobehavioral disorders. *Behavioral and Brain Functions, 5*(1), 11. doi:10.1186/1744-9081-5-11\n\nWaterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., . . . Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. *Nature, 420*(6915), 520-562. doi:10.1038/nature01262\n\nWessler. (1976). Introduction : what is a model? . In *Animal models of thrombosis and hemorrhagic diseases*. \n\nAnimal Model Systems in Neuroscience Elena V. Romanova and Jonathan V. Sweedler ACS Chemical Neuroscience 2018 9 (8), 1869-1870 DOI: 10.1021/acschemneuro.8b00380\n\nWright, C. (2002). Animal models of depression in neuropsychopharmacology qua Feyerabendian philosophy of science. In S. P. Shohov (Ed.), *Advances in psychology research,* Vol. 13, pp. 129–148). Nova Science Publishers.\n\nMorgan, Thomas H. “Random Segregation Versus Coupling in Mendelian Inheritance.” *Science* (1911): 384. http://science.sciencemag.org/content/34/873/384\n\nAdams MD, Celniker SE, Holt RA, Evans CA, Gocayne JD, Amanatides PG, Scherer SE, Li PW, Hoskins RA, Galle RF, et al. (2000) The genome sequence of Drosophila melanogaster. Science 287:2185–2195.\n\nReiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.\n","slug":"2021-11-28-Lei-model-species-essay","published":1,"updated":"2022-08-24T17:08:39.332Z","comments":1,"layout":"post","photos":[],"_id":"cuid7Wyo5mniGShWDiObVqWIV","content":"<p>I described the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria</p>\n<h2 id=\"Body\"><a href=\"#Body\" class=\"headerlink\" title=\"Body\"></a>Body</h2><p><code>describe the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria</code></p>\n<p>Throughout the history of scientific research, animals have been used countless times. The earliest written record is that Aristotle (384 to 322 BC) and Erasistratus (304 to 258 BC), two early Greek physician-scientists conducted experiments on animals (Cohen and Loew 1984). In recent years, there is some new archaeological evidence to suggest that humans tried to operate a Neolithic surgery performing trepanation on a cow in 3400-3000 BCE (Ramirez and Froment, 2018). No matter what the behind meaning is, this action may be regarded as the first attempt at animal experiments in human history. When it comes to the modern era, as model biology rides on the locomotive of the rapid development of modern science, model animals become an essential topic in biology. August Krogh (1929), the 1920 Nobel Laureate in Physiology and Medicine, famously and succinctly articulated the selection of a model of a naturally occurring species, often known as the comparative approach: “For a large number of problems there will be some animal of choice or a few such animals on which it can be (most) conveniently studied”. Nowadays, the textbook definition of an animal model “as a living organism with an inherited, naturally acquired, or induced disease state that in one or more ways closely mimics the same phenomenon existing in man” has affected how researchers approach animal models (Wessler, 1976).</p>\n<p>For neuroscience, several factors are supposed to be considered during selecting a model species. The criteria are stated by Davidson et al. (1987) as followed 9 points: 1) suitability as an analogue, 2) information transferability, 3) genetic uniformity, 4) biological background, 5) expense and accessibility, 6) generalizability for an outcome, 7) usability and adaptability of experimental manipulation, 8) environmental status, 9) moral involvement. Considering these criteria, model selection is mostly a matter of personal preference for individual scientists, who must then persuade the rest of the research world that their choice is sound.  Many model animals, such as drosophila, zebrafish, and mice, share physiological, behavioural, and other features with humans, according to modern science. However, these rules have not treated model animals in many details. As far as Wright was concerned in 2002, the goal of an animal model specifies the requirements that it must meet in order to be considered legitimate. As a result, to decide the weights allocated to the different evaluation criteria, any model evaluation approach must consider the goals and needs that a model is designed to meet, as well as the questions it is anticipated to answer. Meanwhile, some argue that specific research should be conducted on intact, live organisms with as little experimental manipulation as feasible to avoid experimenter-induced artefact (Dow, 2007). Otherwise, the experiment, like Schrödinger’s cat (Schrödinger, 1935), will undermine the validity of the outcome. In 2009, a more systemic approach (fig 1) was put forward by van der Staay et. al. At the beginning, an ethical question must be asked: whether it is acceptable? The model evaluation process continues with the question of whether the data generated by the model is reliable and repeatable, implying that deficiencies must be reproducible and behavioural dysfunctions must be quantified using reliable procedures. The model’s face validity, construct validity is then discussed. After that, if the proposed model has predictive validity becomes another problem to be concerned. All these above validities reach requirements, external validity and generalizability of the model is the final step in the model evaluation cycle. Those standards are important, but as we mentioned before, each independent experiment requires various models. Therefore, we are going to discuss 3 general model animals, mice, zebrafish and drosophila as follows.</p>\n<p>In the past decades, a lot of different types of model animals meeting these criteria were proposed and applied, some of which decay while others show strong vitality. PubMed search results by publication on the date (Fig 2) shows that the mice continue to be the powerhouse for bioscience. The other two model animals have also been used thousands of times. The very first reason why they can be the most common model animals is that they are all affordable, usability and adaptability. There is no doubt that the most significant shift in the last decades has been the dramatic increase in the use of mice in research (McCammon, 2015). Eckardt et al. (2011) argued that the mouse appears to be the most prevalent genetically altered animal model for studying novel therapeutic compounds for various illnesses at the moment, for the following reasons. As for genome conservation, 99 per cent of human genes have homologues in mice (Mouse Genome Sequencing Consortium et al., 2002). Therefore, generalizability for the outcome is doubtless accessible. The use of mouse models to evaluate pharmacological targets and develop effective and safe dose schemes for combination therapies in humans has proven successful. These scenarios all have one thing in common: they don’t seek out to fully simulate a disease or disease mechanisms, but rather to gather relevant functional data. In this case, rough modelling refers to an efficient method. As for new models involving the mouse, pathological processes in human-mouse chimaeras can be uncovered by combining cellular and whole-animal techniques. To create human and mouse hybrids, human iPSCs are injected into blastula of a mouse, or tissue from human is implanted into immune-deficient mice that are older (Eckardt et al., 2011). Due to evolutionary similarities and historical reasons, mice are estimated to be the most used species to model human diseases and many other diseases. However, it is not possible to fully replicate all symptoms for one certain strain. The details are also very important when doing experiments, which is why there are specific protocols.</p>\n<p>The mouse is a good model animal with many advantages; however, it is not the only solution or the best choice for some questions. Both the basic macro-organization of the brain and cellular morphology are strikingly comparable in zebrafish and mammalian models, the mouse for example (Kalueff, Stewart &amp; Gerlai, 2014). The intermediate complexity of Danio rerio makes it appropriate for brain study and drug testing. It has a genetic structure that is similar to primates and a physiology that is comparable to mammals. A genetically tractable species with a sequenced genome and a broad toolset for genetic alteration, the zebrafish, like a drosophila. (Elena, 2018). The genomes of zebrafish and mammals are highly similar, with the zebrafish genome containing more than 80% of human disease genes (Howe et al., 2013). McCammon (2015) holds the view that the zebrafish is a human-like animal model that blends experimental tractability with conservation. They are quite inexpensive to keep and maintain, and they generate a high number of embryos. A considerable standard of molecular, cellular, morphological, and developmental conservation, fast temporary hereditary tests, ability for editing gene, imaging of living organism, behaviours with characteristics, multiple-diseases research, and suitability for identifying putative medicines of chemical screening    are among the zebrafish’s significant attributes for addressing psychiatric disorders. The zebrafish is an excellent model organism for studying the neurological underpinnings of natural behaviour. This has been made possible by a number of technologies, including new advances in animal monitoring, computational analysis of behaviour, functional imaging of the whole brain, and methods for specific circuits and genetic manipulation. (Orger and De Polavieja 2017). In conclusion, zebrafish genetics is best adapted to large amount transient analyses, especially variant analysis and genetic interactions. However, there are also substantial disadvantages to using zebrafish models in the neuroscience research. Even though combining chemical substances with water is a simple way to do pharmacological manipulations, Chemicals can be quickly metabolized through skin and gills, based on the surface area of a particular fish and gill activity, therefore such experiments couldn’t appropriately manage the medication amount taken (Rubinstein, 2006). Furthermore, from the results from Chatterjee and Gerlai (2009), zebrafish pharmacokinetic studies are still limited, and the amount of drug that reaches different target tissues is poorly explored, despite the fact that its presence and amount in the CNS can be confirmed using various chemo-analytical methods such as mass spectroscopy or high-performance liquid chromatography. The above reasons are partly why we introduce an insect as follows.</p>\n<p>There is a smaller and simpler model animal that can be competent for a job the above two animals can’t replace. Drosophila melanogaster, a well-known model animal, was famous for the finding of the concept of heritable qualities being carried on chromosomes, as well as many other ground-breaking genetic findings (Morgan 1911). The genome of drosophila was sequenced as the first main for the first time in the modern era (Adams et al., 2000). But why is drosophila a suitable model for neuroscience? Elena et al. (2018) suggest that many of these species are excellent models for understanding the cellular circuits underlying behaviour and physiology, neurotransmission, sensory perception, and plasticity, as well as the cellular basis of learning and memory at the level of the individual cell, due to the simpler organisation of the invertebrate nervous system and the presence of many accessible neurons of surprisingly large sizes at landmark locations throughout the central nervous system. Another benefit of using drosophila as a model is that the life cycle of the fly is quite short. In 10 to 12 days at 25°C, a single viable mating pair can generate hundreds of genetically identical offspring. This is in contrast to standard mouse models, which generate just a few offspring every three to four months (Pandey, 2011). At the gene level, the fly has a number of distinguishing characteristics that make it an appealing model to examine. The genome of drosophila is entirely sequenced and annotated, which encodes for more than 14,000 genes on totally four chromosomes, with three of four carrying the majority of the genome. Almost 75 per cent of genes linked to disease in humans have functioning orthologs in the drosophila, according to estimates (Reiter et al., 2001). Of course, when transferring proteins like A-beta or alpha-synuclein to fruit flies to build a disease model, someone will question: if you transfer a protein that this organism does not have originally at all, there may be some symptoms. But what is the point and whether it is meaningful or not? Moreover, the evolutionary difference between this kind of creature and human beings is too far regarding the rodent. Based on this statement, it is generally believed that the drosophila is suitable for large-scale screening, for instance, RNAi or EMS mutagenesis belonging to reverse or forward screen and the existing resources are abundant. (Pandey 2011) Experiments such as imaging behaviour are easy to operate and easy to raise. There is a big gap, but at least the targets that are worthy of in-depth selection can be screened out in the early stage. However, with the emergence of new technologies such as RNAi in mice (Slobodan 2013), these advantages may gradually weaken, but it is undeniable that some people still make models of such small animals.</p>\n<p>All in all, these model animals do a firm favourite to the development of neuroscience. On the other hand, the contributions to this issue show that a range of less common and, at times, more specialised animal model systems are used to make numerous breakthroughs in neuroscience. Our understanding of evolutionarily conserved core processes and adaptive solutions that are basic to CNS function across phyla has improved thanks to research employing this diverse set of models (Elena 2018). Advances in stimulus delivery, behavioural monitoring, and the measurement and modulation of brain activity have made model animals behaviour more accurate and experimentally accessible in naturalistic settings. The rapid pace of research in this area should result in more quantitative modelling approaches, a better understanding of behaviour ontogeny, and better optical tools, making mice, zebrafish and drosophila an appealing system not only for genetics and development research but also for investigating the neural circuit basis of complex behaviours (Orger and De Polavieja 2017). In neuroscience research, model animals will add a rich and colourful stroke to the annals of history. The next century will be illuminated as more and more new animal models are being designed and put into use. The building of biology is waiting for us to add bricks and mortar. Zebrafish is an ideal species to study the neurobiological basis of natural behaviour.</p>\n<h2 id=\"Figures-and-Tables\"><a href=\"#Figures-and-Tables\" class=\"headerlink\" title=\"Figures and Tables\"></a>Figures and Tables</h2><p><img src=\"https://z3.ax1x.com/2021/11/29/oKaJMD.png\" alt=\"oKaJMD.png\"></p>\n<p><strong>Figure 1.</strong> assessment for animal models with moral and scientific assessment standards (van der Staay, 2009)</p>\n<p><img src=\"https://z3.ax1x.com/2021/11/29/oKadII.png\" alt=\"oKadII.png\"></p>\n<p><strong>Figure 2.</strong> PubMed results by publication indexed on the date, 1950 through 2020. Each species’ search phrases contained both the scientific and popular names</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>Cohen BJ, Loew FM. Laboratory Animal Medicine: Historical Perspectives in Laboratory Animal Medicine 1984 Academic Press, Inc: Orlando, FL, USA; Fox JG, Cohen BJ, Loew FM (eds)</p>\n<p>Krogh A. The Progress of Physiology. Science 1929;70:200-4.</p>\n<p>Chatterjee, D., Gerlai, R., 2009. High precision liquid chromatography analysis of dopaminergic and serotoninergic responses to acute alcohol exposure in zebrafish. Behav Brain Res 200, 208-213</p>\n<p>Nutton, V. (2021, January 1). Galen. Encyclopedia Britannica. </p>\n<p>Ramirez Rozzi, F., Froment, A., 2018. Earliest Animal Cranial Surgery: from Cow to Man in the Neolithic. Scientific Reports 8.. doi:10.1038/s41598-018-23914-1</p>\n<p>Reiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.]</p>\n<p>Howe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., Collins, J. E., Humphray, S., McLaren, K., Matthews, L., McLaren, S., Sealy, I., Caccamo, M., Churcher, C., Scott, C., Barrett, J. C., Koch, R., Rauch, G. J., White, S., Chow, W., … Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. Nature, 496(7446), 498–503. <a href=\"https://doi.org/10.1038/nature12111\">https://doi.org/10.1038/nature12111</a></p>\n<p>Kalueff, A. V., Stewart, A. M., &amp; Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. Trends in pharmacological sciences, 35(2), 63–75. <a href=\"https://doi.org/10.1016/j.tips.2013.12.002\">https://doi.org/10.1016/j.tips.2013.12.002</a></p>\n<p>Rubinstein, A.L., 2006. Zebrafish assays for drug toxicity screening. Expert Opin Drug Metab Toxicol 2, 231-240.</p>\n<p>Eckardt, S., McLaughlin, K. J., &amp; Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. Cell cycle (Georgetown, Tex.), 10(13), 2091–2099. <a href=\"https://doi.org/10.4161/cc.10.13.16360\">https://doi.org/10.4161/cc.10.13.16360</a></p>\n<p>Mouse Genome Sequencing Consortium, Waterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., Agarwala, R., Ainscough, R., Alexandersson, M., An, P., Antonarakis, S. E., Attwood, J., Baertsch, R., Bailey, J., Barlow, K., Beck, S., Berry, E., Birren, B., Bloom, T., … Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. Nature, 420(6915), 520–562. <a href=\"https://doi.org/10.1038/nature01262\">https://doi.org/10.1038/nature01262</a></p>\n<p>McCammon, J. M., &amp; Sive, H. (2015). Challenges in understanding psychiatric disorders and developing therapeutics: a role for zebrafish. Dis Model Mech, 8(7), 647-656. doi:10.1242/dmm.019620</p>\n<p>Beronja, S., Janki, P., Heller, E., Lien, W.-H., Keyes, B. E., Oshimori, N., &amp; Fuchs, E. (2013). RNAi screens in mice identify physiological regulators of oncogenic growth. <em>Nature, 501</em>(7466), 185-190. doi:10.1038/nature12464</p>\n<p>Bovenkerk, B., &amp; Kaldewaij, F. (2014). The Use of Animal Models in Behavioural Neuroscience Research. In (pp. 17-46): Springer Berlin Heidelberg.</p>\n<p>Davidson, M. K., Lindsey, J. R., &amp; Davis, J. K. (1987). Requirements and selection of an animal model. <em>Isr J Med Sci, 23</em>(6), 551-555. Retrieved from <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/3312096\">https://www.ncbi.nlm.nih.gov/pubmed/3312096</a></p>\n<p>Eckardt, S., McLaughlin, K. J., &amp; Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. <em>Cell Cycle, 10</em>(13), 2091-2099. doi:10.4161/cc.10.13.16360</p>\n<p>Ericsson, A. C., Crim, M. J., &amp; Franklin, C. L. (2013). A brief history of animal modeling. <em>Mo Med, 110</em>(3), 201-205. Retrieved from <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/23829102\">https://www.ncbi.nlm.nih.gov/pubmed/23829102</a></p>\n<p>Hajar, R. (2011). The Physician’s Little Black Bag. <em>Heart Views, 12</em>(1), 42-42. doi:10.4103/1995-705x.153004</p>\n<p>Howe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., . . . Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. <em>Nature, 496</em>(7446), 498-503. doi:10.1038/nature12111</p>\n<p>Kalueff, A. V., Stewart, A. M., &amp; Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. <em>Trends Pharmacol Sci, 35</em>(2), 63-75. doi:10.1016/j.tips.2013.12.002</p>\n<p>Orger, M. B., &amp; De Polavieja, G. G. (2017). Zebrafish Behavior: Opportunities and Challenges. <em>Annual Review of Neuroscience, 40</em>(1), 125-147. doi:10.1146/annurev-neuro-071714-033857</p>\n<p>Pandey, U. B., &amp; Nichols, C. D. (2011). Human Disease Models in Drosophila melanogaster and the Role of the Fly in Therapeutic Drug Discovery. <em>Pharmacological Reviews, 63</em>(2), 411-436. doi:10.1124/pr.110.003293</p>\n<p>Romanova, E. V., &amp; Sweedler, J. V. (2018). Animal Model Systems in Neuroscience. <em>ACS Chemical Neuroscience, 9</em>(8), 1869-1870. doi:10.1021/acschemneuro.8b00380</p>\n<p>Saxena, M. (2013). Huntington’s Disease Animal Models. doi://dx.doi.org/10.13070/mm.en.3.205</p>\n<p>Schrödinger, E. (1935). Die gegenwärtige Situation in der Quantenmechanik. <em>Naturwissenschaften, 23</em>(48), 807-812. doi:10.1007/BF01491891</p>\n<p>van der Staay, F. J., Arndt, S. S., &amp; Nordquist, R. E. (2009). Evaluation of animal models of neurobehavioral disorders. <em>Behavioral and Brain Functions, 5</em>(1), 11. doi:10.1186/1744-9081-5-11</p>\n<p>Waterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., . . . Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. <em>Nature, 420</em>(6915), 520-562. doi:10.1038/nature01262</p>\n<p>Wessler. (1976). Introduction : what is a model? . In <em>Animal models of thrombosis and hemorrhagic diseases</em>. </p>\n<p>Animal Model Systems in Neuroscience Elena V. Romanova and Jonathan V. Sweedler ACS Chemical Neuroscience 2018 9 (8), 1869-1870 DOI: 10.1021/acschemneuro.8b00380</p>\n<p>Wright, C. (2002). Animal models of depression in neuropsychopharmacology qua Feyerabendian philosophy of science. In S. P. Shohov (Ed.), <em>Advances in psychology research,</em> Vol. 13, pp. 129–148). Nova Science Publishers.</p>\n<p>Morgan, Thomas H. “Random Segregation Versus Coupling in Mendelian Inheritance.” <em>Science</em> (1911): 384. <a href=\"http://science.sciencemag.org/content/34/873/384\">http://science.sciencemag.org/content/34/873/384</a></p>\n<p>Adams MD, Celniker SE, Holt RA, Evans CA, Gocayne JD, Amanatides PG, Scherer SE, Li PW, Hoskins RA, Galle RF, et al. (2000) The genome sequence of Drosophila melanogaster. Science 287:2185–2195.</p>\n<p>Reiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.</p>\n","excerpt":"","more":"<p>I described the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria</p>\n<h2 id=\"Body\"><a href=\"#Body\" class=\"headerlink\" title=\"Body\"></a>Body</h2><p><code>describe the key factors to be considered when selecting a model species for neuroscience research, and using examples from the literature, discuss how drosophila, zebrafish and mice meet these criteria</code></p>\n<p>Throughout the history of scientific research, animals have been used countless times. The earliest written record is that Aristotle (384 to 322 BC) and Erasistratus (304 to 258 BC), two early Greek physician-scientists conducted experiments on animals (Cohen and Loew 1984). In recent years, there is some new archaeological evidence to suggest that humans tried to operate a Neolithic surgery performing trepanation on a cow in 3400-3000 BCE (Ramirez and Froment, 2018). No matter what the behind meaning is, this action may be regarded as the first attempt at animal experiments in human history. When it comes to the modern era, as model biology rides on the locomotive of the rapid development of modern science, model animals become an essential topic in biology. August Krogh (1929), the 1920 Nobel Laureate in Physiology and Medicine, famously and succinctly articulated the selection of a model of a naturally occurring species, often known as the comparative approach: “For a large number of problems there will be some animal of choice or a few such animals on which it can be (most) conveniently studied”. Nowadays, the textbook definition of an animal model “as a living organism with an inherited, naturally acquired, or induced disease state that in one or more ways closely mimics the same phenomenon existing in man” has affected how researchers approach animal models (Wessler, 1976).</p>\n<p>For neuroscience, several factors are supposed to be considered during selecting a model species. The criteria are stated by Davidson et al. (1987) as followed 9 points: 1) suitability as an analogue, 2) information transferability, 3) genetic uniformity, 4) biological background, 5) expense and accessibility, 6) generalizability for an outcome, 7) usability and adaptability of experimental manipulation, 8) environmental status, 9) moral involvement. Considering these criteria, model selection is mostly a matter of personal preference for individual scientists, who must then persuade the rest of the research world that their choice is sound.  Many model animals, such as drosophila, zebrafish, and mice, share physiological, behavioural, and other features with humans, according to modern science. However, these rules have not treated model animals in many details. As far as Wright was concerned in 2002, the goal of an animal model specifies the requirements that it must meet in order to be considered legitimate. As a result, to decide the weights allocated to the different evaluation criteria, any model evaluation approach must consider the goals and needs that a model is designed to meet, as well as the questions it is anticipated to answer. Meanwhile, some argue that specific research should be conducted on intact, live organisms with as little experimental manipulation as feasible to avoid experimenter-induced artefact (Dow, 2007). Otherwise, the experiment, like Schrödinger’s cat (Schrödinger, 1935), will undermine the validity of the outcome. In 2009, a more systemic approach (fig 1) was put forward by van der Staay et. al. At the beginning, an ethical question must be asked: whether it is acceptable? The model evaluation process continues with the question of whether the data generated by the model is reliable and repeatable, implying that deficiencies must be reproducible and behavioural dysfunctions must be quantified using reliable procedures. The model’s face validity, construct validity is then discussed. After that, if the proposed model has predictive validity becomes another problem to be concerned. All these above validities reach requirements, external validity and generalizability of the model is the final step in the model evaluation cycle. Those standards are important, but as we mentioned before, each independent experiment requires various models. Therefore, we are going to discuss 3 general model animals, mice, zebrafish and drosophila as follows.</p>\n<p>In the past decades, a lot of different types of model animals meeting these criteria were proposed and applied, some of which decay while others show strong vitality. PubMed search results by publication on the date (Fig 2) shows that the mice continue to be the powerhouse for bioscience. The other two model animals have also been used thousands of times. The very first reason why they can be the most common model animals is that they are all affordable, usability and adaptability. There is no doubt that the most significant shift in the last decades has been the dramatic increase in the use of mice in research (McCammon, 2015). Eckardt et al. (2011) argued that the mouse appears to be the most prevalent genetically altered animal model for studying novel therapeutic compounds for various illnesses at the moment, for the following reasons. As for genome conservation, 99 per cent of human genes have homologues in mice (Mouse Genome Sequencing Consortium et al., 2002). Therefore, generalizability for the outcome is doubtless accessible. The use of mouse models to evaluate pharmacological targets and develop effective and safe dose schemes for combination therapies in humans has proven successful. These scenarios all have one thing in common: they don’t seek out to fully simulate a disease or disease mechanisms, but rather to gather relevant functional data. In this case, rough modelling refers to an efficient method. As for new models involving the mouse, pathological processes in human-mouse chimaeras can be uncovered by combining cellular and whole-animal techniques. To create human and mouse hybrids, human iPSCs are injected into blastula of a mouse, or tissue from human is implanted into immune-deficient mice that are older (Eckardt et al., 2011). Due to evolutionary similarities and historical reasons, mice are estimated to be the most used species to model human diseases and many other diseases. However, it is not possible to fully replicate all symptoms for one certain strain. The details are also very important when doing experiments, which is why there are specific protocols.</p>\n<p>The mouse is a good model animal with many advantages; however, it is not the only solution or the best choice for some questions. Both the basic macro-organization of the brain and cellular morphology are strikingly comparable in zebrafish and mammalian models, the mouse for example (Kalueff, Stewart &amp; Gerlai, 2014). The intermediate complexity of Danio rerio makes it appropriate for brain study and drug testing. It has a genetic structure that is similar to primates and a physiology that is comparable to mammals. A genetically tractable species with a sequenced genome and a broad toolset for genetic alteration, the zebrafish, like a drosophila. (Elena, 2018). The genomes of zebrafish and mammals are highly similar, with the zebrafish genome containing more than 80% of human disease genes (Howe et al., 2013). McCammon (2015) holds the view that the zebrafish is a human-like animal model that blends experimental tractability with conservation. They are quite inexpensive to keep and maintain, and they generate a high number of embryos. A considerable standard of molecular, cellular, morphological, and developmental conservation, fast temporary hereditary tests, ability for editing gene, imaging of living organism, behaviours with characteristics, multiple-diseases research, and suitability for identifying putative medicines of chemical screening    are among the zebrafish’s significant attributes for addressing psychiatric disorders. The zebrafish is an excellent model organism for studying the neurological underpinnings of natural behaviour. This has been made possible by a number of technologies, including new advances in animal monitoring, computational analysis of behaviour, functional imaging of the whole brain, and methods for specific circuits and genetic manipulation. (Orger and De Polavieja 2017). In conclusion, zebrafish genetics is best adapted to large amount transient analyses, especially variant analysis and genetic interactions. However, there are also substantial disadvantages to using zebrafish models in the neuroscience research. Even though combining chemical substances with water is a simple way to do pharmacological manipulations, Chemicals can be quickly metabolized through skin and gills, based on the surface area of a particular fish and gill activity, therefore such experiments couldn’t appropriately manage the medication amount taken (Rubinstein, 2006). Furthermore, from the results from Chatterjee and Gerlai (2009), zebrafish pharmacokinetic studies are still limited, and the amount of drug that reaches different target tissues is poorly explored, despite the fact that its presence and amount in the CNS can be confirmed using various chemo-analytical methods such as mass spectroscopy or high-performance liquid chromatography. The above reasons are partly why we introduce an insect as follows.</p>\n<p>There is a smaller and simpler model animal that can be competent for a job the above two animals can’t replace. Drosophila melanogaster, a well-known model animal, was famous for the finding of the concept of heritable qualities being carried on chromosomes, as well as many other ground-breaking genetic findings (Morgan 1911). The genome of drosophila was sequenced as the first main for the first time in the modern era (Adams et al., 2000). But why is drosophila a suitable model for neuroscience? Elena et al. (2018) suggest that many of these species are excellent models for understanding the cellular circuits underlying behaviour and physiology, neurotransmission, sensory perception, and plasticity, as well as the cellular basis of learning and memory at the level of the individual cell, due to the simpler organisation of the invertebrate nervous system and the presence of many accessible neurons of surprisingly large sizes at landmark locations throughout the central nervous system. Another benefit of using drosophila as a model is that the life cycle of the fly is quite short. In 10 to 12 days at 25°C, a single viable mating pair can generate hundreds of genetically identical offspring. This is in contrast to standard mouse models, which generate just a few offspring every three to four months (Pandey, 2011). At the gene level, the fly has a number of distinguishing characteristics that make it an appealing model to examine. The genome of drosophila is entirely sequenced and annotated, which encodes for more than 14,000 genes on totally four chromosomes, with three of four carrying the majority of the genome. Almost 75 per cent of genes linked to disease in humans have functioning orthologs in the drosophila, according to estimates (Reiter et al., 2001). Of course, when transferring proteins like A-beta or alpha-synuclein to fruit flies to build a disease model, someone will question: if you transfer a protein that this organism does not have originally at all, there may be some symptoms. But what is the point and whether it is meaningful or not? Moreover, the evolutionary difference between this kind of creature and human beings is too far regarding the rodent. Based on this statement, it is generally believed that the drosophila is suitable for large-scale screening, for instance, RNAi or EMS mutagenesis belonging to reverse or forward screen and the existing resources are abundant. (Pandey 2011) Experiments such as imaging behaviour are easy to operate and easy to raise. There is a big gap, but at least the targets that are worthy of in-depth selection can be screened out in the early stage. However, with the emergence of new technologies such as RNAi in mice (Slobodan 2013), these advantages may gradually weaken, but it is undeniable that some people still make models of such small animals.</p>\n<p>All in all, these model animals do a firm favourite to the development of neuroscience. On the other hand, the contributions to this issue show that a range of less common and, at times, more specialised animal model systems are used to make numerous breakthroughs in neuroscience. Our understanding of evolutionarily conserved core processes and adaptive solutions that are basic to CNS function across phyla has improved thanks to research employing this diverse set of models (Elena 2018). Advances in stimulus delivery, behavioural monitoring, and the measurement and modulation of brain activity have made model animals behaviour more accurate and experimentally accessible in naturalistic settings. The rapid pace of research in this area should result in more quantitative modelling approaches, a better understanding of behaviour ontogeny, and better optical tools, making mice, zebrafish and drosophila an appealing system not only for genetics and development research but also for investigating the neural circuit basis of complex behaviours (Orger and De Polavieja 2017). In neuroscience research, model animals will add a rich and colourful stroke to the annals of history. The next century will be illuminated as more and more new animal models are being designed and put into use. The building of biology is waiting for us to add bricks and mortar. Zebrafish is an ideal species to study the neurobiological basis of natural behaviour.</p>\n<h2 id=\"Figures-and-Tables\"><a href=\"#Figures-and-Tables\" class=\"headerlink\" title=\"Figures and Tables\"></a>Figures and Tables</h2><p><img src=\"https://z3.ax1x.com/2021/11/29/oKaJMD.png\" alt=\"oKaJMD.png\"></p>\n<p><strong>Figure 1.</strong> assessment for animal models with moral and scientific assessment standards (van der Staay, 2009)</p>\n<p><img src=\"https://z3.ax1x.com/2021/11/29/oKadII.png\" alt=\"oKadII.png\"></p>\n<p><strong>Figure 2.</strong> PubMed results by publication indexed on the date, 1950 through 2020. Each species’ search phrases contained both the scientific and popular names</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>Cohen BJ, Loew FM. Laboratory Animal Medicine: Historical Perspectives in Laboratory Animal Medicine 1984 Academic Press, Inc: Orlando, FL, USA; Fox JG, Cohen BJ, Loew FM (eds)</p>\n<p>Krogh A. The Progress of Physiology. Science 1929;70:200-4.</p>\n<p>Chatterjee, D., Gerlai, R., 2009. High precision liquid chromatography analysis of dopaminergic and serotoninergic responses to acute alcohol exposure in zebrafish. Behav Brain Res 200, 208-213</p>\n<p>Nutton, V. (2021, January 1). Galen. Encyclopedia Britannica. </p>\n<p>Ramirez Rozzi, F., Froment, A., 2018. Earliest Animal Cranial Surgery: from Cow to Man in the Neolithic. Scientific Reports 8.. doi:10.1038/s41598-018-23914-1</p>\n<p>Reiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.]</p>\n<p>Howe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., Collins, J. E., Humphray, S., McLaren, K., Matthews, L., McLaren, S., Sealy, I., Caccamo, M., Churcher, C., Scott, C., Barrett, J. C., Koch, R., Rauch, G. J., White, S., Chow, W., … Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. Nature, 496(7446), 498–503. <a href=\"https://doi.org/10.1038/nature12111\">https://doi.org/10.1038/nature12111</a></p>\n<p>Kalueff, A. V., Stewart, A. M., &amp; Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. Trends in pharmacological sciences, 35(2), 63–75. <a href=\"https://doi.org/10.1016/j.tips.2013.12.002\">https://doi.org/10.1016/j.tips.2013.12.002</a></p>\n<p>Rubinstein, A.L., 2006. Zebrafish assays for drug toxicity screening. Expert Opin Drug Metab Toxicol 2, 231-240.</p>\n<p>Eckardt, S., McLaughlin, K. J., &amp; Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. Cell cycle (Georgetown, Tex.), 10(13), 2091–2099. <a href=\"https://doi.org/10.4161/cc.10.13.16360\">https://doi.org/10.4161/cc.10.13.16360</a></p>\n<p>Mouse Genome Sequencing Consortium, Waterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., Agarwala, R., Ainscough, R., Alexandersson, M., An, P., Antonarakis, S. E., Attwood, J., Baertsch, R., Bailey, J., Barlow, K., Beck, S., Berry, E., Birren, B., Bloom, T., … Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. Nature, 420(6915), 520–562. <a href=\"https://doi.org/10.1038/nature01262\">https://doi.org/10.1038/nature01262</a></p>\n<p>McCammon, J. M., &amp; Sive, H. (2015). Challenges in understanding psychiatric disorders and developing therapeutics: a role for zebrafish. Dis Model Mech, 8(7), 647-656. doi:10.1242/dmm.019620</p>\n<p>Beronja, S., Janki, P., Heller, E., Lien, W.-H., Keyes, B. E., Oshimori, N., &amp; Fuchs, E. (2013). RNAi screens in mice identify physiological regulators of oncogenic growth. <em>Nature, 501</em>(7466), 185-190. doi:10.1038/nature12464</p>\n<p>Bovenkerk, B., &amp; Kaldewaij, F. (2014). The Use of Animal Models in Behavioural Neuroscience Research. In (pp. 17-46): Springer Berlin Heidelberg.</p>\n<p>Davidson, M. K., Lindsey, J. R., &amp; Davis, J. K. (1987). Requirements and selection of an animal model. <em>Isr J Med Sci, 23</em>(6), 551-555. Retrieved from <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/3312096\">https://www.ncbi.nlm.nih.gov/pubmed/3312096</a></p>\n<p>Eckardt, S., McLaughlin, K. J., &amp; Willenbring, H. (2011). Mouse chimeras as a system to investigate development, cell and tissue function, disease mechanisms and organ regeneration. <em>Cell Cycle, 10</em>(13), 2091-2099. doi:10.4161/cc.10.13.16360</p>\n<p>Ericsson, A. C., Crim, M. J., &amp; Franklin, C. L. (2013). A brief history of animal modeling. <em>Mo Med, 110</em>(3), 201-205. Retrieved from <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/23829102\">https://www.ncbi.nlm.nih.gov/pubmed/23829102</a></p>\n<p>Hajar, R. (2011). The Physician’s Little Black Bag. <em>Heart Views, 12</em>(1), 42-42. doi:10.4103/1995-705x.153004</p>\n<p>Howe, K., Clark, M. D., Torroja, C. F., Torrance, J., Berthelot, C., Muffato, M., . . . Stemple, D. L. (2013). The zebrafish reference genome sequence and its relationship to the human genome. <em>Nature, 496</em>(7446), 498-503. doi:10.1038/nature12111</p>\n<p>Kalueff, A. V., Stewart, A. M., &amp; Gerlai, R. (2014). Zebrafish as an emerging model for studying complex brain disorders. <em>Trends Pharmacol Sci, 35</em>(2), 63-75. doi:10.1016/j.tips.2013.12.002</p>\n<p>Orger, M. B., &amp; De Polavieja, G. G. (2017). Zebrafish Behavior: Opportunities and Challenges. <em>Annual Review of Neuroscience, 40</em>(1), 125-147. doi:10.1146/annurev-neuro-071714-033857</p>\n<p>Pandey, U. B., &amp; Nichols, C. D. (2011). Human Disease Models in Drosophila melanogaster and the Role of the Fly in Therapeutic Drug Discovery. <em>Pharmacological Reviews, 63</em>(2), 411-436. doi:10.1124/pr.110.003293</p>\n<p>Romanova, E. V., &amp; Sweedler, J. V. (2018). Animal Model Systems in Neuroscience. <em>ACS Chemical Neuroscience, 9</em>(8), 1869-1870. doi:10.1021/acschemneuro.8b00380</p>\n<p>Saxena, M. (2013). Huntington’s Disease Animal Models. doi://dx.doi.org/10.13070/mm.en.3.205</p>\n<p>Schrödinger, E. (1935). Die gegenwärtige Situation in der Quantenmechanik. <em>Naturwissenschaften, 23</em>(48), 807-812. doi:10.1007/BF01491891</p>\n<p>van der Staay, F. J., Arndt, S. S., &amp; Nordquist, R. E. (2009). Evaluation of animal models of neurobehavioral disorders. <em>Behavioral and Brain Functions, 5</em>(1), 11. doi:10.1186/1744-9081-5-11</p>\n<p>Waterston, R. H., Lindblad-Toh, K., Birney, E., Rogers, J., Abril, J. F., Agarwal, P., . . . Lander, E. S. (2002). Initial sequencing and comparative analysis of the mouse genome. <em>Nature, 420</em>(6915), 520-562. doi:10.1038/nature01262</p>\n<p>Wessler. (1976). Introduction : what is a model? . In <em>Animal models of thrombosis and hemorrhagic diseases</em>. </p>\n<p>Animal Model Systems in Neuroscience Elena V. Romanova and Jonathan V. Sweedler ACS Chemical Neuroscience 2018 9 (8), 1869-1870 DOI: 10.1021/acschemneuro.8b00380</p>\n<p>Wright, C. (2002). Animal models of depression in neuropsychopharmacology qua Feyerabendian philosophy of science. In S. P. Shohov (Ed.), <em>Advances in psychology research,</em> Vol. 13, pp. 129–148). Nova Science Publishers.</p>\n<p>Morgan, Thomas H. “Random Segregation Versus Coupling in Mendelian Inheritance.” <em>Science</em> (1911): 384. <a href=\"http://science.sciencemag.org/content/34/873/384\">http://science.sciencemag.org/content/34/873/384</a></p>\n<p>Adams MD, Celniker SE, Holt RA, Evans CA, Gocayne JD, Amanatides PG, Scherer SE, Li PW, Hoskins RA, Galle RF, et al. (2000) The genome sequence of Drosophila melanogaster. Science 287:2185–2195.</p>\n<p>Reiter LT, Potocki L, Chien S, Gribskov M, and Bier E (2001) E A systematic analysis of human disease-associated gene sequences in Drosophila melanogaster. Genome Res 11:1114–1125.</p>\n"},{"title":"Model proteinopathies essay","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-13T12:00:00.000Z","password":null,"summary":null,"_content":"\n\n\n\nThis is a comparison and contrast between two common proteinopathies (Alzheimer's disease & Parkinson's disease), discussing clinical symptoms, epidimiology and pathological hallmarks.\n\n\n\n# Main body\n\nThe present view takes proteinopathy as an umbrella term for the neurodegenerative disorders caused by the accumulation of misfolded protein, which is attributable to the conformational error of the protein (Bayer, 2015, Lanuti, 2020) These aggregated proteins were verified to gain typical amyloid features (Virchow, 1854) which means the “starch” conformation. In this case, these proteins might not only lose their original normal function but also gain toxicity (Luheshi et al., 2008). Speaking of proteinopathies, two diseases must be mentioned: One is Parkinson’s disease (PD), the most famous progressive neurodegenerative diseases associated with motor as well as nonmotor deficits, which is known as the second common neurodegenerative disorder, (Capriotti & Terzakis, 2016; Simon et al., 2020; Hayes, 2019); the other one is Alzheimer’s disease (AD), one of the most major reason for dementia, the most common neurodegenerative disorder (Lane, Hardy & Schott, 2018). There are around one billion sufferers around the world who are suffering both physical and psychological agony from these neurodegenerative disorders in 2019 (Bulck et al., 2019). Various factors, for instance genomic, epigenomic, metabolic, or environmental factors (Bulck et al., 2019), are shown to have an impact on PD and AD in a permutation and combination way. Here this essay will go into detail about these two common proteinopathies in three aspects: clinical symptoms, epidemiology and pathological hallmarks.\n\nIn terms of clinical symptoms between PD and AD, multiple similar as well as differing pathological phenotypes can be identified, which is treated under the comparison and contrast between PD and AD (Table 1). PD and AD are both irreversible progressive, degenerative diseases meaning the symptoms will gradually become more severe as the stages develop. The most obvious problems about patients’ cognitive and psychiatric symptoms come first as we consider these neurodegenerative diseases. As far as we know, AD is well-known for its influence on memory, academically called amnesia which was first conceptualized as memory loss in 1763 by Sauvagues (Langer, 2019). Most of the advanced AD sufferers are reported to have Amnesia symptoms, accounting for fifty per cent to seventy per cent of all patients with dementia (Burns & Iliffe 2009), while it seldomly happens to PD patients. Only the most severe PD sufferers are reported to experience similar amnesia symptoms (Querfurth & LaFerla, 2010). At the memory level, patients with AD not only have amnesia but also often experience memory distortions (El Haj et al. 2020, Younan et al., 2020), such as having comprehensive and vivid memories of episodic occurrences that have never been observed. AD symptoms are generally considered as an essential impairment of episodic memory (Younan et al., 2020), while one’s attention is compromised on AD’s early stage as well, especially in those with early age onset and atypical syndromes (Malhotra, 2018). One feature of AD is that the symptoms are accompanied by severe attentional impairment frequently which is linked with other neurodegenerative disorders as well (Malhotra, 2018). It is suggested that PD patients suffer more depression and anxiety (Sveinbjornsdottir, 2016) than AD patients, which may be concluded to the inconsistency between one’s movements and willingness.\n\nApart from memory problems for AD and PD, some other motor symptoms can also put huge inconvenience to one’s life. PD patients are reported to have three main symptoms which are tremor, bradykinesia and rigidity (Hayes, 2019). Tremor means shaking, especially after a short pause of a postural movement. Bradykinesia implies a slower movement than normal action which may cause difficulties for some ordinary tasks like walking or doing dishes. Rigidity or spasticity refers to muscle stiffness, which is academically called dystonia (Tolosa & Compta, 2006). Unlike those symptoms in AD, these three main symptoms in PD are more relying on the neuromuscular connection so that these are all related to muscle control abnormality which is the direct result of neurodegeneration the same as AD (McGregor & Nelson, 2019). Similarly, AD patients also suffer motor problems like dysphagia referring to the difficulty in swallowing, which is also reported in eleven to eighty-one per cent of PD patients (Takizawa et al., 2016). Patients with AD gradually lose cognitive functions until they reach the final stage of the disease, which is characterised by full failure of control over body functions (Boccardi et al., 2016).\n\nRegarding the nonmotor symptoms, anosmia (the sense loss of smell) and ageusia (the sense loss of taste), are common in PD. And the equivalent olfactory loss is also observed in AD (Doty 2012), which may be contributed to the shared pathological features. It may be corroborated that the olfactory loss is significantly linked to cognitive level (Tarakad & Jankovic, 2017). This is different from PD: AD patients show more cognitive impairments. There occur some other cognitive problems in AD more than memory. For example, one type of language disorder, aphasia is usually related to AD owing to the damage of frontal, temporal, or parietal language cortices. And these aphasias caused by AD accounts for nearly thirty per cent of primary degenerative aphasias (Teichmann & Ferrieux, 2013). The problems are not only about daily life activity but also about the biological clock. Sleep disturbances and sleep disorders come to be big problems for AD and PD patients since these are long term and progressive diseases. (Peter-Derex, 2015). Sleep disorders, on the other hand, is reported to be linked to an increased risk of AD. Both situations have a negative impact on one’s attention (Hennawy et al., 2019). Insomnia and exhaustion are also the following side effects of sleep disorders. Together with physical discomfort, those symptoms above can cause psychological discomfort in PD when comparing PD and AD. Neuralgia has become a severe problem for patients. There are five main forms of pain are documented in PD sufferers which are separately dystonia, musculoskeletal pain, nerve or nerve root pain, primary or central pain and akathisia with some samples (Rana 2013). \n\nTo sum up, AD and PD symptoms are generally different, but these share some key features at the same time. PD patients are more likely to have primarily motor abnormalities, whereas AD patients normally experience dementia and cognitive impairment (Meireles & Massano 2012). The neuronal death is a typical feature of both illnesses, the autopsy histopathology of the brains from AD and PD patients are distinct in each instance and diverse from one another (Ganguly et al., 2017). AD focuses more on cognitive symptoms while PD focus more on physical symptoms even though these can be divided into motor and nonmotor symptoms.\n\n \n\n**Table 1.** Comparison and contrast table of Alzheimer’s disease and Parkinson’s disease in symptoms, causes, onset age, treatment, and lifespan expectancy.\n\n|                             | AD                                                           | PD                                                           |\n| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Clinical symptoms           | Amnesia (El Haj et  al., 2020)  Impairments of  attention (Malhotra, 2018)  Disorder of episodic  memory (Younan et al., 2020)  Memory distortions (El  Haj et al. 2020)  Dysphagia (Boccardi et  al., 2016)  Dysphasia (Teichmann  & Ferrieux, 2013)  Sleep disruption and  sleep disorders (Hennawy et al., 2019) | Tremor  Bradykinesia  Rigidity (NHS, 2019)  Loss of balance  Anosmia and ageusia  (Doty, 2012; Tarakad & Jankovic, 2017)  Neuralgia (Rana et  al., 2013)  Urinary infection (Gerlach,  Winogrodzka & Weber 2011)  Depression, anxiety  (Sveinbjornsdottir, 2016) |\n| Factors that may  influence | Increasing age (Hou et  al., 2019)  Family history  Head Injury  Cardiovascular  diseases (Leszek et al., 2021)  Environmental toxins  (Vasefi et al., 2020) | Increasing age (Hou et  al., 2019)  Family history  Head Injury  Male gender (Picillo  et al., 2017) |\n| Onset ages                  | First symptoms usually  appear in the mid-60s. Early-onset AD begin between the 30s and mid-60s  (National Institute on Aging, 2017) | The average age is 60  years old, whoever younger than 50 is considered young-onset PD (Johns  Hopkins medicine, 2021) |\n| Current treatment           | Medication  Physical therapy  Dietary control (Zhang  et al., 2020)  Deep brain stimulation  (Krauss et al., 2021) | Medication  Physical therapy  Cognitive behavioural  therapy (Egan, Laidlaw & Starkstein, 2015) |\n| Life expectancy             | After diagnosis, the  average expectancy for remaining life is 3 to 10 years (Zanetti, Solerte  & Cantoni, 2009) | The relevant  comparator is 23.3 years for average onset age of 60 years old (Golbe &  Leyton, 2018). PD does not obviously reduce the lifespan |\n\n \n\nWhen it comes to epidemiology, four key elements come to stand revealed on the paper: how much, when, where and whom. From Statista (2021), Official death certificates are recorded to be 37 in 100,000 for AD and 10.3 in 100,000 in PD in 2019 in the United States. AD has turned into the seventh single biggest killer in the world (WHO, 2019) and the sixth leading cause of death in the United States (Alzheimer's Association, 2020). Followed with AD, PD has become the second most common neurodegenerative disease (Lebouvier 2009).\n\n \n\n![image005](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354886.gif)\n\n**Figure 1.** Death rate from Parkinson's disease and Alzheimer’s disease in the United States from 2000 to 2019 (data is from Statista: John Elflein, 2021; Statista Research Department, 2021)\n\n \n\nThe factor “whom” I mentioned above can be illustrated briefly by the following considering ages, sex and so on. There is some evidence to suggest that age is the main risk factor for AD and PD (Hou et al., 2019). According to the research of Cui et al. (2020), the rates of both AD and PD grew consistently with age growing, but this phenomenon is more likely applicable for AD (Figure 2). Even though Cui et al. failed to account for worldwide data, it presents a positive correlation of prevalence of AD and PD as well as the slight difference between each other. \n\n \n\n![image006](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354377.jpg)\n\n**Figure 2.** Prevalence of Alzheimer’s disease and Parkinson’s disease in China\n\n(Cui et al., 2020)\n\n \n\nIt is a widely held view that females get more possibility at risk of developing AD, while males get a higher risk for vascular dementia (Podcasy & Epperson, 2016). Ample evidence suggests that female PD patients tend to show a more benign symptom for which many scholars hold the view that it is due to the consequence of oestrogen (Picillo et al., 2017). It is essential to bear in mind that there is a possible bias in the sex effect on AD and PD.\n\nIn the 1950s, researchers successively discovered that the presence of Lewy bodies in substantia nigra and locus nucleus patients in PD patients, gradually determining the pathological hallmarks of PD (Xiao-dan, 2017). One of the limitations with this explanation is that in some cases like a mutation of PARK-2, there are no Lewy bodies (Matsumine, 1999). The research team of Arvid and Isamu find that there are dopamine abnormalities in the brain tissue of PD patients then (LeWitt, 2015). According to Dickson (2012) and Kouli (2018), alpha-synuclein accumulates in Lewy bodies and neurites in the brain and peripheral nerves. And it can be pathological hallmarks of PD, in which case, the abnormal cytoplasmic deposits occur in cell bodies. Neuropathologically, senile plaques and neurofibrillary tangles can be hallmarks of AD (Sengoku, 2020). Under the action of endonuclease, the cleaved-off extracellular part of APP is the amyloid-β protein (O'Brien & Wong, 2011). The amyloid-β deposition is another hallmark for AD. Analogously, AD and PD both have tau pathology. Braak (1991) holds the view that the magnitude and location of tau deposition might be related to clinical symptoms of AD. The tau pathology is also reported to have an impact on neurons and glia in PD (Dickson 2012). Several observations suggest that there is a link between the dysfunction, even partly, of the mitochondria or the oxidative stress and the neuropathology of AD and PD (Swerdlow, 2018; Jamwal, Blackburn & Elsworth, 2021). Succinctly, AD and PD share both similarities and differences (Table 2).\n\n \n\n**Table 2.** Pathological hallmarks of AD and PD\n\n|                        | AD                                                           | PD                                                           |\n| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Pathological hallmarks | Extracellular  β-amyloid deposits, i.e., senile plaques  Extracellular  β-amyloid deposits, i.e., senile plaques (MSD manuals, 2020)  Nerve cell death in  hippocampus and prefrontal cortex (Akhtar & Sah, 2020) | Lewy bodies in the  substantia nigra striatum (MSD manuals, 2020)   Synuclein deposition  Degeneration of  neurons in substantia nigra, locus coeruleus and other brainstem dopaminergic  cells (Hansen, 2021) |\n\n \n\nAll in all, there is a big difference between the pathological characteristics, the affected brain parts and the clinical symptoms of AD and PD. As global life expectancy has increased, proteinopathies of the brain, which particularly affect the elderly, have placed an increasing burden on society. AD and PD invade the patients’ intellectual and emotional health, thereby potentially destroying their lives and family life. AD and PD invade the victim's intellectual and emotional health, thereby potentially destroying their lives and family. Since there is a long prodromal period, if we can diagnosis those in advance, earlier and timely treatment might be able to be applied (Ubeda-Bañon et al., 2020), thus, sufferings might be relieved. Both PD and AD get involved in broad regions of the nervous system, neurotransmitters and protein aggregation (Kalia & Lang 2015). The difference is that PD mainly happens in substantia nigra, locus coeruleus and other brainstem dopaminergic cells (Hansen, 2021) while AD typically starts in the temporal lobe, in more detail, hippocampus and prefrontal cortex (Akhtar & Sah, 2020). No matter how similar or different those diseases are, one issue is certain, it is our biologists’ duty to pull those suffers with PD or AD out of the hell.\n\n# **Reference**\n\nBayer, T. A. (2015). Proteinopathies, a core concept for understanding and ultimately treating degenerative disorders? Eur Neuropsychopharmacol, 25(5), 713-724. doi: 10.1016/j.euroneuro.2013.03.007\n\nLanuti, P. et al. (2020). Neurodegenerative diseases as proteinopathies-driven immune disorders. Neural regeneration research, 15 (5), s. 850. doi:10.4103/1673-5374.268971\n\nVirchow, R. (1854). Handbuch der Speciellen Pathologie und Therapie\n\nLuheshi, L. M., Crowther, D. C., & Dobson, C. M. (2008). Protein misfolding and disease: from the test tube to the organism. Current Opinion in Chemical Biology, 12(1), 25-31. doi: https://doi.org/10.1016/j.cbpa.2008.02.011\n\nCapriotti, T., & Terzakis, K. (2016). Parkinson Disease. Home healthcare now, 34(6), 300–307. https://doi.org/10.1097/NHH.0000000000000398\n\nSimon, D. K., Tanner, C. M., & Brundin, P. (2020). Parkinson Disease Epidemiology, Pathology, Genetics, and Pathophysiology. Clinics in geriatric medicine, 36(1), 1–12. https://doi.org/10.1016/j.cger.2019.08.002\n\nHayes, M. T. (2019). Parkinson's Disease and Parkinsonism. The American Journal of Medicine, 132(7), 802-807. doi: https://doi.org/10.1016/j.amjmed.2019.03.001\n\nLane, C. A., Hardy, J., & Schott, J. M. (2018). Alzheimer's disease. European Journal of Neurology, 25(1), 59-70. doi:10.1111/ene.13439\n\nVan Bulck, M., Sierra-Magro, A., Alarcon-Gil, J., Perez-Castillo, A., & Morales-Garcia, J. A. (2019). Novel Approaches for the Treatment of Alzheimer's and Parkinson's Disease. International journal of molecular sciences, 20(3), 719. https://doi.org/10.3390/ijms20030719\n\nNHS.uk. (2019). Parkinson's disease - Symptoms.\n\nNHS.uk. (2019). Alzheimer’s disease - Symptoms.\n\nTarakad, A., & Jankovic, J. (2017). Anosmia and Ageusia in Parkinson's Disease. International review of neurobiology, 133, 541–556. https://doi.org/10.1016/bs.irn.2017.05.028\n\nRana, A. Q., Kabir, A., Jesudasan, M., Siddiqui, I., & Khondker, S. (2013). Pain in Parkinson's disease: Analysis and literature review. Clinical Neurology and Neurosurgery, 115(11), 2313-2317. doi: https://doi.org/10.1016/j.clineuro.2013.08.022\n\nYounan, D., Petkus, A. J., Widaman, K. F., Wang, X., Casanova, R., Espeland, M. A., Gatz, M., Henderson, V. W., Manson, J. E., Rapp, S. R., Sachs, B. C., Serre, M. L., Gaussoin, S. A., Barnard, R., Saldana, S., Vizuete, W., Beavers, D. P., Salinas, J. A., Chui, H. C., Resnick, S. M., … Chen, J. C. (2020). Particulate matter and episodic memory decline mediated by early neuroanatomic biomarkers of Alzheimer's disease. Brain: a journal of neurology, 143(1), 289–302. https://doi.org/10.1093/brain/awz348\n\nEl Haj, M., Colombel, F., Kapogiannis, D., & Gallouj, K. (2020). False Memory in Alzheimer's Disease. Behavioural neurology, 2020, 5284504. https://doi.org/10.1155/2020/5284504\n\nBoccardi, V., Ruggiero, C., Patriti, A., & Marano, L. (2016). Diagnostic Assessment and Management of Dysphagia in Patients with Alzheimer's Disease. Journal of Alzheimer's disease: JAD, 50(4), 947–955. https://doi.org/10.3233/JAD-150931\n\nTeichmann, M., & Ferrieux, S. (2013). Aphasia(s) in Alzheimer. Revue neurologique, 169(10), 680–686. https://doi.org/10.1016/j.neurol.2013.06.001\n\nHennawy, M., Sabovich, S., Liu, C. S., Herrmann, N., & Lanctôt, K. L. (2019). Sleep and Attention in Alzheimer's Disease. The Yale journal of biology and medicine, 92(1), 53–61. \n\nLeszek, J., Mikhaylenko, E. V., Belousov, D. M., Koutsouraki, E., Szczechowiak, K., Kobusiak-Prokopowicz, M., Mysiak, A., Diniz, B. S., Somasundaram, S. G., Kirkland, C. E., & Aliev, G. (2021). The Links between Cardiovascular Diseases and Alzheimer's Disease. Current neuropharmacology, 19(2), 152–169. https://doi.org/10.2174/1570159X18666200729093724 \n\nVasefi, M., Ghaboolian-Zare, E., Abedelwahab, H., & Osu, A. (2020). Environmental toxins and Alzheimer's disease progression. Neurochemistry international, 141, 104852. https://doi.org/10.1016/j.neuint.2020.104852 \n\nPicillo, M., Nicoletti, A., Fetoni, V., Garavaglia, B., Barone, P., & Pellecchia, M. T. (2017). The relevance of gender in Parkinson's disease: a review. Journal of neurology, 264(8), 1583–1607. https://doi.org/10.1007/s00415-016-8384-9\n\nEgan, S. J., Laidlaw, K., & Starkstein, S. (2015). Cognitive Behaviour Therapy for Depression and Anxiety in Parkinson's Disease. Journal of Parkinson's disease, 5(3), 443–451. https://doi.org/10.3233/JPD-150542\n\nZhang, M., Zhao, D., Zhou, G., & Li, C. (2020). Dietary Pattern, Gut Microbiota, and Alzheimer's Disease. Journal of agricultural and food chemistry, 68(46), 12800–12809. https://doi.org/10.1021/acs.jafc.9b08309 \n\nKrauss, J. K., Lipsman, N., Aziz, T., Boutet, A., Brown, P., Chang, J. W., Davidson, B., Grill, W. M., Hariz, M. I., Horn, A., Schulder, M., Mammis, A., Tass, P. A., Volkmann, J., & Lozano, A. M. (2021). Technology of deep brain stimulation: current status and future directions. Nature reviews. Neurology, 17(2), 75–87. https://doi.org/10.1038/s41582-020-00426-z \n\nZanetti, O., Solerte, S. B., & Cantoni, F. (2009). Life expectancy in Alzheimer's disease (AD). Archives of gerontology and geriatrics, 49 Suppl 1, 237–243. https://doi.org/10.1016/j.archger.2009.09.035\n\nGolbe, L. I., & Leyton, C. E. (2018). Life expectancy in Parkinson disease. Neurology, 91(22), 991–992. https://doi.org/10.1212/WNL.0000000000006560\n\nHopkinsmedicine.org. 2021. Young-Onset Parkinson's Disease. \n\nNational Institute on Aging. 2017. What Are the Signs of Alzheimer's Disease?\n\nLanger K. G. (2019). Early History of Amnesia. Frontiers of neurology and neuroscience, 44, 64–74. https://doi.org/10.1159/000494953\n\nSveinbjornsdottir S. (2016). The clinical symptoms of Parkinson's disease. Journal of neurochemistry, 139 Suppl 1, 318–324. https://doi.org/10.1111/jnc.13691\n\nQuerfurth, H. W., & LaFerla, F. M. (2010). Alzheimer's disease. The New England journal of medicine, 362(4), 329–344. https://doi.org/10.1056/NEJMra0909142\n\nBurns, A., & Iliffe, S. (2009). Dementia. BMJ (Clinical research ed.), 338, b75. https://doi.org/10.1136/bmj.b75\n\nFang, E. F., Hou, Y., Palikaras, K., Adriaanse, B. A., Kerr, J. S., Yang, B., Lautrup, S., Hasan-Olive, M. M., Caponio, D., Dan, X., Rocktäschel, P., Croteau, D. L., Akbari, M., Greig, N. H., Fladby, T., Nilsen, H., Cader, M. Z., Mattson, M. P., Tavernarakis, N., & Bohr, V. A. (2019). Mitophagy inhibits amyloid-β and tau pathology and reverses cognitive deficits in models of Alzheimer's disease. Nature neuroscience, 22(3), 401–412. https://doi.org/10.1038/s41593-018-0332-9\n\nTolosa, E., & Compta, Y. (2006). Dystonia in Parkinson's disease. Journal of neurology, 253 Suppl 7, VII7–VII13. https://doi.org/10.1007/s00415-006-7003-6\n\nGanguly, G., Chakrabarti, S., Chatterjee, U., & Saso, L. (2017). Proteinopathy, oxidative stress and mitochondrial dysfunction: cross talk in Alzheimer's disease and Parkinson's disease. Drug design, development and therapy, 11, 797–810. https://doi.org/10.2147/DDDT.S130514\n\nHou, Y., Dan, X., Babbar, M., Wei, Y., Hasselbalch, S. G., Croteau, D. L., & Bohr, V. A. (2019). Ageing as a risk factor for neurodegenerative disease. Nature reviews. Neurology, 15(10), 565–581. https://doi.org/10.1038/s41582-019-0244-7\n\nMcGregor, M. M., & Nelson, A. B. (2019). Circuit Mechanisms of Parkinson's Disease. Neuron, 101(6), 1042–1056. https://doi.org/10.1016/j.neuron.2019.03.004\n\nDoty R. L. (2012). Olfactory dysfunction in Parkinson disease. Nature reviews. Neurology, 8(6), 329–339. https://doi.org/10.1038/nrneurol.2012.80\n\nPeter-Derex, L., Yammine, P., Bastuji, H., & Croisile, B. (2015). Sleep and Alzheimer's disease. Sleep medicine reviews, 19, 29–38. https://doi.org/10.1016/j.smrv.2014.03.007\n\nMeireles, J., & Massano, J. (2012). Cognitive impairment and dementia in Parkinson's disease: clinical features, diagnosis, and management. Frontiers in neurology, 3, 88. https://doi.org/10.3389/fneur.2012.00088\n\nCui L, Hou NN, Wu HM, Zuo X, Lian YZ, Zhang CN, Wang ZF, Zhang X, Zhu JH. Prevalence of Alzheimer's Disease and Parkinson's Disease in China: An Updated Systematical Analysis. Front Aging Neurosci. 2020 Dec 21; 12:603854. doi: 10.3389/fnagi.2020.603854. PMID: 33424580; PMCID: PMC7793643.\n\nTakizawa, C., Gemmell, E., Kenworthy, J. et al. A Systematic Review of the Prevalence of Oropharyngeal Dysphagia in Stroke, Parkinson’s Disease, Alzheimer’s Disease, Head Injury, and Pneumonia. Dysphagia 31, 434–441 (2016). https://doi.org/10.1007/s00455-016-9695-9\n\nNumber of deaths due to Parkinson's disease | Statista. (2021). Retrieved 12 December 2021, from https://www.statista.com/statistics/753594/number-of-deaths-from-parkinson-in-spain/\n\nAlzheimer disease mortality rate U.S. 2000-2019 | Statista. (2021). Retrieved 12 December 2021, from https://www.statista.com/statistics/452945/mortality-rate-of-alzheimers-patients-in-the-us/\n\nLebouvier T, Chaumette T, Paillusson S, Duyckaerts C, Bruley des Varannes S, Neunlist M, Derkinderen P. The second brain and Parkinson's disease. Eur J Neurosci. 2009 Sep;30(5):735-41. doi: 10.1111/j.1460-9568.2009.06873. x. Epub 2009 Aug 27. PMID: 19712093.\n\nWorld Health Organization. The top 10 causes of death. (2019). \n\nAlzheimer's Association. (2020). 2020 Alzheimer's disease facts and figures. Alzheimer's & dementia: the journal of the Alzheimer's Association, 10.1002/alz.12068. Advance online publication. https://doi.org/10.1002/alz.12068\n\nPodcasy, J. L., & Epperson, C. N. (2016). Considering sex and gender in Alzheimer disease and other dementias. Dialogues in clinical neuroscience, 18(4), 437–446. https://doi.org/10.31887/DCNS.2016.18.4/cepperson\n\nSengoku R. (2020). Aging and Alzheimer's disease pathology. Neuropathology: official journal of the Japanese Society of Neuropathology, 40(1), 22–29. https://doi.org/10.1111/neup.12626\n\nBraak, H., & Braak, E. (1991). Neuropathological stageing of Alzheimer-related changes. Acta neuropathologica, 82(4), 239–259. https://doi.org/10.1007/BF00308809\n\nSwerdlow R. H. (2018). Mitochondria and Mitochondrial Cascades in Alzheimer's Disease. Journal of Alzheimer's disease: JAD, 62(3), 1403–1416. https://doi.org/10.3233/JAD-170585\n\nJamwal, S., Blackburn, J. K., & Elsworth, J. D. (2021). Expression of PON2 isoforms varies among brain regions in male and female African green monkeys. Free radical biology & medicine, S0891-5849(21)00856-X. Advance online publication. https://doi.org/10.1016/j.freeradbiomed.2021.12.005\n\nKouli, A., Torsney, K. M., & Kuan, W. L. (2018). Parkinson’s Disease: Etiology, Neuropathology, and Pathogenesis. In T. B. Stoker (Eds.) et. al., Parkinson’s Disease: Pathogenesis and Clinical Aspects. Codon Publications. \n\nXiao⁃dan, W., Yong, J. (2017) 200⁃year history of Parkinson's disease. Chin J Contemp Neurol Neurosurg\n\nLeWitt P. A. (2015). Levodopa therapy for Parkinson's disease: Pharmacokinetics and pharmacodynamics. Movement disorders: official journal of the Movement Disorder Society, 30(1), 64–72. https://doi.org/10.1002/mds.26082\n\nMatsumine H. (1999). Rinsho shinkeigaku = Clinical neurology, 39(1), 9–12.\n\nMSD manual: professional version. (2020). JAC-Antimicrobial Resistance, 2(3). doi:10.1093/jacamr/dlaa042\n\nAkhtar, A., & Sah, S. P. (2020). Insulin signaling pathway and related molecules: Role in neurodegeneration and Alzheimer's disease. Neurochemistry international, 135, 104707. https://doi.org/10.1016/j.neuint.2020.104707\n\nO'Brien, R. J., & Wong, P. C. (2011). Amyloid precursor protein processing and Alzheimer's disease. Annual review of neuroscience, 34, 185–204. https://doi.org/10.1146/annurev-neuro-061010-113613\n\nUbeda-Bañon, I., Saiz-Sanchez, D., Flores-Cuadrado, A., Rioja-Corroto, E., Gonzalez-Rodriguez, M., Villar-Conde, S., Astillero-Lopez, V., Cabello-de la Rosa, J. P., Gallardo-Alcañiz, M. J., Vaamonde-Gamo, J., Relea-Calatayud, F., Gonzalez-Lopez, L., Mohedano-Moriano, A., Rabano, A., & Martinez-Marcos, A. (2020). The human olfactory system in two proteinopathies: Alzheimer's and Parkinson's diseases. Translational neurodegeneration, 9(1), 22. https://doi.org/10.1186/s40035-020-00200-7\n\nHansen N. (2021). Locus Coeruleus Malfunction Is Linked to Psychopathology in Prodromal Dementia With Lewy Bodies. Frontiers in aging neuroscience, 13, 641101. https://doi.org/10.3389/fnagi.2021.641101\n","source":"_posts/2021-12-13-Lei-proteinopathies-essay.md","raw":"---\ntitle: Model proteinopathies essay\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-13 12:00\npassword:\nsummary:\ntags:\n- Essay\ncategories:\n- Neuroscience\n---\n\n\n\n\nThis is a comparison and contrast between two common proteinopathies (Alzheimer's disease & Parkinson's disease), discussing clinical symptoms, epidimiology and pathological hallmarks.\n\n\n\n# Main body\n\nThe present view takes proteinopathy as an umbrella term for the neurodegenerative disorders caused by the accumulation of misfolded protein, which is attributable to the conformational error of the protein (Bayer, 2015, Lanuti, 2020) These aggregated proteins were verified to gain typical amyloid features (Virchow, 1854) which means the “starch” conformation. In this case, these proteins might not only lose their original normal function but also gain toxicity (Luheshi et al., 2008). Speaking of proteinopathies, two diseases must be mentioned: One is Parkinson’s disease (PD), the most famous progressive neurodegenerative diseases associated with motor as well as nonmotor deficits, which is known as the second common neurodegenerative disorder, (Capriotti & Terzakis, 2016; Simon et al., 2020; Hayes, 2019); the other one is Alzheimer’s disease (AD), one of the most major reason for dementia, the most common neurodegenerative disorder (Lane, Hardy & Schott, 2018). There are around one billion sufferers around the world who are suffering both physical and psychological agony from these neurodegenerative disorders in 2019 (Bulck et al., 2019). Various factors, for instance genomic, epigenomic, metabolic, or environmental factors (Bulck et al., 2019), are shown to have an impact on PD and AD in a permutation and combination way. Here this essay will go into detail about these two common proteinopathies in three aspects: clinical symptoms, epidemiology and pathological hallmarks.\n\nIn terms of clinical symptoms between PD and AD, multiple similar as well as differing pathological phenotypes can be identified, which is treated under the comparison and contrast between PD and AD (Table 1). PD and AD are both irreversible progressive, degenerative diseases meaning the symptoms will gradually become more severe as the stages develop. The most obvious problems about patients’ cognitive and psychiatric symptoms come first as we consider these neurodegenerative diseases. As far as we know, AD is well-known for its influence on memory, academically called amnesia which was first conceptualized as memory loss in 1763 by Sauvagues (Langer, 2019). Most of the advanced AD sufferers are reported to have Amnesia symptoms, accounting for fifty per cent to seventy per cent of all patients with dementia (Burns & Iliffe 2009), while it seldomly happens to PD patients. Only the most severe PD sufferers are reported to experience similar amnesia symptoms (Querfurth & LaFerla, 2010). At the memory level, patients with AD not only have amnesia but also often experience memory distortions (El Haj et al. 2020, Younan et al., 2020), such as having comprehensive and vivid memories of episodic occurrences that have never been observed. AD symptoms are generally considered as an essential impairment of episodic memory (Younan et al., 2020), while one’s attention is compromised on AD’s early stage as well, especially in those with early age onset and atypical syndromes (Malhotra, 2018). One feature of AD is that the symptoms are accompanied by severe attentional impairment frequently which is linked with other neurodegenerative disorders as well (Malhotra, 2018). It is suggested that PD patients suffer more depression and anxiety (Sveinbjornsdottir, 2016) than AD patients, which may be concluded to the inconsistency between one’s movements and willingness.\n\nApart from memory problems for AD and PD, some other motor symptoms can also put huge inconvenience to one’s life. PD patients are reported to have three main symptoms which are tremor, bradykinesia and rigidity (Hayes, 2019). Tremor means shaking, especially after a short pause of a postural movement. Bradykinesia implies a slower movement than normal action which may cause difficulties for some ordinary tasks like walking or doing dishes. Rigidity or spasticity refers to muscle stiffness, which is academically called dystonia (Tolosa & Compta, 2006). Unlike those symptoms in AD, these three main symptoms in PD are more relying on the neuromuscular connection so that these are all related to muscle control abnormality which is the direct result of neurodegeneration the same as AD (McGregor & Nelson, 2019). Similarly, AD patients also suffer motor problems like dysphagia referring to the difficulty in swallowing, which is also reported in eleven to eighty-one per cent of PD patients (Takizawa et al., 2016). Patients with AD gradually lose cognitive functions until they reach the final stage of the disease, which is characterised by full failure of control over body functions (Boccardi et al., 2016).\n\nRegarding the nonmotor symptoms, anosmia (the sense loss of smell) and ageusia (the sense loss of taste), are common in PD. And the equivalent olfactory loss is also observed in AD (Doty 2012), which may be contributed to the shared pathological features. It may be corroborated that the olfactory loss is significantly linked to cognitive level (Tarakad & Jankovic, 2017). This is different from PD: AD patients show more cognitive impairments. There occur some other cognitive problems in AD more than memory. For example, one type of language disorder, aphasia is usually related to AD owing to the damage of frontal, temporal, or parietal language cortices. And these aphasias caused by AD accounts for nearly thirty per cent of primary degenerative aphasias (Teichmann & Ferrieux, 2013). The problems are not only about daily life activity but also about the biological clock. Sleep disturbances and sleep disorders come to be big problems for AD and PD patients since these are long term and progressive diseases. (Peter-Derex, 2015). Sleep disorders, on the other hand, is reported to be linked to an increased risk of AD. Both situations have a negative impact on one’s attention (Hennawy et al., 2019). Insomnia and exhaustion are also the following side effects of sleep disorders. Together with physical discomfort, those symptoms above can cause psychological discomfort in PD when comparing PD and AD. Neuralgia has become a severe problem for patients. There are five main forms of pain are documented in PD sufferers which are separately dystonia, musculoskeletal pain, nerve or nerve root pain, primary or central pain and akathisia with some samples (Rana 2013). \n\nTo sum up, AD and PD symptoms are generally different, but these share some key features at the same time. PD patients are more likely to have primarily motor abnormalities, whereas AD patients normally experience dementia and cognitive impairment (Meireles & Massano 2012). The neuronal death is a typical feature of both illnesses, the autopsy histopathology of the brains from AD and PD patients are distinct in each instance and diverse from one another (Ganguly et al., 2017). AD focuses more on cognitive symptoms while PD focus more on physical symptoms even though these can be divided into motor and nonmotor symptoms.\n\n \n\n**Table 1.** Comparison and contrast table of Alzheimer’s disease and Parkinson’s disease in symptoms, causes, onset age, treatment, and lifespan expectancy.\n\n|                             | AD                                                           | PD                                                           |\n| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Clinical symptoms           | Amnesia (El Haj et  al., 2020)  Impairments of  attention (Malhotra, 2018)  Disorder of episodic  memory (Younan et al., 2020)  Memory distortions (El  Haj et al. 2020)  Dysphagia (Boccardi et  al., 2016)  Dysphasia (Teichmann  & Ferrieux, 2013)  Sleep disruption and  sleep disorders (Hennawy et al., 2019) | Tremor  Bradykinesia  Rigidity (NHS, 2019)  Loss of balance  Anosmia and ageusia  (Doty, 2012; Tarakad & Jankovic, 2017)  Neuralgia (Rana et  al., 2013)  Urinary infection (Gerlach,  Winogrodzka & Weber 2011)  Depression, anxiety  (Sveinbjornsdottir, 2016) |\n| Factors that may  influence | Increasing age (Hou et  al., 2019)  Family history  Head Injury  Cardiovascular  diseases (Leszek et al., 2021)  Environmental toxins  (Vasefi et al., 2020) | Increasing age (Hou et  al., 2019)  Family history  Head Injury  Male gender (Picillo  et al., 2017) |\n| Onset ages                  | First symptoms usually  appear in the mid-60s. Early-onset AD begin between the 30s and mid-60s  (National Institute on Aging, 2017) | The average age is 60  years old, whoever younger than 50 is considered young-onset PD (Johns  Hopkins medicine, 2021) |\n| Current treatment           | Medication  Physical therapy  Dietary control (Zhang  et al., 2020)  Deep brain stimulation  (Krauss et al., 2021) | Medication  Physical therapy  Cognitive behavioural  therapy (Egan, Laidlaw & Starkstein, 2015) |\n| Life expectancy             | After diagnosis, the  average expectancy for remaining life is 3 to 10 years (Zanetti, Solerte  & Cantoni, 2009) | The relevant  comparator is 23.3 years for average onset age of 60 years old (Golbe &  Leyton, 2018). PD does not obviously reduce the lifespan |\n\n \n\nWhen it comes to epidemiology, four key elements come to stand revealed on the paper: how much, when, where and whom. From Statista (2021), Official death certificates are recorded to be 37 in 100,000 for AD and 10.3 in 100,000 in PD in 2019 in the United States. AD has turned into the seventh single biggest killer in the world (WHO, 2019) and the sixth leading cause of death in the United States (Alzheimer's Association, 2020). Followed with AD, PD has become the second most common neurodegenerative disease (Lebouvier 2009).\n\n \n\n![image005](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354886.gif)\n\n**Figure 1.** Death rate from Parkinson's disease and Alzheimer’s disease in the United States from 2000 to 2019 (data is from Statista: John Elflein, 2021; Statista Research Department, 2021)\n\n \n\nThe factor “whom” I mentioned above can be illustrated briefly by the following considering ages, sex and so on. There is some evidence to suggest that age is the main risk factor for AD and PD (Hou et al., 2019). According to the research of Cui et al. (2020), the rates of both AD and PD grew consistently with age growing, but this phenomenon is more likely applicable for AD (Figure 2). Even though Cui et al. failed to account for worldwide data, it presents a positive correlation of prevalence of AD and PD as well as the slight difference between each other. \n\n \n\n![image006](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354377.jpg)\n\n**Figure 2.** Prevalence of Alzheimer’s disease and Parkinson’s disease in China\n\n(Cui et al., 2020)\n\n \n\nIt is a widely held view that females get more possibility at risk of developing AD, while males get a higher risk for vascular dementia (Podcasy & Epperson, 2016). Ample evidence suggests that female PD patients tend to show a more benign symptom for which many scholars hold the view that it is due to the consequence of oestrogen (Picillo et al., 2017). It is essential to bear in mind that there is a possible bias in the sex effect on AD and PD.\n\nIn the 1950s, researchers successively discovered that the presence of Lewy bodies in substantia nigra and locus nucleus patients in PD patients, gradually determining the pathological hallmarks of PD (Xiao-dan, 2017). One of the limitations with this explanation is that in some cases like a mutation of PARK-2, there are no Lewy bodies (Matsumine, 1999). The research team of Arvid and Isamu find that there are dopamine abnormalities in the brain tissue of PD patients then (LeWitt, 2015). According to Dickson (2012) and Kouli (2018), alpha-synuclein accumulates in Lewy bodies and neurites in the brain and peripheral nerves. And it can be pathological hallmarks of PD, in which case, the abnormal cytoplasmic deposits occur in cell bodies. Neuropathologically, senile plaques and neurofibrillary tangles can be hallmarks of AD (Sengoku, 2020). Under the action of endonuclease, the cleaved-off extracellular part of APP is the amyloid-β protein (O'Brien & Wong, 2011). The amyloid-β deposition is another hallmark for AD. Analogously, AD and PD both have tau pathology. Braak (1991) holds the view that the magnitude and location of tau deposition might be related to clinical symptoms of AD. The tau pathology is also reported to have an impact on neurons and glia in PD (Dickson 2012). Several observations suggest that there is a link between the dysfunction, even partly, of the mitochondria or the oxidative stress and the neuropathology of AD and PD (Swerdlow, 2018; Jamwal, Blackburn & Elsworth, 2021). Succinctly, AD and PD share both similarities and differences (Table 2).\n\n \n\n**Table 2.** Pathological hallmarks of AD and PD\n\n|                        | AD                                                           | PD                                                           |\n| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Pathological hallmarks | Extracellular  β-amyloid deposits, i.e., senile plaques  Extracellular  β-amyloid deposits, i.e., senile plaques (MSD manuals, 2020)  Nerve cell death in  hippocampus and prefrontal cortex (Akhtar & Sah, 2020) | Lewy bodies in the  substantia nigra striatum (MSD manuals, 2020)   Synuclein deposition  Degeneration of  neurons in substantia nigra, locus coeruleus and other brainstem dopaminergic  cells (Hansen, 2021) |\n\n \n\nAll in all, there is a big difference between the pathological characteristics, the affected brain parts and the clinical symptoms of AD and PD. As global life expectancy has increased, proteinopathies of the brain, which particularly affect the elderly, have placed an increasing burden on society. AD and PD invade the patients’ intellectual and emotional health, thereby potentially destroying their lives and family life. AD and PD invade the victim's intellectual and emotional health, thereby potentially destroying their lives and family. Since there is a long prodromal period, if we can diagnosis those in advance, earlier and timely treatment might be able to be applied (Ubeda-Bañon et al., 2020), thus, sufferings might be relieved. Both PD and AD get involved in broad regions of the nervous system, neurotransmitters and protein aggregation (Kalia & Lang 2015). The difference is that PD mainly happens in substantia nigra, locus coeruleus and other brainstem dopaminergic cells (Hansen, 2021) while AD typically starts in the temporal lobe, in more detail, hippocampus and prefrontal cortex (Akhtar & Sah, 2020). No matter how similar or different those diseases are, one issue is certain, it is our biologists’ duty to pull those suffers with PD or AD out of the hell.\n\n# **Reference**\n\nBayer, T. A. (2015). Proteinopathies, a core concept for understanding and ultimately treating degenerative disorders? Eur Neuropsychopharmacol, 25(5), 713-724. doi: 10.1016/j.euroneuro.2013.03.007\n\nLanuti, P. et al. (2020). Neurodegenerative diseases as proteinopathies-driven immune disorders. Neural regeneration research, 15 (5), s. 850. doi:10.4103/1673-5374.268971\n\nVirchow, R. (1854). Handbuch der Speciellen Pathologie und Therapie\n\nLuheshi, L. M., Crowther, D. C., & Dobson, C. M. (2008). Protein misfolding and disease: from the test tube to the organism. Current Opinion in Chemical Biology, 12(1), 25-31. doi: https://doi.org/10.1016/j.cbpa.2008.02.011\n\nCapriotti, T., & Terzakis, K. (2016). Parkinson Disease. Home healthcare now, 34(6), 300–307. https://doi.org/10.1097/NHH.0000000000000398\n\nSimon, D. K., Tanner, C. M., & Brundin, P. (2020). Parkinson Disease Epidemiology, Pathology, Genetics, and Pathophysiology. Clinics in geriatric medicine, 36(1), 1–12. https://doi.org/10.1016/j.cger.2019.08.002\n\nHayes, M. T. (2019). Parkinson's Disease and Parkinsonism. The American Journal of Medicine, 132(7), 802-807. doi: https://doi.org/10.1016/j.amjmed.2019.03.001\n\nLane, C. A., Hardy, J., & Schott, J. M. (2018). Alzheimer's disease. European Journal of Neurology, 25(1), 59-70. doi:10.1111/ene.13439\n\nVan Bulck, M., Sierra-Magro, A., Alarcon-Gil, J., Perez-Castillo, A., & Morales-Garcia, J. A. (2019). Novel Approaches for the Treatment of Alzheimer's and Parkinson's Disease. International journal of molecular sciences, 20(3), 719. https://doi.org/10.3390/ijms20030719\n\nNHS.uk. (2019). Parkinson's disease - Symptoms.\n\nNHS.uk. (2019). Alzheimer’s disease - Symptoms.\n\nTarakad, A., & Jankovic, J. (2017). Anosmia and Ageusia in Parkinson's Disease. International review of neurobiology, 133, 541–556. https://doi.org/10.1016/bs.irn.2017.05.028\n\nRana, A. Q., Kabir, A., Jesudasan, M., Siddiqui, I., & Khondker, S. (2013). Pain in Parkinson's disease: Analysis and literature review. Clinical Neurology and Neurosurgery, 115(11), 2313-2317. doi: https://doi.org/10.1016/j.clineuro.2013.08.022\n\nYounan, D., Petkus, A. J., Widaman, K. F., Wang, X., Casanova, R., Espeland, M. A., Gatz, M., Henderson, V. W., Manson, J. E., Rapp, S. R., Sachs, B. C., Serre, M. L., Gaussoin, S. A., Barnard, R., Saldana, S., Vizuete, W., Beavers, D. P., Salinas, J. A., Chui, H. C., Resnick, S. M., … Chen, J. C. (2020). Particulate matter and episodic memory decline mediated by early neuroanatomic biomarkers of Alzheimer's disease. Brain: a journal of neurology, 143(1), 289–302. https://doi.org/10.1093/brain/awz348\n\nEl Haj, M., Colombel, F., Kapogiannis, D., & Gallouj, K. (2020). False Memory in Alzheimer's Disease. Behavioural neurology, 2020, 5284504. https://doi.org/10.1155/2020/5284504\n\nBoccardi, V., Ruggiero, C., Patriti, A., & Marano, L. (2016). Diagnostic Assessment and Management of Dysphagia in Patients with Alzheimer's Disease. Journal of Alzheimer's disease: JAD, 50(4), 947–955. https://doi.org/10.3233/JAD-150931\n\nTeichmann, M., & Ferrieux, S. (2013). Aphasia(s) in Alzheimer. Revue neurologique, 169(10), 680–686. https://doi.org/10.1016/j.neurol.2013.06.001\n\nHennawy, M., Sabovich, S., Liu, C. S., Herrmann, N., & Lanctôt, K. L. (2019). Sleep and Attention in Alzheimer's Disease. The Yale journal of biology and medicine, 92(1), 53–61. \n\nLeszek, J., Mikhaylenko, E. V., Belousov, D. M., Koutsouraki, E., Szczechowiak, K., Kobusiak-Prokopowicz, M., Mysiak, A., Diniz, B. S., Somasundaram, S. G., Kirkland, C. E., & Aliev, G. (2021). The Links between Cardiovascular Diseases and Alzheimer's Disease. Current neuropharmacology, 19(2), 152–169. https://doi.org/10.2174/1570159X18666200729093724 \n\nVasefi, M., Ghaboolian-Zare, E., Abedelwahab, H., & Osu, A. (2020). Environmental toxins and Alzheimer's disease progression. Neurochemistry international, 141, 104852. https://doi.org/10.1016/j.neuint.2020.104852 \n\nPicillo, M., Nicoletti, A., Fetoni, V., Garavaglia, B., Barone, P., & Pellecchia, M. T. (2017). The relevance of gender in Parkinson's disease: a review. Journal of neurology, 264(8), 1583–1607. https://doi.org/10.1007/s00415-016-8384-9\n\nEgan, S. J., Laidlaw, K., & Starkstein, S. (2015). Cognitive Behaviour Therapy for Depression and Anxiety in Parkinson's Disease. Journal of Parkinson's disease, 5(3), 443–451. https://doi.org/10.3233/JPD-150542\n\nZhang, M., Zhao, D., Zhou, G., & Li, C. (2020). Dietary Pattern, Gut Microbiota, and Alzheimer's Disease. Journal of agricultural and food chemistry, 68(46), 12800–12809. https://doi.org/10.1021/acs.jafc.9b08309 \n\nKrauss, J. K., Lipsman, N., Aziz, T., Boutet, A., Brown, P., Chang, J. W., Davidson, B., Grill, W. M., Hariz, M. I., Horn, A., Schulder, M., Mammis, A., Tass, P. A., Volkmann, J., & Lozano, A. M. (2021). Technology of deep brain stimulation: current status and future directions. Nature reviews. Neurology, 17(2), 75–87. https://doi.org/10.1038/s41582-020-00426-z \n\nZanetti, O., Solerte, S. B., & Cantoni, F. (2009). Life expectancy in Alzheimer's disease (AD). Archives of gerontology and geriatrics, 49 Suppl 1, 237–243. https://doi.org/10.1016/j.archger.2009.09.035\n\nGolbe, L. I., & Leyton, C. E. (2018). Life expectancy in Parkinson disease. Neurology, 91(22), 991–992. https://doi.org/10.1212/WNL.0000000000006560\n\nHopkinsmedicine.org. 2021. Young-Onset Parkinson's Disease. \n\nNational Institute on Aging. 2017. What Are the Signs of Alzheimer's Disease?\n\nLanger K. G. (2019). Early History of Amnesia. Frontiers of neurology and neuroscience, 44, 64–74. https://doi.org/10.1159/000494953\n\nSveinbjornsdottir S. (2016). The clinical symptoms of Parkinson's disease. Journal of neurochemistry, 139 Suppl 1, 318–324. https://doi.org/10.1111/jnc.13691\n\nQuerfurth, H. W., & LaFerla, F. M. (2010). Alzheimer's disease. The New England journal of medicine, 362(4), 329–344. https://doi.org/10.1056/NEJMra0909142\n\nBurns, A., & Iliffe, S. (2009). Dementia. BMJ (Clinical research ed.), 338, b75. https://doi.org/10.1136/bmj.b75\n\nFang, E. F., Hou, Y., Palikaras, K., Adriaanse, B. A., Kerr, J. S., Yang, B., Lautrup, S., Hasan-Olive, M. M., Caponio, D., Dan, X., Rocktäschel, P., Croteau, D. L., Akbari, M., Greig, N. H., Fladby, T., Nilsen, H., Cader, M. Z., Mattson, M. P., Tavernarakis, N., & Bohr, V. A. (2019). Mitophagy inhibits amyloid-β and tau pathology and reverses cognitive deficits in models of Alzheimer's disease. Nature neuroscience, 22(3), 401–412. https://doi.org/10.1038/s41593-018-0332-9\n\nTolosa, E., & Compta, Y. (2006). Dystonia in Parkinson's disease. Journal of neurology, 253 Suppl 7, VII7–VII13. https://doi.org/10.1007/s00415-006-7003-6\n\nGanguly, G., Chakrabarti, S., Chatterjee, U., & Saso, L. (2017). Proteinopathy, oxidative stress and mitochondrial dysfunction: cross talk in Alzheimer's disease and Parkinson's disease. Drug design, development and therapy, 11, 797–810. https://doi.org/10.2147/DDDT.S130514\n\nHou, Y., Dan, X., Babbar, M., Wei, Y., Hasselbalch, S. G., Croteau, D. L., & Bohr, V. A. (2019). Ageing as a risk factor for neurodegenerative disease. Nature reviews. Neurology, 15(10), 565–581. https://doi.org/10.1038/s41582-019-0244-7\n\nMcGregor, M. M., & Nelson, A. B. (2019). Circuit Mechanisms of Parkinson's Disease. Neuron, 101(6), 1042–1056. https://doi.org/10.1016/j.neuron.2019.03.004\n\nDoty R. L. (2012). Olfactory dysfunction in Parkinson disease. Nature reviews. Neurology, 8(6), 329–339. https://doi.org/10.1038/nrneurol.2012.80\n\nPeter-Derex, L., Yammine, P., Bastuji, H., & Croisile, B. (2015). Sleep and Alzheimer's disease. Sleep medicine reviews, 19, 29–38. https://doi.org/10.1016/j.smrv.2014.03.007\n\nMeireles, J., & Massano, J. (2012). Cognitive impairment and dementia in Parkinson's disease: clinical features, diagnosis, and management. Frontiers in neurology, 3, 88. https://doi.org/10.3389/fneur.2012.00088\n\nCui L, Hou NN, Wu HM, Zuo X, Lian YZ, Zhang CN, Wang ZF, Zhang X, Zhu JH. Prevalence of Alzheimer's Disease and Parkinson's Disease in China: An Updated Systematical Analysis. Front Aging Neurosci. 2020 Dec 21; 12:603854. doi: 10.3389/fnagi.2020.603854. PMID: 33424580; PMCID: PMC7793643.\n\nTakizawa, C., Gemmell, E., Kenworthy, J. et al. A Systematic Review of the Prevalence of Oropharyngeal Dysphagia in Stroke, Parkinson’s Disease, Alzheimer’s Disease, Head Injury, and Pneumonia. Dysphagia 31, 434–441 (2016). https://doi.org/10.1007/s00455-016-9695-9\n\nNumber of deaths due to Parkinson's disease | Statista. (2021). Retrieved 12 December 2021, from https://www.statista.com/statistics/753594/number-of-deaths-from-parkinson-in-spain/\n\nAlzheimer disease mortality rate U.S. 2000-2019 | Statista. (2021). Retrieved 12 December 2021, from https://www.statista.com/statistics/452945/mortality-rate-of-alzheimers-patients-in-the-us/\n\nLebouvier T, Chaumette T, Paillusson S, Duyckaerts C, Bruley des Varannes S, Neunlist M, Derkinderen P. The second brain and Parkinson's disease. Eur J Neurosci. 2009 Sep;30(5):735-41. doi: 10.1111/j.1460-9568.2009.06873. x. Epub 2009 Aug 27. PMID: 19712093.\n\nWorld Health Organization. The top 10 causes of death. (2019). \n\nAlzheimer's Association. (2020). 2020 Alzheimer's disease facts and figures. Alzheimer's & dementia: the journal of the Alzheimer's Association, 10.1002/alz.12068. Advance online publication. https://doi.org/10.1002/alz.12068\n\nPodcasy, J. L., & Epperson, C. N. (2016). Considering sex and gender in Alzheimer disease and other dementias. Dialogues in clinical neuroscience, 18(4), 437–446. https://doi.org/10.31887/DCNS.2016.18.4/cepperson\n\nSengoku R. (2020). Aging and Alzheimer's disease pathology. Neuropathology: official journal of the Japanese Society of Neuropathology, 40(1), 22–29. https://doi.org/10.1111/neup.12626\n\nBraak, H., & Braak, E. (1991). Neuropathological stageing of Alzheimer-related changes. Acta neuropathologica, 82(4), 239–259. https://doi.org/10.1007/BF00308809\n\nSwerdlow R. H. (2018). Mitochondria and Mitochondrial Cascades in Alzheimer's Disease. Journal of Alzheimer's disease: JAD, 62(3), 1403–1416. https://doi.org/10.3233/JAD-170585\n\nJamwal, S., Blackburn, J. K., & Elsworth, J. D. (2021). Expression of PON2 isoforms varies among brain regions in male and female African green monkeys. Free radical biology & medicine, S0891-5849(21)00856-X. Advance online publication. https://doi.org/10.1016/j.freeradbiomed.2021.12.005\n\nKouli, A., Torsney, K. M., & Kuan, W. L. (2018). Parkinson’s Disease: Etiology, Neuropathology, and Pathogenesis. In T. B. Stoker (Eds.) et. al., Parkinson’s Disease: Pathogenesis and Clinical Aspects. Codon Publications. \n\nXiao⁃dan, W., Yong, J. (2017) 200⁃year history of Parkinson's disease. Chin J Contemp Neurol Neurosurg\n\nLeWitt P. A. (2015). Levodopa therapy for Parkinson's disease: Pharmacokinetics and pharmacodynamics. Movement disorders: official journal of the Movement Disorder Society, 30(1), 64–72. https://doi.org/10.1002/mds.26082\n\nMatsumine H. (1999). Rinsho shinkeigaku = Clinical neurology, 39(1), 9–12.\n\nMSD manual: professional version. (2020). JAC-Antimicrobial Resistance, 2(3). doi:10.1093/jacamr/dlaa042\n\nAkhtar, A., & Sah, S. P. (2020). Insulin signaling pathway and related molecules: Role in neurodegeneration and Alzheimer's disease. Neurochemistry international, 135, 104707. https://doi.org/10.1016/j.neuint.2020.104707\n\nO'Brien, R. J., & Wong, P. C. (2011). Amyloid precursor protein processing and Alzheimer's disease. Annual review of neuroscience, 34, 185–204. https://doi.org/10.1146/annurev-neuro-061010-113613\n\nUbeda-Bañon, I., Saiz-Sanchez, D., Flores-Cuadrado, A., Rioja-Corroto, E., Gonzalez-Rodriguez, M., Villar-Conde, S., Astillero-Lopez, V., Cabello-de la Rosa, J. P., Gallardo-Alcañiz, M. J., Vaamonde-Gamo, J., Relea-Calatayud, F., Gonzalez-Lopez, L., Mohedano-Moriano, A., Rabano, A., & Martinez-Marcos, A. (2020). The human olfactory system in two proteinopathies: Alzheimer's and Parkinson's diseases. Translational neurodegeneration, 9(1), 22. https://doi.org/10.1186/s40035-020-00200-7\n\nHansen N. (2021). Locus Coeruleus Malfunction Is Linked to Psychopathology in Prodromal Dementia With Lewy Bodies. Frontiers in aging neuroscience, 13, 641101. https://doi.org/10.3389/fnagi.2021.641101\n","slug":"2021-12-13-Lei-proteinopathies-essay","published":1,"updated":"2022-08-24T17:08:39.332Z","comments":1,"layout":"post","photos":[],"_id":"cuidk8rR66MGMwM-5hDgjmb3O","content":"<p>This is a comparison and contrast between two common proteinopathies (Alzheimer’s disease &amp; Parkinson’s disease), discussing clinical symptoms, epidimiology and pathological hallmarks.</p>\n<h1 id=\"Main-body\"><a href=\"#Main-body\" class=\"headerlink\" title=\"Main body\"></a>Main body</h1><p>The present view takes proteinopathy as an umbrella term for the neurodegenerative disorders caused by the accumulation of misfolded protein, which is attributable to the conformational error of the protein (Bayer, 2015, Lanuti, 2020) These aggregated proteins were verified to gain typical amyloid features (Virchow, 1854) which means the “starch” conformation. In this case, these proteins might not only lose their original normal function but also gain toxicity (Luheshi et al., 2008). Speaking of proteinopathies, two diseases must be mentioned: One is Parkinson’s disease (PD), the most famous progressive neurodegenerative diseases associated with motor as well as nonmotor deficits, which is known as the second common neurodegenerative disorder, (Capriotti &amp; Terzakis, 2016; Simon et al., 2020; Hayes, 2019); the other one is Alzheimer’s disease (AD), one of the most major reason for dementia, the most common neurodegenerative disorder (Lane, Hardy &amp; Schott, 2018). There are around one billion sufferers around the world who are suffering both physical and psychological agony from these neurodegenerative disorders in 2019 (Bulck et al., 2019). Various factors, for instance genomic, epigenomic, metabolic, or environmental factors (Bulck et al., 2019), are shown to have an impact on PD and AD in a permutation and combination way. Here this essay will go into detail about these two common proteinopathies in three aspects: clinical symptoms, epidemiology and pathological hallmarks.</p>\n<p>In terms of clinical symptoms between PD and AD, multiple similar as well as differing pathological phenotypes can be identified, which is treated under the comparison and contrast between PD and AD (Table 1). PD and AD are both irreversible progressive, degenerative diseases meaning the symptoms will gradually become more severe as the stages develop. The most obvious problems about patients’ cognitive and psychiatric symptoms come first as we consider these neurodegenerative diseases. As far as we know, AD is well-known for its influence on memory, academically called amnesia which was first conceptualized as memory loss in 1763 by Sauvagues (Langer, 2019). Most of the advanced AD sufferers are reported to have Amnesia symptoms, accounting for fifty per cent to seventy per cent of all patients with dementia (Burns &amp; Iliffe 2009), while it seldomly happens to PD patients. Only the most severe PD sufferers are reported to experience similar amnesia symptoms (Querfurth &amp; LaFerla, 2010). At the memory level, patients with AD not only have amnesia but also often experience memory distortions (El Haj et al. 2020, Younan et al., 2020), such as having comprehensive and vivid memories of episodic occurrences that have never been observed. AD symptoms are generally considered as an essential impairment of episodic memory (Younan et al., 2020), while one’s attention is compromised on AD’s early stage as well, especially in those with early age onset and atypical syndromes (Malhotra, 2018). One feature of AD is that the symptoms are accompanied by severe attentional impairment frequently which is linked with other neurodegenerative disorders as well (Malhotra, 2018). It is suggested that PD patients suffer more depression and anxiety (Sveinbjornsdottir, 2016) than AD patients, which may be concluded to the inconsistency between one’s movements and willingness.</p>\n<p>Apart from memory problems for AD and PD, some other motor symptoms can also put huge inconvenience to one’s life. PD patients are reported to have three main symptoms which are tremor, bradykinesia and rigidity (Hayes, 2019). Tremor means shaking, especially after a short pause of a postural movement. Bradykinesia implies a slower movement than normal action which may cause difficulties for some ordinary tasks like walking or doing dishes. Rigidity or spasticity refers to muscle stiffness, which is academically called dystonia (Tolosa &amp; Compta, 2006). Unlike those symptoms in AD, these three main symptoms in PD are more relying on the neuromuscular connection so that these are all related to muscle control abnormality which is the direct result of neurodegeneration the same as AD (McGregor &amp; Nelson, 2019). Similarly, AD patients also suffer motor problems like dysphagia referring to the difficulty in swallowing, which is also reported in eleven to eighty-one per cent of PD patients (Takizawa et al., 2016). Patients with AD gradually lose cognitive functions until they reach the final stage of the disease, which is characterised by full failure of control over body functions (Boccardi et al., 2016).</p>\n<p>Regarding the nonmotor symptoms, anosmia (the sense loss of smell) and ageusia (the sense loss of taste), are common in PD. And the equivalent olfactory loss is also observed in AD (Doty 2012), which may be contributed to the shared pathological features. It may be corroborated that the olfactory loss is significantly linked to cognitive level (Tarakad &amp; Jankovic, 2017). This is different from PD: AD patients show more cognitive impairments. There occur some other cognitive problems in AD more than memory. For example, one type of language disorder, aphasia is usually related to AD owing to the damage of frontal, temporal, or parietal language cortices. And these aphasias caused by AD accounts for nearly thirty per cent of primary degenerative aphasias (Teichmann &amp; Ferrieux, 2013). The problems are not only about daily life activity but also about the biological clock. Sleep disturbances and sleep disorders come to be big problems for AD and PD patients since these are long term and progressive diseases. (Peter-Derex, 2015). Sleep disorders, on the other hand, is reported to be linked to an increased risk of AD. Both situations have a negative impact on one’s attention (Hennawy et al., 2019). Insomnia and exhaustion are also the following side effects of sleep disorders. Together with physical discomfort, those symptoms above can cause psychological discomfort in PD when comparing PD and AD. Neuralgia has become a severe problem for patients. There are five main forms of pain are documented in PD sufferers which are separately dystonia, musculoskeletal pain, nerve or nerve root pain, primary or central pain and akathisia with some samples (Rana 2013). </p>\n<p>To sum up, AD and PD symptoms are generally different, but these share some key features at the same time. PD patients are more likely to have primarily motor abnormalities, whereas AD patients normally experience dementia and cognitive impairment (Meireles &amp; Massano 2012). The neuronal death is a typical feature of both illnesses, the autopsy histopathology of the brains from AD and PD patients are distinct in each instance and diverse from one another (Ganguly et al., 2017). AD focuses more on cognitive symptoms while PD focus more on physical symptoms even though these can be divided into motor and nonmotor symptoms.</p>\n<p><strong>Table 1.</strong> Comparison and contrast table of Alzheimer’s disease and Parkinson’s disease in symptoms, causes, onset age, treatment, and lifespan expectancy.</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>AD</th>\n<th>PD</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clinical symptoms</td>\n<td>Amnesia (El Haj et  al., 2020)  Impairments of  attention (Malhotra, 2018)  Disorder of episodic  memory (Younan et al., 2020)  Memory distortions (El  Haj et al. 2020)  Dysphagia (Boccardi et  al., 2016)  Dysphasia (Teichmann  &amp; Ferrieux, 2013)  Sleep disruption and  sleep disorders (Hennawy et al., 2019)</td>\n<td>Tremor  Bradykinesia  Rigidity (NHS, 2019)  Loss of balance  Anosmia and ageusia  (Doty, 2012; Tarakad &amp; Jankovic, 2017)  Neuralgia (Rana et  al., 2013)  Urinary infection (Gerlach,  Winogrodzka &amp; Weber 2011)  Depression, anxiety  (Sveinbjornsdottir, 2016)</td>\n</tr>\n<tr>\n<td>Factors that may  influence</td>\n<td>Increasing age (Hou et  al., 2019)  Family history  Head Injury  Cardiovascular  diseases (Leszek et al., 2021)  Environmental toxins  (Vasefi et al., 2020)</td>\n<td>Increasing age (Hou et  al., 2019)  Family history  Head Injury  Male gender (Picillo  et al., 2017)</td>\n</tr>\n<tr>\n<td>Onset ages</td>\n<td>First symptoms usually  appear in the mid-60s. Early-onset AD begin between the 30s and mid-60s  (National Institute on Aging, 2017)</td>\n<td>The average age is 60  years old, whoever younger than 50 is considered young-onset PD (Johns  Hopkins medicine, 2021)</td>\n</tr>\n<tr>\n<td>Current treatment</td>\n<td>Medication  Physical therapy  Dietary control (Zhang  et al., 2020)  Deep brain stimulation  (Krauss et al., 2021)</td>\n<td>Medication  Physical therapy  Cognitive behavioural  therapy (Egan, Laidlaw &amp; Starkstein, 2015)</td>\n</tr>\n<tr>\n<td>Life expectancy</td>\n<td>After diagnosis, the  average expectancy for remaining life is 3 to 10 years (Zanetti, Solerte  &amp; Cantoni, 2009)</td>\n<td>The relevant  comparator is 23.3 years for average onset age of 60 years old (Golbe &amp;  Leyton, 2018). PD does not obviously reduce the lifespan</td>\n</tr>\n</tbody></table>\n<p>When it comes to epidemiology, four key elements come to stand revealed on the paper: how much, when, where and whom. From Statista (2021), Official death certificates are recorded to be 37 in 100,000 for AD and 10.3 in 100,000 in PD in 2019 in the United States. AD has turned into the seventh single biggest killer in the world (WHO, 2019) and the sixth leading cause of death in the United States (Alzheimer’s Association, 2020). Followed with AD, PD has become the second most common neurodegenerative disease (Lebouvier 2009).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354886.gif\" alt=\"image005\"></p>\n<p><strong>Figure 1.</strong> Death rate from Parkinson’s disease and Alzheimer’s disease in the United States from 2000 to 2019 (data is from Statista: John Elflein, 2021; Statista Research Department, 2021)</p>\n<p>The factor “whom” I mentioned above can be illustrated briefly by the following considering ages, sex and so on. There is some evidence to suggest that age is the main risk factor for AD and PD (Hou et al., 2019). According to the research of Cui et al. (2020), the rates of both AD and PD grew consistently with age growing, but this phenomenon is more likely applicable for AD (Figure 2). Even though Cui et al. failed to account for worldwide data, it presents a positive correlation of prevalence of AD and PD as well as the slight difference between each other. </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354377.jpg\" alt=\"image006\"></p>\n<p><strong>Figure 2.</strong> Prevalence of Alzheimer’s disease and Parkinson’s disease in China</p>\n<p>(Cui et al., 2020)</p>\n<p>It is a widely held view that females get more possibility at risk of developing AD, while males get a higher risk for vascular dementia (Podcasy &amp; Epperson, 2016). Ample evidence suggests that female PD patients tend to show a more benign symptom for which many scholars hold the view that it is due to the consequence of oestrogen (Picillo et al., 2017). It is essential to bear in mind that there is a possible bias in the sex effect on AD and PD.</p>\n<p>In the 1950s, researchers successively discovered that the presence of Lewy bodies in substantia nigra and locus nucleus patients in PD patients, gradually determining the pathological hallmarks of PD (Xiao-dan, 2017). One of the limitations with this explanation is that in some cases like a mutation of PARK-2, there are no Lewy bodies (Matsumine, 1999). The research team of Arvid and Isamu find that there are dopamine abnormalities in the brain tissue of PD patients then (LeWitt, 2015). According to Dickson (2012) and Kouli (2018), alpha-synuclein accumulates in Lewy bodies and neurites in the brain and peripheral nerves. And it can be pathological hallmarks of PD, in which case, the abnormal cytoplasmic deposits occur in cell bodies. Neuropathologically, senile plaques and neurofibrillary tangles can be hallmarks of AD (Sengoku, 2020). Under the action of endonuclease, the cleaved-off extracellular part of APP is the amyloid-β protein (O’Brien &amp; Wong, 2011). The amyloid-β deposition is another hallmark for AD. Analogously, AD and PD both have tau pathology. Braak (1991) holds the view that the magnitude and location of tau deposition might be related to clinical symptoms of AD. The tau pathology is also reported to have an impact on neurons and glia in PD (Dickson 2012). Several observations suggest that there is a link between the dysfunction, even partly, of the mitochondria or the oxidative stress and the neuropathology of AD and PD (Swerdlow, 2018; Jamwal, Blackburn &amp; Elsworth, 2021). Succinctly, AD and PD share both similarities and differences (Table 2).</p>\n<p><strong>Table 2.</strong> Pathological hallmarks of AD and PD</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>AD</th>\n<th>PD</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pathological hallmarks</td>\n<td>Extracellular  β-amyloid deposits, i.e., senile plaques  Extracellular  β-amyloid deposits, i.e., senile plaques (MSD manuals, 2020)  Nerve cell death in  hippocampus and prefrontal cortex (Akhtar &amp; Sah, 2020)</td>\n<td>Lewy bodies in the  substantia nigra striatum (MSD manuals, 2020)   Synuclein deposition  Degeneration of  neurons in substantia nigra, locus coeruleus and other brainstem dopaminergic  cells (Hansen, 2021)</td>\n</tr>\n</tbody></table>\n<p>All in all, there is a big difference between the pathological characteristics, the affected brain parts and the clinical symptoms of AD and PD. As global life expectancy has increased, proteinopathies of the brain, which particularly affect the elderly, have placed an increasing burden on society. AD and PD invade the patients’ intellectual and emotional health, thereby potentially destroying their lives and family life. AD and PD invade the victim’s intellectual and emotional health, thereby potentially destroying their lives and family. Since there is a long prodromal period, if we can diagnosis those in advance, earlier and timely treatment might be able to be applied (Ubeda-Bañon et al., 2020), thus, sufferings might be relieved. Both PD and AD get involved in broad regions of the nervous system, neurotransmitters and protein aggregation (Kalia &amp; Lang 2015). The difference is that PD mainly happens in substantia nigra, locus coeruleus and other brainstem dopaminergic cells (Hansen, 2021) while AD typically starts in the temporal lobe, in more detail, hippocampus and prefrontal cortex (Akhtar &amp; Sah, 2020). No matter how similar or different those diseases are, one issue is certain, it is our biologists’ duty to pull those suffers with PD or AD out of the hell.</p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a><strong>Reference</strong></h1><p>Bayer, T. A. (2015). Proteinopathies, a core concept for understanding and ultimately treating degenerative disorders? Eur Neuropsychopharmacol, 25(5), 713-724. doi: 10.1016/j.euroneuro.2013.03.007</p>\n<p>Lanuti, P. et al. (2020). Neurodegenerative diseases as proteinopathies-driven immune disorders. Neural regeneration research, 15 (5), s. 850. doi:10.4103/1673-5374.268971</p>\n<p>Virchow, R. (1854). Handbuch der Speciellen Pathologie und Therapie</p>\n<p>Luheshi, L. M., Crowther, D. C., &amp; Dobson, C. M. (2008). Protein misfolding and disease: from the test tube to the organism. Current Opinion in Chemical Biology, 12(1), 25-31. doi: <a href=\"https://doi.org/10.1016/j.cbpa.2008.02.011\">https://doi.org/10.1016/j.cbpa.2008.02.011</a></p>\n<p>Capriotti, T., &amp; Terzakis, K. (2016). Parkinson Disease. Home healthcare now, 34(6), 300–307. <a href=\"https://doi.org/10.1097/NHH.0000000000000398\">https://doi.org/10.1097/NHH.0000000000000398</a></p>\n<p>Simon, D. K., Tanner, C. M., &amp; Brundin, P. (2020). Parkinson Disease Epidemiology, Pathology, Genetics, and Pathophysiology. Clinics in geriatric medicine, 36(1), 1–12. <a href=\"https://doi.org/10.1016/j.cger.2019.08.002\">https://doi.org/10.1016/j.cger.2019.08.002</a></p>\n<p>Hayes, M. T. (2019). Parkinson’s Disease and Parkinsonism. The American Journal of Medicine, 132(7), 802-807. doi: <a href=\"https://doi.org/10.1016/j.amjmed.2019.03.001\">https://doi.org/10.1016/j.amjmed.2019.03.001</a></p>\n<p>Lane, C. A., Hardy, J., &amp; Schott, J. M. (2018). Alzheimer’s disease. European Journal of Neurology, 25(1), 59-70. doi:10.1111/ene.13439</p>\n<p>Van Bulck, M., Sierra-Magro, A., Alarcon-Gil, J., Perez-Castillo, A., &amp; Morales-Garcia, J. A. (2019). Novel Approaches for the Treatment of Alzheimer’s and Parkinson’s Disease. International journal of molecular sciences, 20(3), 719. <a href=\"https://doi.org/10.3390/ijms20030719\">https://doi.org/10.3390/ijms20030719</a></p>\n<p>NHS.uk. (2019). Parkinson’s disease - Symptoms.</p>\n<p>NHS.uk. (2019). Alzheimer’s disease - Symptoms.</p>\n<p>Tarakad, A., &amp; Jankovic, J. (2017). Anosmia and Ageusia in Parkinson’s Disease. International review of neurobiology, 133, 541–556. <a href=\"https://doi.org/10.1016/bs.irn.2017.05.028\">https://doi.org/10.1016/bs.irn.2017.05.028</a></p>\n<p>Rana, A. Q., Kabir, A., Jesudasan, M., Siddiqui, I., &amp; Khondker, S. (2013). Pain in Parkinson’s disease: Analysis and literature review. Clinical Neurology and Neurosurgery, 115(11), 2313-2317. doi: <a href=\"https://doi.org/10.1016/j.clineuro.2013.08.022\">https://doi.org/10.1016/j.clineuro.2013.08.022</a></p>\n<p>Younan, D., Petkus, A. J., Widaman, K. F., Wang, X., Casanova, R., Espeland, M. A., Gatz, M., Henderson, V. W., Manson, J. E., Rapp, S. R., Sachs, B. C., Serre, M. L., Gaussoin, S. A., Barnard, R., Saldana, S., Vizuete, W., Beavers, D. P., Salinas, J. A., Chui, H. C., Resnick, S. M., … Chen, J. C. (2020). Particulate matter and episodic memory decline mediated by early neuroanatomic biomarkers of Alzheimer’s disease. Brain: a journal of neurology, 143(1), 289–302. <a href=\"https://doi.org/10.1093/brain/awz348\">https://doi.org/10.1093/brain/awz348</a></p>\n<p>El Haj, M., Colombel, F., Kapogiannis, D., &amp; Gallouj, K. (2020). False Memory in Alzheimer’s Disease. Behavioural neurology, 2020, 5284504. <a href=\"https://doi.org/10.1155/2020/5284504\">https://doi.org/10.1155/2020/5284504</a></p>\n<p>Boccardi, V., Ruggiero, C., Patriti, A., &amp; Marano, L. (2016). Diagnostic Assessment and Management of Dysphagia in Patients with Alzheimer’s Disease. Journal of Alzheimer’s disease: JAD, 50(4), 947–955. <a href=\"https://doi.org/10.3233/JAD-150931\">https://doi.org/10.3233/JAD-150931</a></p>\n<p>Teichmann, M., &amp; Ferrieux, S. (2013). Aphasia(s) in Alzheimer. Revue neurologique, 169(10), 680–686. <a href=\"https://doi.org/10.1016/j.neurol.2013.06.001\">https://doi.org/10.1016/j.neurol.2013.06.001</a></p>\n<p>Hennawy, M., Sabovich, S., Liu, C. S., Herrmann, N., &amp; Lanctôt, K. L. (2019). Sleep and Attention in Alzheimer’s Disease. The Yale journal of biology and medicine, 92(1), 53–61. </p>\n<p>Leszek, J., Mikhaylenko, E. V., Belousov, D. M., Koutsouraki, E., Szczechowiak, K., Kobusiak-Prokopowicz, M., Mysiak, A., Diniz, B. S., Somasundaram, S. G., Kirkland, C. E., &amp; Aliev, G. (2021). The Links between Cardiovascular Diseases and Alzheimer’s Disease. Current neuropharmacology, 19(2), 152–169. <a href=\"https://doi.org/10.2174/1570159X18666200729093724\">https://doi.org/10.2174/1570159X18666200729093724</a> </p>\n<p>Vasefi, M., Ghaboolian-Zare, E., Abedelwahab, H., &amp; Osu, A. (2020). Environmental toxins and Alzheimer’s disease progression. Neurochemistry international, 141, 104852. <a href=\"https://doi.org/10.1016/j.neuint.2020.104852\">https://doi.org/10.1016/j.neuint.2020.104852</a> </p>\n<p>Picillo, M., Nicoletti, A., Fetoni, V., Garavaglia, B., Barone, P., &amp; Pellecchia, M. T. (2017). The relevance of gender in Parkinson’s disease: a review. Journal of neurology, 264(8), 1583–1607. <a href=\"https://doi.org/10.1007/s00415-016-8384-9\">https://doi.org/10.1007/s00415-016-8384-9</a></p>\n<p>Egan, S. J., Laidlaw, K., &amp; Starkstein, S. (2015). Cognitive Behaviour Therapy for Depression and Anxiety in Parkinson’s Disease. Journal of Parkinson’s disease, 5(3), 443–451. <a href=\"https://doi.org/10.3233/JPD-150542\">https://doi.org/10.3233/JPD-150542</a></p>\n<p>Zhang, M., Zhao, D., Zhou, G., &amp; Li, C. (2020). Dietary Pattern, Gut Microbiota, and Alzheimer’s Disease. Journal of agricultural and food chemistry, 68(46), 12800–12809. <a href=\"https://doi.org/10.1021/acs.jafc.9b08309\">https://doi.org/10.1021/acs.jafc.9b08309</a> </p>\n<p>Krauss, J. K., Lipsman, N., Aziz, T., Boutet, A., Brown, P., Chang, J. W., Davidson, B., Grill, W. M., Hariz, M. I., Horn, A., Schulder, M., Mammis, A., Tass, P. A., Volkmann, J., &amp; Lozano, A. M. (2021). Technology of deep brain stimulation: current status and future directions. Nature reviews. Neurology, 17(2), 75–87. <a href=\"https://doi.org/10.1038/s41582-020-00426-z\">https://doi.org/10.1038/s41582-020-00426-z</a> </p>\n<p>Zanetti, O., Solerte, S. B., &amp; Cantoni, F. (2009). Life expectancy in Alzheimer’s disease (AD). Archives of gerontology and geriatrics, 49 Suppl 1, 237–243. <a href=\"https://doi.org/10.1016/j.archger.2009.09.035\">https://doi.org/10.1016/j.archger.2009.09.035</a></p>\n<p>Golbe, L. I., &amp; Leyton, C. E. (2018). Life expectancy in Parkinson disease. Neurology, 91(22), 991–992. <a href=\"https://doi.org/10.1212/WNL.0000000000006560\">https://doi.org/10.1212/WNL.0000000000006560</a></p>\n<p>Hopkinsmedicine.org. 2021. Young-Onset Parkinson’s Disease. </p>\n<p>National Institute on Aging. 2017. What Are the Signs of Alzheimer’s Disease?</p>\n<p>Langer K. G. (2019). Early History of Amnesia. Frontiers of neurology and neuroscience, 44, 64–74. <a href=\"https://doi.org/10.1159/000494953\">https://doi.org/10.1159/000494953</a></p>\n<p>Sveinbjornsdottir S. (2016). The clinical symptoms of Parkinson’s disease. Journal of neurochemistry, 139 Suppl 1, 318–324. <a href=\"https://doi.org/10.1111/jnc.13691\">https://doi.org/10.1111/jnc.13691</a></p>\n<p>Querfurth, H. W., &amp; LaFerla, F. M. (2010). Alzheimer’s disease. The New England journal of medicine, 362(4), 329–344. <a href=\"https://doi.org/10.1056/NEJMra0909142\">https://doi.org/10.1056/NEJMra0909142</a></p>\n<p>Burns, A., &amp; Iliffe, S. (2009). Dementia. BMJ (Clinical research ed.), 338, b75. <a href=\"https://doi.org/10.1136/bmj.b75\">https://doi.org/10.1136/bmj.b75</a></p>\n<p>Fang, E. F., Hou, Y., Palikaras, K., Adriaanse, B. A., Kerr, J. S., Yang, B., Lautrup, S., Hasan-Olive, M. M., Caponio, D., Dan, X., Rocktäschel, P., Croteau, D. L., Akbari, M., Greig, N. H., Fladby, T., Nilsen, H., Cader, M. Z., Mattson, M. P., Tavernarakis, N., &amp; Bohr, V. A. (2019). Mitophagy inhibits amyloid-β and tau pathology and reverses cognitive deficits in models of Alzheimer’s disease. Nature neuroscience, 22(3), 401–412. <a href=\"https://doi.org/10.1038/s41593-018-0332-9\">https://doi.org/10.1038/s41593-018-0332-9</a></p>\n<p>Tolosa, E., &amp; Compta, Y. (2006). Dystonia in Parkinson’s disease. Journal of neurology, 253 Suppl 7, VII7–VII13. <a href=\"https://doi.org/10.1007/s00415-006-7003-6\">https://doi.org/10.1007/s00415-006-7003-6</a></p>\n<p>Ganguly, G., Chakrabarti, S., Chatterjee, U., &amp; Saso, L. (2017). Proteinopathy, oxidative stress and mitochondrial dysfunction: cross talk in Alzheimer’s disease and Parkinson’s disease. Drug design, development and therapy, 11, 797–810. <a href=\"https://doi.org/10.2147/DDDT.S130514\">https://doi.org/10.2147/DDDT.S130514</a></p>\n<p>Hou, Y., Dan, X., Babbar, M., Wei, Y., Hasselbalch, S. G., Croteau, D. L., &amp; Bohr, V. A. (2019). Ageing as a risk factor for neurodegenerative disease. Nature reviews. Neurology, 15(10), 565–581. <a href=\"https://doi.org/10.1038/s41582-019-0244-7\">https://doi.org/10.1038/s41582-019-0244-7</a></p>\n<p>McGregor, M. M., &amp; Nelson, A. B. (2019). Circuit Mechanisms of Parkinson’s Disease. Neuron, 101(6), 1042–1056. <a href=\"https://doi.org/10.1016/j.neuron.2019.03.004\">https://doi.org/10.1016/j.neuron.2019.03.004</a></p>\n<p>Doty R. L. (2012). Olfactory dysfunction in Parkinson disease. Nature reviews. Neurology, 8(6), 329–339. <a href=\"https://doi.org/10.1038/nrneurol.2012.80\">https://doi.org/10.1038/nrneurol.2012.80</a></p>\n<p>Peter-Derex, L., Yammine, P., Bastuji, H., &amp; Croisile, B. (2015). Sleep and Alzheimer’s disease. Sleep medicine reviews, 19, 29–38. <a href=\"https://doi.org/10.1016/j.smrv.2014.03.007\">https://doi.org/10.1016/j.smrv.2014.03.007</a></p>\n<p>Meireles, J., &amp; Massano, J. (2012). Cognitive impairment and dementia in Parkinson’s disease: clinical features, diagnosis, and management. Frontiers in neurology, 3, 88. <a href=\"https://doi.org/10.3389/fneur.2012.00088\">https://doi.org/10.3389/fneur.2012.00088</a></p>\n<p>Cui L, Hou NN, Wu HM, Zuo X, Lian YZ, Zhang CN, Wang ZF, Zhang X, Zhu JH. Prevalence of Alzheimer’s Disease and Parkinson’s Disease in China: An Updated Systematical Analysis. Front Aging Neurosci. 2020 Dec 21; 12:603854. doi: 10.3389/fnagi.2020.603854. PMID: 33424580; PMCID: PMC7793643.</p>\n<p>Takizawa, C., Gemmell, E., Kenworthy, J. et al. A Systematic Review of the Prevalence of Oropharyngeal Dysphagia in Stroke, Parkinson’s Disease, Alzheimer’s Disease, Head Injury, and Pneumonia. Dysphagia 31, 434–441 (2016). <a href=\"https://doi.org/10.1007/s00455-016-9695-9\">https://doi.org/10.1007/s00455-016-9695-9</a></p>\n<p>Number of deaths due to Parkinson’s disease | Statista. (2021). Retrieved 12 December 2021, from <a href=\"https://www.statista.com/statistics/753594/number-of-deaths-from-parkinson-in-spain/\">https://www.statista.com/statistics/753594/number-of-deaths-from-parkinson-in-spain/</a></p>\n<p>Alzheimer disease mortality rate U.S. 2000-2019 | Statista. (2021). Retrieved 12 December 2021, from <a href=\"https://www.statista.com/statistics/452945/mortality-rate-of-alzheimers-patients-in-the-us/\">https://www.statista.com/statistics/452945/mortality-rate-of-alzheimers-patients-in-the-us/</a></p>\n<p>Lebouvier T, Chaumette T, Paillusson S, Duyckaerts C, Bruley des Varannes S, Neunlist M, Derkinderen P. The second brain and Parkinson’s disease. Eur J Neurosci. 2009 Sep;30(5):735-41. doi: 10.1111/j.1460-9568.2009.06873. x. Epub 2009 Aug 27. PMID: 19712093.</p>\n<p>World Health Organization. The top 10 causes of death. (2019). </p>\n<p>Alzheimer’s Association. (2020). 2020 Alzheimer’s disease facts and figures. Alzheimer’s &amp; dementia: the journal of the Alzheimer’s Association, 10.1002/alz.12068. Advance online publication. <a href=\"https://doi.org/10.1002/alz.12068\">https://doi.org/10.1002/alz.12068</a></p>\n<p>Podcasy, J. L., &amp; Epperson, C. N. (2016). Considering sex and gender in Alzheimer disease and other dementias. Dialogues in clinical neuroscience, 18(4), 437–446. <a href=\"https://doi.org/10.31887/DCNS.2016.18.4/cepperson\">https://doi.org/10.31887/DCNS.2016.18.4/cepperson</a></p>\n<p>Sengoku R. (2020). Aging and Alzheimer’s disease pathology. Neuropathology: official journal of the Japanese Society of Neuropathology, 40(1), 22–29. <a href=\"https://doi.org/10.1111/neup.12626\">https://doi.org/10.1111/neup.12626</a></p>\n<p>Braak, H., &amp; Braak, E. (1991). Neuropathological stageing of Alzheimer-related changes. Acta neuropathologica, 82(4), 239–259. <a href=\"https://doi.org/10.1007/BF00308809\">https://doi.org/10.1007/BF00308809</a></p>\n<p>Swerdlow R. H. (2018). Mitochondria and Mitochondrial Cascades in Alzheimer’s Disease. Journal of Alzheimer’s disease: JAD, 62(3), 1403–1416. <a href=\"https://doi.org/10.3233/JAD-170585\">https://doi.org/10.3233/JAD-170585</a></p>\n<p>Jamwal, S., Blackburn, J. K., &amp; Elsworth, J. D. (2021). Expression of PON2 isoforms varies among brain regions in male and female African green monkeys. Free radical biology &amp; medicine, S0891-5849(21)00856-X. Advance online publication. <a href=\"https://doi.org/10.1016/j.freeradbiomed.2021.12.005\">https://doi.org/10.1016/j.freeradbiomed.2021.12.005</a></p>\n<p>Kouli, A., Torsney, K. M., &amp; Kuan, W. L. (2018). Parkinson’s Disease: Etiology, Neuropathology, and Pathogenesis. In T. B. Stoker (Eds.) et. al., Parkinson’s Disease: Pathogenesis and Clinical Aspects. Codon Publications. </p>\n<p>Xiao⁃dan, W., Yong, J. (2017) 200⁃year history of Parkinson’s disease. Chin J Contemp Neurol Neurosurg</p>\n<p>LeWitt P. A. (2015). Levodopa therapy for Parkinson’s disease: Pharmacokinetics and pharmacodynamics. Movement disorders: official journal of the Movement Disorder Society, 30(1), 64–72. <a href=\"https://doi.org/10.1002/mds.26082\">https://doi.org/10.1002/mds.26082</a></p>\n<p>Matsumine H. (1999). Rinsho shinkeigaku = Clinical neurology, 39(1), 9–12.</p>\n<p>MSD manual: professional version. (2020). JAC-Antimicrobial Resistance, 2(3). doi:10.1093/jacamr/dlaa042</p>\n<p>Akhtar, A., &amp; Sah, S. P. (2020). Insulin signaling pathway and related molecules: Role in neurodegeneration and Alzheimer’s disease. Neurochemistry international, 135, 104707. <a href=\"https://doi.org/10.1016/j.neuint.2020.104707\">https://doi.org/10.1016/j.neuint.2020.104707</a></p>\n<p>O’Brien, R. J., &amp; Wong, P. C. (2011). Amyloid precursor protein processing and Alzheimer’s disease. Annual review of neuroscience, 34, 185–204. <a href=\"https://doi.org/10.1146/annurev-neuro-061010-113613\">https://doi.org/10.1146/annurev-neuro-061010-113613</a></p>\n<p>Ubeda-Bañon, I., Saiz-Sanchez, D., Flores-Cuadrado, A., Rioja-Corroto, E., Gonzalez-Rodriguez, M., Villar-Conde, S., Astillero-Lopez, V., Cabello-de la Rosa, J. P., Gallardo-Alcañiz, M. J., Vaamonde-Gamo, J., Relea-Calatayud, F., Gonzalez-Lopez, L., Mohedano-Moriano, A., Rabano, A., &amp; Martinez-Marcos, A. (2020). The human olfactory system in two proteinopathies: Alzheimer’s and Parkinson’s diseases. Translational neurodegeneration, 9(1), 22. <a href=\"https://doi.org/10.1186/s40035-020-00200-7\">https://doi.org/10.1186/s40035-020-00200-7</a></p>\n<p>Hansen N. (2021). Locus Coeruleus Malfunction Is Linked to Psychopathology in Prodromal Dementia With Lewy Bodies. Frontiers in aging neuroscience, 13, 641101. <a href=\"https://doi.org/10.3389/fnagi.2021.641101\">https://doi.org/10.3389/fnagi.2021.641101</a></p>\n","excerpt":"","more":"<p>This is a comparison and contrast between two common proteinopathies (Alzheimer’s disease &amp; Parkinson’s disease), discussing clinical symptoms, epidimiology and pathological hallmarks.</p>\n<h1 id=\"Main-body\"><a href=\"#Main-body\" class=\"headerlink\" title=\"Main body\"></a>Main body</h1><p>The present view takes proteinopathy as an umbrella term for the neurodegenerative disorders caused by the accumulation of misfolded protein, which is attributable to the conformational error of the protein (Bayer, 2015, Lanuti, 2020) These aggregated proteins were verified to gain typical amyloid features (Virchow, 1854) which means the “starch” conformation. In this case, these proteins might not only lose their original normal function but also gain toxicity (Luheshi et al., 2008). Speaking of proteinopathies, two diseases must be mentioned: One is Parkinson’s disease (PD), the most famous progressive neurodegenerative diseases associated with motor as well as nonmotor deficits, which is known as the second common neurodegenerative disorder, (Capriotti &amp; Terzakis, 2016; Simon et al., 2020; Hayes, 2019); the other one is Alzheimer’s disease (AD), one of the most major reason for dementia, the most common neurodegenerative disorder (Lane, Hardy &amp; Schott, 2018). There are around one billion sufferers around the world who are suffering both physical and psychological agony from these neurodegenerative disorders in 2019 (Bulck et al., 2019). Various factors, for instance genomic, epigenomic, metabolic, or environmental factors (Bulck et al., 2019), are shown to have an impact on PD and AD in a permutation and combination way. Here this essay will go into detail about these two common proteinopathies in three aspects: clinical symptoms, epidemiology and pathological hallmarks.</p>\n<p>In terms of clinical symptoms between PD and AD, multiple similar as well as differing pathological phenotypes can be identified, which is treated under the comparison and contrast between PD and AD (Table 1). PD and AD are both irreversible progressive, degenerative diseases meaning the symptoms will gradually become more severe as the stages develop. The most obvious problems about patients’ cognitive and psychiatric symptoms come first as we consider these neurodegenerative diseases. As far as we know, AD is well-known for its influence on memory, academically called amnesia which was first conceptualized as memory loss in 1763 by Sauvagues (Langer, 2019). Most of the advanced AD sufferers are reported to have Amnesia symptoms, accounting for fifty per cent to seventy per cent of all patients with dementia (Burns &amp; Iliffe 2009), while it seldomly happens to PD patients. Only the most severe PD sufferers are reported to experience similar amnesia symptoms (Querfurth &amp; LaFerla, 2010). At the memory level, patients with AD not only have amnesia but also often experience memory distortions (El Haj et al. 2020, Younan et al., 2020), such as having comprehensive and vivid memories of episodic occurrences that have never been observed. AD symptoms are generally considered as an essential impairment of episodic memory (Younan et al., 2020), while one’s attention is compromised on AD’s early stage as well, especially in those with early age onset and atypical syndromes (Malhotra, 2018). One feature of AD is that the symptoms are accompanied by severe attentional impairment frequently which is linked with other neurodegenerative disorders as well (Malhotra, 2018). It is suggested that PD patients suffer more depression and anxiety (Sveinbjornsdottir, 2016) than AD patients, which may be concluded to the inconsistency between one’s movements and willingness.</p>\n<p>Apart from memory problems for AD and PD, some other motor symptoms can also put huge inconvenience to one’s life. PD patients are reported to have three main symptoms which are tremor, bradykinesia and rigidity (Hayes, 2019). Tremor means shaking, especially after a short pause of a postural movement. Bradykinesia implies a slower movement than normal action which may cause difficulties for some ordinary tasks like walking or doing dishes. Rigidity or spasticity refers to muscle stiffness, which is academically called dystonia (Tolosa &amp; Compta, 2006). Unlike those symptoms in AD, these three main symptoms in PD are more relying on the neuromuscular connection so that these are all related to muscle control abnormality which is the direct result of neurodegeneration the same as AD (McGregor &amp; Nelson, 2019). Similarly, AD patients also suffer motor problems like dysphagia referring to the difficulty in swallowing, which is also reported in eleven to eighty-one per cent of PD patients (Takizawa et al., 2016). Patients with AD gradually lose cognitive functions until they reach the final stage of the disease, which is characterised by full failure of control over body functions (Boccardi et al., 2016).</p>\n<p>Regarding the nonmotor symptoms, anosmia (the sense loss of smell) and ageusia (the sense loss of taste), are common in PD. And the equivalent olfactory loss is also observed in AD (Doty 2012), which may be contributed to the shared pathological features. It may be corroborated that the olfactory loss is significantly linked to cognitive level (Tarakad &amp; Jankovic, 2017). This is different from PD: AD patients show more cognitive impairments. There occur some other cognitive problems in AD more than memory. For example, one type of language disorder, aphasia is usually related to AD owing to the damage of frontal, temporal, or parietal language cortices. And these aphasias caused by AD accounts for nearly thirty per cent of primary degenerative aphasias (Teichmann &amp; Ferrieux, 2013). The problems are not only about daily life activity but also about the biological clock. Sleep disturbances and sleep disorders come to be big problems for AD and PD patients since these are long term and progressive diseases. (Peter-Derex, 2015). Sleep disorders, on the other hand, is reported to be linked to an increased risk of AD. Both situations have a negative impact on one’s attention (Hennawy et al., 2019). Insomnia and exhaustion are also the following side effects of sleep disorders. Together with physical discomfort, those symptoms above can cause psychological discomfort in PD when comparing PD and AD. Neuralgia has become a severe problem for patients. There are five main forms of pain are documented in PD sufferers which are separately dystonia, musculoskeletal pain, nerve or nerve root pain, primary or central pain and akathisia with some samples (Rana 2013). </p>\n<p>To sum up, AD and PD symptoms are generally different, but these share some key features at the same time. PD patients are more likely to have primarily motor abnormalities, whereas AD patients normally experience dementia and cognitive impairment (Meireles &amp; Massano 2012). The neuronal death is a typical feature of both illnesses, the autopsy histopathology of the brains from AD and PD patients are distinct in each instance and diverse from one another (Ganguly et al., 2017). AD focuses more on cognitive symptoms while PD focus more on physical symptoms even though these can be divided into motor and nonmotor symptoms.</p>\n<p><strong>Table 1.</strong> Comparison and contrast table of Alzheimer’s disease and Parkinson’s disease in symptoms, causes, onset age, treatment, and lifespan expectancy.</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>AD</th>\n<th>PD</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clinical symptoms</td>\n<td>Amnesia (El Haj et  al., 2020)  Impairments of  attention (Malhotra, 2018)  Disorder of episodic  memory (Younan et al., 2020)  Memory distortions (El  Haj et al. 2020)  Dysphagia (Boccardi et  al., 2016)  Dysphasia (Teichmann  &amp; Ferrieux, 2013)  Sleep disruption and  sleep disorders (Hennawy et al., 2019)</td>\n<td>Tremor  Bradykinesia  Rigidity (NHS, 2019)  Loss of balance  Anosmia and ageusia  (Doty, 2012; Tarakad &amp; Jankovic, 2017)  Neuralgia (Rana et  al., 2013)  Urinary infection (Gerlach,  Winogrodzka &amp; Weber 2011)  Depression, anxiety  (Sveinbjornsdottir, 2016)</td>\n</tr>\n<tr>\n<td>Factors that may  influence</td>\n<td>Increasing age (Hou et  al., 2019)  Family history  Head Injury  Cardiovascular  diseases (Leszek et al., 2021)  Environmental toxins  (Vasefi et al., 2020)</td>\n<td>Increasing age (Hou et  al., 2019)  Family history  Head Injury  Male gender (Picillo  et al., 2017)</td>\n</tr>\n<tr>\n<td>Onset ages</td>\n<td>First symptoms usually  appear in the mid-60s. Early-onset AD begin between the 30s and mid-60s  (National Institute on Aging, 2017)</td>\n<td>The average age is 60  years old, whoever younger than 50 is considered young-onset PD (Johns  Hopkins medicine, 2021)</td>\n</tr>\n<tr>\n<td>Current treatment</td>\n<td>Medication  Physical therapy  Dietary control (Zhang  et al., 2020)  Deep brain stimulation  (Krauss et al., 2021)</td>\n<td>Medication  Physical therapy  Cognitive behavioural  therapy (Egan, Laidlaw &amp; Starkstein, 2015)</td>\n</tr>\n<tr>\n<td>Life expectancy</td>\n<td>After diagnosis, the  average expectancy for remaining life is 3 to 10 years (Zanetti, Solerte  &amp; Cantoni, 2009)</td>\n<td>The relevant  comparator is 23.3 years for average onset age of 60 years old (Golbe &amp;  Leyton, 2018). PD does not obviously reduce the lifespan</td>\n</tr>\n</tbody></table>\n<p>When it comes to epidemiology, four key elements come to stand revealed on the paper: how much, when, where and whom. From Statista (2021), Official death certificates are recorded to be 37 in 100,000 for AD and 10.3 in 100,000 in PD in 2019 in the United States. AD has turned into the seventh single biggest killer in the world (WHO, 2019) and the sixth leading cause of death in the United States (Alzheimer’s Association, 2020). Followed with AD, PD has become the second most common neurodegenerative disease (Lebouvier 2009).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354886.gif\" alt=\"image005\"></p>\n<p><strong>Figure 1.</strong> Death rate from Parkinson’s disease and Alzheimer’s disease in the United States from 2000 to 2019 (data is from Statista: John Elflein, 2021; Statista Research Department, 2021)</p>\n<p>The factor “whom” I mentioned above can be illustrated briefly by the following considering ages, sex and so on. There is some evidence to suggest that age is the main risk factor for AD and PD (Hou et al., 2019). According to the research of Cui et al. (2020), the rates of both AD and PD grew consistently with age growing, but this phenomenon is more likely applicable for AD (Figure 2). Even though Cui et al. failed to account for worldwide data, it presents a positive correlation of prevalence of AD and PD as well as the slight difference between each other. </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201042354377.jpg\" alt=\"image006\"></p>\n<p><strong>Figure 2.</strong> Prevalence of Alzheimer’s disease and Parkinson’s disease in China</p>\n<p>(Cui et al., 2020)</p>\n<p>It is a widely held view that females get more possibility at risk of developing AD, while males get a higher risk for vascular dementia (Podcasy &amp; Epperson, 2016). Ample evidence suggests that female PD patients tend to show a more benign symptom for which many scholars hold the view that it is due to the consequence of oestrogen (Picillo et al., 2017). It is essential to bear in mind that there is a possible bias in the sex effect on AD and PD.</p>\n<p>In the 1950s, researchers successively discovered that the presence of Lewy bodies in substantia nigra and locus nucleus patients in PD patients, gradually determining the pathological hallmarks of PD (Xiao-dan, 2017). One of the limitations with this explanation is that in some cases like a mutation of PARK-2, there are no Lewy bodies (Matsumine, 1999). The research team of Arvid and Isamu find that there are dopamine abnormalities in the brain tissue of PD patients then (LeWitt, 2015). According to Dickson (2012) and Kouli (2018), alpha-synuclein accumulates in Lewy bodies and neurites in the brain and peripheral nerves. And it can be pathological hallmarks of PD, in which case, the abnormal cytoplasmic deposits occur in cell bodies. Neuropathologically, senile plaques and neurofibrillary tangles can be hallmarks of AD (Sengoku, 2020). Under the action of endonuclease, the cleaved-off extracellular part of APP is the amyloid-β protein (O’Brien &amp; Wong, 2011). The amyloid-β deposition is another hallmark for AD. Analogously, AD and PD both have tau pathology. Braak (1991) holds the view that the magnitude and location of tau deposition might be related to clinical symptoms of AD. The tau pathology is also reported to have an impact on neurons and glia in PD (Dickson 2012). Several observations suggest that there is a link between the dysfunction, even partly, of the mitochondria or the oxidative stress and the neuropathology of AD and PD (Swerdlow, 2018; Jamwal, Blackburn &amp; Elsworth, 2021). Succinctly, AD and PD share both similarities and differences (Table 2).</p>\n<p><strong>Table 2.</strong> Pathological hallmarks of AD and PD</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>AD</th>\n<th>PD</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pathological hallmarks</td>\n<td>Extracellular  β-amyloid deposits, i.e., senile plaques  Extracellular  β-amyloid deposits, i.e., senile plaques (MSD manuals, 2020)  Nerve cell death in  hippocampus and prefrontal cortex (Akhtar &amp; Sah, 2020)</td>\n<td>Lewy bodies in the  substantia nigra striatum (MSD manuals, 2020)   Synuclein deposition  Degeneration of  neurons in substantia nigra, locus coeruleus and other brainstem dopaminergic  cells (Hansen, 2021)</td>\n</tr>\n</tbody></table>\n<p>All in all, there is a big difference between the pathological characteristics, the affected brain parts and the clinical symptoms of AD and PD. As global life expectancy has increased, proteinopathies of the brain, which particularly affect the elderly, have placed an increasing burden on society. AD and PD invade the patients’ intellectual and emotional health, thereby potentially destroying their lives and family life. AD and PD invade the victim’s intellectual and emotional health, thereby potentially destroying their lives and family. Since there is a long prodromal period, if we can diagnosis those in advance, earlier and timely treatment might be able to be applied (Ubeda-Bañon et al., 2020), thus, sufferings might be relieved. Both PD and AD get involved in broad regions of the nervous system, neurotransmitters and protein aggregation (Kalia &amp; Lang 2015). The difference is that PD mainly happens in substantia nigra, locus coeruleus and other brainstem dopaminergic cells (Hansen, 2021) while AD typically starts in the temporal lobe, in more detail, hippocampus and prefrontal cortex (Akhtar &amp; Sah, 2020). No matter how similar or different those diseases are, one issue is certain, it is our biologists’ duty to pull those suffers with PD or AD out of the hell.</p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a><strong>Reference</strong></h1><p>Bayer, T. A. (2015). Proteinopathies, a core concept for understanding and ultimately treating degenerative disorders? Eur Neuropsychopharmacol, 25(5), 713-724. doi: 10.1016/j.euroneuro.2013.03.007</p>\n<p>Lanuti, P. et al. (2020). Neurodegenerative diseases as proteinopathies-driven immune disorders. Neural regeneration research, 15 (5), s. 850. doi:10.4103/1673-5374.268971</p>\n<p>Virchow, R. (1854). Handbuch der Speciellen Pathologie und Therapie</p>\n<p>Luheshi, L. M., Crowther, D. C., &amp; Dobson, C. M. (2008). Protein misfolding and disease: from the test tube to the organism. Current Opinion in Chemical Biology, 12(1), 25-31. doi: <a href=\"https://doi.org/10.1016/j.cbpa.2008.02.011\">https://doi.org/10.1016/j.cbpa.2008.02.011</a></p>\n<p>Capriotti, T., &amp; Terzakis, K. (2016). Parkinson Disease. Home healthcare now, 34(6), 300–307. <a href=\"https://doi.org/10.1097/NHH.0000000000000398\">https://doi.org/10.1097/NHH.0000000000000398</a></p>\n<p>Simon, D. K., Tanner, C. M., &amp; Brundin, P. (2020). Parkinson Disease Epidemiology, Pathology, Genetics, and Pathophysiology. Clinics in geriatric medicine, 36(1), 1–12. <a href=\"https://doi.org/10.1016/j.cger.2019.08.002\">https://doi.org/10.1016/j.cger.2019.08.002</a></p>\n<p>Hayes, M. T. (2019). Parkinson’s Disease and Parkinsonism. The American Journal of Medicine, 132(7), 802-807. doi: <a href=\"https://doi.org/10.1016/j.amjmed.2019.03.001\">https://doi.org/10.1016/j.amjmed.2019.03.001</a></p>\n<p>Lane, C. A., Hardy, J., &amp; Schott, J. M. (2018). Alzheimer’s disease. European Journal of Neurology, 25(1), 59-70. doi:10.1111/ene.13439</p>\n<p>Van Bulck, M., Sierra-Magro, A., Alarcon-Gil, J., Perez-Castillo, A., &amp; Morales-Garcia, J. A. (2019). Novel Approaches for the Treatment of Alzheimer’s and Parkinson’s Disease. International journal of molecular sciences, 20(3), 719. <a href=\"https://doi.org/10.3390/ijms20030719\">https://doi.org/10.3390/ijms20030719</a></p>\n<p>NHS.uk. (2019). Parkinson’s disease - Symptoms.</p>\n<p>NHS.uk. (2019). Alzheimer’s disease - Symptoms.</p>\n<p>Tarakad, A., &amp; Jankovic, J. (2017). Anosmia and Ageusia in Parkinson’s Disease. International review of neurobiology, 133, 541–556. <a href=\"https://doi.org/10.1016/bs.irn.2017.05.028\">https://doi.org/10.1016/bs.irn.2017.05.028</a></p>\n<p>Rana, A. Q., Kabir, A., Jesudasan, M., Siddiqui, I., &amp; Khondker, S. (2013). Pain in Parkinson’s disease: Analysis and literature review. Clinical Neurology and Neurosurgery, 115(11), 2313-2317. doi: <a href=\"https://doi.org/10.1016/j.clineuro.2013.08.022\">https://doi.org/10.1016/j.clineuro.2013.08.022</a></p>\n<p>Younan, D., Petkus, A. J., Widaman, K. F., Wang, X., Casanova, R., Espeland, M. A., Gatz, M., Henderson, V. W., Manson, J. E., Rapp, S. R., Sachs, B. C., Serre, M. L., Gaussoin, S. A., Barnard, R., Saldana, S., Vizuete, W., Beavers, D. P., Salinas, J. A., Chui, H. C., Resnick, S. M., … Chen, J. C. (2020). Particulate matter and episodic memory decline mediated by early neuroanatomic biomarkers of Alzheimer’s disease. Brain: a journal of neurology, 143(1), 289–302. <a href=\"https://doi.org/10.1093/brain/awz348\">https://doi.org/10.1093/brain/awz348</a></p>\n<p>El Haj, M., Colombel, F., Kapogiannis, D., &amp; Gallouj, K. (2020). False Memory in Alzheimer’s Disease. Behavioural neurology, 2020, 5284504. <a href=\"https://doi.org/10.1155/2020/5284504\">https://doi.org/10.1155/2020/5284504</a></p>\n<p>Boccardi, V., Ruggiero, C., Patriti, A., &amp; Marano, L. (2016). Diagnostic Assessment and Management of Dysphagia in Patients with Alzheimer’s Disease. Journal of Alzheimer’s disease: JAD, 50(4), 947–955. <a href=\"https://doi.org/10.3233/JAD-150931\">https://doi.org/10.3233/JAD-150931</a></p>\n<p>Teichmann, M., &amp; Ferrieux, S. (2013). Aphasia(s) in Alzheimer. Revue neurologique, 169(10), 680–686. <a href=\"https://doi.org/10.1016/j.neurol.2013.06.001\">https://doi.org/10.1016/j.neurol.2013.06.001</a></p>\n<p>Hennawy, M., Sabovich, S., Liu, C. S., Herrmann, N., &amp; Lanctôt, K. L. (2019). Sleep and Attention in Alzheimer’s Disease. The Yale journal of biology and medicine, 92(1), 53–61. </p>\n<p>Leszek, J., Mikhaylenko, E. V., Belousov, D. M., Koutsouraki, E., Szczechowiak, K., Kobusiak-Prokopowicz, M., Mysiak, A., Diniz, B. S., Somasundaram, S. G., Kirkland, C. E., &amp; Aliev, G. (2021). The Links between Cardiovascular Diseases and Alzheimer’s Disease. Current neuropharmacology, 19(2), 152–169. <a href=\"https://doi.org/10.2174/1570159X18666200729093724\">https://doi.org/10.2174/1570159X18666200729093724</a> </p>\n<p>Vasefi, M., Ghaboolian-Zare, E., Abedelwahab, H., &amp; Osu, A. (2020). Environmental toxins and Alzheimer’s disease progression. Neurochemistry international, 141, 104852. <a href=\"https://doi.org/10.1016/j.neuint.2020.104852\">https://doi.org/10.1016/j.neuint.2020.104852</a> </p>\n<p>Picillo, M., Nicoletti, A., Fetoni, V., Garavaglia, B., Barone, P., &amp; Pellecchia, M. T. (2017). The relevance of gender in Parkinson’s disease: a review. Journal of neurology, 264(8), 1583–1607. <a href=\"https://doi.org/10.1007/s00415-016-8384-9\">https://doi.org/10.1007/s00415-016-8384-9</a></p>\n<p>Egan, S. J., Laidlaw, K., &amp; Starkstein, S. (2015). Cognitive Behaviour Therapy for Depression and Anxiety in Parkinson’s Disease. Journal of Parkinson’s disease, 5(3), 443–451. <a href=\"https://doi.org/10.3233/JPD-150542\">https://doi.org/10.3233/JPD-150542</a></p>\n<p>Zhang, M., Zhao, D., Zhou, G., &amp; Li, C. (2020). Dietary Pattern, Gut Microbiota, and Alzheimer’s Disease. Journal of agricultural and food chemistry, 68(46), 12800–12809. <a href=\"https://doi.org/10.1021/acs.jafc.9b08309\">https://doi.org/10.1021/acs.jafc.9b08309</a> </p>\n<p>Krauss, J. K., Lipsman, N., Aziz, T., Boutet, A., Brown, P., Chang, J. W., Davidson, B., Grill, W. M., Hariz, M. I., Horn, A., Schulder, M., Mammis, A., Tass, P. A., Volkmann, J., &amp; Lozano, A. M. (2021). Technology of deep brain stimulation: current status and future directions. Nature reviews. Neurology, 17(2), 75–87. <a href=\"https://doi.org/10.1038/s41582-020-00426-z\">https://doi.org/10.1038/s41582-020-00426-z</a> </p>\n<p>Zanetti, O., Solerte, S. B., &amp; Cantoni, F. (2009). Life expectancy in Alzheimer’s disease (AD). Archives of gerontology and geriatrics, 49 Suppl 1, 237–243. <a href=\"https://doi.org/10.1016/j.archger.2009.09.035\">https://doi.org/10.1016/j.archger.2009.09.035</a></p>\n<p>Golbe, L. I., &amp; Leyton, C. E. (2018). Life expectancy in Parkinson disease. Neurology, 91(22), 991–992. <a href=\"https://doi.org/10.1212/WNL.0000000000006560\">https://doi.org/10.1212/WNL.0000000000006560</a></p>\n<p>Hopkinsmedicine.org. 2021. Young-Onset Parkinson’s Disease. </p>\n<p>National Institute on Aging. 2017. What Are the Signs of Alzheimer’s Disease?</p>\n<p>Langer K. G. (2019). Early History of Amnesia. Frontiers of neurology and neuroscience, 44, 64–74. <a href=\"https://doi.org/10.1159/000494953\">https://doi.org/10.1159/000494953</a></p>\n<p>Sveinbjornsdottir S. (2016). The clinical symptoms of Parkinson’s disease. Journal of neurochemistry, 139 Suppl 1, 318–324. <a href=\"https://doi.org/10.1111/jnc.13691\">https://doi.org/10.1111/jnc.13691</a></p>\n<p>Querfurth, H. W., &amp; LaFerla, F. M. (2010). Alzheimer’s disease. The New England journal of medicine, 362(4), 329–344. <a href=\"https://doi.org/10.1056/NEJMra0909142\">https://doi.org/10.1056/NEJMra0909142</a></p>\n<p>Burns, A., &amp; Iliffe, S. (2009). Dementia. BMJ (Clinical research ed.), 338, b75. <a href=\"https://doi.org/10.1136/bmj.b75\">https://doi.org/10.1136/bmj.b75</a></p>\n<p>Fang, E. F., Hou, Y., Palikaras, K., Adriaanse, B. A., Kerr, J. S., Yang, B., Lautrup, S., Hasan-Olive, M. M., Caponio, D., Dan, X., Rocktäschel, P., Croteau, D. L., Akbari, M., Greig, N. H., Fladby, T., Nilsen, H., Cader, M. Z., Mattson, M. P., Tavernarakis, N., &amp; Bohr, V. A. (2019). Mitophagy inhibits amyloid-β and tau pathology and reverses cognitive deficits in models of Alzheimer’s disease. Nature neuroscience, 22(3), 401–412. <a href=\"https://doi.org/10.1038/s41593-018-0332-9\">https://doi.org/10.1038/s41593-018-0332-9</a></p>\n<p>Tolosa, E., &amp; Compta, Y. (2006). Dystonia in Parkinson’s disease. Journal of neurology, 253 Suppl 7, VII7–VII13. <a href=\"https://doi.org/10.1007/s00415-006-7003-6\">https://doi.org/10.1007/s00415-006-7003-6</a></p>\n<p>Ganguly, G., Chakrabarti, S., Chatterjee, U., &amp; Saso, L. (2017). Proteinopathy, oxidative stress and mitochondrial dysfunction: cross talk in Alzheimer’s disease and Parkinson’s disease. Drug design, development and therapy, 11, 797–810. <a href=\"https://doi.org/10.2147/DDDT.S130514\">https://doi.org/10.2147/DDDT.S130514</a></p>\n<p>Hou, Y., Dan, X., Babbar, M., Wei, Y., Hasselbalch, S. G., Croteau, D. L., &amp; Bohr, V. A. (2019). Ageing as a risk factor for neurodegenerative disease. Nature reviews. Neurology, 15(10), 565–581. <a href=\"https://doi.org/10.1038/s41582-019-0244-7\">https://doi.org/10.1038/s41582-019-0244-7</a></p>\n<p>McGregor, M. M., &amp; Nelson, A. B. (2019). Circuit Mechanisms of Parkinson’s Disease. Neuron, 101(6), 1042–1056. <a href=\"https://doi.org/10.1016/j.neuron.2019.03.004\">https://doi.org/10.1016/j.neuron.2019.03.004</a></p>\n<p>Doty R. L. (2012). Olfactory dysfunction in Parkinson disease. Nature reviews. Neurology, 8(6), 329–339. <a href=\"https://doi.org/10.1038/nrneurol.2012.80\">https://doi.org/10.1038/nrneurol.2012.80</a></p>\n<p>Peter-Derex, L., Yammine, P., Bastuji, H., &amp; Croisile, B. (2015). Sleep and Alzheimer’s disease. Sleep medicine reviews, 19, 29–38. <a href=\"https://doi.org/10.1016/j.smrv.2014.03.007\">https://doi.org/10.1016/j.smrv.2014.03.007</a></p>\n<p>Meireles, J., &amp; Massano, J. (2012). Cognitive impairment and dementia in Parkinson’s disease: clinical features, diagnosis, and management. Frontiers in neurology, 3, 88. <a href=\"https://doi.org/10.3389/fneur.2012.00088\">https://doi.org/10.3389/fneur.2012.00088</a></p>\n<p>Cui L, Hou NN, Wu HM, Zuo X, Lian YZ, Zhang CN, Wang ZF, Zhang X, Zhu JH. Prevalence of Alzheimer’s Disease and Parkinson’s Disease in China: An Updated Systematical Analysis. Front Aging Neurosci. 2020 Dec 21; 12:603854. doi: 10.3389/fnagi.2020.603854. PMID: 33424580; PMCID: PMC7793643.</p>\n<p>Takizawa, C., Gemmell, E., Kenworthy, J. et al. A Systematic Review of the Prevalence of Oropharyngeal Dysphagia in Stroke, Parkinson’s Disease, Alzheimer’s Disease, Head Injury, and Pneumonia. Dysphagia 31, 434–441 (2016). <a href=\"https://doi.org/10.1007/s00455-016-9695-9\">https://doi.org/10.1007/s00455-016-9695-9</a></p>\n<p>Number of deaths due to Parkinson’s disease | Statista. (2021). Retrieved 12 December 2021, from <a href=\"https://www.statista.com/statistics/753594/number-of-deaths-from-parkinson-in-spain/\">https://www.statista.com/statistics/753594/number-of-deaths-from-parkinson-in-spain/</a></p>\n<p>Alzheimer disease mortality rate U.S. 2000-2019 | Statista. (2021). Retrieved 12 December 2021, from <a href=\"https://www.statista.com/statistics/452945/mortality-rate-of-alzheimers-patients-in-the-us/\">https://www.statista.com/statistics/452945/mortality-rate-of-alzheimers-patients-in-the-us/</a></p>\n<p>Lebouvier T, Chaumette T, Paillusson S, Duyckaerts C, Bruley des Varannes S, Neunlist M, Derkinderen P. The second brain and Parkinson’s disease. Eur J Neurosci. 2009 Sep;30(5):735-41. doi: 10.1111/j.1460-9568.2009.06873. x. Epub 2009 Aug 27. PMID: 19712093.</p>\n<p>World Health Organization. The top 10 causes of death. (2019). </p>\n<p>Alzheimer’s Association. (2020). 2020 Alzheimer’s disease facts and figures. Alzheimer’s &amp; dementia: the journal of the Alzheimer’s Association, 10.1002/alz.12068. Advance online publication. <a href=\"https://doi.org/10.1002/alz.12068\">https://doi.org/10.1002/alz.12068</a></p>\n<p>Podcasy, J. L., &amp; Epperson, C. N. (2016). Considering sex and gender in Alzheimer disease and other dementias. Dialogues in clinical neuroscience, 18(4), 437–446. <a href=\"https://doi.org/10.31887/DCNS.2016.18.4/cepperson\">https://doi.org/10.31887/DCNS.2016.18.4/cepperson</a></p>\n<p>Sengoku R. (2020). Aging and Alzheimer’s disease pathology. Neuropathology: official journal of the Japanese Society of Neuropathology, 40(1), 22–29. <a href=\"https://doi.org/10.1111/neup.12626\">https://doi.org/10.1111/neup.12626</a></p>\n<p>Braak, H., &amp; Braak, E. (1991). Neuropathological stageing of Alzheimer-related changes. Acta neuropathologica, 82(4), 239–259. <a href=\"https://doi.org/10.1007/BF00308809\">https://doi.org/10.1007/BF00308809</a></p>\n<p>Swerdlow R. H. (2018). Mitochondria and Mitochondrial Cascades in Alzheimer’s Disease. Journal of Alzheimer’s disease: JAD, 62(3), 1403–1416. <a href=\"https://doi.org/10.3233/JAD-170585\">https://doi.org/10.3233/JAD-170585</a></p>\n<p>Jamwal, S., Blackburn, J. K., &amp; Elsworth, J. D. (2021). Expression of PON2 isoforms varies among brain regions in male and female African green monkeys. Free radical biology &amp; medicine, S0891-5849(21)00856-X. Advance online publication. <a href=\"https://doi.org/10.1016/j.freeradbiomed.2021.12.005\">https://doi.org/10.1016/j.freeradbiomed.2021.12.005</a></p>\n<p>Kouli, A., Torsney, K. M., &amp; Kuan, W. L. (2018). Parkinson’s Disease: Etiology, Neuropathology, and Pathogenesis. In T. B. Stoker (Eds.) et. al., Parkinson’s Disease: Pathogenesis and Clinical Aspects. Codon Publications. </p>\n<p>Xiao⁃dan, W., Yong, J. (2017) 200⁃year history of Parkinson’s disease. Chin J Contemp Neurol Neurosurg</p>\n<p>LeWitt P. A. (2015). Levodopa therapy for Parkinson’s disease: Pharmacokinetics and pharmacodynamics. Movement disorders: official journal of the Movement Disorder Society, 30(1), 64–72. <a href=\"https://doi.org/10.1002/mds.26082\">https://doi.org/10.1002/mds.26082</a></p>\n<p>Matsumine H. (1999). Rinsho shinkeigaku = Clinical neurology, 39(1), 9–12.</p>\n<p>MSD manual: professional version. (2020). JAC-Antimicrobial Resistance, 2(3). doi:10.1093/jacamr/dlaa042</p>\n<p>Akhtar, A., &amp; Sah, S. P. (2020). Insulin signaling pathway and related molecules: Role in neurodegeneration and Alzheimer’s disease. Neurochemistry international, 135, 104707. <a href=\"https://doi.org/10.1016/j.neuint.2020.104707\">https://doi.org/10.1016/j.neuint.2020.104707</a></p>\n<p>O’Brien, R. J., &amp; Wong, P. C. (2011). Amyloid precursor protein processing and Alzheimer’s disease. Annual review of neuroscience, 34, 185–204. <a href=\"https://doi.org/10.1146/annurev-neuro-061010-113613\">https://doi.org/10.1146/annurev-neuro-061010-113613</a></p>\n<p>Ubeda-Bañon, I., Saiz-Sanchez, D., Flores-Cuadrado, A., Rioja-Corroto, E., Gonzalez-Rodriguez, M., Villar-Conde, S., Astillero-Lopez, V., Cabello-de la Rosa, J. P., Gallardo-Alcañiz, M. J., Vaamonde-Gamo, J., Relea-Calatayud, F., Gonzalez-Lopez, L., Mohedano-Moriano, A., Rabano, A., &amp; Martinez-Marcos, A. (2020). The human olfactory system in two proteinopathies: Alzheimer’s and Parkinson’s diseases. Translational neurodegeneration, 9(1), 22. <a href=\"https://doi.org/10.1186/s40035-020-00200-7\">https://doi.org/10.1186/s40035-020-00200-7</a></p>\n<p>Hansen N. (2021). Locus Coeruleus Malfunction Is Linked to Psychopathology in Prodromal Dementia With Lewy Bodies. Frontiers in aging neuroscience, 13, 641101. <a href=\"https://doi.org/10.3389/fnagi.2021.641101\">https://doi.org/10.3389/fnagi.2021.641101</a></p>\n"},{"title":"NMDA receptor-dependent LTP roles","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-01-18T17:59:11.000Z","password":null,"summary":null,"_content":"\n# Discuss whether or not NMDA  receptor-dependent LTP in different hippocampal subregions can have distinct  roles in learning and memory\n\nThe hippocampus is generally considered to be the foundation of memory and learning. As early as 1949, Hebb proposed that learning and memory are stored as changes in the strength of synaptic connections between neurons. Along with the discovery of the LTP phenomenon by Bliss & Lomo (1973) and subsequent research, the hypothesis that the LTP provides a neural basis for learning and memory formation has been widely accepted by the public. The NMDAR-dependent LTP processes in the hippocampus, especially in the CA1 subregion of the hippocampus, are thought to be the neural basis for spatial learning and memory (Martin et al., 2000, Bliss & Collingridge, 1993). The hippocampus consists of four Cornu Ammonis regions (CA1 to CA4) and dentate gyrus (DG), of which CA4 can also be considered part of the DG due to the partial overlap of structure and function (Andersen et al., 2007, Anand & Dhikav, 2012). With the desire of studying hippocampal subregions, one question is proposed: how can we specifically study the subregions? The arrangement of hippocampal neurons allows the hippocampus to be sliced, leaving most of the relevant circuitry intact (Purves, Augustine & Fitzpatrick, 2001). The undamaged circuit of the individual subregions ensures the feasibility and authenticity of our study about each subregion. Thus, in-depth study of each subregion has become a hot topic in the past decades. This essay aims to discuss NMDAR-dependent LTP in different hippocampal subregions can have distinct and similar roles in learning and memory.\n\nLTP can be observed at three main excitatory synapses in the hippocampal circuit, the excitatory synaptic pathway of the hippocampus. In this circuit, the perforant pathway extends from pyramidal cells in the entorhinal area to granule cells in the DG; the mossy fibre pathway extends from granule cells in the DG to CA3 pyramidal cells; Schaffer collateral pathways from CA3 pyramidal cells to CA1 pyramidal cells (Fig 1). Bliss & Collingridge (1993), Nicoll & Malenka (1995) believe that two subregions, CA1 and DG, show NMDAR-dependent LTP. However, their findings do not imply the absence of NMDA receptor-dependent LTP in other hippocampal subregions due to the limitations in-vitro experiments. In 2002, Lee & Kesner collected some data indicating the involvement of NMDAR in CA3, which may be explained as an attractor state (a temporarily self-sustaining state), with a computational model based on physiological evidence and behavioural experiments. In this research, Lee suggested behavioural evidence for differences in NMDAR spatial working memory function among hippocampal subregions. Lee\\'s research eliminates the influence of another type of LTP with the local subregion-specific injection of NMDAR antagonists. As the participation of CA3, the role of the hippocampal NMDAR-dependent LTP might be misunderstood. However, previous research still cannot explain the role in the hippocampal subregions well. The association hypothesis between NMDAR-dependent LTP and learning and memory in hippocampal subregions require more experiments to validate. When we focus on each subregion, their distinct and similar roles in learning and memory may be revealed.\n\n![image-20220216191746673](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202161917751.png)\n\n**Figure 1**. LTP in Schaffer collateral pathway, mossy fibre pathway and perforant pathway (Chen et al. 1997)\n\nThe CA1 subregion is the neural foundation linking spatial learning and memory. Tsien et. al (1996a, 1996b) knockout the GluN1 subunit (in NMDAR) resulting in the deficit of LTP in Schaffer collateral CA1 synapses finding the spatial reference memory is impaired in mice. This research directly proves that NMDAR-dependent LTP at CA1 synapses is the neural foundation for associative, long-term spatial memory formation. Additionally, CA1-KO mice lack NMDAR-mediated postsynaptic currents and LTP in CA1. These mice showed impaired spatial memory in the Morris hidden platform water maze, in the opposite, performed well on non-spatial learning tasks. The results provide contrastive support for the hypothesis that NMDAR-mediated LTP in the CA1 region is critical for the formation of some specific types of memory. Similarly, spatial learning deficits were reported in mice with the impaired LTP in CA1 owing to the lack of the gene encoding α subunit of calmodulin-dependent protein kinase II (αCaMKII) (Silva et al., 1992a, 1992b). These mice lack spatial memory, the same as spatial memory deficits in CA1-KO mice. A possible shortcoming in this experiment is that previous experiments are based on direct injection of NMDAR antagonists into the brain, which may not be sufficiently convincing in terms of regional idiosyncrasy. According to Hestrin\\'s discovery in 1996: NMDAR contributes to synaptic transmission in some regions of the neocortex. We can conclude that memory impairment can be explained, at least in part, by deficits in the computing ability of the neocortex, rather than impairments in synaptic plasticity within the hippocampus. Subsequently, Bannerman et al. (2012) used transgenic mice lacking the GluN1 subunit and NMDARs in the pyramidal cells of CA1 and the granule cells of DG finding that the spatial reference memory of the mice acquired the radial maze task was impaired. It furtherly demonstrates the fact: hippocampal CA1 plays an important role in the learning of spatial reference memory. In 2013, it took a turn when Taylor et al. found that such mice performed well on the classic open-field spatial reference memory water maze task. How can it happen? It possibly indicates that the hippocampal NMDAR is not actually required for the formation of long-term associative spatial memory, which is against Tsien\\'s results. But Taylor does not explain this in detail, thus it cannot determine whether there are any other compensatory mechanisms for NMDA-dependent LTP. Whatever, as Niewoehner et al. (2007) argues, the development of spatially restricted genetic modifications has identified synaptic plasticity, which is a broader idea than LTP, with specific and separable roles in different hippocampal subregions. We may want to see more genetic modification experiments in this field. Despite the shortcomings of these research, the inter-experimental corroboration still demonstrates that CA1 has an irreplaceable role in associative, long-term spatial memory. We can consider CA1 LTP to be the basis of spatial memory formation.\n\nIn the CA2 subregion, NMDA-dependent LTP cannot be induced. Zhao et al. (2007) attempted to test whether synaptic stimulation could induce LTP in CA2 neurons, which is proved to induce NMDAR-dependent LTP in CA1, using a variety of approaches including perforated whole-cell patch-clamp recording. However, all results lead to that the synaptic current is not increased. One of the explanations from Caruana, Alexander, & Dudek (2012) is that the high expression of TREK-1 and TREK-2 potassium channels in CA2, compared with other hippocampal subregions, leads to the lack of LTP. These channels produce potassium-mediated leakage currents significantly hyperpolarizing the resting membrane potential. Thus, larger depolarizing currents are required to initiate LTP. Therefore, is it necessary to look for the memory learning function of LTP in CA2? Zhao compared the expression patterns of NMDAR mRNAs in CA2 and CA3 finding that those mRNAs are expressed in both subregions. What distinguish the CA2 and the CA3? Certain \\\"memory suppressor\\\" genes (e.g., RGS14) play a key role in suppressing LTP induction (Lee et al., 2010a, 2010b, Dudek et al., 2016). More evidence suggests that the induction of NMDAR-dependent LTP and memory formation in CA2 can occur under very specific conditions (Wersinger et al., 2002, Prediger & Takahashi, 2005, DeVito et al., 2009, Caruana et al., 2012). We conclude that NMDAR-dependent LTP in the CA2 area is rare, but not impossible. Therefore, its role in CA2 needs further study.\n\nThe NMDAR-dependent LTP in CA3 is involved in learning and memory storage acquisition although NMDAR-dependent LTP in CA3 is uncommon. The fact that LTP in the Moss fiber-CA3 system coincides with the progress in learning demonstrates the role of CA3 in learning and memory. Based on electrophysiological data by Martinez et al. (2002), an associative LTP was found in the perforant pathway inputting into CA3, which means that there is NMDAR-dependent LTP between perforant pathway and the CA3 synapse. The following step is to study its function. Nakazawa et al. (2003) found that \\\"one-time learning\\\" is blocked by specific knockout of CA3 NMDAR in mice. We thus argue that NMDA-dependent LTP in CA3 plays an important role in the information acquiring and storing from new experiences. Lee & Kesner\\'s (2004) study also demonstrated that CA3 neurons are activated during recall of objects or locations. It refers that NMDA-dependent LTP in CA3 may affect object-location pairing association tasks. In hippocampal CA3, two distinct forms of LTP have been described, one of which is the classical NMDA-dependent LTP (Zalutsky and Nicoll, 1990). The disadvantage of these experiments is that we do not know whether to confirm the function of another LTP and whether it is also involved in memory and learning functions. Although these experiments do not cover all types of LTPs, at least we know that NMDAR-dependent LTP in CA3 is involved in memory acquisition.\n\nThe NMDAR-dependent LTP in DG focuses more on spatial working memory (SWM) (Active spatial information in working memory over a short period (van Asselen et al., 2006)) than spatial reference memory (SRM). Nosten-Bertrand et al. (1996) first proposed that spatial learning is not obviously blocked in the absence of a DG LTP gene anaesthetized rats, which we mentioned present in CA1. Although a subsequent study by Errington et al. (1997) speculated that this phenomenon may be due to the effect of gene knockout on inhibitory neurons. Additional evidence for this hypothesis is that massive loss of the NR1 subunit of the NMDAR only showed severely impaired LTP in the perforant pathway inputs of the DG, whereas LTP is unchanged from CA3 to CA1. Based on this study, behavioural assessments of these mice show significant SWM impairment but no effect on hippocampal-dependent SRM performance for the same task. However, other studies have demonstrated that DG selectivity, fibre-sparing, and colchicine lesions can lead to impairment of both SWM and SRM (Xavier, Oliveira-Filho & Santos, 1999). This is complemented with behavioural experiments by Jeltsch et al. (2001), where DG impairment significantly increases SRM and SWM errors in the four-from-eight radial maze task. The downside, however, is that these results fail to provide positive evidence for the hypothesis that NMDAR-mediated synaptic plasticity in the DG supports spatial pattern separation. The present results cannot completely rule out a role for the NMDAR LTP in the DG in spatial pattern separation across tasks, although it is clearly shown that any putative role must be limited to the working memory. We can argue that DG may be involved in both spatial working memory and SRM but is more focused on spatial working memory.\n\nThe biggest difference among the function of NMDAR-dependent LTP hippocampal subregions is the roles these played in spatial learning. According to earlier studies, in contrast to CA1, damages to mossy fibre to CA3 LTP (Huang et al., 1995) and perforant pathway to DG LTP (Nosten-Bertrand et al., 1996) are not associated with deficits in spatial memory. Huang et al. (1999) found that mossy fibre CA3 LTP and perforant DG LTP are dispensable for spatial learning. This is consistent with the notion that CA1 LTP is critical for spatial learning. CA1 LTPs are particularly important for spatial and contextual learning in the hippocampus compared to CA3 or DG LTPs. What is more, subsequent further studies confirmed that other subregions are also involved in learning and memory. Okada et al. (2003) examined the effect of NMDA-dependent LTP on spatial learning in rats after increasing the extent of NMDA-dependent LTP by using viral vectors for gene editing. It is demonstrated that although CA1 and the DG have similar mechanisms of LTP induction, they play distinct functional roles in spatial learning. To explore the differences in information storage capacity, Bromer et al. (2018) used a method combining signal detection theory with accurate 3D reconstruction of serial section electron microscopy to study in vivo perforant pathway LTP processes in the DG of the mature hippocampus. Bromer et al. investigate synaptic plasticity and information storage capacity. It is found that the information storage capacity of the DG is much lower than CA1. This study elucidates the temporal LTP process of storing information and the inter-regional variation of information storage capacity, that is, differences in spatial learning between CA1 and DG.\n\nThis essay focuses on the roles of NMDAR-dependent LTP in learning and memory in various hippocampal subregions. From these studies, we can conclude that the NMDA-dependent LTP in CA1 and the DG gets involved in acquiring memory that needs to be retrieved after a delay period beyond the short-term. CA1 is the basis of spatial memory formation, associating spatial learning and memory. DG also plays an important role in spatial working memory, mainly in spatial working memory. The NMDAR-dependent LTP in CA3 is significant in situations where reorganization of spatial representations memory is required. It is involved in memory acquisition as well, with a focus on spatial reference memory. The recognition of each subregion can help us understand the integral mechanism. We should consider each subregion separately but focus on the overall functional interaction. It may become an innovative point for future research. Although many computational models and anatomical studies have highlighted functional differences between NMDAR-dependent LTP in the hippocampus, the subregional heterogeneity of NMDAR function is still largely unknown. Therefore, as the technology develops, the following research on the mechanisms of NMDA-dependent LTP in each subregion and interaction are supposed to be further explored.\n\n## **Reference**\n\n1.  Hebb, D. O. (1949). The organization of behavior. New York, NY: John Wiley.\n\n2.  Bliss, T. V., & Lomo, T. (1973). Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. The Journal of physiology, 232(2), 331--356. https://doi.org/10.1113/jphysiol.1973.sp010273\n\n3.  Bliss, T. V., & Collingridge, G. L. (1993). A synaptic model of memory: long-term potentiation in the hippocampus. Nature, 361(6407), 31--39. https://doi.org/10.1038/361031a0\n\n4.  Martin, S. J., Grimwood, P. D., & Morris, R. G. (2000). Synaptic plasticity and memory: an evaluation of the hypothesis. Annual review of neuroscience, 23, 649--711. https://doi.org/10.1146/annurev.neuro.23.1.649\n\n5.  Andersen, P., Morris, R., Amaral, D., Bliss, T., & O\\'Keefe, J. (2007). The Hippocampus Book. Oxford University press.\n\n6.  Anand, K. S., & Dhikav, V. (2012). Hippocampus in health and disease: An overview. Annals of Indian Academy of Neurology, 15(4), 239--246. https://doi.org/10.4103/0972-2327.104323\n\n7.  Purves, D., Augustine, G. J., Fitzpatrick, D. (2001). Neuroscience. 2nd edition.\n\n8.  Lee, I., & Kesner, R. P. (2002). Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nature neuroscience, 5(2), 162--168. https://doi.org/10.1038/nn790\n\n9.  Tsien, J. Z., Chen, D. F., Gerber, D., Tom, C., Mercer, E. H., Anderson, D. J., Mayford, M., Kandel, E. R., & Tonegawa, S. (1996). Subregion- and cell type-restricted gene knockout in mouse brain. Cell, 87(7), 1317--1326. https://doi.org/10.1016/s0092-8674(00)81826-7\n\n10. Tsien, J. Z., Huerta, P. T., & Tonegawa, S. (1996). The essential role of hippocampal CA1 NMDA receptor-dependent synaptic plasticity in spatial memory. Cell, 87(7), 1327--1338. https://doi.org/10.1016/s0092-8674(00)81827-9\n\n11. Bannerman, D. M., Bus, T., Taylor, A., Sanderson, D. J., Schwarz, I., Jensen, V., Hvalby, Ø., Rawlins, J. N., Seeburg, P. H., & Sprengel, R. (2012). Dissecting spatial knowledge from spatial choice by hippocampal NMDA receptor deletion. Nature neuroscience, 15(8), 1153--1159. https://doi.org/10.1038/nn.3166\n\n12. Taylor, A. M., Bus, T., Sprengel, R., Seeburg, P. H., Rawlins, J. N., & Bannerman, D. M. (2013). Hippocampal NMDA receptors are important for behavioural inhibition but not for encoding associative spatial memories. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 369(1633), 20130149. https://doi.org/10.1098/rstb.2013.0149\n\n13. Silva, A. J., Stevens, C. F., Tonegawa, S., & Wang, Y. (1992). Deficient hippocampal long-term potentiation in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 201--206. https://doi.org/10.1126/science.1378648\n\n14. Silva, A. J., Paylor, R., Wehner, J. M., & Tonegawa, S. (1992). Impaired spatial learning in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 206--211. https://doi.org/10.1126/science.1321493\n\n15. Chen, C. & Tonegawa, S. (1997). MOLECULAR GENETIC ANALYSIS OF SYNAPTIC PLASTICITY, ACTIVITY-DEPENDENT NEURAL DEVELOPMENT, LEARNING, AND MEMORY IN THE MAMMALIAN BRAIN. Annual review of neuroscience, 20 (1), s. 157--184. doi: 10.1146/annurev.neuro.20.1.157\n\n16. Hestrin, S. (1996). Physiology of NMDA receptors and synaptic currents. Excitatory amino acids and the cerebral cortex. Edited by F. Conti and TP Hicks. MIT Press/Bradford Books, Cambridge, Mass, 53-62.\n\n17. Niewoehner, B., Single, F. N., Hvalby, Ø., Jensen, V., Meyer zum Alten Borgloh, S., Seeburg, P. H., Rawlins, J. N., Sprengel, R., & Bannerman, D. M. (2007). Impaired spatial working memory but spared spatial reference memory following functional loss of NMDA receptors in the dentate gyrus. The European journal of neuroscience, 25(3), 837--846. https://doi.org/10.1111/j.1460-9568.2007.05312.x\n\n18. Lee, I., Kesner, R. Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nat Neurosci 5, 162--168 (2002). https://doi.org/10.1038/nn790\n\n19. Lee, I., & Kesner, R. P. (2004). Encoding versus retrieval of spatial memory: double dissociation between the dentate gyrus and the perforant path inputs into CA3 in the dorsal hippocampus. Hippocampus, 14(1), 66--76. https://doi.org/10.1002/hipo.10167\n\n20. Lee, I., & Solivan, F. (2010). Dentate gyrus is necessary for disambiguating similar object-place representations. Learning & Memory, 17(5), 252-258.\n\n21. Lee, S. E., Simons, S. B., Heldt, S. A., Zhao, M., Schroeder, J. P., Vellano, C. P., et al. (2010). RGS14 is a natural suppressor of both synaptic plasticity in CA2 neurons and hippocampal-based learning and memory. Proc. Natl. Acad. Sci. U.S.A. 107, 16994--16998. doi: 10.1073/pnas.1005362107\n\n22. Dudek, S. M., Alexander, G. M., and Farris, S. (2016). Rediscovering area CA2: unique properties and function. Nat. Rev. Neurosci. 17, 89--102. doi: 10.1038/nrn.2015.22\n\n23. Wersinger, S. R., Ginns, E. I., O'Carroll, A. M., Lolait, S. J., and Young, W. S. III (2002). Vasopressin V1b receptor knockout reduces aggressive behavior in male mice. Mol. Psychiatry 7, 975--984. doi: 10.1038/sj.mp.4001195\n\n24. Prediger, R. D., and Takahashi, R. N. (2005). Modulation of short-term social memory in rats by adenosine A1 and A(2A) receptors. Neurosci. Lett. 376, 160--165. doi: 10.1016/j.neulet.2004.11.049\n\n25. DeVito, L. M., Konigsberg, R., Lykken, C., Sauvage, M., Young, W. S. III, and Eichenbaum, H. (2009). Vasopressin 1b receptor knockout impairs memory for temporal order. J. Neurosci. 29, 2676--2683. doi: 10.1523/JNEUROSCI.5488-08.2009\n\n26. Caruana, D. A., Alexander, G. M., and Dudek, S. M. (2012). New insights into the regulation of synaptic plasticity from an unexpected place: hippocampal area CA2. Learn. Mem. 19, 391--400. doi: 10.1101/lm.025304.111\n\n27. Martinez, C. O., Do, V. H., Martinez, J. L., Derrick, B.E. (2002) Associative long-term potentiation (LTP) among extrinsic afferents of the hippocampal CA3 region in vivo. Brain Res. 940:86--94\n\n28. Nakazawa, K., Sun, L.D., Quirk, M.C., Rondi-Reig, L., Wilson, M.A., Tonegawa, S. (2003). Hippocampal CA3 NMDA receptors are crucial for memory acquisition of one-time experience. Neuron 38, 305--315.\n\n29. Huang, Y. Q., Lu, W. Y., Aoto, H., Sasaki, T., Salter, M. W., & MacDonald, J. F. (1999). Upregulation of NMDA receptor function by tyrosine kinase CAKβ;/Pyk2. In Soc Neurosci Abstr (Vol. 25, p. 785).\n\n30. Nosten-Bertrand, M., Errington, M. L., Murphy, K. P. S. J., Tokugawa, Y., Barboni, E., Kozlova, E., \\... & Morris, R. J. (1996). Normal spatial learning despite regional inhibition of LTP in mice lacking Thy-1. Nature, 379(6568), 826-829.\n\n31. Huang, Y. Y., Kandel, E. R., Varshavsky, L., Brandont, E. P., Qi, M., Idzerda, R. L., \\... & Bourtchouladz, R. (1995). A genetic test of the effects of mutations in PKA on mossy fiber LTP and its relation to spatial and contextual learning. Cell, 83(7), 1211-1222.\n\n32. Bromer, C., Bartol, T. M., Bowden, J. B., Hubbard, D. D., Hanka, D. C., Gonzalez, P. V., Kuwajima, M., Mendenhall, J. M., Parker, P. H., Abraham, W. C., Sejnowski, T. J., & Harris, K. M. (2018). Long-term potentiation expands information content of hippocampal dentate gyrus synapses. Proceedings of the National Academy of Sciences of the United States of America, 115(10), E2410--E2418. https://doi.org/10.1073/pnas.1716189115\n\n33. Okada, T., Yamada, N., Tsuzuki, K., Horikawa, H. P., Tanaka, K., & Ozawa, S. (2003). Long-term potentiation in the hippocampal CA1 area and dentate gyrus plays different roles in spatial learning. The European journal of neuroscience, 17(2), 341--349. https://doi.org/10.1046/j.1460-9568.2003.02458.x\n\n34. Errington, M.L., Bliss, T.V., Morris, R.J., Laroche, S., Davis, S. (1997). Long-term potentiation in awake mutant mice. Nature 387, 666--667.\n\n35. Xavier, G.F., Oliveira-Filho, F.J.B. & Santos, A.M.G. (1999) Dentate gyrus-selective colchicine lesion and disruption of performance in spatial tasks: difficulties in 'place strategy' because of a lack of flexibility in the use of environmental cues? Hippocampus, 9, 668--681.\n\n36. Jeltsch, H., Bertrand, F., Lazarus, C. & Cassel, J.-C. (2001) Cognitive performances and locomotor activity following dentate granule cell damage in rats: role of lesion extent and type of memory tested. Neurobiol. Learn. Mem., 76, 81--105.\n\n37. van Asselen, M., Kessels, R. P., Neggers, S. F., Kappelle, L. J., Frijns, C. J., & Postma, A. (2006). Brain areas involved in spatial working memory. Neuropsychologia, 44(7), 1185--1194. https://doi.org/10.1016/j.neuropsychologia.2005.10.005\n","source":"_posts/2022-01-18-NMDA-receptor-dependent-LTP-roles.md","raw":"---\ntitle: NMDA receptor-dependent LTP roles\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-01-18 17:59:11\npassword:\nsummary:\ntags:\n- Essay\ncategories:\n- Neuroscience\n---\n\n# Discuss whether or not NMDA  receptor-dependent LTP in different hippocampal subregions can have distinct  roles in learning and memory\n\nThe hippocampus is generally considered to be the foundation of memory and learning. As early as 1949, Hebb proposed that learning and memory are stored as changes in the strength of synaptic connections between neurons. Along with the discovery of the LTP phenomenon by Bliss & Lomo (1973) and subsequent research, the hypothesis that the LTP provides a neural basis for learning and memory formation has been widely accepted by the public. The NMDAR-dependent LTP processes in the hippocampus, especially in the CA1 subregion of the hippocampus, are thought to be the neural basis for spatial learning and memory (Martin et al., 2000, Bliss & Collingridge, 1993). The hippocampus consists of four Cornu Ammonis regions (CA1 to CA4) and dentate gyrus (DG), of which CA4 can also be considered part of the DG due to the partial overlap of structure and function (Andersen et al., 2007, Anand & Dhikav, 2012). With the desire of studying hippocampal subregions, one question is proposed: how can we specifically study the subregions? The arrangement of hippocampal neurons allows the hippocampus to be sliced, leaving most of the relevant circuitry intact (Purves, Augustine & Fitzpatrick, 2001). The undamaged circuit of the individual subregions ensures the feasibility and authenticity of our study about each subregion. Thus, in-depth study of each subregion has become a hot topic in the past decades. This essay aims to discuss NMDAR-dependent LTP in different hippocampal subregions can have distinct and similar roles in learning and memory.\n\nLTP can be observed at three main excitatory synapses in the hippocampal circuit, the excitatory synaptic pathway of the hippocampus. In this circuit, the perforant pathway extends from pyramidal cells in the entorhinal area to granule cells in the DG; the mossy fibre pathway extends from granule cells in the DG to CA3 pyramidal cells; Schaffer collateral pathways from CA3 pyramidal cells to CA1 pyramidal cells (Fig 1). Bliss & Collingridge (1993), Nicoll & Malenka (1995) believe that two subregions, CA1 and DG, show NMDAR-dependent LTP. However, their findings do not imply the absence of NMDA receptor-dependent LTP in other hippocampal subregions due to the limitations in-vitro experiments. In 2002, Lee & Kesner collected some data indicating the involvement of NMDAR in CA3, which may be explained as an attractor state (a temporarily self-sustaining state), with a computational model based on physiological evidence and behavioural experiments. In this research, Lee suggested behavioural evidence for differences in NMDAR spatial working memory function among hippocampal subregions. Lee\\'s research eliminates the influence of another type of LTP with the local subregion-specific injection of NMDAR antagonists. As the participation of CA3, the role of the hippocampal NMDAR-dependent LTP might be misunderstood. However, previous research still cannot explain the role in the hippocampal subregions well. The association hypothesis between NMDAR-dependent LTP and learning and memory in hippocampal subregions require more experiments to validate. When we focus on each subregion, their distinct and similar roles in learning and memory may be revealed.\n\n![image-20220216191746673](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202161917751.png)\n\n**Figure 1**. LTP in Schaffer collateral pathway, mossy fibre pathway and perforant pathway (Chen et al. 1997)\n\nThe CA1 subregion is the neural foundation linking spatial learning and memory. Tsien et. al (1996a, 1996b) knockout the GluN1 subunit (in NMDAR) resulting in the deficit of LTP in Schaffer collateral CA1 synapses finding the spatial reference memory is impaired in mice. This research directly proves that NMDAR-dependent LTP at CA1 synapses is the neural foundation for associative, long-term spatial memory formation. Additionally, CA1-KO mice lack NMDAR-mediated postsynaptic currents and LTP in CA1. These mice showed impaired spatial memory in the Morris hidden platform water maze, in the opposite, performed well on non-spatial learning tasks. The results provide contrastive support for the hypothesis that NMDAR-mediated LTP in the CA1 region is critical for the formation of some specific types of memory. Similarly, spatial learning deficits were reported in mice with the impaired LTP in CA1 owing to the lack of the gene encoding α subunit of calmodulin-dependent protein kinase II (αCaMKII) (Silva et al., 1992a, 1992b). These mice lack spatial memory, the same as spatial memory deficits in CA1-KO mice. A possible shortcoming in this experiment is that previous experiments are based on direct injection of NMDAR antagonists into the brain, which may not be sufficiently convincing in terms of regional idiosyncrasy. According to Hestrin\\'s discovery in 1996: NMDAR contributes to synaptic transmission in some regions of the neocortex. We can conclude that memory impairment can be explained, at least in part, by deficits in the computing ability of the neocortex, rather than impairments in synaptic plasticity within the hippocampus. Subsequently, Bannerman et al. (2012) used transgenic mice lacking the GluN1 subunit and NMDARs in the pyramidal cells of CA1 and the granule cells of DG finding that the spatial reference memory of the mice acquired the radial maze task was impaired. It furtherly demonstrates the fact: hippocampal CA1 plays an important role in the learning of spatial reference memory. In 2013, it took a turn when Taylor et al. found that such mice performed well on the classic open-field spatial reference memory water maze task. How can it happen? It possibly indicates that the hippocampal NMDAR is not actually required for the formation of long-term associative spatial memory, which is against Tsien\\'s results. But Taylor does not explain this in detail, thus it cannot determine whether there are any other compensatory mechanisms for NMDA-dependent LTP. Whatever, as Niewoehner et al. (2007) argues, the development of spatially restricted genetic modifications has identified synaptic plasticity, which is a broader idea than LTP, with specific and separable roles in different hippocampal subregions. We may want to see more genetic modification experiments in this field. Despite the shortcomings of these research, the inter-experimental corroboration still demonstrates that CA1 has an irreplaceable role in associative, long-term spatial memory. We can consider CA1 LTP to be the basis of spatial memory formation.\n\nIn the CA2 subregion, NMDA-dependent LTP cannot be induced. Zhao et al. (2007) attempted to test whether synaptic stimulation could induce LTP in CA2 neurons, which is proved to induce NMDAR-dependent LTP in CA1, using a variety of approaches including perforated whole-cell patch-clamp recording. However, all results lead to that the synaptic current is not increased. One of the explanations from Caruana, Alexander, & Dudek (2012) is that the high expression of TREK-1 and TREK-2 potassium channels in CA2, compared with other hippocampal subregions, leads to the lack of LTP. These channels produce potassium-mediated leakage currents significantly hyperpolarizing the resting membrane potential. Thus, larger depolarizing currents are required to initiate LTP. Therefore, is it necessary to look for the memory learning function of LTP in CA2? Zhao compared the expression patterns of NMDAR mRNAs in CA2 and CA3 finding that those mRNAs are expressed in both subregions. What distinguish the CA2 and the CA3? Certain \\\"memory suppressor\\\" genes (e.g., RGS14) play a key role in suppressing LTP induction (Lee et al., 2010a, 2010b, Dudek et al., 2016). More evidence suggests that the induction of NMDAR-dependent LTP and memory formation in CA2 can occur under very specific conditions (Wersinger et al., 2002, Prediger & Takahashi, 2005, DeVito et al., 2009, Caruana et al., 2012). We conclude that NMDAR-dependent LTP in the CA2 area is rare, but not impossible. Therefore, its role in CA2 needs further study.\n\nThe NMDAR-dependent LTP in CA3 is involved in learning and memory storage acquisition although NMDAR-dependent LTP in CA3 is uncommon. The fact that LTP in the Moss fiber-CA3 system coincides with the progress in learning demonstrates the role of CA3 in learning and memory. Based on electrophysiological data by Martinez et al. (2002), an associative LTP was found in the perforant pathway inputting into CA3, which means that there is NMDAR-dependent LTP between perforant pathway and the CA3 synapse. The following step is to study its function. Nakazawa et al. (2003) found that \\\"one-time learning\\\" is blocked by specific knockout of CA3 NMDAR in mice. We thus argue that NMDA-dependent LTP in CA3 plays an important role in the information acquiring and storing from new experiences. Lee & Kesner\\'s (2004) study also demonstrated that CA3 neurons are activated during recall of objects or locations. It refers that NMDA-dependent LTP in CA3 may affect object-location pairing association tasks. In hippocampal CA3, two distinct forms of LTP have been described, one of which is the classical NMDA-dependent LTP (Zalutsky and Nicoll, 1990). The disadvantage of these experiments is that we do not know whether to confirm the function of another LTP and whether it is also involved in memory and learning functions. Although these experiments do not cover all types of LTPs, at least we know that NMDAR-dependent LTP in CA3 is involved in memory acquisition.\n\nThe NMDAR-dependent LTP in DG focuses more on spatial working memory (SWM) (Active spatial information in working memory over a short period (van Asselen et al., 2006)) than spatial reference memory (SRM). Nosten-Bertrand et al. (1996) first proposed that spatial learning is not obviously blocked in the absence of a DG LTP gene anaesthetized rats, which we mentioned present in CA1. Although a subsequent study by Errington et al. (1997) speculated that this phenomenon may be due to the effect of gene knockout on inhibitory neurons. Additional evidence for this hypothesis is that massive loss of the NR1 subunit of the NMDAR only showed severely impaired LTP in the perforant pathway inputs of the DG, whereas LTP is unchanged from CA3 to CA1. Based on this study, behavioural assessments of these mice show significant SWM impairment but no effect on hippocampal-dependent SRM performance for the same task. However, other studies have demonstrated that DG selectivity, fibre-sparing, and colchicine lesions can lead to impairment of both SWM and SRM (Xavier, Oliveira-Filho & Santos, 1999). This is complemented with behavioural experiments by Jeltsch et al. (2001), where DG impairment significantly increases SRM and SWM errors in the four-from-eight radial maze task. The downside, however, is that these results fail to provide positive evidence for the hypothesis that NMDAR-mediated synaptic plasticity in the DG supports spatial pattern separation. The present results cannot completely rule out a role for the NMDAR LTP in the DG in spatial pattern separation across tasks, although it is clearly shown that any putative role must be limited to the working memory. We can argue that DG may be involved in both spatial working memory and SRM but is more focused on spatial working memory.\n\nThe biggest difference among the function of NMDAR-dependent LTP hippocampal subregions is the roles these played in spatial learning. According to earlier studies, in contrast to CA1, damages to mossy fibre to CA3 LTP (Huang et al., 1995) and perforant pathway to DG LTP (Nosten-Bertrand et al., 1996) are not associated with deficits in spatial memory. Huang et al. (1999) found that mossy fibre CA3 LTP and perforant DG LTP are dispensable for spatial learning. This is consistent with the notion that CA1 LTP is critical for spatial learning. CA1 LTPs are particularly important for spatial and contextual learning in the hippocampus compared to CA3 or DG LTPs. What is more, subsequent further studies confirmed that other subregions are also involved in learning and memory. Okada et al. (2003) examined the effect of NMDA-dependent LTP on spatial learning in rats after increasing the extent of NMDA-dependent LTP by using viral vectors for gene editing. It is demonstrated that although CA1 and the DG have similar mechanisms of LTP induction, they play distinct functional roles in spatial learning. To explore the differences in information storage capacity, Bromer et al. (2018) used a method combining signal detection theory with accurate 3D reconstruction of serial section electron microscopy to study in vivo perforant pathway LTP processes in the DG of the mature hippocampus. Bromer et al. investigate synaptic plasticity and information storage capacity. It is found that the information storage capacity of the DG is much lower than CA1. This study elucidates the temporal LTP process of storing information and the inter-regional variation of information storage capacity, that is, differences in spatial learning between CA1 and DG.\n\nThis essay focuses on the roles of NMDAR-dependent LTP in learning and memory in various hippocampal subregions. From these studies, we can conclude that the NMDA-dependent LTP in CA1 and the DG gets involved in acquiring memory that needs to be retrieved after a delay period beyond the short-term. CA1 is the basis of spatial memory formation, associating spatial learning and memory. DG also plays an important role in spatial working memory, mainly in spatial working memory. The NMDAR-dependent LTP in CA3 is significant in situations where reorganization of spatial representations memory is required. It is involved in memory acquisition as well, with a focus on spatial reference memory. The recognition of each subregion can help us understand the integral mechanism. We should consider each subregion separately but focus on the overall functional interaction. It may become an innovative point for future research. Although many computational models and anatomical studies have highlighted functional differences between NMDAR-dependent LTP in the hippocampus, the subregional heterogeneity of NMDAR function is still largely unknown. Therefore, as the technology develops, the following research on the mechanisms of NMDA-dependent LTP in each subregion and interaction are supposed to be further explored.\n\n## **Reference**\n\n1.  Hebb, D. O. (1949). The organization of behavior. New York, NY: John Wiley.\n\n2.  Bliss, T. V., & Lomo, T. (1973). Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. The Journal of physiology, 232(2), 331--356. https://doi.org/10.1113/jphysiol.1973.sp010273\n\n3.  Bliss, T. V., & Collingridge, G. L. (1993). A synaptic model of memory: long-term potentiation in the hippocampus. Nature, 361(6407), 31--39. https://doi.org/10.1038/361031a0\n\n4.  Martin, S. J., Grimwood, P. D., & Morris, R. G. (2000). Synaptic plasticity and memory: an evaluation of the hypothesis. Annual review of neuroscience, 23, 649--711. https://doi.org/10.1146/annurev.neuro.23.1.649\n\n5.  Andersen, P., Morris, R., Amaral, D., Bliss, T., & O\\'Keefe, J. (2007). The Hippocampus Book. Oxford University press.\n\n6.  Anand, K. S., & Dhikav, V. (2012). Hippocampus in health and disease: An overview. Annals of Indian Academy of Neurology, 15(4), 239--246. https://doi.org/10.4103/0972-2327.104323\n\n7.  Purves, D., Augustine, G. J., Fitzpatrick, D. (2001). Neuroscience. 2nd edition.\n\n8.  Lee, I., & Kesner, R. P. (2002). Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nature neuroscience, 5(2), 162--168. https://doi.org/10.1038/nn790\n\n9.  Tsien, J. Z., Chen, D. F., Gerber, D., Tom, C., Mercer, E. H., Anderson, D. J., Mayford, M., Kandel, E. R., & Tonegawa, S. (1996). Subregion- and cell type-restricted gene knockout in mouse brain. Cell, 87(7), 1317--1326. https://doi.org/10.1016/s0092-8674(00)81826-7\n\n10. Tsien, J. Z., Huerta, P. T., & Tonegawa, S. (1996). The essential role of hippocampal CA1 NMDA receptor-dependent synaptic plasticity in spatial memory. Cell, 87(7), 1327--1338. https://doi.org/10.1016/s0092-8674(00)81827-9\n\n11. Bannerman, D. M., Bus, T., Taylor, A., Sanderson, D. J., Schwarz, I., Jensen, V., Hvalby, Ø., Rawlins, J. N., Seeburg, P. H., & Sprengel, R. (2012). Dissecting spatial knowledge from spatial choice by hippocampal NMDA receptor deletion. Nature neuroscience, 15(8), 1153--1159. https://doi.org/10.1038/nn.3166\n\n12. Taylor, A. M., Bus, T., Sprengel, R., Seeburg, P. H., Rawlins, J. N., & Bannerman, D. M. (2013). Hippocampal NMDA receptors are important for behavioural inhibition but not for encoding associative spatial memories. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 369(1633), 20130149. https://doi.org/10.1098/rstb.2013.0149\n\n13. Silva, A. J., Stevens, C. F., Tonegawa, S., & Wang, Y. (1992). Deficient hippocampal long-term potentiation in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 201--206. https://doi.org/10.1126/science.1378648\n\n14. Silva, A. J., Paylor, R., Wehner, J. M., & Tonegawa, S. (1992). Impaired spatial learning in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 206--211. https://doi.org/10.1126/science.1321493\n\n15. Chen, C. & Tonegawa, S. (1997). MOLECULAR GENETIC ANALYSIS OF SYNAPTIC PLASTICITY, ACTIVITY-DEPENDENT NEURAL DEVELOPMENT, LEARNING, AND MEMORY IN THE MAMMALIAN BRAIN. Annual review of neuroscience, 20 (1), s. 157--184. doi: 10.1146/annurev.neuro.20.1.157\n\n16. Hestrin, S. (1996). Physiology of NMDA receptors and synaptic currents. Excitatory amino acids and the cerebral cortex. Edited by F. Conti and TP Hicks. MIT Press/Bradford Books, Cambridge, Mass, 53-62.\n\n17. Niewoehner, B., Single, F. N., Hvalby, Ø., Jensen, V., Meyer zum Alten Borgloh, S., Seeburg, P. H., Rawlins, J. N., Sprengel, R., & Bannerman, D. M. (2007). Impaired spatial working memory but spared spatial reference memory following functional loss of NMDA receptors in the dentate gyrus. The European journal of neuroscience, 25(3), 837--846. https://doi.org/10.1111/j.1460-9568.2007.05312.x\n\n18. Lee, I., Kesner, R. Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nat Neurosci 5, 162--168 (2002). https://doi.org/10.1038/nn790\n\n19. Lee, I., & Kesner, R. P. (2004). Encoding versus retrieval of spatial memory: double dissociation between the dentate gyrus and the perforant path inputs into CA3 in the dorsal hippocampus. Hippocampus, 14(1), 66--76. https://doi.org/10.1002/hipo.10167\n\n20. Lee, I., & Solivan, F. (2010). Dentate gyrus is necessary for disambiguating similar object-place representations. Learning & Memory, 17(5), 252-258.\n\n21. Lee, S. E., Simons, S. B., Heldt, S. A., Zhao, M., Schroeder, J. P., Vellano, C. P., et al. (2010). RGS14 is a natural suppressor of both synaptic plasticity in CA2 neurons and hippocampal-based learning and memory. Proc. Natl. Acad. Sci. U.S.A. 107, 16994--16998. doi: 10.1073/pnas.1005362107\n\n22. Dudek, S. M., Alexander, G. M., and Farris, S. (2016). Rediscovering area CA2: unique properties and function. Nat. Rev. Neurosci. 17, 89--102. doi: 10.1038/nrn.2015.22\n\n23. Wersinger, S. R., Ginns, E. I., O'Carroll, A. M., Lolait, S. J., and Young, W. S. III (2002). Vasopressin V1b receptor knockout reduces aggressive behavior in male mice. Mol. Psychiatry 7, 975--984. doi: 10.1038/sj.mp.4001195\n\n24. Prediger, R. D., and Takahashi, R. N. (2005). Modulation of short-term social memory in rats by adenosine A1 and A(2A) receptors. Neurosci. Lett. 376, 160--165. doi: 10.1016/j.neulet.2004.11.049\n\n25. DeVito, L. M., Konigsberg, R., Lykken, C., Sauvage, M., Young, W. S. III, and Eichenbaum, H. (2009). Vasopressin 1b receptor knockout impairs memory for temporal order. J. Neurosci. 29, 2676--2683. doi: 10.1523/JNEUROSCI.5488-08.2009\n\n26. Caruana, D. A., Alexander, G. M., and Dudek, S. M. (2012). New insights into the regulation of synaptic plasticity from an unexpected place: hippocampal area CA2. Learn. Mem. 19, 391--400. doi: 10.1101/lm.025304.111\n\n27. Martinez, C. O., Do, V. H., Martinez, J. L., Derrick, B.E. (2002) Associative long-term potentiation (LTP) among extrinsic afferents of the hippocampal CA3 region in vivo. Brain Res. 940:86--94\n\n28. Nakazawa, K., Sun, L.D., Quirk, M.C., Rondi-Reig, L., Wilson, M.A., Tonegawa, S. (2003). Hippocampal CA3 NMDA receptors are crucial for memory acquisition of one-time experience. Neuron 38, 305--315.\n\n29. Huang, Y. Q., Lu, W. Y., Aoto, H., Sasaki, T., Salter, M. W., & MacDonald, J. F. (1999). Upregulation of NMDA receptor function by tyrosine kinase CAKβ;/Pyk2. In Soc Neurosci Abstr (Vol. 25, p. 785).\n\n30. Nosten-Bertrand, M., Errington, M. L., Murphy, K. P. S. J., Tokugawa, Y., Barboni, E., Kozlova, E., \\... & Morris, R. J. (1996). Normal spatial learning despite regional inhibition of LTP in mice lacking Thy-1. Nature, 379(6568), 826-829.\n\n31. Huang, Y. Y., Kandel, E. R., Varshavsky, L., Brandont, E. P., Qi, M., Idzerda, R. L., \\... & Bourtchouladz, R. (1995). A genetic test of the effects of mutations in PKA on mossy fiber LTP and its relation to spatial and contextual learning. Cell, 83(7), 1211-1222.\n\n32. Bromer, C., Bartol, T. M., Bowden, J. B., Hubbard, D. D., Hanka, D. C., Gonzalez, P. V., Kuwajima, M., Mendenhall, J. M., Parker, P. H., Abraham, W. C., Sejnowski, T. J., & Harris, K. M. (2018). Long-term potentiation expands information content of hippocampal dentate gyrus synapses. Proceedings of the National Academy of Sciences of the United States of America, 115(10), E2410--E2418. https://doi.org/10.1073/pnas.1716189115\n\n33. Okada, T., Yamada, N., Tsuzuki, K., Horikawa, H. P., Tanaka, K., & Ozawa, S. (2003). Long-term potentiation in the hippocampal CA1 area and dentate gyrus plays different roles in spatial learning. The European journal of neuroscience, 17(2), 341--349. https://doi.org/10.1046/j.1460-9568.2003.02458.x\n\n34. Errington, M.L., Bliss, T.V., Morris, R.J., Laroche, S., Davis, S. (1997). Long-term potentiation in awake mutant mice. Nature 387, 666--667.\n\n35. Xavier, G.F., Oliveira-Filho, F.J.B. & Santos, A.M.G. (1999) Dentate gyrus-selective colchicine lesion and disruption of performance in spatial tasks: difficulties in 'place strategy' because of a lack of flexibility in the use of environmental cues? Hippocampus, 9, 668--681.\n\n36. Jeltsch, H., Bertrand, F., Lazarus, C. & Cassel, J.-C. (2001) Cognitive performances and locomotor activity following dentate granule cell damage in rats: role of lesion extent and type of memory tested. Neurobiol. Learn. Mem., 76, 81--105.\n\n37. van Asselen, M., Kessels, R. P., Neggers, S. F., Kappelle, L. J., Frijns, C. J., & Postma, A. (2006). Brain areas involved in spatial working memory. Neuropsychologia, 44(7), 1185--1194. https://doi.org/10.1016/j.neuropsychologia.2005.10.005\n","slug":"2022-01-18-NMDA-receptor-dependent-LTP-roles","published":1,"updated":"2022-08-24T17:08:39.334Z","comments":1,"layout":"post","photos":[],"_id":"cuidDpkP9Mitf5W5CE4eZnvoW","content":"<h1 id=\"Discuss-whether-or-not-NMDA-receptor-dependent-LTP-in-different-hippocampal-subregions-can-have-distinct-roles-in-learning-and-memory\"><a href=\"#Discuss-whether-or-not-NMDA-receptor-dependent-LTP-in-different-hippocampal-subregions-can-have-distinct-roles-in-learning-and-memory\" class=\"headerlink\" title=\"Discuss whether or not NMDA  receptor-dependent LTP in different hippocampal subregions can have distinct  roles in learning and memory\"></a>Discuss whether or not NMDA  receptor-dependent LTP in different hippocampal subregions can have distinct  roles in learning and memory</h1><p>The hippocampus is generally considered to be the foundation of memory and learning. As early as 1949, Hebb proposed that learning and memory are stored as changes in the strength of synaptic connections between neurons. Along with the discovery of the LTP phenomenon by Bliss &amp; Lomo (1973) and subsequent research, the hypothesis that the LTP provides a neural basis for learning and memory formation has been widely accepted by the public. The NMDAR-dependent LTP processes in the hippocampus, especially in the CA1 subregion of the hippocampus, are thought to be the neural basis for spatial learning and memory (Martin et al., 2000, Bliss &amp; Collingridge, 1993). The hippocampus consists of four Cornu Ammonis regions (CA1 to CA4) and dentate gyrus (DG), of which CA4 can also be considered part of the DG due to the partial overlap of structure and function (Andersen et al., 2007, Anand &amp; Dhikav, 2012). With the desire of studying hippocampal subregions, one question is proposed: how can we specifically study the subregions? The arrangement of hippocampal neurons allows the hippocampus to be sliced, leaving most of the relevant circuitry intact (Purves, Augustine &amp; Fitzpatrick, 2001). The undamaged circuit of the individual subregions ensures the feasibility and authenticity of our study about each subregion. Thus, in-depth study of each subregion has become a hot topic in the past decades. This essay aims to discuss NMDAR-dependent LTP in different hippocampal subregions can have distinct and similar roles in learning and memory.</p>\n<p>LTP can be observed at three main excitatory synapses in the hippocampal circuit, the excitatory synaptic pathway of the hippocampus. In this circuit, the perforant pathway extends from pyramidal cells in the entorhinal area to granule cells in the DG; the mossy fibre pathway extends from granule cells in the DG to CA3 pyramidal cells; Schaffer collateral pathways from CA3 pyramidal cells to CA1 pyramidal cells (Fig 1). Bliss &amp; Collingridge (1993), Nicoll &amp; Malenka (1995) believe that two subregions, CA1 and DG, show NMDAR-dependent LTP. However, their findings do not imply the absence of NMDA receptor-dependent LTP in other hippocampal subregions due to the limitations in-vitro experiments. In 2002, Lee &amp; Kesner collected some data indicating the involvement of NMDAR in CA3, which may be explained as an attractor state (a temporarily self-sustaining state), with a computational model based on physiological evidence and behavioural experiments. In this research, Lee suggested behavioural evidence for differences in NMDAR spatial working memory function among hippocampal subregions. Lee&#39;s research eliminates the influence of another type of LTP with the local subregion-specific injection of NMDAR antagonists. As the participation of CA3, the role of the hippocampal NMDAR-dependent LTP might be misunderstood. However, previous research still cannot explain the role in the hippocampal subregions well. The association hypothesis between NMDAR-dependent LTP and learning and memory in hippocampal subregions require more experiments to validate. When we focus on each subregion, their distinct and similar roles in learning and memory may be revealed.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202161917751.png\" alt=\"image-20220216191746673\"></p>\n<p><strong>Figure 1</strong>. LTP in Schaffer collateral pathway, mossy fibre pathway and perforant pathway (Chen et al. 1997)</p>\n<p>The CA1 subregion is the neural foundation linking spatial learning and memory. Tsien et. al (1996a, 1996b) knockout the GluN1 subunit (in NMDAR) resulting in the deficit of LTP in Schaffer collateral CA1 synapses finding the spatial reference memory is impaired in mice. This research directly proves that NMDAR-dependent LTP at CA1 synapses is the neural foundation for associative, long-term spatial memory formation. Additionally, CA1-KO mice lack NMDAR-mediated postsynaptic currents and LTP in CA1. These mice showed impaired spatial memory in the Morris hidden platform water maze, in the opposite, performed well on non-spatial learning tasks. The results provide contrastive support for the hypothesis that NMDAR-mediated LTP in the CA1 region is critical for the formation of some specific types of memory. Similarly, spatial learning deficits were reported in mice with the impaired LTP in CA1 owing to the lack of the gene encoding α subunit of calmodulin-dependent protein kinase II (αCaMKII) (Silva et al., 1992a, 1992b). These mice lack spatial memory, the same as spatial memory deficits in CA1-KO mice. A possible shortcoming in this experiment is that previous experiments are based on direct injection of NMDAR antagonists into the brain, which may not be sufficiently convincing in terms of regional idiosyncrasy. According to Hestrin&#39;s discovery in 1996: NMDAR contributes to synaptic transmission in some regions of the neocortex. We can conclude that memory impairment can be explained, at least in part, by deficits in the computing ability of the neocortex, rather than impairments in synaptic plasticity within the hippocampus. Subsequently, Bannerman et al. (2012) used transgenic mice lacking the GluN1 subunit and NMDARs in the pyramidal cells of CA1 and the granule cells of DG finding that the spatial reference memory of the mice acquired the radial maze task was impaired. It furtherly demonstrates the fact: hippocampal CA1 plays an important role in the learning of spatial reference memory. In 2013, it took a turn when Taylor et al. found that such mice performed well on the classic open-field spatial reference memory water maze task. How can it happen? It possibly indicates that the hippocampal NMDAR is not actually required for the formation of long-term associative spatial memory, which is against Tsien&#39;s results. But Taylor does not explain this in detail, thus it cannot determine whether there are any other compensatory mechanisms for NMDA-dependent LTP. Whatever, as Niewoehner et al. (2007) argues, the development of spatially restricted genetic modifications has identified synaptic plasticity, which is a broader idea than LTP, with specific and separable roles in different hippocampal subregions. We may want to see more genetic modification experiments in this field. Despite the shortcomings of these research, the inter-experimental corroboration still demonstrates that CA1 has an irreplaceable role in associative, long-term spatial memory. We can consider CA1 LTP to be the basis of spatial memory formation.</p>\n<p>In the CA2 subregion, NMDA-dependent LTP cannot be induced. Zhao et al. (2007) attempted to test whether synaptic stimulation could induce LTP in CA2 neurons, which is proved to induce NMDAR-dependent LTP in CA1, using a variety of approaches including perforated whole-cell patch-clamp recording. However, all results lead to that the synaptic current is not increased. One of the explanations from Caruana, Alexander, &amp; Dudek (2012) is that the high expression of TREK-1 and TREK-2 potassium channels in CA2, compared with other hippocampal subregions, leads to the lack of LTP. These channels produce potassium-mediated leakage currents significantly hyperpolarizing the resting membrane potential. Thus, larger depolarizing currents are required to initiate LTP. Therefore, is it necessary to look for the memory learning function of LTP in CA2? Zhao compared the expression patterns of NMDAR mRNAs in CA2 and CA3 finding that those mRNAs are expressed in both subregions. What distinguish the CA2 and the CA3? Certain &quot;memory suppressor&quot; genes (e.g., RGS14) play a key role in suppressing LTP induction (Lee et al., 2010a, 2010b, Dudek et al., 2016). More evidence suggests that the induction of NMDAR-dependent LTP and memory formation in CA2 can occur under very specific conditions (Wersinger et al., 2002, Prediger &amp; Takahashi, 2005, DeVito et al., 2009, Caruana et al., 2012). We conclude that NMDAR-dependent LTP in the CA2 area is rare, but not impossible. Therefore, its role in CA2 needs further study.</p>\n<p>The NMDAR-dependent LTP in CA3 is involved in learning and memory storage acquisition although NMDAR-dependent LTP in CA3 is uncommon. The fact that LTP in the Moss fiber-CA3 system coincides with the progress in learning demonstrates the role of CA3 in learning and memory. Based on electrophysiological data by Martinez et al. (2002), an associative LTP was found in the perforant pathway inputting into CA3, which means that there is NMDAR-dependent LTP between perforant pathway and the CA3 synapse. The following step is to study its function. Nakazawa et al. (2003) found that &quot;one-time learning&quot; is blocked by specific knockout of CA3 NMDAR in mice. We thus argue that NMDA-dependent LTP in CA3 plays an important role in the information acquiring and storing from new experiences. Lee &amp; Kesner&#39;s (2004) study also demonstrated that CA3 neurons are activated during recall of objects or locations. It refers that NMDA-dependent LTP in CA3 may affect object-location pairing association tasks. In hippocampal CA3, two distinct forms of LTP have been described, one of which is the classical NMDA-dependent LTP (Zalutsky and Nicoll, 1990). The disadvantage of these experiments is that we do not know whether to confirm the function of another LTP and whether it is also involved in memory and learning functions. Although these experiments do not cover all types of LTPs, at least we know that NMDAR-dependent LTP in CA3 is involved in memory acquisition.</p>\n<p>The NMDAR-dependent LTP in DG focuses more on spatial working memory (SWM) (Active spatial information in working memory over a short period (van Asselen et al., 2006)) than spatial reference memory (SRM). Nosten-Bertrand et al. (1996) first proposed that spatial learning is not obviously blocked in the absence of a DG LTP gene anaesthetized rats, which we mentioned present in CA1. Although a subsequent study by Errington et al. (1997) speculated that this phenomenon may be due to the effect of gene knockout on inhibitory neurons. Additional evidence for this hypothesis is that massive loss of the NR1 subunit of the NMDAR only showed severely impaired LTP in the perforant pathway inputs of the DG, whereas LTP is unchanged from CA3 to CA1. Based on this study, behavioural assessments of these mice show significant SWM impairment but no effect on hippocampal-dependent SRM performance for the same task. However, other studies have demonstrated that DG selectivity, fibre-sparing, and colchicine lesions can lead to impairment of both SWM and SRM (Xavier, Oliveira-Filho &amp; Santos, 1999). This is complemented with behavioural experiments by Jeltsch et al. (2001), where DG impairment significantly increases SRM and SWM errors in the four-from-eight radial maze task. The downside, however, is that these results fail to provide positive evidence for the hypothesis that NMDAR-mediated synaptic plasticity in the DG supports spatial pattern separation. The present results cannot completely rule out a role for the NMDAR LTP in the DG in spatial pattern separation across tasks, although it is clearly shown that any putative role must be limited to the working memory. We can argue that DG may be involved in both spatial working memory and SRM but is more focused on spatial working memory.</p>\n<p>The biggest difference among the function of NMDAR-dependent LTP hippocampal subregions is the roles these played in spatial learning. According to earlier studies, in contrast to CA1, damages to mossy fibre to CA3 LTP (Huang et al., 1995) and perforant pathway to DG LTP (Nosten-Bertrand et al., 1996) are not associated with deficits in spatial memory. Huang et al. (1999) found that mossy fibre CA3 LTP and perforant DG LTP are dispensable for spatial learning. This is consistent with the notion that CA1 LTP is critical for spatial learning. CA1 LTPs are particularly important for spatial and contextual learning in the hippocampus compared to CA3 or DG LTPs. What is more, subsequent further studies confirmed that other subregions are also involved in learning and memory. Okada et al. (2003) examined the effect of NMDA-dependent LTP on spatial learning in rats after increasing the extent of NMDA-dependent LTP by using viral vectors for gene editing. It is demonstrated that although CA1 and the DG have similar mechanisms of LTP induction, they play distinct functional roles in spatial learning. To explore the differences in information storage capacity, Bromer et al. (2018) used a method combining signal detection theory with accurate 3D reconstruction of serial section electron microscopy to study in vivo perforant pathway LTP processes in the DG of the mature hippocampus. Bromer et al. investigate synaptic plasticity and information storage capacity. It is found that the information storage capacity of the DG is much lower than CA1. This study elucidates the temporal LTP process of storing information and the inter-regional variation of information storage capacity, that is, differences in spatial learning between CA1 and DG.</p>\n<p>This essay focuses on the roles of NMDAR-dependent LTP in learning and memory in various hippocampal subregions. From these studies, we can conclude that the NMDA-dependent LTP in CA1 and the DG gets involved in acquiring memory that needs to be retrieved after a delay period beyond the short-term. CA1 is the basis of spatial memory formation, associating spatial learning and memory. DG also plays an important role in spatial working memory, mainly in spatial working memory. The NMDAR-dependent LTP in CA3 is significant in situations where reorganization of spatial representations memory is required. It is involved in memory acquisition as well, with a focus on spatial reference memory. The recognition of each subregion can help us understand the integral mechanism. We should consider each subregion separately but focus on the overall functional interaction. It may become an innovative point for future research. Although many computational models and anatomical studies have highlighted functional differences between NMDAR-dependent LTP in the hippocampus, the subregional heterogeneity of NMDAR function is still largely unknown. Therefore, as the technology develops, the following research on the mechanisms of NMDA-dependent LTP in each subregion and interaction are supposed to be further explored.</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a><strong>Reference</strong></h2><ol>\n<li><p>Hebb, D. O. (1949). The organization of behavior. New York, NY: John Wiley.</p>\n</li>\n<li><p>Bliss, T. V., &amp; Lomo, T. (1973). Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. The Journal of physiology, 232(2), 331–356. <a href=\"https://doi.org/10.1113/jphysiol.1973.sp010273\">https://doi.org/10.1113/jphysiol.1973.sp010273</a></p>\n</li>\n<li><p>Bliss, T. V., &amp; Collingridge, G. L. (1993). A synaptic model of memory: long-term potentiation in the hippocampus. Nature, 361(6407), 31–39. <a href=\"https://doi.org/10.1038/361031a0\">https://doi.org/10.1038/361031a0</a></p>\n</li>\n<li><p>Martin, S. J., Grimwood, P. D., &amp; Morris, R. G. (2000). Synaptic plasticity and memory: an evaluation of the hypothesis. Annual review of neuroscience, 23, 649–711. <a href=\"https://doi.org/10.1146/annurev.neuro.23.1.649\">https://doi.org/10.1146/annurev.neuro.23.1.649</a></p>\n</li>\n<li><p>Andersen, P., Morris, R., Amaral, D., Bliss, T., &amp; O&#39;Keefe, J. (2007). The Hippocampus Book. Oxford University press.</p>\n</li>\n<li><p>Anand, K. S., &amp; Dhikav, V. (2012). Hippocampus in health and disease: An overview. Annals of Indian Academy of Neurology, 15(4), 239–246. <a href=\"https://doi.org/10.4103/0972-2327.104323\">https://doi.org/10.4103/0972-2327.104323</a></p>\n</li>\n<li><p>Purves, D., Augustine, G. J., Fitzpatrick, D. (2001). Neuroscience. 2nd edition.</p>\n</li>\n<li><p>Lee, I., &amp; Kesner, R. P. (2002). Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nature neuroscience, 5(2), 162–168. <a href=\"https://doi.org/10.1038/nn790\">https://doi.org/10.1038/nn790</a></p>\n</li>\n<li><p>Tsien, J. Z., Chen, D. F., Gerber, D., Tom, C., Mercer, E. H., Anderson, D. J., Mayford, M., Kandel, E. R., &amp; Tonegawa, S. (1996). Subregion- and cell type-restricted gene knockout in mouse brain. Cell, 87(7), 1317–1326. <a href=\"https://doi.org/10.1016/s0092-8674(00)81826-7\">https://doi.org/10.1016/s0092-8674(00)81826-7</a></p>\n</li>\n<li><p>Tsien, J. Z., Huerta, P. T., &amp; Tonegawa, S. (1996). The essential role of hippocampal CA1 NMDA receptor-dependent synaptic plasticity in spatial memory. Cell, 87(7), 1327–1338. <a href=\"https://doi.org/10.1016/s0092-8674(00)81827-9\">https://doi.org/10.1016/s0092-8674(00)81827-9</a></p>\n</li>\n<li><p>Bannerman, D. M., Bus, T., Taylor, A., Sanderson, D. J., Schwarz, I., Jensen, V., Hvalby, Ø., Rawlins, J. N., Seeburg, P. H., &amp; Sprengel, R. (2012). Dissecting spatial knowledge from spatial choice by hippocampal NMDA receptor deletion. Nature neuroscience, 15(8), 1153–1159. <a href=\"https://doi.org/10.1038/nn.3166\">https://doi.org/10.1038/nn.3166</a></p>\n</li>\n<li><p>Taylor, A. M., Bus, T., Sprengel, R., Seeburg, P. H., Rawlins, J. N., &amp; Bannerman, D. M. (2013). Hippocampal NMDA receptors are important for behavioural inhibition but not for encoding associative spatial memories. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 369(1633), 20130149. <a href=\"https://doi.org/10.1098/rstb.2013.0149\">https://doi.org/10.1098/rstb.2013.0149</a></p>\n</li>\n<li><p>Silva, A. J., Stevens, C. F., Tonegawa, S., &amp; Wang, Y. (1992). Deficient hippocampal long-term potentiation in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 201–206. <a href=\"https://doi.org/10.1126/science.1378648\">https://doi.org/10.1126/science.1378648</a></p>\n</li>\n<li><p>Silva, A. J., Paylor, R., Wehner, J. M., &amp; Tonegawa, S. (1992). Impaired spatial learning in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 206–211. <a href=\"https://doi.org/10.1126/science.1321493\">https://doi.org/10.1126/science.1321493</a></p>\n</li>\n<li><p>Chen, C. &amp; Tonegawa, S. (1997). MOLECULAR GENETIC ANALYSIS OF SYNAPTIC PLASTICITY, ACTIVITY-DEPENDENT NEURAL DEVELOPMENT, LEARNING, AND MEMORY IN THE MAMMALIAN BRAIN. Annual review of neuroscience, 20 (1), s. 157–184. doi: 10.1146/annurev.neuro.20.1.157</p>\n</li>\n<li><p>Hestrin, S. (1996). Physiology of NMDA receptors and synaptic currents. Excitatory amino acids and the cerebral cortex. Edited by F. Conti and TP Hicks. MIT Press/Bradford Books, Cambridge, Mass, 53-62.</p>\n</li>\n<li><p>Niewoehner, B., Single, F. N., Hvalby, Ø., Jensen, V., Meyer zum Alten Borgloh, S., Seeburg, P. H., Rawlins, J. N., Sprengel, R., &amp; Bannerman, D. M. (2007). Impaired spatial working memory but spared spatial reference memory following functional loss of NMDA receptors in the dentate gyrus. The European journal of neuroscience, 25(3), 837–846. <a href=\"https://doi.org/10.1111/j.1460-9568.2007.05312.x\">https://doi.org/10.1111/j.1460-9568.2007.05312.x</a></p>\n</li>\n<li><p>Lee, I., Kesner, R. Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nat Neurosci 5, 162–168 (2002). <a href=\"https://doi.org/10.1038/nn790\">https://doi.org/10.1038/nn790</a></p>\n</li>\n<li><p>Lee, I., &amp; Kesner, R. P. (2004). Encoding versus retrieval of spatial memory: double dissociation between the dentate gyrus and the perforant path inputs into CA3 in the dorsal hippocampus. Hippocampus, 14(1), 66–76. <a href=\"https://doi.org/10.1002/hipo.10167\">https://doi.org/10.1002/hipo.10167</a></p>\n</li>\n<li><p>Lee, I., &amp; Solivan, F. (2010). Dentate gyrus is necessary for disambiguating similar object-place representations. Learning &amp; Memory, 17(5), 252-258.</p>\n</li>\n<li><p>Lee, S. E., Simons, S. B., Heldt, S. A., Zhao, M., Schroeder, J. P., Vellano, C. P., et al. (2010). RGS14 is a natural suppressor of both synaptic plasticity in CA2 neurons and hippocampal-based learning and memory. Proc. Natl. Acad. Sci. U.S.A. 107, 16994–16998. doi: 10.1073/pnas.1005362107</p>\n</li>\n<li><p>Dudek, S. M., Alexander, G. M., and Farris, S. (2016). Rediscovering area CA2: unique properties and function. Nat. Rev. Neurosci. 17, 89–102. doi: 10.1038/nrn.2015.22</p>\n</li>\n<li><p>Wersinger, S. R., Ginns, E. I., O’Carroll, A. M., Lolait, S. J., and Young, W. S. III (2002). Vasopressin V1b receptor knockout reduces aggressive behavior in male mice. Mol. Psychiatry 7, 975–984. doi: 10.1038/sj.mp.4001195</p>\n</li>\n<li><p>Prediger, R. D., and Takahashi, R. N. (2005). Modulation of short-term social memory in rats by adenosine A1 and A(2A) receptors. Neurosci. Lett. 376, 160–165. doi: 10.1016/j.neulet.2004.11.049</p>\n</li>\n<li><p>DeVito, L. M., Konigsberg, R., Lykken, C., Sauvage, M., Young, W. S. III, and Eichenbaum, H. (2009). Vasopressin 1b receptor knockout impairs memory for temporal order. J. Neurosci. 29, 2676–2683. doi: 10.1523/JNEUROSCI.5488-08.2009</p>\n</li>\n<li><p>Caruana, D. A., Alexander, G. M., and Dudek, S. M. (2012). New insights into the regulation of synaptic plasticity from an unexpected place: hippocampal area CA2. Learn. Mem. 19, 391–400. doi: 10.1101/lm.025304.111</p>\n</li>\n<li><p>Martinez, C. O., Do, V. H., Martinez, J. L., Derrick, B.E. (2002) Associative long-term potentiation (LTP) among extrinsic afferents of the hippocampal CA3 region in vivo. Brain Res. 940:86–94</p>\n</li>\n<li><p>Nakazawa, K., Sun, L.D., Quirk, M.C., Rondi-Reig, L., Wilson, M.A., Tonegawa, S. (2003). Hippocampal CA3 NMDA receptors are crucial for memory acquisition of one-time experience. Neuron 38, 305–315.</p>\n</li>\n<li><p>Huang, Y. Q., Lu, W. Y., Aoto, H., Sasaki, T., Salter, M. W., &amp; MacDonald, J. F. (1999). Upregulation of NMDA receptor function by tyrosine kinase CAKβ;/Pyk2. In Soc Neurosci Abstr (Vol. 25, p. 785).</p>\n</li>\n<li><p>Nosten-Bertrand, M., Errington, M. L., Murphy, K. P. S. J., Tokugawa, Y., Barboni, E., Kozlova, E., ... &amp; Morris, R. J. (1996). Normal spatial learning despite regional inhibition of LTP in mice lacking Thy-1. Nature, 379(6568), 826-829.</p>\n</li>\n<li><p>Huang, Y. Y., Kandel, E. R., Varshavsky, L., Brandont, E. P., Qi, M., Idzerda, R. L., ... &amp; Bourtchouladz, R. (1995). A genetic test of the effects of mutations in PKA on mossy fiber LTP and its relation to spatial and contextual learning. Cell, 83(7), 1211-1222.</p>\n</li>\n<li><p>Bromer, C., Bartol, T. M., Bowden, J. B., Hubbard, D. D., Hanka, D. C., Gonzalez, P. V., Kuwajima, M., Mendenhall, J. M., Parker, P. H., Abraham, W. C., Sejnowski, T. J., &amp; Harris, K. M. (2018). Long-term potentiation expands information content of hippocampal dentate gyrus synapses. Proceedings of the National Academy of Sciences of the United States of America, 115(10), E2410–E2418. <a href=\"https://doi.org/10.1073/pnas.1716189115\">https://doi.org/10.1073/pnas.1716189115</a></p>\n</li>\n<li><p>Okada, T., Yamada, N., Tsuzuki, K., Horikawa, H. P., Tanaka, K., &amp; Ozawa, S. (2003). Long-term potentiation in the hippocampal CA1 area and dentate gyrus plays different roles in spatial learning. The European journal of neuroscience, 17(2), 341–349. <a href=\"https://doi.org/10.1046/j.1460-9568.2003.02458.x\">https://doi.org/10.1046/j.1460-9568.2003.02458.x</a></p>\n</li>\n<li><p>Errington, M.L., Bliss, T.V., Morris, R.J., Laroche, S., Davis, S. (1997). Long-term potentiation in awake mutant mice. Nature 387, 666–667.</p>\n</li>\n<li><p>Xavier, G.F., Oliveira-Filho, F.J.B. &amp; Santos, A.M.G. (1999) Dentate gyrus-selective colchicine lesion and disruption of performance in spatial tasks: difficulties in ‘place strategy’ because of a lack of flexibility in the use of environmental cues? Hippocampus, 9, 668–681.</p>\n</li>\n<li><p>Jeltsch, H., Bertrand, F., Lazarus, C. &amp; Cassel, J.-C. (2001) Cognitive performances and locomotor activity following dentate granule cell damage in rats: role of lesion extent and type of memory tested. Neurobiol. Learn. Mem., 76, 81–105.</p>\n</li>\n<li><p>van Asselen, M., Kessels, R. P., Neggers, S. F., Kappelle, L. J., Frijns, C. J., &amp; Postma, A. (2006). Brain areas involved in spatial working memory. Neuropsychologia, 44(7), 1185–1194. <a href=\"https://doi.org/10.1016/j.neuropsychologia.2005.10.005\">https://doi.org/10.1016/j.neuropsychologia.2005.10.005</a></p>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Discuss-whether-or-not-NMDA-receptor-dependent-LTP-in-different-hippocampal-subregions-can-have-distinct-roles-in-learning-and-memory\"><a href=\"#Discuss-whether-or-not-NMDA-receptor-dependent-LTP-in-different-hippocampal-subregions-can-have-distinct-roles-in-learning-and-memory\" class=\"headerlink\" title=\"Discuss whether or not NMDA  receptor-dependent LTP in different hippocampal subregions can have distinct  roles in learning and memory\"></a>Discuss whether or not NMDA  receptor-dependent LTP in different hippocampal subregions can have distinct  roles in learning and memory</h1><p>The hippocampus is generally considered to be the foundation of memory and learning. As early as 1949, Hebb proposed that learning and memory are stored as changes in the strength of synaptic connections between neurons. Along with the discovery of the LTP phenomenon by Bliss &amp; Lomo (1973) and subsequent research, the hypothesis that the LTP provides a neural basis for learning and memory formation has been widely accepted by the public. The NMDAR-dependent LTP processes in the hippocampus, especially in the CA1 subregion of the hippocampus, are thought to be the neural basis for spatial learning and memory (Martin et al., 2000, Bliss &amp; Collingridge, 1993). The hippocampus consists of four Cornu Ammonis regions (CA1 to CA4) and dentate gyrus (DG), of which CA4 can also be considered part of the DG due to the partial overlap of structure and function (Andersen et al., 2007, Anand &amp; Dhikav, 2012). With the desire of studying hippocampal subregions, one question is proposed: how can we specifically study the subregions? The arrangement of hippocampal neurons allows the hippocampus to be sliced, leaving most of the relevant circuitry intact (Purves, Augustine &amp; Fitzpatrick, 2001). The undamaged circuit of the individual subregions ensures the feasibility and authenticity of our study about each subregion. Thus, in-depth study of each subregion has become a hot topic in the past decades. This essay aims to discuss NMDAR-dependent LTP in different hippocampal subregions can have distinct and similar roles in learning and memory.</p>\n<p>LTP can be observed at three main excitatory synapses in the hippocampal circuit, the excitatory synaptic pathway of the hippocampus. In this circuit, the perforant pathway extends from pyramidal cells in the entorhinal area to granule cells in the DG; the mossy fibre pathway extends from granule cells in the DG to CA3 pyramidal cells; Schaffer collateral pathways from CA3 pyramidal cells to CA1 pyramidal cells (Fig 1). Bliss &amp; Collingridge (1993), Nicoll &amp; Malenka (1995) believe that two subregions, CA1 and DG, show NMDAR-dependent LTP. However, their findings do not imply the absence of NMDA receptor-dependent LTP in other hippocampal subregions due to the limitations in-vitro experiments. In 2002, Lee &amp; Kesner collected some data indicating the involvement of NMDAR in CA3, which may be explained as an attractor state (a temporarily self-sustaining state), with a computational model based on physiological evidence and behavioural experiments. In this research, Lee suggested behavioural evidence for differences in NMDAR spatial working memory function among hippocampal subregions. Lee&#39;s research eliminates the influence of another type of LTP with the local subregion-specific injection of NMDAR antagonists. As the participation of CA3, the role of the hippocampal NMDAR-dependent LTP might be misunderstood. However, previous research still cannot explain the role in the hippocampal subregions well. The association hypothesis between NMDAR-dependent LTP and learning and memory in hippocampal subregions require more experiments to validate. When we focus on each subregion, their distinct and similar roles in learning and memory may be revealed.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202161917751.png\" alt=\"image-20220216191746673\"></p>\n<p><strong>Figure 1</strong>. LTP in Schaffer collateral pathway, mossy fibre pathway and perforant pathway (Chen et al. 1997)</p>\n<p>The CA1 subregion is the neural foundation linking spatial learning and memory. Tsien et. al (1996a, 1996b) knockout the GluN1 subunit (in NMDAR) resulting in the deficit of LTP in Schaffer collateral CA1 synapses finding the spatial reference memory is impaired in mice. This research directly proves that NMDAR-dependent LTP at CA1 synapses is the neural foundation for associative, long-term spatial memory formation. Additionally, CA1-KO mice lack NMDAR-mediated postsynaptic currents and LTP in CA1. These mice showed impaired spatial memory in the Morris hidden platform water maze, in the opposite, performed well on non-spatial learning tasks. The results provide contrastive support for the hypothesis that NMDAR-mediated LTP in the CA1 region is critical for the formation of some specific types of memory. Similarly, spatial learning deficits were reported in mice with the impaired LTP in CA1 owing to the lack of the gene encoding α subunit of calmodulin-dependent protein kinase II (αCaMKII) (Silva et al., 1992a, 1992b). These mice lack spatial memory, the same as spatial memory deficits in CA1-KO mice. A possible shortcoming in this experiment is that previous experiments are based on direct injection of NMDAR antagonists into the brain, which may not be sufficiently convincing in terms of regional idiosyncrasy. According to Hestrin&#39;s discovery in 1996: NMDAR contributes to synaptic transmission in some regions of the neocortex. We can conclude that memory impairment can be explained, at least in part, by deficits in the computing ability of the neocortex, rather than impairments in synaptic plasticity within the hippocampus. Subsequently, Bannerman et al. (2012) used transgenic mice lacking the GluN1 subunit and NMDARs in the pyramidal cells of CA1 and the granule cells of DG finding that the spatial reference memory of the mice acquired the radial maze task was impaired. It furtherly demonstrates the fact: hippocampal CA1 plays an important role in the learning of spatial reference memory. In 2013, it took a turn when Taylor et al. found that such mice performed well on the classic open-field spatial reference memory water maze task. How can it happen? It possibly indicates that the hippocampal NMDAR is not actually required for the formation of long-term associative spatial memory, which is against Tsien&#39;s results. But Taylor does not explain this in detail, thus it cannot determine whether there are any other compensatory mechanisms for NMDA-dependent LTP. Whatever, as Niewoehner et al. (2007) argues, the development of spatially restricted genetic modifications has identified synaptic plasticity, which is a broader idea than LTP, with specific and separable roles in different hippocampal subregions. We may want to see more genetic modification experiments in this field. Despite the shortcomings of these research, the inter-experimental corroboration still demonstrates that CA1 has an irreplaceable role in associative, long-term spatial memory. We can consider CA1 LTP to be the basis of spatial memory formation.</p>\n<p>In the CA2 subregion, NMDA-dependent LTP cannot be induced. Zhao et al. (2007) attempted to test whether synaptic stimulation could induce LTP in CA2 neurons, which is proved to induce NMDAR-dependent LTP in CA1, using a variety of approaches including perforated whole-cell patch-clamp recording. However, all results lead to that the synaptic current is not increased. One of the explanations from Caruana, Alexander, &amp; Dudek (2012) is that the high expression of TREK-1 and TREK-2 potassium channels in CA2, compared with other hippocampal subregions, leads to the lack of LTP. These channels produce potassium-mediated leakage currents significantly hyperpolarizing the resting membrane potential. Thus, larger depolarizing currents are required to initiate LTP. Therefore, is it necessary to look for the memory learning function of LTP in CA2? Zhao compared the expression patterns of NMDAR mRNAs in CA2 and CA3 finding that those mRNAs are expressed in both subregions. What distinguish the CA2 and the CA3? Certain &quot;memory suppressor&quot; genes (e.g., RGS14) play a key role in suppressing LTP induction (Lee et al., 2010a, 2010b, Dudek et al., 2016). More evidence suggests that the induction of NMDAR-dependent LTP and memory formation in CA2 can occur under very specific conditions (Wersinger et al., 2002, Prediger &amp; Takahashi, 2005, DeVito et al., 2009, Caruana et al., 2012). We conclude that NMDAR-dependent LTP in the CA2 area is rare, but not impossible. Therefore, its role in CA2 needs further study.</p>\n<p>The NMDAR-dependent LTP in CA3 is involved in learning and memory storage acquisition although NMDAR-dependent LTP in CA3 is uncommon. The fact that LTP in the Moss fiber-CA3 system coincides with the progress in learning demonstrates the role of CA3 in learning and memory. Based on electrophysiological data by Martinez et al. (2002), an associative LTP was found in the perforant pathway inputting into CA3, which means that there is NMDAR-dependent LTP between perforant pathway and the CA3 synapse. The following step is to study its function. Nakazawa et al. (2003) found that &quot;one-time learning&quot; is blocked by specific knockout of CA3 NMDAR in mice. We thus argue that NMDA-dependent LTP in CA3 plays an important role in the information acquiring and storing from new experiences. Lee &amp; Kesner&#39;s (2004) study also demonstrated that CA3 neurons are activated during recall of objects or locations. It refers that NMDA-dependent LTP in CA3 may affect object-location pairing association tasks. In hippocampal CA3, two distinct forms of LTP have been described, one of which is the classical NMDA-dependent LTP (Zalutsky and Nicoll, 1990). The disadvantage of these experiments is that we do not know whether to confirm the function of another LTP and whether it is also involved in memory and learning functions. Although these experiments do not cover all types of LTPs, at least we know that NMDAR-dependent LTP in CA3 is involved in memory acquisition.</p>\n<p>The NMDAR-dependent LTP in DG focuses more on spatial working memory (SWM) (Active spatial information in working memory over a short period (van Asselen et al., 2006)) than spatial reference memory (SRM). Nosten-Bertrand et al. (1996) first proposed that spatial learning is not obviously blocked in the absence of a DG LTP gene anaesthetized rats, which we mentioned present in CA1. Although a subsequent study by Errington et al. (1997) speculated that this phenomenon may be due to the effect of gene knockout on inhibitory neurons. Additional evidence for this hypothesis is that massive loss of the NR1 subunit of the NMDAR only showed severely impaired LTP in the perforant pathway inputs of the DG, whereas LTP is unchanged from CA3 to CA1. Based on this study, behavioural assessments of these mice show significant SWM impairment but no effect on hippocampal-dependent SRM performance for the same task. However, other studies have demonstrated that DG selectivity, fibre-sparing, and colchicine lesions can lead to impairment of both SWM and SRM (Xavier, Oliveira-Filho &amp; Santos, 1999). This is complemented with behavioural experiments by Jeltsch et al. (2001), where DG impairment significantly increases SRM and SWM errors in the four-from-eight radial maze task. The downside, however, is that these results fail to provide positive evidence for the hypothesis that NMDAR-mediated synaptic plasticity in the DG supports spatial pattern separation. The present results cannot completely rule out a role for the NMDAR LTP in the DG in spatial pattern separation across tasks, although it is clearly shown that any putative role must be limited to the working memory. We can argue that DG may be involved in both spatial working memory and SRM but is more focused on spatial working memory.</p>\n<p>The biggest difference among the function of NMDAR-dependent LTP hippocampal subregions is the roles these played in spatial learning. According to earlier studies, in contrast to CA1, damages to mossy fibre to CA3 LTP (Huang et al., 1995) and perforant pathway to DG LTP (Nosten-Bertrand et al., 1996) are not associated with deficits in spatial memory. Huang et al. (1999) found that mossy fibre CA3 LTP and perforant DG LTP are dispensable for spatial learning. This is consistent with the notion that CA1 LTP is critical for spatial learning. CA1 LTPs are particularly important for spatial and contextual learning in the hippocampus compared to CA3 or DG LTPs. What is more, subsequent further studies confirmed that other subregions are also involved in learning and memory. Okada et al. (2003) examined the effect of NMDA-dependent LTP on spatial learning in rats after increasing the extent of NMDA-dependent LTP by using viral vectors for gene editing. It is demonstrated that although CA1 and the DG have similar mechanisms of LTP induction, they play distinct functional roles in spatial learning. To explore the differences in information storage capacity, Bromer et al. (2018) used a method combining signal detection theory with accurate 3D reconstruction of serial section electron microscopy to study in vivo perforant pathway LTP processes in the DG of the mature hippocampus. Bromer et al. investigate synaptic plasticity and information storage capacity. It is found that the information storage capacity of the DG is much lower than CA1. This study elucidates the temporal LTP process of storing information and the inter-regional variation of information storage capacity, that is, differences in spatial learning between CA1 and DG.</p>\n<p>This essay focuses on the roles of NMDAR-dependent LTP in learning and memory in various hippocampal subregions. From these studies, we can conclude that the NMDA-dependent LTP in CA1 and the DG gets involved in acquiring memory that needs to be retrieved after a delay period beyond the short-term. CA1 is the basis of spatial memory formation, associating spatial learning and memory. DG also plays an important role in spatial working memory, mainly in spatial working memory. The NMDAR-dependent LTP in CA3 is significant in situations where reorganization of spatial representations memory is required. It is involved in memory acquisition as well, with a focus on spatial reference memory. The recognition of each subregion can help us understand the integral mechanism. We should consider each subregion separately but focus on the overall functional interaction. It may become an innovative point for future research. Although many computational models and anatomical studies have highlighted functional differences between NMDAR-dependent LTP in the hippocampus, the subregional heterogeneity of NMDAR function is still largely unknown. Therefore, as the technology develops, the following research on the mechanisms of NMDA-dependent LTP in each subregion and interaction are supposed to be further explored.</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a><strong>Reference</strong></h2><ol>\n<li><p>Hebb, D. O. (1949). The organization of behavior. New York, NY: John Wiley.</p>\n</li>\n<li><p>Bliss, T. V., &amp; Lomo, T. (1973). Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. The Journal of physiology, 232(2), 331–356. <a href=\"https://doi.org/10.1113/jphysiol.1973.sp010273\">https://doi.org/10.1113/jphysiol.1973.sp010273</a></p>\n</li>\n<li><p>Bliss, T. V., &amp; Collingridge, G. L. (1993). A synaptic model of memory: long-term potentiation in the hippocampus. Nature, 361(6407), 31–39. <a href=\"https://doi.org/10.1038/361031a0\">https://doi.org/10.1038/361031a0</a></p>\n</li>\n<li><p>Martin, S. J., Grimwood, P. D., &amp; Morris, R. G. (2000). Synaptic plasticity and memory: an evaluation of the hypothesis. Annual review of neuroscience, 23, 649–711. <a href=\"https://doi.org/10.1146/annurev.neuro.23.1.649\">https://doi.org/10.1146/annurev.neuro.23.1.649</a></p>\n</li>\n<li><p>Andersen, P., Morris, R., Amaral, D., Bliss, T., &amp; O&#39;Keefe, J. (2007). The Hippocampus Book. Oxford University press.</p>\n</li>\n<li><p>Anand, K. S., &amp; Dhikav, V. (2012). Hippocampus in health and disease: An overview. Annals of Indian Academy of Neurology, 15(4), 239–246. <a href=\"https://doi.org/10.4103/0972-2327.104323\">https://doi.org/10.4103/0972-2327.104323</a></p>\n</li>\n<li><p>Purves, D., Augustine, G. J., Fitzpatrick, D. (2001). Neuroscience. 2nd edition.</p>\n</li>\n<li><p>Lee, I., &amp; Kesner, R. P. (2002). Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nature neuroscience, 5(2), 162–168. <a href=\"https://doi.org/10.1038/nn790\">https://doi.org/10.1038/nn790</a></p>\n</li>\n<li><p>Tsien, J. Z., Chen, D. F., Gerber, D., Tom, C., Mercer, E. H., Anderson, D. J., Mayford, M., Kandel, E. R., &amp; Tonegawa, S. (1996). Subregion- and cell type-restricted gene knockout in mouse brain. Cell, 87(7), 1317–1326. <a href=\"https://doi.org/10.1016/s0092-8674(00)81826-7\">https://doi.org/10.1016/s0092-8674(00)81826-7</a></p>\n</li>\n<li><p>Tsien, J. Z., Huerta, P. T., &amp; Tonegawa, S. (1996). The essential role of hippocampal CA1 NMDA receptor-dependent synaptic plasticity in spatial memory. Cell, 87(7), 1327–1338. <a href=\"https://doi.org/10.1016/s0092-8674(00)81827-9\">https://doi.org/10.1016/s0092-8674(00)81827-9</a></p>\n</li>\n<li><p>Bannerman, D. M., Bus, T., Taylor, A., Sanderson, D. J., Schwarz, I., Jensen, V., Hvalby, Ø., Rawlins, J. N., Seeburg, P. H., &amp; Sprengel, R. (2012). Dissecting spatial knowledge from spatial choice by hippocampal NMDA receptor deletion. Nature neuroscience, 15(8), 1153–1159. <a href=\"https://doi.org/10.1038/nn.3166\">https://doi.org/10.1038/nn.3166</a></p>\n</li>\n<li><p>Taylor, A. M., Bus, T., Sprengel, R., Seeburg, P. H., Rawlins, J. N., &amp; Bannerman, D. M. (2013). Hippocampal NMDA receptors are important for behavioural inhibition but not for encoding associative spatial memories. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 369(1633), 20130149. <a href=\"https://doi.org/10.1098/rstb.2013.0149\">https://doi.org/10.1098/rstb.2013.0149</a></p>\n</li>\n<li><p>Silva, A. J., Stevens, C. F., Tonegawa, S., &amp; Wang, Y. (1992). Deficient hippocampal long-term potentiation in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 201–206. <a href=\"https://doi.org/10.1126/science.1378648\">https://doi.org/10.1126/science.1378648</a></p>\n</li>\n<li><p>Silva, A. J., Paylor, R., Wehner, J. M., &amp; Tonegawa, S. (1992). Impaired spatial learning in alpha-calcium-calmodulin kinase II mutant mice. Science (New York, N.Y.), 257(5067), 206–211. <a href=\"https://doi.org/10.1126/science.1321493\">https://doi.org/10.1126/science.1321493</a></p>\n</li>\n<li><p>Chen, C. &amp; Tonegawa, S. (1997). MOLECULAR GENETIC ANALYSIS OF SYNAPTIC PLASTICITY, ACTIVITY-DEPENDENT NEURAL DEVELOPMENT, LEARNING, AND MEMORY IN THE MAMMALIAN BRAIN. Annual review of neuroscience, 20 (1), s. 157–184. doi: 10.1146/annurev.neuro.20.1.157</p>\n</li>\n<li><p>Hestrin, S. (1996). Physiology of NMDA receptors and synaptic currents. Excitatory amino acids and the cerebral cortex. Edited by F. Conti and TP Hicks. MIT Press/Bradford Books, Cambridge, Mass, 53-62.</p>\n</li>\n<li><p>Niewoehner, B., Single, F. N., Hvalby, Ø., Jensen, V., Meyer zum Alten Borgloh, S., Seeburg, P. H., Rawlins, J. N., Sprengel, R., &amp; Bannerman, D. M. (2007). Impaired spatial working memory but spared spatial reference memory following functional loss of NMDA receptors in the dentate gyrus. The European journal of neuroscience, 25(3), 837–846. <a href=\"https://doi.org/10.1111/j.1460-9568.2007.05312.x\">https://doi.org/10.1111/j.1460-9568.2007.05312.x</a></p>\n</li>\n<li><p>Lee, I., Kesner, R. Differential contribution of NMDA receptors in hippocampal subregions to spatial working memory. Nat Neurosci 5, 162–168 (2002). <a href=\"https://doi.org/10.1038/nn790\">https://doi.org/10.1038/nn790</a></p>\n</li>\n<li><p>Lee, I., &amp; Kesner, R. P. (2004). Encoding versus retrieval of spatial memory: double dissociation between the dentate gyrus and the perforant path inputs into CA3 in the dorsal hippocampus. Hippocampus, 14(1), 66–76. <a href=\"https://doi.org/10.1002/hipo.10167\">https://doi.org/10.1002/hipo.10167</a></p>\n</li>\n<li><p>Lee, I., &amp; Solivan, F. (2010). Dentate gyrus is necessary for disambiguating similar object-place representations. Learning &amp; Memory, 17(5), 252-258.</p>\n</li>\n<li><p>Lee, S. E., Simons, S. B., Heldt, S. A., Zhao, M., Schroeder, J. P., Vellano, C. P., et al. (2010). RGS14 is a natural suppressor of both synaptic plasticity in CA2 neurons and hippocampal-based learning and memory. Proc. Natl. Acad. Sci. U.S.A. 107, 16994–16998. doi: 10.1073/pnas.1005362107</p>\n</li>\n<li><p>Dudek, S. M., Alexander, G. M., and Farris, S. (2016). Rediscovering area CA2: unique properties and function. Nat. Rev. Neurosci. 17, 89–102. doi: 10.1038/nrn.2015.22</p>\n</li>\n<li><p>Wersinger, S. R., Ginns, E. I., O’Carroll, A. M., Lolait, S. J., and Young, W. S. III (2002). Vasopressin V1b receptor knockout reduces aggressive behavior in male mice. Mol. Psychiatry 7, 975–984. doi: 10.1038/sj.mp.4001195</p>\n</li>\n<li><p>Prediger, R. D., and Takahashi, R. N. (2005). Modulation of short-term social memory in rats by adenosine A1 and A(2A) receptors. Neurosci. Lett. 376, 160–165. doi: 10.1016/j.neulet.2004.11.049</p>\n</li>\n<li><p>DeVito, L. M., Konigsberg, R., Lykken, C., Sauvage, M., Young, W. S. III, and Eichenbaum, H. (2009). Vasopressin 1b receptor knockout impairs memory for temporal order. J. Neurosci. 29, 2676–2683. doi: 10.1523/JNEUROSCI.5488-08.2009</p>\n</li>\n<li><p>Caruana, D. A., Alexander, G. M., and Dudek, S. M. (2012). New insights into the regulation of synaptic plasticity from an unexpected place: hippocampal area CA2. Learn. Mem. 19, 391–400. doi: 10.1101/lm.025304.111</p>\n</li>\n<li><p>Martinez, C. O., Do, V. H., Martinez, J. L., Derrick, B.E. (2002) Associative long-term potentiation (LTP) among extrinsic afferents of the hippocampal CA3 region in vivo. Brain Res. 940:86–94</p>\n</li>\n<li><p>Nakazawa, K., Sun, L.D., Quirk, M.C., Rondi-Reig, L., Wilson, M.A., Tonegawa, S. (2003). Hippocampal CA3 NMDA receptors are crucial for memory acquisition of one-time experience. Neuron 38, 305–315.</p>\n</li>\n<li><p>Huang, Y. Q., Lu, W. Y., Aoto, H., Sasaki, T., Salter, M. W., &amp; MacDonald, J. F. (1999). Upregulation of NMDA receptor function by tyrosine kinase CAKβ;/Pyk2. In Soc Neurosci Abstr (Vol. 25, p. 785).</p>\n</li>\n<li><p>Nosten-Bertrand, M., Errington, M. L., Murphy, K. P. S. J., Tokugawa, Y., Barboni, E., Kozlova, E., ... &amp; Morris, R. J. (1996). Normal spatial learning despite regional inhibition of LTP in mice lacking Thy-1. Nature, 379(6568), 826-829.</p>\n</li>\n<li><p>Huang, Y. Y., Kandel, E. R., Varshavsky, L., Brandont, E. P., Qi, M., Idzerda, R. L., ... &amp; Bourtchouladz, R. (1995). A genetic test of the effects of mutations in PKA on mossy fiber LTP and its relation to spatial and contextual learning. Cell, 83(7), 1211-1222.</p>\n</li>\n<li><p>Bromer, C., Bartol, T. M., Bowden, J. B., Hubbard, D. D., Hanka, D. C., Gonzalez, P. V., Kuwajima, M., Mendenhall, J. M., Parker, P. H., Abraham, W. C., Sejnowski, T. J., &amp; Harris, K. M. (2018). Long-term potentiation expands information content of hippocampal dentate gyrus synapses. Proceedings of the National Academy of Sciences of the United States of America, 115(10), E2410–E2418. <a href=\"https://doi.org/10.1073/pnas.1716189115\">https://doi.org/10.1073/pnas.1716189115</a></p>\n</li>\n<li><p>Okada, T., Yamada, N., Tsuzuki, K., Horikawa, H. P., Tanaka, K., &amp; Ozawa, S. (2003). Long-term potentiation in the hippocampal CA1 area and dentate gyrus plays different roles in spatial learning. The European journal of neuroscience, 17(2), 341–349. <a href=\"https://doi.org/10.1046/j.1460-9568.2003.02458.x\">https://doi.org/10.1046/j.1460-9568.2003.02458.x</a></p>\n</li>\n<li><p>Errington, M.L., Bliss, T.V., Morris, R.J., Laroche, S., Davis, S. (1997). Long-term potentiation in awake mutant mice. Nature 387, 666–667.</p>\n</li>\n<li><p>Xavier, G.F., Oliveira-Filho, F.J.B. &amp; Santos, A.M.G. (1999) Dentate gyrus-selective colchicine lesion and disruption of performance in spatial tasks: difficulties in ‘place strategy’ because of a lack of flexibility in the use of environmental cues? Hippocampus, 9, 668–681.</p>\n</li>\n<li><p>Jeltsch, H., Bertrand, F., Lazarus, C. &amp; Cassel, J.-C. (2001) Cognitive performances and locomotor activity following dentate granule cell damage in rats: role of lesion extent and type of memory tested. Neurobiol. Learn. Mem., 76, 81–105.</p>\n</li>\n<li><p>van Asselen, M., Kessels, R. P., Neggers, S. F., Kappelle, L. J., Frijns, C. J., &amp; Postma, A. (2006). Brain areas involved in spatial working memory. Neuropsychologia, 44(7), 1185–1194. <a href=\"https://doi.org/10.1016/j.neuropsychologia.2005.10.005\">https://doi.org/10.1016/j.neuropsychologia.2005.10.005</a></p>\n</li>\n</ol>\n"},{"layout":"post","title":"Nature of dopamine dysfunction in schizophrenia","date":"2022-01-22T09:56:06.000Z","_content":"\n\n\n# How do we measure dopamine in the living human brain and what do these measures tell us about the nature of dopamine dysfunction in schizophrenia?\n\nIn the brain of humans, most of the dopamine cells are located in the anterior part of the midbrain or the midbrain itself, especially in the striatum.\n\nThere are various methods to measure dopamine in the living human brain,\n\n1. Microdialysis, a method with relatively small damage to the tested tissue and high sensitivity. A microdialysis probe is surgically inserted into the brain region that we want to study. The front end of the probe is covered by a semipermeable fibre membrane, and the two ends are connected to the inlet and outlet tubes of artificial cerebrospinal fluid. The dopamine in human brain passively diffuses across the semipermeable membrane into the artificial cerebrospinal fluid by the exchange of substances in artificial cerebrospinal fluid and in the cerebrospinal fluid. This is a sensitive method, however, unfortunately, it has a low temporal resolution.\n\n2. Electrochemical method. The first step, the same as the method mentioned above, is to undergo surgery to implant deep-brain stimulation electrodes. The carbon fibre electrodes are placed near the surface of the cells to be recorded, and a certain voltage is applied to the electrodes, which is kept higher than the redox potential of the neurotransmitters to be detected. The fast scan cyclic voltammetry is used with the electrodes to collect the electrical signals for relevant fast dopamine pulse and obtains results after a series of processes and analyses. This method results in a specific detection at the cellular level. However, although the fast-scan cyclic voltammetry has high temporal resolution and certain specificity of neurotransmitter molecules, it is difficult to achieve simultaneous detection of multiple regions.\n\n3. Molecular imaging, a non-invasive methodology. One important method is positron emission tomography, PET. In this molecular imaging method, a radiolabelled ligand is administered intravenously. Afterwards, the patients are placed in a PET camera, and the data is collected every few seconds while the volunteers perform tasks in the scanner. If the neurotransmitter is released during the scan, the concentration of ligand in the receptor will decrease as it is replaced by the endogenously released neurotransmitter. The dopamine synthesis and the concentration of transporters, which are positively correlated with dopamine cells, can be measured in this way. The test involves injecting a radioactive substance that binds to a dopamine transporter, which can be measured using the camera. \n\nHowever, the researchers may be more interested in the interpretation of the nature of dopamine dysfunction in schizophrenia by these measurements than by the methods.\n\nIn previous studies, both striatal dopamine synthesis capacity and release are found to be elevated in patients with schizophrenia. Clinically, schizophrenia is generally classified as a dopaminergic sub-type and a non-dopaminergic sub-type. For antipsychotic responders, the measure for dopamine via the measure for the dopamine-related enzyme is shown to have a higher level, while indirectly demonstrating psychosis patients have higher dopamine synthesis capacity and the disease is responsive to subsequent antipsychotic treatment. The level of dopamine synthesis and secretion is related to the treatment of schizophrenia. With Voxel-wise analysis, The research of Jauhar et. al demonstrate that the lack of dopamine synthesis is consistent with whether patients respond to the treatments in the clinic has consistency with dopamine dysfunction. For the patients who responded to treatment, there is an increase in dopamine synthesis capacity relative to non-responder. Patients who responded to treatment had increased dopamine synthesis capacity compared with healthy individuals. The classic dopamine hypothesis states that the dopamine dysfunction in the prefrontal cortex leads to negative symptoms in schizophrenia, while dopamine hyperfunction in the mesolimbic pathway leads to positive symptoms. The measurement of dopamine in neuroimaging informs us about the phenomenon of dopamine dysfunction in schizophrenia. And combining with the basis that dopamine signalling is involved in labelling environmental spurs, we can predict that dopamine dysfunction in striatal regions is the main cause of schizophrenia which may lead to functional impairment of striatal regions,\n\nHowever, our detection techniques for the brain are still not accurate enough, such as we cannot accurately detect receptor and synaptic dopamine levels in vivo. Based on the current level of science and technology, we cannot fully understand the role of the dopamine system in the start and development of schizophrenia. Nevertheless, the dopamine hypothesis is still powerful and relevant. With the continuous increase of human understanding of the brain, targeting this system, the development of new treatments still has great potential and prospects.\n","source":"_posts/2022-01-22-Nature-of-dopamine-dysfunction-in-schizophrenia.md","raw":"---\nlayout: post\ntitle:  \"Nature of dopamine dysfunction in schizophrenia\"\ndate:   2022-01-22 09:56:06\ncategories: discussion\ntags: Neuroscience\n---\n\n\n\n# How do we measure dopamine in the living human brain and what do these measures tell us about the nature of dopamine dysfunction in schizophrenia?\n\nIn the brain of humans, most of the dopamine cells are located in the anterior part of the midbrain or the midbrain itself, especially in the striatum.\n\nThere are various methods to measure dopamine in the living human brain,\n\n1. Microdialysis, a method with relatively small damage to the tested tissue and high sensitivity. A microdialysis probe is surgically inserted into the brain region that we want to study. The front end of the probe is covered by a semipermeable fibre membrane, and the two ends are connected to the inlet and outlet tubes of artificial cerebrospinal fluid. The dopamine in human brain passively diffuses across the semipermeable membrane into the artificial cerebrospinal fluid by the exchange of substances in artificial cerebrospinal fluid and in the cerebrospinal fluid. This is a sensitive method, however, unfortunately, it has a low temporal resolution.\n\n2. Electrochemical method. The first step, the same as the method mentioned above, is to undergo surgery to implant deep-brain stimulation electrodes. The carbon fibre electrodes are placed near the surface of the cells to be recorded, and a certain voltage is applied to the electrodes, which is kept higher than the redox potential of the neurotransmitters to be detected. The fast scan cyclic voltammetry is used with the electrodes to collect the electrical signals for relevant fast dopamine pulse and obtains results after a series of processes and analyses. This method results in a specific detection at the cellular level. However, although the fast-scan cyclic voltammetry has high temporal resolution and certain specificity of neurotransmitter molecules, it is difficult to achieve simultaneous detection of multiple regions.\n\n3. Molecular imaging, a non-invasive methodology. One important method is positron emission tomography, PET. In this molecular imaging method, a radiolabelled ligand is administered intravenously. Afterwards, the patients are placed in a PET camera, and the data is collected every few seconds while the volunteers perform tasks in the scanner. If the neurotransmitter is released during the scan, the concentration of ligand in the receptor will decrease as it is replaced by the endogenously released neurotransmitter. The dopamine synthesis and the concentration of transporters, which are positively correlated with dopamine cells, can be measured in this way. The test involves injecting a radioactive substance that binds to a dopamine transporter, which can be measured using the camera. \n\nHowever, the researchers may be more interested in the interpretation of the nature of dopamine dysfunction in schizophrenia by these measurements than by the methods.\n\nIn previous studies, both striatal dopamine synthesis capacity and release are found to be elevated in patients with schizophrenia. Clinically, schizophrenia is generally classified as a dopaminergic sub-type and a non-dopaminergic sub-type. For antipsychotic responders, the measure for dopamine via the measure for the dopamine-related enzyme is shown to have a higher level, while indirectly demonstrating psychosis patients have higher dopamine synthesis capacity and the disease is responsive to subsequent antipsychotic treatment. The level of dopamine synthesis and secretion is related to the treatment of schizophrenia. With Voxel-wise analysis, The research of Jauhar et. al demonstrate that the lack of dopamine synthesis is consistent with whether patients respond to the treatments in the clinic has consistency with dopamine dysfunction. For the patients who responded to treatment, there is an increase in dopamine synthesis capacity relative to non-responder. Patients who responded to treatment had increased dopamine synthesis capacity compared with healthy individuals. The classic dopamine hypothesis states that the dopamine dysfunction in the prefrontal cortex leads to negative symptoms in schizophrenia, while dopamine hyperfunction in the mesolimbic pathway leads to positive symptoms. The measurement of dopamine in neuroimaging informs us about the phenomenon of dopamine dysfunction in schizophrenia. And combining with the basis that dopamine signalling is involved in labelling environmental spurs, we can predict that dopamine dysfunction in striatal regions is the main cause of schizophrenia which may lead to functional impairment of striatal regions,\n\nHowever, our detection techniques for the brain are still not accurate enough, such as we cannot accurately detect receptor and synaptic dopamine levels in vivo. Based on the current level of science and technology, we cannot fully understand the role of the dopamine system in the start and development of schizophrenia. Nevertheless, the dopamine hypothesis is still powerful and relevant. With the continuous increase of human understanding of the brain, targeting this system, the development of new treatments still has great potential and prospects.\n","slug":"2022-01-22-Nature-of-dopamine-dysfunction-in-schizophrenia","published":1,"updated":"2022-08-24T17:08:39.335Z","comments":1,"photos":[],"_id":"cuidVeEF_HKFjb6iUVegXAOjc","content":"<h1 id=\"How-do-we-measure-dopamine-in-the-living-human-brain-and-what-do-these-measures-tell-us-about-the-nature-of-dopamine-dysfunction-in-schizophrenia\"><a href=\"#How-do-we-measure-dopamine-in-the-living-human-brain-and-what-do-these-measures-tell-us-about-the-nature-of-dopamine-dysfunction-in-schizophrenia\" class=\"headerlink\" title=\"How do we measure dopamine in the living human brain and what do these measures tell us about the nature of dopamine dysfunction in schizophrenia?\"></a>How do we measure dopamine in the living human brain and what do these measures tell us about the nature of dopamine dysfunction in schizophrenia?</h1><p>In the brain of humans, most of the dopamine cells are located in the anterior part of the midbrain or the midbrain itself, especially in the striatum.</p>\n<p>There are various methods to measure dopamine in the living human brain,</p>\n<ol>\n<li><p>Microdialysis, a method with relatively small damage to the tested tissue and high sensitivity. A microdialysis probe is surgically inserted into the brain region that we want to study. The front end of the probe is covered by a semipermeable fibre membrane, and the two ends are connected to the inlet and outlet tubes of artificial cerebrospinal fluid. The dopamine in human brain passively diffuses across the semipermeable membrane into the artificial cerebrospinal fluid by the exchange of substances in artificial cerebrospinal fluid and in the cerebrospinal fluid. This is a sensitive method, however, unfortunately, it has a low temporal resolution.</p>\n</li>\n<li><p>Electrochemical method. The first step, the same as the method mentioned above, is to undergo surgery to implant deep-brain stimulation electrodes. The carbon fibre electrodes are placed near the surface of the cells to be recorded, and a certain voltage is applied to the electrodes, which is kept higher than the redox potential of the neurotransmitters to be detected. The fast scan cyclic voltammetry is used with the electrodes to collect the electrical signals for relevant fast dopamine pulse and obtains results after a series of processes and analyses. This method results in a specific detection at the cellular level. However, although the fast-scan cyclic voltammetry has high temporal resolution and certain specificity of neurotransmitter molecules, it is difficult to achieve simultaneous detection of multiple regions.</p>\n</li>\n<li><p>Molecular imaging, a non-invasive methodology. One important method is positron emission tomography, PET. In this molecular imaging method, a radiolabelled ligand is administered intravenously. Afterwards, the patients are placed in a PET camera, and the data is collected every few seconds while the volunteers perform tasks in the scanner. If the neurotransmitter is released during the scan, the concentration of ligand in the receptor will decrease as it is replaced by the endogenously released neurotransmitter. The dopamine synthesis and the concentration of transporters, which are positively correlated with dopamine cells, can be measured in this way. The test involves injecting a radioactive substance that binds to a dopamine transporter, which can be measured using the camera. </p>\n</li>\n</ol>\n<p>However, the researchers may be more interested in the interpretation of the nature of dopamine dysfunction in schizophrenia by these measurements than by the methods.</p>\n<p>In previous studies, both striatal dopamine synthesis capacity and release are found to be elevated in patients with schizophrenia. Clinically, schizophrenia is generally classified as a dopaminergic sub-type and a non-dopaminergic sub-type. For antipsychotic responders, the measure for dopamine via the measure for the dopamine-related enzyme is shown to have a higher level, while indirectly demonstrating psychosis patients have higher dopamine synthesis capacity and the disease is responsive to subsequent antipsychotic treatment. The level of dopamine synthesis and secretion is related to the treatment of schizophrenia. With Voxel-wise analysis, The research of Jauhar et. al demonstrate that the lack of dopamine synthesis is consistent with whether patients respond to the treatments in the clinic has consistency with dopamine dysfunction. For the patients who responded to treatment, there is an increase in dopamine synthesis capacity relative to non-responder. Patients who responded to treatment had increased dopamine synthesis capacity compared with healthy individuals. The classic dopamine hypothesis states that the dopamine dysfunction in the prefrontal cortex leads to negative symptoms in schizophrenia, while dopamine hyperfunction in the mesolimbic pathway leads to positive symptoms. The measurement of dopamine in neuroimaging informs us about the phenomenon of dopamine dysfunction in schizophrenia. And combining with the basis that dopamine signalling is involved in labelling environmental spurs, we can predict that dopamine dysfunction in striatal regions is the main cause of schizophrenia which may lead to functional impairment of striatal regions,</p>\n<p>However, our detection techniques for the brain are still not accurate enough, such as we cannot accurately detect receptor and synaptic dopamine levels in vivo. Based on the current level of science and technology, we cannot fully understand the role of the dopamine system in the start and development of schizophrenia. Nevertheless, the dopamine hypothesis is still powerful and relevant. With the continuous increase of human understanding of the brain, targeting this system, the development of new treatments still has great potential and prospects.</p>\n","excerpt":"","more":"<h1 id=\"How-do-we-measure-dopamine-in-the-living-human-brain-and-what-do-these-measures-tell-us-about-the-nature-of-dopamine-dysfunction-in-schizophrenia\"><a href=\"#How-do-we-measure-dopamine-in-the-living-human-brain-and-what-do-these-measures-tell-us-about-the-nature-of-dopamine-dysfunction-in-schizophrenia\" class=\"headerlink\" title=\"How do we measure dopamine in the living human brain and what do these measures tell us about the nature of dopamine dysfunction in schizophrenia?\"></a>How do we measure dopamine in the living human brain and what do these measures tell us about the nature of dopamine dysfunction in schizophrenia?</h1><p>In the brain of humans, most of the dopamine cells are located in the anterior part of the midbrain or the midbrain itself, especially in the striatum.</p>\n<p>There are various methods to measure dopamine in the living human brain,</p>\n<ol>\n<li><p>Microdialysis, a method with relatively small damage to the tested tissue and high sensitivity. A microdialysis probe is surgically inserted into the brain region that we want to study. The front end of the probe is covered by a semipermeable fibre membrane, and the two ends are connected to the inlet and outlet tubes of artificial cerebrospinal fluid. The dopamine in human brain passively diffuses across the semipermeable membrane into the artificial cerebrospinal fluid by the exchange of substances in artificial cerebrospinal fluid and in the cerebrospinal fluid. This is a sensitive method, however, unfortunately, it has a low temporal resolution.</p>\n</li>\n<li><p>Electrochemical method. The first step, the same as the method mentioned above, is to undergo surgery to implant deep-brain stimulation electrodes. The carbon fibre electrodes are placed near the surface of the cells to be recorded, and a certain voltage is applied to the electrodes, which is kept higher than the redox potential of the neurotransmitters to be detected. The fast scan cyclic voltammetry is used with the electrodes to collect the electrical signals for relevant fast dopamine pulse and obtains results after a series of processes and analyses. This method results in a specific detection at the cellular level. However, although the fast-scan cyclic voltammetry has high temporal resolution and certain specificity of neurotransmitter molecules, it is difficult to achieve simultaneous detection of multiple regions.</p>\n</li>\n<li><p>Molecular imaging, a non-invasive methodology. One important method is positron emission tomography, PET. In this molecular imaging method, a radiolabelled ligand is administered intravenously. Afterwards, the patients are placed in a PET camera, and the data is collected every few seconds while the volunteers perform tasks in the scanner. If the neurotransmitter is released during the scan, the concentration of ligand in the receptor will decrease as it is replaced by the endogenously released neurotransmitter. The dopamine synthesis and the concentration of transporters, which are positively correlated with dopamine cells, can be measured in this way. The test involves injecting a radioactive substance that binds to a dopamine transporter, which can be measured using the camera. </p>\n</li>\n</ol>\n<p>However, the researchers may be more interested in the interpretation of the nature of dopamine dysfunction in schizophrenia by these measurements than by the methods.</p>\n<p>In previous studies, both striatal dopamine synthesis capacity and release are found to be elevated in patients with schizophrenia. Clinically, schizophrenia is generally classified as a dopaminergic sub-type and a non-dopaminergic sub-type. For antipsychotic responders, the measure for dopamine via the measure for the dopamine-related enzyme is shown to have a higher level, while indirectly demonstrating psychosis patients have higher dopamine synthesis capacity and the disease is responsive to subsequent antipsychotic treatment. The level of dopamine synthesis and secretion is related to the treatment of schizophrenia. With Voxel-wise analysis, The research of Jauhar et. al demonstrate that the lack of dopamine synthesis is consistent with whether patients respond to the treatments in the clinic has consistency with dopamine dysfunction. For the patients who responded to treatment, there is an increase in dopamine synthesis capacity relative to non-responder. Patients who responded to treatment had increased dopamine synthesis capacity compared with healthy individuals. The classic dopamine hypothesis states that the dopamine dysfunction in the prefrontal cortex leads to negative symptoms in schizophrenia, while dopamine hyperfunction in the mesolimbic pathway leads to positive symptoms. The measurement of dopamine in neuroimaging informs us about the phenomenon of dopamine dysfunction in schizophrenia. And combining with the basis that dopamine signalling is involved in labelling environmental spurs, we can predict that dopamine dysfunction in striatal regions is the main cause of schizophrenia which may lead to functional impairment of striatal regions,</p>\n<p>However, our detection techniques for the brain are still not accurate enough, such as we cannot accurately detect receptor and synaptic dopamine levels in vivo. Based on the current level of science and technology, we cannot fully understand the role of the dopamine system in the start and development of schizophrenia. Nevertheless, the dopamine hypothesis is still powerful and relevant. With the continuous increase of human understanding of the brain, targeting this system, the development of new treatments still has great potential and prospects.</p>\n"},{"layout":"post","title":"phenomenon of ‘Blocking’ on predicted reward","date":"2022-01-22T09:56:06.000Z","_content":"\n\n\n# The so-called ‘delta rule’ has been used to describe learning based on predicted reward. Explain, using equations, the phenomenon of ‘Blocking’. \n\nBlocking is the phenomenon where there will be no association with the new stimulus is formed when the unconditional reflex has been predicted. It generally refers to the inability to express knowledge or skills due to failures in learning or memory. If the unconditional stimulus is already predicted fully by one stimulus, and the addition of a new stimulus does not provide any new important information about the unconditional stimuli, the unconditional stimuli will not activate or support the learning process which is responsible for establishing the new conditional reflex. Explaining the phenomenon of blocking in detail, here first come the delta law and reinforcement learning model:\n\nThe delta law model is a learning model that describes changes in the strength of synapse, such as learning the relationship between stimulus and reward, using gradient descent to find the optimal weight vector. The gradient descent method is to solve the minimum value of the function, i.e., the error, along the direction of gradient descent.\n\nClassical conditioning is a basic form of associative learning which is considered an essential component of complex learning. Typically, classical conditioning occurs when a neutral stimulus (conditional stimulus) is paired closely or consecutively temporally with a biological stimulus (unconditional stimulus) eliciting a reflex behaviour that is still unlearned (unconditional response).\n\nHere is a simple stimuli- reward model:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004405.png)\n\nIn this equation, the w is the weight ratio which is learned with the delta rule from the association of stimulus and reward. It is a vector, which means that its direction can be changed as the stimulus changes. This directionality is necessary for the presence of multiple stimuli. The u is the presence or absence of a stimulus, which takes a binary value between 0 and 1, that is, u is 1 if there is a stimulus, and u is 0 if there is no stimulus.\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005012.png)\n\nHere δ is the predictive error for a given stimulus and reward, which can be predicted by the following equation:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005829.png)\n\nHere the ε defines a learning rate, i.e., how fast shall we update the association between the stimulus and reward, this value is between 0 and 1. If ε is 0, it means there is no learning, thus this stimulus-reward association model is locked, and the association between stimulus and reward is not updated with any subsequent learning. If ε = 1 means that the association between stimulus and reward will change completely after one learning, this learning model is also generally meaningless for prediction. Usually, this learning rate is individually dependent and different in various conditions. Through this equation, we can predict the efficiency of learning. Another problem is that the external noise will interfere with the forecast. For the external noise error, we can introduce a filter coefficient and a series of convolution operations to eliminate it. \n\nA simple learning equation based on unconditional reflexes can explain the phenomenon of the blocking well:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004196.png)\n\nHere ε still represents the learning rate. The λ is the maximum binding strength for a given unconditional stimuli. The σv is the sum of the strengths of associations between all conditional and unconditional stimuli. The δv is the change in binding strength of a particular conditional reflex on various trials. According to this equation, the blocking occurs when λ equals σv, i.e., the binding strength obtained by the conditional stimulus paired with the unconditional stimulus reaches the λ value. There are two groups in one experiment to test it. First, a conditional stimulus is paired with an unconditional stimulus. The second conditional stimulus then undergoes compound conditioning with the first and the same unconditional stimulus. If it is in the absence of blocking, the second combination has little regulation. However, if the combination of the first group is not or weakly regulated, there will be a large amount of associative strength the second combination as well as the first combination in the second group. Blocking occurs because the second stimulus loses relevance. In this equation, blocking will result in an ignorance of new information, which means “stop learning”.\n\nAll in all, blocking, in a simple word, is an expression of the learning failure or a classical conditional response. The blocking may play an important role in how animals process information in their environment. Because animals are constantly exposed to numerous stimuli, in which case, selectively responding to those stimuli may keep us away from “brain crashes” caused by too much information. Sometimes, ignorance is a blessing.\n\n","source":"_posts/2022-01-22-Phenomenon-of-‘Blocking’-on-predicted-reward.md","raw":"---\nlayout: post\ntitle:  \"phenomenon of ‘Blocking’ on predicted reward\"\ndate:   2022-01-22 09:56:06\ncategories: discussion\ntags: Neuroscience\n---\n\n\n\n# The so-called ‘delta rule’ has been used to describe learning based on predicted reward. Explain, using equations, the phenomenon of ‘Blocking’. \n\nBlocking is the phenomenon where there will be no association with the new stimulus is formed when the unconditional reflex has been predicted. It generally refers to the inability to express knowledge or skills due to failures in learning or memory. If the unconditional stimulus is already predicted fully by one stimulus, and the addition of a new stimulus does not provide any new important information about the unconditional stimuli, the unconditional stimuli will not activate or support the learning process which is responsible for establishing the new conditional reflex. Explaining the phenomenon of blocking in detail, here first come the delta law and reinforcement learning model:\n\nThe delta law model is a learning model that describes changes in the strength of synapse, such as learning the relationship between stimulus and reward, using gradient descent to find the optimal weight vector. The gradient descent method is to solve the minimum value of the function, i.e., the error, along the direction of gradient descent.\n\nClassical conditioning is a basic form of associative learning which is considered an essential component of complex learning. Typically, classical conditioning occurs when a neutral stimulus (conditional stimulus) is paired closely or consecutively temporally with a biological stimulus (unconditional stimulus) eliciting a reflex behaviour that is still unlearned (unconditional response).\n\nHere is a simple stimuli- reward model:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004405.png)\n\nIn this equation, the w is the weight ratio which is learned with the delta rule from the association of stimulus and reward. It is a vector, which means that its direction can be changed as the stimulus changes. This directionality is necessary for the presence of multiple stimuli. The u is the presence or absence of a stimulus, which takes a binary value between 0 and 1, that is, u is 1 if there is a stimulus, and u is 0 if there is no stimulus.\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005012.png)\n\nHere δ is the predictive error for a given stimulus and reward, which can be predicted by the following equation:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005829.png)\n\nHere the ε defines a learning rate, i.e., how fast shall we update the association between the stimulus and reward, this value is between 0 and 1. If ε is 0, it means there is no learning, thus this stimulus-reward association model is locked, and the association between stimulus and reward is not updated with any subsequent learning. If ε = 1 means that the association between stimulus and reward will change completely after one learning, this learning model is also generally meaningless for prediction. Usually, this learning rate is individually dependent and different in various conditions. Through this equation, we can predict the efficiency of learning. Another problem is that the external noise will interfere with the forecast. For the external noise error, we can introduce a filter coefficient and a series of convolution operations to eliminate it. \n\nA simple learning equation based on unconditional reflexes can explain the phenomenon of the blocking well:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004196.png)\n\nHere ε still represents the learning rate. The λ is the maximum binding strength for a given unconditional stimuli. The σv is the sum of the strengths of associations between all conditional and unconditional stimuli. The δv is the change in binding strength of a particular conditional reflex on various trials. According to this equation, the blocking occurs when λ equals σv, i.e., the binding strength obtained by the conditional stimulus paired with the unconditional stimulus reaches the λ value. There are two groups in one experiment to test it. First, a conditional stimulus is paired with an unconditional stimulus. The second conditional stimulus then undergoes compound conditioning with the first and the same unconditional stimulus. If it is in the absence of blocking, the second combination has little regulation. However, if the combination of the first group is not or weakly regulated, there will be a large amount of associative strength the second combination as well as the first combination in the second group. Blocking occurs because the second stimulus loses relevance. In this equation, blocking will result in an ignorance of new information, which means “stop learning”.\n\nAll in all, blocking, in a simple word, is an expression of the learning failure or a classical conditional response. The blocking may play an important role in how animals process information in their environment. Because animals are constantly exposed to numerous stimuli, in which case, selectively responding to those stimuli may keep us away from “brain crashes” caused by too much information. Sometimes, ignorance is a blessing.\n\n","slug":"2022-01-22-Phenomenon-of-‘Blocking’-on-predicted-reward","published":1,"updated":"2022-08-24T17:08:39.335Z","comments":1,"photos":[],"_id":"cuidJC4hPGsp_xR6w1fHvAcbb","content":"<h1 id=\"The-so-called-‘delta-rule’-has-been-used-to-describe-learning-based-on-predicted-reward-Explain-using-equations-the-phenomenon-of-‘Blocking’\"><a href=\"#The-so-called-‘delta-rule’-has-been-used-to-describe-learning-based-on-predicted-reward-Explain-using-equations-the-phenomenon-of-‘Blocking’\" class=\"headerlink\" title=\"The so-called ‘delta rule’ has been used to describe learning based on predicted reward. Explain, using equations, the phenomenon of ‘Blocking’.\"></a>The so-called ‘delta rule’ has been used to describe learning based on predicted reward. Explain, using equations, the phenomenon of ‘Blocking’.</h1><p>Blocking is the phenomenon where there will be no association with the new stimulus is formed when the unconditional reflex has been predicted. It generally refers to the inability to express knowledge or skills due to failures in learning or memory. If the unconditional stimulus is already predicted fully by one stimulus, and the addition of a new stimulus does not provide any new important information about the unconditional stimuli, the unconditional stimuli will not activate or support the learning process which is responsible for establishing the new conditional reflex. Explaining the phenomenon of blocking in detail, here first come the delta law and reinforcement learning model:</p>\n<p>The delta law model is a learning model that describes changes in the strength of synapse, such as learning the relationship between stimulus and reward, using gradient descent to find the optimal weight vector. The gradient descent method is to solve the minimum value of the function, i.e., the error, along the direction of gradient descent.</p>\n<p>Classical conditioning is a basic form of associative learning which is considered an essential component of complex learning. Typically, classical conditioning occurs when a neutral stimulus (conditional stimulus) is paired closely or consecutively temporally with a biological stimulus (unconditional stimulus) eliciting a reflex behaviour that is still unlearned (unconditional response).</p>\n<p>Here is a simple stimuli- reward model:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004405.png\" alt=\"img\"></p>\n<p>In this equation, the w is the weight ratio which is learned with the delta rule from the association of stimulus and reward. It is a vector, which means that its direction can be changed as the stimulus changes. This directionality is necessary for the presence of multiple stimuli. The u is the presence or absence of a stimulus, which takes a binary value between 0 and 1, that is, u is 1 if there is a stimulus, and u is 0 if there is no stimulus.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005012.png\" alt=\"img\"></p>\n<p>Here δ is the predictive error for a given stimulus and reward, which can be predicted by the following equation:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005829.png\" alt=\"img\"></p>\n<p>Here the ε defines a learning rate, i.e., how fast shall we update the association between the stimulus and reward, this value is between 0 and 1. If ε is 0, it means there is no learning, thus this stimulus-reward association model is locked, and the association between stimulus and reward is not updated with any subsequent learning. If ε = 1 means that the association between stimulus and reward will change completely after one learning, this learning model is also generally meaningless for prediction. Usually, this learning rate is individually dependent and different in various conditions. Through this equation, we can predict the efficiency of learning. Another problem is that the external noise will interfere with the forecast. For the external noise error, we can introduce a filter coefficient and a series of convolution operations to eliminate it. </p>\n<p>A simple learning equation based on unconditional reflexes can explain the phenomenon of the blocking well:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004196.png\" alt=\"img\"></p>\n<p>Here ε still represents the learning rate. The λ is the maximum binding strength for a given unconditional stimuli. The σv is the sum of the strengths of associations between all conditional and unconditional stimuli. The δv is the change in binding strength of a particular conditional reflex on various trials. According to this equation, the blocking occurs when λ equals σv, i.e., the binding strength obtained by the conditional stimulus paired with the unconditional stimulus reaches the λ value. There are two groups in one experiment to test it. First, a conditional stimulus is paired with an unconditional stimulus. The second conditional stimulus then undergoes compound conditioning with the first and the same unconditional stimulus. If it is in the absence of blocking, the second combination has little regulation. However, if the combination of the first group is not or weakly regulated, there will be a large amount of associative strength the second combination as well as the first combination in the second group. Blocking occurs because the second stimulus loses relevance. In this equation, blocking will result in an ignorance of new information, which means “stop learning”.</p>\n<p>All in all, blocking, in a simple word, is an expression of the learning failure or a classical conditional response. The blocking may play an important role in how animals process information in their environment. Because animals are constantly exposed to numerous stimuli, in which case, selectively responding to those stimuli may keep us away from “brain crashes” caused by too much information. Sometimes, ignorance is a blessing.</p>\n","excerpt":"","more":"<h1 id=\"The-so-called-‘delta-rule’-has-been-used-to-describe-learning-based-on-predicted-reward-Explain-using-equations-the-phenomenon-of-‘Blocking’\"><a href=\"#The-so-called-‘delta-rule’-has-been-used-to-describe-learning-based-on-predicted-reward-Explain-using-equations-the-phenomenon-of-‘Blocking’\" class=\"headerlink\" title=\"The so-called ‘delta rule’ has been used to describe learning based on predicted reward. Explain, using equations, the phenomenon of ‘Blocking’.\"></a>The so-called ‘delta rule’ has been used to describe learning based on predicted reward. Explain, using equations, the phenomenon of ‘Blocking’.</h1><p>Blocking is the phenomenon where there will be no association with the new stimulus is formed when the unconditional reflex has been predicted. It generally refers to the inability to express knowledge or skills due to failures in learning or memory. If the unconditional stimulus is already predicted fully by one stimulus, and the addition of a new stimulus does not provide any new important information about the unconditional stimuli, the unconditional stimuli will not activate or support the learning process which is responsible for establishing the new conditional reflex. Explaining the phenomenon of blocking in detail, here first come the delta law and reinforcement learning model:</p>\n<p>The delta law model is a learning model that describes changes in the strength of synapse, such as learning the relationship between stimulus and reward, using gradient descent to find the optimal weight vector. The gradient descent method is to solve the minimum value of the function, i.e., the error, along the direction of gradient descent.</p>\n<p>Classical conditioning is a basic form of associative learning which is considered an essential component of complex learning. Typically, classical conditioning occurs when a neutral stimulus (conditional stimulus) is paired closely or consecutively temporally with a biological stimulus (unconditional stimulus) eliciting a reflex behaviour that is still unlearned (unconditional response).</p>\n<p>Here is a simple stimuli- reward model:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004405.png\" alt=\"img\"></p>\n<p>In this equation, the w is the weight ratio which is learned with the delta rule from the association of stimulus and reward. It is a vector, which means that its direction can be changed as the stimulus changes. This directionality is necessary for the presence of multiple stimuli. The u is the presence or absence of a stimulus, which takes a binary value between 0 and 1, that is, u is 1 if there is a stimulus, and u is 0 if there is no stimulus.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005012.png\" alt=\"img\"></p>\n<p>Here δ is the predictive error for a given stimulus and reward, which can be predicted by the following equation:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221005829.png\" alt=\"img\"></p>\n<p>Here the ε defines a learning rate, i.e., how fast shall we update the association between the stimulus and reward, this value is between 0 and 1. If ε is 0, it means there is no learning, thus this stimulus-reward association model is locked, and the association between stimulus and reward is not updated with any subsequent learning. If ε = 1 means that the association between stimulus and reward will change completely after one learning, this learning model is also generally meaningless for prediction. Usually, this learning rate is individually dependent and different in various conditions. Through this equation, we can predict the efficiency of learning. Another problem is that the external noise will interfere with the forecast. For the external noise error, we can introduce a filter coefficient and a series of convolution operations to eliminate it. </p>\n<p>A simple learning equation based on unconditional reflexes can explain the phenomenon of the blocking well:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202201221004196.png\" alt=\"img\"></p>\n<p>Here ε still represents the learning rate. The λ is the maximum binding strength for a given unconditional stimuli. The σv is the sum of the strengths of associations between all conditional and unconditional stimuli. The δv is the change in binding strength of a particular conditional reflex on various trials. According to this equation, the blocking occurs when λ equals σv, i.e., the binding strength obtained by the conditional stimulus paired with the unconditional stimulus reaches the λ value. There are two groups in one experiment to test it. First, a conditional stimulus is paired with an unconditional stimulus. The second conditional stimulus then undergoes compound conditioning with the first and the same unconditional stimulus. If it is in the absence of blocking, the second combination has little regulation. However, if the combination of the first group is not or weakly regulated, there will be a large amount of associative strength the second combination as well as the first combination in the second group. Blocking occurs because the second stimulus loses relevance. In this equation, blocking will result in an ignorance of new information, which means “stop learning”.</p>\n<p>All in all, blocking, in a simple word, is an expression of the learning failure or a classical conditional response. The blocking may play an important role in how animals process information in their environment. Because animals are constantly exposed to numerous stimuli, in which case, selectively responding to those stimuli may keep us away from “brain crashes” caused by too much information. Sometimes, ignorance is a blessing.</p>\n"},{"layout":"post","title":"Usages of animal models in the study of human brain structural connectivity","date":"2022-01-22T09:56:06.000Z","_content":"\n\n\n# Critically evaluate the use of animal models in the study of human brain structural connectivity. \n\nThe animal model is the animal experimental objects that are established in biomedical scientific research with human-simulating properties. The use of animal models is an extremely important experimental approach in modern biological research, which contributes to a more convenient and effective understanding of human brain connectivity research. Much of our knowledge about advanced cognitive functions and complex behaviours come from the use of animal models. Research on the structural connectivity of the human brain could lead to a new understanding of the connectome.\n\nNetwork analysis of animal brains can bring us closer to the reality of how the human brain really works. Undoubtedly, animal models are of great help to the study of human brain structural connectivity, and they greatly facilitate such studies. First, the risks associated with direct experiments on humans are avoided in this way. For example, Brenner et. al construct a model of Caenorhabditis elegans and Larry et. al found a model of mice. Second, some commonly seen diseases in clinics that we want to study with the connectome can be replicated with animal models at any time. Moreover, this type of research can overcome the shortcomings of long incubation periods, duration and low morbidity. The experimental conditions can be strictly controlled to enhance the comparability of experimental materials. Finally, it also helps to understand the essence of the human brain. If only through clinical research, its performance may have its own characteristics. Through the comparative study of the map of neural connections between humans and animals, we can understand the various effects of the same condition on different organisms. Therefore, in a sense, the research work can be sublimated to a three-dimensional level to reveal the essence of certain connectivity, which is more conducive to explaining all the changes that have occurred in the human body. The use of animal models also allows us to observe the impact of environmental or genetic factors on the development in detail, which is impossible in clinical practice.\n\nOne example is that using animal models, the animal brain is serially sliced into many slices, each slice is imaged at high resolution with an electron microscope, and each neuron\\'s branches and synaptic connections to other neurons are traced. Meanwhile, research on human brain structural connectivity can be classified into the connectomics discipline, deciphering vast neural systems with automatization and computer-assisted collaboration.\n\nIn this case, what is the significance of a large-scale animal model for whole-brain structural connectivity to address closer to our own nervous system?\n\nThe emergence of large-scale connectomic data in animal models, including complete reconstructions of neurons in the adult central brain, has great importance. Comparing non-invasive connectome maps of the same animal model brain will enhance our understanding of the structural basis of signals measured by current non-invasive techniques widely used in the human brain.\n\nThe mouse is an excellent animal model for studying brain connectivity, as there are many mouse models involving a variety of brain diseases, well-established experimental methods and theories. Mammalian brains all contain lots of the same cortical and subcortical regions, interregional projections, and intraregional connectivity. The mice have many organizational features that are also present in the human nervous system. Importantly, once the connectomic infrastructure at the scale required to connect the entire mouse brain is established, it will also be useful in animal models of diseases. Many other connectomic studies will be possible.\n\nHowever, the use of animal models in the study of human brain structural connectivity is not perfect. First and foremost, the advanced level of animal evolution does not mean that all organs and functions are close to the human level. The unique structure and function are difficult to reproduce in animal models, so blindly using animal models to explain the mechanism of the human brain will undoubtedly be far from the truth. Moreover, with the development of big data science, the demand for non-biological thinking systems for the study of human brain structural connectivity is increasing day by day. In some way, those models can explain mechanisms better.\n\nHowever, everything has its pros and cons. For the application of human brain connectivity research in big data science, the revelation of animal models to its engineering and computers is of great significance. For sure living animals have higher learning intelligence than computer programs. In terms of cognitive learning, animal models are more effective. One example is that inductive learning can be performed through a small number of samples, which AI systems cannot yet have. Besides, our research using mammalian brains is more resource efficient.\n\nDue to the limitations of technology, it is still difficult for us to understand the connected group, and it is largely unexplainable. The connectome will generate entirely unexpected questions about the nervous system and may allow us to understand the principles.\n\n","source":"_posts/2022-01-22-Usages-of-animal-models-in-the-study-of-human-brain-structural-connectivity.md","raw":"---\nlayout: post\ntitle:  \"Usages of animal models in the study of human brain structural connectivity\"\ndate:   2022-01-22 09:56:06\ncategories: discussion\ntags: Neuroscience\n---\n\n\n\n# Critically evaluate the use of animal models in the study of human brain structural connectivity. \n\nThe animal model is the animal experimental objects that are established in biomedical scientific research with human-simulating properties. The use of animal models is an extremely important experimental approach in modern biological research, which contributes to a more convenient and effective understanding of human brain connectivity research. Much of our knowledge about advanced cognitive functions and complex behaviours come from the use of animal models. Research on the structural connectivity of the human brain could lead to a new understanding of the connectome.\n\nNetwork analysis of animal brains can bring us closer to the reality of how the human brain really works. Undoubtedly, animal models are of great help to the study of human brain structural connectivity, and they greatly facilitate such studies. First, the risks associated with direct experiments on humans are avoided in this way. For example, Brenner et. al construct a model of Caenorhabditis elegans and Larry et. al found a model of mice. Second, some commonly seen diseases in clinics that we want to study with the connectome can be replicated with animal models at any time. Moreover, this type of research can overcome the shortcomings of long incubation periods, duration and low morbidity. The experimental conditions can be strictly controlled to enhance the comparability of experimental materials. Finally, it also helps to understand the essence of the human brain. If only through clinical research, its performance may have its own characteristics. Through the comparative study of the map of neural connections between humans and animals, we can understand the various effects of the same condition on different organisms. Therefore, in a sense, the research work can be sublimated to a three-dimensional level to reveal the essence of certain connectivity, which is more conducive to explaining all the changes that have occurred in the human body. The use of animal models also allows us to observe the impact of environmental or genetic factors on the development in detail, which is impossible in clinical practice.\n\nOne example is that using animal models, the animal brain is serially sliced into many slices, each slice is imaged at high resolution with an electron microscope, and each neuron\\'s branches and synaptic connections to other neurons are traced. Meanwhile, research on human brain structural connectivity can be classified into the connectomics discipline, deciphering vast neural systems with automatization and computer-assisted collaboration.\n\nIn this case, what is the significance of a large-scale animal model for whole-brain structural connectivity to address closer to our own nervous system?\n\nThe emergence of large-scale connectomic data in animal models, including complete reconstructions of neurons in the adult central brain, has great importance. Comparing non-invasive connectome maps of the same animal model brain will enhance our understanding of the structural basis of signals measured by current non-invasive techniques widely used in the human brain.\n\nThe mouse is an excellent animal model for studying brain connectivity, as there are many mouse models involving a variety of brain diseases, well-established experimental methods and theories. Mammalian brains all contain lots of the same cortical and subcortical regions, interregional projections, and intraregional connectivity. The mice have many organizational features that are also present in the human nervous system. Importantly, once the connectomic infrastructure at the scale required to connect the entire mouse brain is established, it will also be useful in animal models of diseases. Many other connectomic studies will be possible.\n\nHowever, the use of animal models in the study of human brain structural connectivity is not perfect. First and foremost, the advanced level of animal evolution does not mean that all organs and functions are close to the human level. The unique structure and function are difficult to reproduce in animal models, so blindly using animal models to explain the mechanism of the human brain will undoubtedly be far from the truth. Moreover, with the development of big data science, the demand for non-biological thinking systems for the study of human brain structural connectivity is increasing day by day. In some way, those models can explain mechanisms better.\n\nHowever, everything has its pros and cons. For the application of human brain connectivity research in big data science, the revelation of animal models to its engineering and computers is of great significance. For sure living animals have higher learning intelligence than computer programs. In terms of cognitive learning, animal models are more effective. One example is that inductive learning can be performed through a small number of samples, which AI systems cannot yet have. Besides, our research using mammalian brains is more resource efficient.\n\nDue to the limitations of technology, it is still difficult for us to understand the connected group, and it is largely unexplainable. The connectome will generate entirely unexpected questions about the nervous system and may allow us to understand the principles.\n\n","slug":"2022-01-22-Usages-of-animal-models-in-the-study-of-human-brain-structural-connectivity","published":1,"updated":"2022-08-24T17:08:39.337Z","comments":1,"photos":[],"_id":"cuid5XlR5Sge2B3EODz-XHOn9","content":"<h1 id=\"Critically-evaluate-the-use-of-animal-models-in-the-study-of-human-brain-structural-connectivity\"><a href=\"#Critically-evaluate-the-use-of-animal-models-in-the-study-of-human-brain-structural-connectivity\" class=\"headerlink\" title=\"Critically evaluate the use of animal models in the study of human brain structural connectivity.\"></a>Critically evaluate the use of animal models in the study of human brain structural connectivity.</h1><p>The animal model is the animal experimental objects that are established in biomedical scientific research with human-simulating properties. The use of animal models is an extremely important experimental approach in modern biological research, which contributes to a more convenient and effective understanding of human brain connectivity research. Much of our knowledge about advanced cognitive functions and complex behaviours come from the use of animal models. Research on the structural connectivity of the human brain could lead to a new understanding of the connectome.</p>\n<p>Network analysis of animal brains can bring us closer to the reality of how the human brain really works. Undoubtedly, animal models are of great help to the study of human brain structural connectivity, and they greatly facilitate such studies. First, the risks associated with direct experiments on humans are avoided in this way. For example, Brenner et. al construct a model of Caenorhabditis elegans and Larry et. al found a model of mice. Second, some commonly seen diseases in clinics that we want to study with the connectome can be replicated with animal models at any time. Moreover, this type of research can overcome the shortcomings of long incubation periods, duration and low morbidity. The experimental conditions can be strictly controlled to enhance the comparability of experimental materials. Finally, it also helps to understand the essence of the human brain. If only through clinical research, its performance may have its own characteristics. Through the comparative study of the map of neural connections between humans and animals, we can understand the various effects of the same condition on different organisms. Therefore, in a sense, the research work can be sublimated to a three-dimensional level to reveal the essence of certain connectivity, which is more conducive to explaining all the changes that have occurred in the human body. The use of animal models also allows us to observe the impact of environmental or genetic factors on the development in detail, which is impossible in clinical practice.</p>\n<p>One example is that using animal models, the animal brain is serially sliced into many slices, each slice is imaged at high resolution with an electron microscope, and each neuron&#39;s branches and synaptic connections to other neurons are traced. Meanwhile, research on human brain structural connectivity can be classified into the connectomics discipline, deciphering vast neural systems with automatization and computer-assisted collaboration.</p>\n<p>In this case, what is the significance of a large-scale animal model for whole-brain structural connectivity to address closer to our own nervous system?</p>\n<p>The emergence of large-scale connectomic data in animal models, including complete reconstructions of neurons in the adult central brain, has great importance. Comparing non-invasive connectome maps of the same animal model brain will enhance our understanding of the structural basis of signals measured by current non-invasive techniques widely used in the human brain.</p>\n<p>The mouse is an excellent animal model for studying brain connectivity, as there are many mouse models involving a variety of brain diseases, well-established experimental methods and theories. Mammalian brains all contain lots of the same cortical and subcortical regions, interregional projections, and intraregional connectivity. The mice have many organizational features that are also present in the human nervous system. Importantly, once the connectomic infrastructure at the scale required to connect the entire mouse brain is established, it will also be useful in animal models of diseases. Many other connectomic studies will be possible.</p>\n<p>However, the use of animal models in the study of human brain structural connectivity is not perfect. First and foremost, the advanced level of animal evolution does not mean that all organs and functions are close to the human level. The unique structure and function are difficult to reproduce in animal models, so blindly using animal models to explain the mechanism of the human brain will undoubtedly be far from the truth. Moreover, with the development of big data science, the demand for non-biological thinking systems for the study of human brain structural connectivity is increasing day by day. In some way, those models can explain mechanisms better.</p>\n<p>However, everything has its pros and cons. For the application of human brain connectivity research in big data science, the revelation of animal models to its engineering and computers is of great significance. For sure living animals have higher learning intelligence than computer programs. In terms of cognitive learning, animal models are more effective. One example is that inductive learning can be performed through a small number of samples, which AI systems cannot yet have. Besides, our research using mammalian brains is more resource efficient.</p>\n<p>Due to the limitations of technology, it is still difficult for us to understand the connected group, and it is largely unexplainable. The connectome will generate entirely unexpected questions about the nervous system and may allow us to understand the principles.</p>\n","excerpt":"","more":"<h1 id=\"Critically-evaluate-the-use-of-animal-models-in-the-study-of-human-brain-structural-connectivity\"><a href=\"#Critically-evaluate-the-use-of-animal-models-in-the-study-of-human-brain-structural-connectivity\" class=\"headerlink\" title=\"Critically evaluate the use of animal models in the study of human brain structural connectivity.\"></a>Critically evaluate the use of animal models in the study of human brain structural connectivity.</h1><p>The animal model is the animal experimental objects that are established in biomedical scientific research with human-simulating properties. The use of animal models is an extremely important experimental approach in modern biological research, which contributes to a more convenient and effective understanding of human brain connectivity research. Much of our knowledge about advanced cognitive functions and complex behaviours come from the use of animal models. Research on the structural connectivity of the human brain could lead to a new understanding of the connectome.</p>\n<p>Network analysis of animal brains can bring us closer to the reality of how the human brain really works. Undoubtedly, animal models are of great help to the study of human brain structural connectivity, and they greatly facilitate such studies. First, the risks associated with direct experiments on humans are avoided in this way. For example, Brenner et. al construct a model of Caenorhabditis elegans and Larry et. al found a model of mice. Second, some commonly seen diseases in clinics that we want to study with the connectome can be replicated with animal models at any time. Moreover, this type of research can overcome the shortcomings of long incubation periods, duration and low morbidity. The experimental conditions can be strictly controlled to enhance the comparability of experimental materials. Finally, it also helps to understand the essence of the human brain. If only through clinical research, its performance may have its own characteristics. Through the comparative study of the map of neural connections between humans and animals, we can understand the various effects of the same condition on different organisms. Therefore, in a sense, the research work can be sublimated to a three-dimensional level to reveal the essence of certain connectivity, which is more conducive to explaining all the changes that have occurred in the human body. The use of animal models also allows us to observe the impact of environmental or genetic factors on the development in detail, which is impossible in clinical practice.</p>\n<p>One example is that using animal models, the animal brain is serially sliced into many slices, each slice is imaged at high resolution with an electron microscope, and each neuron&#39;s branches and synaptic connections to other neurons are traced. Meanwhile, research on human brain structural connectivity can be classified into the connectomics discipline, deciphering vast neural systems with automatization and computer-assisted collaboration.</p>\n<p>In this case, what is the significance of a large-scale animal model for whole-brain structural connectivity to address closer to our own nervous system?</p>\n<p>The emergence of large-scale connectomic data in animal models, including complete reconstructions of neurons in the adult central brain, has great importance. Comparing non-invasive connectome maps of the same animal model brain will enhance our understanding of the structural basis of signals measured by current non-invasive techniques widely used in the human brain.</p>\n<p>The mouse is an excellent animal model for studying brain connectivity, as there are many mouse models involving a variety of brain diseases, well-established experimental methods and theories. Mammalian brains all contain lots of the same cortical and subcortical regions, interregional projections, and intraregional connectivity. The mice have many organizational features that are also present in the human nervous system. Importantly, once the connectomic infrastructure at the scale required to connect the entire mouse brain is established, it will also be useful in animal models of diseases. Many other connectomic studies will be possible.</p>\n<p>However, the use of animal models in the study of human brain structural connectivity is not perfect. First and foremost, the advanced level of animal evolution does not mean that all organs and functions are close to the human level. The unique structure and function are difficult to reproduce in animal models, so blindly using animal models to explain the mechanism of the human brain will undoubtedly be far from the truth. Moreover, with the development of big data science, the demand for non-biological thinking systems for the study of human brain structural connectivity is increasing day by day. In some way, those models can explain mechanisms better.</p>\n<p>However, everything has its pros and cons. For the application of human brain connectivity research in big data science, the revelation of animal models to its engineering and computers is of great significance. For sure living animals have higher learning intelligence than computer programs. In terms of cognitive learning, animal models are more effective. One example is that inductive learning can be performed through a small number of samples, which AI systems cannot yet have. Besides, our research using mammalian brains is more resource efficient.</p>\n<p>Due to the limitations of technology, it is still difficult for us to understand the connected group, and it is largely unexplainable. The connectome will generate entirely unexpected questions about the nervous system and may allow us to understand the principles.</p>\n"},{"title":"春去秋来","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-09-21T09:00:00.000Z","password":null,"summary":null,"_content":"\n# 春去秋来\n\n不知不觉中在伦敦又呆过了半年的光景。入秋开始泛泛飘坠的梧桐叶让人不禁唏嘘春去秋来，时间过得如此之快。落叶被踩进积水里，与尘土混在一起，再由马车的车辙压过，便成了一封精巧的编年册。低头走过，仿佛发现自己又回到了故乡，然而空中的小积云又真切地告诉我这里并不是我魂牵梦萦的家。\n\n![image-20220921161454108](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211615754.png)\n\n只有每每到夜晚仰望头顶与故乡一样的月，才能稍以慰藉我思乡的愁绪。然而每到十五、十六这两天，月亮变得格外圆的日子，我才愈发能意识到，\"月是故乡明\"；于是便愈是生发出\"对酒当歌\"的冲动。\n\n![image-20220921162114476](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621644.png)\n\n\n\n不过越是如此，我越能感受到肩头的责任。我暗自发下愿望：待到学成之日，便是我归国报效之时。祖国足够强大，吾辈才有足够的自信挺起胸膛。\n\n![image-20220921162121462](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621598.png)\n\n我是生长在长江边的，从小见惯了大江上的风浪，也习惯于长江水的磅礴气势。当我来到了英国伦敦，却发现这条泰晤士河终日风平浪静，与长江比起来未免落得小家子气。然而，就是这条小家子气的河，曾经驶过\"日不落\"帝国炮利船坚的舰队------百年前轰开我们曾经紧锁国门的舰队。\n\n如是，知耻而后勇也，平常心不可弃，鸿鹄志不敢失，耻辱心不能丢也。大丈夫便要\"敢叫日月换新天\"。如今的时代，改革的春风给中国带来科技的进步，经济的发展。吾辈当乘此风，破万里浪。\n\n![image-20220921162131436](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621628.png)\n","source":"_posts/2022-09-21-春去秋来.md","raw":"---\ntitle: 春去秋来\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-09-21 10:00\npassword:\nsummary:\ntags:\n- diary\ncategories:\n- daily life\n---\n\n# 春去秋来\n\n不知不觉中在伦敦又呆过了半年的光景。入秋开始泛泛飘坠的梧桐叶让人不禁唏嘘春去秋来，时间过得如此之快。落叶被踩进积水里，与尘土混在一起，再由马车的车辙压过，便成了一封精巧的编年册。低头走过，仿佛发现自己又回到了故乡，然而空中的小积云又真切地告诉我这里并不是我魂牵梦萦的家。\n\n![image-20220921161454108](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211615754.png)\n\n只有每每到夜晚仰望头顶与故乡一样的月，才能稍以慰藉我思乡的愁绪。然而每到十五、十六这两天，月亮变得格外圆的日子，我才愈发能意识到，\"月是故乡明\"；于是便愈是生发出\"对酒当歌\"的冲动。\n\n![image-20220921162114476](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621644.png)\n\n\n\n不过越是如此，我越能感受到肩头的责任。我暗自发下愿望：待到学成之日，便是我归国报效之时。祖国足够强大，吾辈才有足够的自信挺起胸膛。\n\n![image-20220921162121462](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621598.png)\n\n我是生长在长江边的，从小见惯了大江上的风浪，也习惯于长江水的磅礴气势。当我来到了英国伦敦，却发现这条泰晤士河终日风平浪静，与长江比起来未免落得小家子气。然而，就是这条小家子气的河，曾经驶过\"日不落\"帝国炮利船坚的舰队------百年前轰开我们曾经紧锁国门的舰队。\n\n如是，知耻而后勇也，平常心不可弃，鸿鹄志不敢失，耻辱心不能丢也。大丈夫便要\"敢叫日月换新天\"。如今的时代，改革的春风给中国带来科技的进步，经济的发展。吾辈当乘此风，破万里浪。\n\n![image-20220921162131436](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621628.png)\n","slug":"2022-09-21-春去秋来","published":1,"updated":"2022-09-21T15:27:47.042Z","comments":1,"layout":"post","photos":[],"_id":"cuidJNXOPFgeAWWe8yx3TZiXQ","content":"<h1 id=\"春去秋来\"><a href=\"#春去秋来\" class=\"headerlink\" title=\"春去秋来\"></a>春去秋来</h1><p>不知不觉中在伦敦又呆过了半年的光景。入秋开始泛泛飘坠的梧桐叶让人不禁唏嘘春去秋来，时间过得如此之快。落叶被踩进积水里，与尘土混在一起，再由马车的车辙压过，便成了一封精巧的编年册。低头走过，仿佛发现自己又回到了故乡，然而空中的小积云又真切地告诉我这里并不是我魂牵梦萦的家。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211615754.png\" alt=\"image-20220921161454108\"></p>\n<p>只有每每到夜晚仰望头顶与故乡一样的月，才能稍以慰藉我思乡的愁绪。然而每到十五、十六这两天，月亮变得格外圆的日子，我才愈发能意识到，”月是故乡明”；于是便愈是生发出”对酒当歌”的冲动。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621644.png\" alt=\"image-20220921162114476\"></p>\n<p>不过越是如此，我越能感受到肩头的责任。我暗自发下愿望：待到学成之日，便是我归国报效之时。祖国足够强大，吾辈才有足够的自信挺起胸膛。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621598.png\" alt=\"image-20220921162121462\"></p>\n<p>我是生长在长江边的，从小见惯了大江上的风浪，也习惯于长江水的磅礴气势。当我来到了英国伦敦，却发现这条泰晤士河终日风平浪静，与长江比起来未免落得小家子气。然而，就是这条小家子气的河，曾经驶过”日不落”帝国炮利船坚的舰队——百年前轰开我们曾经紧锁国门的舰队。</p>\n<p>如是，知耻而后勇也，平常心不可弃，鸿鹄志不敢失，耻辱心不能丢也。大丈夫便要”敢叫日月换新天”。如今的时代，改革的春风给中国带来科技的进步，经济的发展。吾辈当乘此风，破万里浪。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621628.png\" alt=\"image-20220921162131436\"></p>\n","excerpt":"","more":"<h1 id=\"春去秋来\"><a href=\"#春去秋来\" class=\"headerlink\" title=\"春去秋来\"></a>春去秋来</h1><p>不知不觉中在伦敦又呆过了半年的光景。入秋开始泛泛飘坠的梧桐叶让人不禁唏嘘春去秋来，时间过得如此之快。落叶被踩进积水里，与尘土混在一起，再由马车的车辙压过，便成了一封精巧的编年册。低头走过，仿佛发现自己又回到了故乡，然而空中的小积云又真切地告诉我这里并不是我魂牵梦萦的家。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211615754.png\" alt=\"image-20220921161454108\"></p>\n<p>只有每每到夜晚仰望头顶与故乡一样的月，才能稍以慰藉我思乡的愁绪。然而每到十五、十六这两天，月亮变得格外圆的日子，我才愈发能意识到，”月是故乡明”；于是便愈是生发出”对酒当歌”的冲动。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621644.png\" alt=\"image-20220921162114476\"></p>\n<p>不过越是如此，我越能感受到肩头的责任。我暗自发下愿望：待到学成之日，便是我归国报效之时。祖国足够强大，吾辈才有足够的自信挺起胸膛。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621598.png\" alt=\"image-20220921162121462\"></p>\n<p>我是生长在长江边的，从小见惯了大江上的风浪，也习惯于长江水的磅礴气势。当我来到了英国伦敦，却发现这条泰晤士河终日风平浪静，与长江比起来未免落得小家子气。然而，就是这条小家子气的河，曾经驶过”日不落”帝国炮利船坚的舰队——百年前轰开我们曾经紧锁国门的舰队。</p>\n<p>如是，知耻而后勇也，平常心不可弃，鸿鹄志不敢失，耻辱心不能丢也。大丈夫便要”敢叫日月换新天”。如今的时代，改革的春风给中国带来科技的进步，经济的发展。吾辈当乘此风，破万里浪。</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202209211621628.png\" alt=\"image-20220921162131436\"></p>\n"},{"title":"Lecture Notes 28/02/22","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-28T10:00:00.000Z","password":null,"summary":null,"_content":"\n# Normal brain development \n\n![Mapping GM & WM across the lifespan](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261550179.png)\n\nWhite matter volume increase from 0-45 (around), and decrease after 45; while grey matter decrease after 50s.\n\n![image-20220228104031409](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281040786.png)\n\n\n\nQ: how the ages affect choice: HOT EF. May the income affects their choice?\n\nMay the background of children affect the results of marshmallow experiment?\n\n![image-20220228105421436](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281054786.png)\n\n## Conclusion\n\n**Normal brain structural development**\n\n- Increased WM/GM ratio\n- Decrease in GM, cort thickness, surface area across adolescence \n- Maturation of WM, GM & WM tracts well into mid -adulthood \n- Latest regions to mature: FL (DLPFC), STL, PL, BG, Cb\n- Latest WM tracts to mature: Fronto-striato-thalamic, fronto-PL/TL.OCC tracts, cingulate tracts\n- Earlier in girls than boys (some studies find not sex differences)\n- Structural brain development is  associated with cognitive maturation\n\n**Normal brain function development of cool & hot EF (Executive functions)**\n\n- Functional maturation of task-relevant lateral “cool” FL-BG-PL &“hot” OFC/vmPFC-limbic networks\n- Progressively increased functional connectivity during cognitive tasks & during rest (DMN)\n- Progressively more deactivation of DMN (default mode network) with increasing age during tasks => better EF/Attention\n- Progressively increased long-distance & reduced short-range connectivity => integration through segregation\n- Network communities include anatomically proximal regions; with age, more distributed networks emerge\n- Network efficiency improves with age\n- Interhemispheric connectivity increases\n\n---\n\n\n\n# Neuroimaging of ASD I\n\n## Objects\n\n1. Describe how we can study the early (pre-diagnostic) development of autism\n\n2. Which neurocognitive functions are important to study in the early development of autism?\n\n   - sensory processing\n\n   - social communication\n\n   - attention/ executive function\n\n   - others\n\n3. What cognitive neuroscience techniques can be used to study early brain and cognitive development in autism?\n\n4. Explain one key set of findings from cognitive neuroscience studies about the early development of autism\n\n5. How have findings from cognitive neuroscience studies been used to design and assess early interventions for autism?\t\n\n## Autism \n\nNeurodevelopmental condition characterised by difficulties in 2 main areas (DSM-5):\n1. Social-communication and interaction\n2. Restricted and repetitive behaviours and sensory processing atypicalities\n\nTypical age of diagnosis: 4-5 years\n\n80% of autistic individuals have co-occurring conditions (ADHD, depression, anxiety)\n\n**Which neurocognitive functions are important to study in the early development of autism?**\n\nSensory processing atypicalities in autism:\n\n- Hypersensitivity to sensory stimuli (e.g. intolerance of specific sounds, textures, smells)\n- Hyposensitivity to sensory stimuli (e.g. blunted pain detection)\n- Sensory-seeking (increased exploration of non-social sensory experiences e.g. stimming)\n\nDevelopmental trajectories to core autism symptom domains are intertwined\n\n**Studying early neurodevelopment in autism: Limitations**\n\n1. Heterogeneity:\n\n   The autism phenotype & underlying neurocognitive mechanisms vary across autistic individuals so it is unlikely that the same neurodevelopmental trajectories will lead to ASD in all individuals\n\n2. Specificity:\n\n   - Autism co-occurs at high rates with other neurodevelopmental conditions (ADHD, anxiety)\n   - It is not clear whether the alterations in neurodevelopmental trajectories identified in infant sibling studies are specific to autism or shared with other conditions\n   - ADHD (e.g.) shows similar social-communication & sensory alterations in infancy\n\n3. Ethical concerns\n\nEarly interventions for autism based on neurodevelopmental studies: iBASIS-VIPP intervention","source":"_posts/28_02_22.md","raw":"---\ntitle: Lecture Notes 28/02/22\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-28 10:00\npassword:\nsummary:\ntags:\n- Lecture Note\ncategories:\n- Neuroscience\n---\n\n# Normal brain development \n\n![Mapping GM & WM across the lifespan](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261550179.png)\n\nWhite matter volume increase from 0-45 (around), and decrease after 45; while grey matter decrease after 50s.\n\n![image-20220228104031409](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281040786.png)\n\n\n\nQ: how the ages affect choice: HOT EF. May the income affects their choice?\n\nMay the background of children affect the results of marshmallow experiment?\n\n![image-20220228105421436](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281054786.png)\n\n## Conclusion\n\n**Normal brain structural development**\n\n- Increased WM/GM ratio\n- Decrease in GM, cort thickness, surface area across adolescence \n- Maturation of WM, GM & WM tracts well into mid -adulthood \n- Latest regions to mature: FL (DLPFC), STL, PL, BG, Cb\n- Latest WM tracts to mature: Fronto-striato-thalamic, fronto-PL/TL.OCC tracts, cingulate tracts\n- Earlier in girls than boys (some studies find not sex differences)\n- Structural brain development is  associated with cognitive maturation\n\n**Normal brain function development of cool & hot EF (Executive functions)**\n\n- Functional maturation of task-relevant lateral “cool” FL-BG-PL &“hot” OFC/vmPFC-limbic networks\n- Progressively increased functional connectivity during cognitive tasks & during rest (DMN)\n- Progressively more deactivation of DMN (default mode network) with increasing age during tasks => better EF/Attention\n- Progressively increased long-distance & reduced short-range connectivity => integration through segregation\n- Network communities include anatomically proximal regions; with age, more distributed networks emerge\n- Network efficiency improves with age\n- Interhemispheric connectivity increases\n\n---\n\n\n\n# Neuroimaging of ASD I\n\n## Objects\n\n1. Describe how we can study the early (pre-diagnostic) development of autism\n\n2. Which neurocognitive functions are important to study in the early development of autism?\n\n   - sensory processing\n\n   - social communication\n\n   - attention/ executive function\n\n   - others\n\n3. What cognitive neuroscience techniques can be used to study early brain and cognitive development in autism?\n\n4. Explain one key set of findings from cognitive neuroscience studies about the early development of autism\n\n5. How have findings from cognitive neuroscience studies been used to design and assess early interventions for autism?\t\n\n## Autism \n\nNeurodevelopmental condition characterised by difficulties in 2 main areas (DSM-5):\n1. Social-communication and interaction\n2. Restricted and repetitive behaviours and sensory processing atypicalities\n\nTypical age of diagnosis: 4-5 years\n\n80% of autistic individuals have co-occurring conditions (ADHD, depression, anxiety)\n\n**Which neurocognitive functions are important to study in the early development of autism?**\n\nSensory processing atypicalities in autism:\n\n- Hypersensitivity to sensory stimuli (e.g. intolerance of specific sounds, textures, smells)\n- Hyposensitivity to sensory stimuli (e.g. blunted pain detection)\n- Sensory-seeking (increased exploration of non-social sensory experiences e.g. stimming)\n\nDevelopmental trajectories to core autism symptom domains are intertwined\n\n**Studying early neurodevelopment in autism: Limitations**\n\n1. Heterogeneity:\n\n   The autism phenotype & underlying neurocognitive mechanisms vary across autistic individuals so it is unlikely that the same neurodevelopmental trajectories will lead to ASD in all individuals\n\n2. Specificity:\n\n   - Autism co-occurs at high rates with other neurodevelopmental conditions (ADHD, anxiety)\n   - It is not clear whether the alterations in neurodevelopmental trajectories identified in infant sibling studies are specific to autism or shared with other conditions\n   - ADHD (e.g.) shows similar social-communication & sensory alterations in infancy\n\n3. Ethical concerns\n\nEarly interventions for autism based on neurodevelopmental studies: iBASIS-VIPP intervention","slug":"28_02_22","published":1,"updated":"2022-08-24T17:08:39.344Z","comments":1,"layout":"post","photos":[],"_id":"cuid5W24V4g48420Tj8piig03","content":"<h1 id=\"Normal-brain-development\"><a href=\"#Normal-brain-development\" class=\"headerlink\" title=\"Normal brain development\"></a>Normal brain development</h1><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261550179.png\" alt=\"Mapping GM &amp; WM across the lifespan\"></p>\n<p>White matter volume increase from 0-45 (around), and decrease after 45; while grey matter decrease after 50s.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281040786.png\" alt=\"image-20220228104031409\"></p>\n<p>Q: how the ages affect choice: HOT EF. May the income affects their choice?</p>\n<p>May the background of children affect the results of marshmallow experiment?</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281054786.png\" alt=\"image-20220228105421436\"></p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p><strong>Normal brain structural development</strong></p>\n<ul>\n<li>Increased WM/GM ratio</li>\n<li>Decrease in GM, cort thickness, surface area across adolescence </li>\n<li>Maturation of WM, GM &amp; WM tracts well into mid -adulthood </li>\n<li>Latest regions to mature: FL (DLPFC), STL, PL, BG, Cb</li>\n<li>Latest WM tracts to mature: Fronto-striato-thalamic, fronto-PL/TL.OCC tracts, cingulate tracts</li>\n<li>Earlier in girls than boys (some studies find not sex differences)</li>\n<li>Structural brain development is  associated with cognitive maturation</li>\n</ul>\n<p><strong>Normal brain function development of cool &amp; hot EF (Executive functions)</strong></p>\n<ul>\n<li>Functional maturation of task-relevant lateral “cool” FL-BG-PL &amp;“hot” OFC/vmPFC-limbic networks</li>\n<li>Progressively increased functional connectivity during cognitive tasks &amp; during rest (DMN)</li>\n<li>Progressively more deactivation of DMN (default mode network) with increasing age during tasks =&gt; better EF/Attention</li>\n<li>Progressively increased long-distance &amp; reduced short-range connectivity =&gt; integration through segregation</li>\n<li>Network communities include anatomically proximal regions; with age, more distributed networks emerge</li>\n<li>Network efficiency improves with age</li>\n<li>Interhemispheric connectivity increases</li>\n</ul>\n<hr>\n<h1 id=\"Neuroimaging-of-ASD-I\"><a href=\"#Neuroimaging-of-ASD-I\" class=\"headerlink\" title=\"Neuroimaging of ASD I\"></a>Neuroimaging of ASD I</h1><h2 id=\"Objects\"><a href=\"#Objects\" class=\"headerlink\" title=\"Objects\"></a>Objects</h2><ol>\n<li><p>Describe how we can study the early (pre-diagnostic) development of autism</p>\n</li>\n<li><p>Which neurocognitive functions are important to study in the early development of autism?</p>\n<ul>\n<li><p>sensory processing</p>\n</li>\n<li><p>social communication</p>\n</li>\n<li><p>attention/ executive function</p>\n</li>\n<li><p>others</p>\n</li>\n</ul>\n</li>\n<li><p>What cognitive neuroscience techniques can be used to study early brain and cognitive development in autism?</p>\n</li>\n<li><p>Explain one key set of findings from cognitive neuroscience studies about the early development of autism</p>\n</li>\n<li><p>How have findings from cognitive neuroscience studies been used to design and assess early interventions for autism?    </p>\n</li>\n</ol>\n<h2 id=\"Autism\"><a href=\"#Autism\" class=\"headerlink\" title=\"Autism\"></a>Autism</h2><p>Neurodevelopmental condition characterised by difficulties in 2 main areas (DSM-5):</p>\n<ol>\n<li>Social-communication and interaction</li>\n<li>Restricted and repetitive behaviours and sensory processing atypicalities</li>\n</ol>\n<p>Typical age of diagnosis: 4-5 years</p>\n<p>80% of autistic individuals have co-occurring conditions (ADHD, depression, anxiety)</p>\n<p><strong>Which neurocognitive functions are important to study in the early development of autism?</strong></p>\n<p>Sensory processing atypicalities in autism:</p>\n<ul>\n<li>Hypersensitivity to sensory stimuli (e.g. intolerance of specific sounds, textures, smells)</li>\n<li>Hyposensitivity to sensory stimuli (e.g. blunted pain detection)</li>\n<li>Sensory-seeking (increased exploration of non-social sensory experiences e.g. stimming)</li>\n</ul>\n<p>Developmental trajectories to core autism symptom domains are intertwined</p>\n<p><strong>Studying early neurodevelopment in autism: Limitations</strong></p>\n<ol>\n<li><p>Heterogeneity:</p>\n<p>The autism phenotype &amp; underlying neurocognitive mechanisms vary across autistic individuals so it is unlikely that the same neurodevelopmental trajectories will lead to ASD in all individuals</p>\n</li>\n<li><p>Specificity:</p>\n<ul>\n<li>Autism co-occurs at high rates with other neurodevelopmental conditions (ADHD, anxiety)</li>\n<li>It is not clear whether the alterations in neurodevelopmental trajectories identified in infant sibling studies are specific to autism or shared with other conditions</li>\n<li>ADHD (e.g.) shows similar social-communication &amp; sensory alterations in infancy</li>\n</ul>\n</li>\n<li><p>Ethical concerns</p>\n</li>\n</ol>\n<p>Early interventions for autism based on neurodevelopmental studies: iBASIS-VIPP intervention</p>\n","excerpt":"","more":"<h1 id=\"Normal-brain-development\"><a href=\"#Normal-brain-development\" class=\"headerlink\" title=\"Normal brain development\"></a>Normal brain development</h1><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202203261550179.png\" alt=\"Mapping GM &amp; WM across the lifespan\"></p>\n<p>White matter volume increase from 0-45 (around), and decrease after 45; while grey matter decrease after 50s.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281040786.png\" alt=\"image-20220228104031409\"></p>\n<p>Q: how the ages affect choice: HOT EF. May the income affects their choice?</p>\n<p>May the background of children affect the results of marshmallow experiment?</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202281054786.png\" alt=\"image-20220228105421436\"></p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p><strong>Normal brain structural development</strong></p>\n<ul>\n<li>Increased WM/GM ratio</li>\n<li>Decrease in GM, cort thickness, surface area across adolescence </li>\n<li>Maturation of WM, GM &amp; WM tracts well into mid -adulthood </li>\n<li>Latest regions to mature: FL (DLPFC), STL, PL, BG, Cb</li>\n<li>Latest WM tracts to mature: Fronto-striato-thalamic, fronto-PL/TL.OCC tracts, cingulate tracts</li>\n<li>Earlier in girls than boys (some studies find not sex differences)</li>\n<li>Structural brain development is  associated with cognitive maturation</li>\n</ul>\n<p><strong>Normal brain function development of cool &amp; hot EF (Executive functions)</strong></p>\n<ul>\n<li>Functional maturation of task-relevant lateral “cool” FL-BG-PL &amp;“hot” OFC/vmPFC-limbic networks</li>\n<li>Progressively increased functional connectivity during cognitive tasks &amp; during rest (DMN)</li>\n<li>Progressively more deactivation of DMN (default mode network) with increasing age during tasks =&gt; better EF/Attention</li>\n<li>Progressively increased long-distance &amp; reduced short-range connectivity =&gt; integration through segregation</li>\n<li>Network communities include anatomically proximal regions; with age, more distributed networks emerge</li>\n<li>Network efficiency improves with age</li>\n<li>Interhemispheric connectivity increases</li>\n</ul>\n<hr>\n<h1 id=\"Neuroimaging-of-ASD-I\"><a href=\"#Neuroimaging-of-ASD-I\" class=\"headerlink\" title=\"Neuroimaging of ASD I\"></a>Neuroimaging of ASD I</h1><h2 id=\"Objects\"><a href=\"#Objects\" class=\"headerlink\" title=\"Objects\"></a>Objects</h2><ol>\n<li><p>Describe how we can study the early (pre-diagnostic) development of autism</p>\n</li>\n<li><p>Which neurocognitive functions are important to study in the early development of autism?</p>\n<ul>\n<li><p>sensory processing</p>\n</li>\n<li><p>social communication</p>\n</li>\n<li><p>attention/ executive function</p>\n</li>\n<li><p>others</p>\n</li>\n</ul>\n</li>\n<li><p>What cognitive neuroscience techniques can be used to study early brain and cognitive development in autism?</p>\n</li>\n<li><p>Explain one key set of findings from cognitive neuroscience studies about the early development of autism</p>\n</li>\n<li><p>How have findings from cognitive neuroscience studies been used to design and assess early interventions for autism?    </p>\n</li>\n</ol>\n<h2 id=\"Autism\"><a href=\"#Autism\" class=\"headerlink\" title=\"Autism\"></a>Autism</h2><p>Neurodevelopmental condition characterised by difficulties in 2 main areas (DSM-5):</p>\n<ol>\n<li>Social-communication and interaction</li>\n<li>Restricted and repetitive behaviours and sensory processing atypicalities</li>\n</ol>\n<p>Typical age of diagnosis: 4-5 years</p>\n<p>80% of autistic individuals have co-occurring conditions (ADHD, depression, anxiety)</p>\n<p><strong>Which neurocognitive functions are important to study in the early development of autism?</strong></p>\n<p>Sensory processing atypicalities in autism:</p>\n<ul>\n<li>Hypersensitivity to sensory stimuli (e.g. intolerance of specific sounds, textures, smells)</li>\n<li>Hyposensitivity to sensory stimuli (e.g. blunted pain detection)</li>\n<li>Sensory-seeking (increased exploration of non-social sensory experiences e.g. stimming)</li>\n</ul>\n<p>Developmental trajectories to core autism symptom domains are intertwined</p>\n<p><strong>Studying early neurodevelopment in autism: Limitations</strong></p>\n<ol>\n<li><p>Heterogeneity:</p>\n<p>The autism phenotype &amp; underlying neurocognitive mechanisms vary across autistic individuals so it is unlikely that the same neurodevelopmental trajectories will lead to ASD in all individuals</p>\n</li>\n<li><p>Specificity:</p>\n<ul>\n<li>Autism co-occurs at high rates with other neurodevelopmental conditions (ADHD, anxiety)</li>\n<li>It is not clear whether the alterations in neurodevelopmental trajectories identified in infant sibling studies are specific to autism or shared with other conditions</li>\n<li>ADHD (e.g.) shows similar social-communication &amp; sensory alterations in infancy</li>\n</ul>\n</li>\n<li><p>Ethical concerns</p>\n</li>\n</ol>\n<p>Early interventions for autism based on neurodevelopmental studies: iBASIS-VIPP intervention</p>\n"},{"title":"Update for RSS subscription and music player","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-24T21:58:00.000Z","password":null,"summary":null,"_content":"\n### RSS subscription\n\n本主题中还使用到了 [hexo-generator-feed](https://github.com/hexojs/hexo-generator-feed) 的 Hexo 插件来做 `RSS`，安装命令如下：\n\n```bash\nnpm install hexo-generator-feed --save\n```\n发现先前版本已经存在相关文件\n\n\n```bash\nnpm WARN read-shrinkwrap This version of npm is compatible with lockfileVersion@1, but package-lock.json was generated for lockfileVersion@2. I'll try to do my best with it!\nnpm ERR! path C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd\nnpm ERR! code EEXIST\nnpm ERR! Refusing to delete C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd: is outside C:\\Users\\Makka Papa\\blog\\node_modules\\eslint and not a link\nnpm ERR! File exists: C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd\nnpm ERR! Move it away, and try again.\n\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     C:\\Users\\Makka Papa\\AppData\\Roaming\\npm-cache\\_logs\\2022-02-24T20_10_57_129Z-debug.log\n\n```\n\n删除之\n\n重试第一步\n\n在 Hexo 根目录下的 `_config.yml` 文件中，新增以下的配置项：\n\n```yaml\nfeed:\n  type: atom\n  path: atom.xml\n  limit: 20\n  hub:\n  content:\n  content_limit: 140\n  content_limit_delim: ' '\n  order_by: -date\n```\n\n执行 `hexo clean && hexo g` 重新生成博客文件，然后在 `public` 文件夹中即可看到 `atom.xml` 文件，说明已经安装成功了。\n\n\n\n### 配置音乐播放器\n\n要支持音乐播放，就必须开启音乐的播放配置和音乐数据的文件。\n\n首先，在博客 `source` 目录下的 `_data` 目录（没有的话就新建一个）中新建 `musics.json` 文件，文件内容如下所示：\n\n```json\n[{\n\t\"name\": \"五月雨变奏电音\",\n\t\"artist\": \"AnimeVibe\",\n\t\"url\": \"http://xxx.com/music1.mp3\",\n\t\"cover\": \"http://xxx.com/music-cover1.png\"\n}, {\n\t\"name\": \"Take me hand\",\n\t\"artist\": \"DAISHI DANCE,Cecile Corbel\",\n\t\"url\": \"/medias/music/music2.mp3\",\n\t\"cover\": \"/medias/music/cover2.png\"\n}, {\n\t\"name\": \"Shape of You\",\n\t\"artist\": \"J.Fla\",\n\t\"url\": \"http://xxx.com/music3.mp3\",\n\t\"cover\": \"http://xxx.com/music-cover3.png\"\n}]\n```\n\n> **注**：以上 JSON 中的属性：`name`、`artist`、`url`、`cover` 分别表示音乐的名称、作者、音乐文件地址、音乐封面。\n\n然后，在主题的 `_config.yml` 配置文件中激活配置即可：\n\n```yaml\n# 是否在首页显示音乐.\nmusic:\n  enable: true\n  showTitle: false\n  title: 听听音乐\n  fixed: false # 是否开启吸底模式\n  autoplay: false # 是否自动播放\n  theme: '#42b983'\n  loop: 'all' # 音频循环播放, 可选值: 'all', 'one', 'none'\n  order: 'list' # 音频循环顺序, 可选值: 'list', 'random'\n  preload: 'auto' # 预加载，可选值: 'none', 'metadata', 'auto'\n  volume: 0.7 # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效\n  listFolded: false # 列表默认折叠\n  listMaxHeight: # 列表最大高度\n```\n","source":"_posts/24_02_22Update for RSS subscription and music player.md","raw":"---\ntitle: Update for RSS subscription and music player\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-24 21:58\npassword:\nsummary:\ntags:\n- blog building\ncategories:\n- programming\n---\n\n### RSS subscription\n\n本主题中还使用到了 [hexo-generator-feed](https://github.com/hexojs/hexo-generator-feed) 的 Hexo 插件来做 `RSS`，安装命令如下：\n\n```bash\nnpm install hexo-generator-feed --save\n```\n发现先前版本已经存在相关文件\n\n\n```bash\nnpm WARN read-shrinkwrap This version of npm is compatible with lockfileVersion@1, but package-lock.json was generated for lockfileVersion@2. I'll try to do my best with it!\nnpm ERR! path C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd\nnpm ERR! code EEXIST\nnpm ERR! Refusing to delete C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd: is outside C:\\Users\\Makka Papa\\blog\\node_modules\\eslint and not a link\nnpm ERR! File exists: C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd\nnpm ERR! Move it away, and try again.\n\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     C:\\Users\\Makka Papa\\AppData\\Roaming\\npm-cache\\_logs\\2022-02-24T20_10_57_129Z-debug.log\n\n```\n\n删除之\n\n重试第一步\n\n在 Hexo 根目录下的 `_config.yml` 文件中，新增以下的配置项：\n\n```yaml\nfeed:\n  type: atom\n  path: atom.xml\n  limit: 20\n  hub:\n  content:\n  content_limit: 140\n  content_limit_delim: ' '\n  order_by: -date\n```\n\n执行 `hexo clean && hexo g` 重新生成博客文件，然后在 `public` 文件夹中即可看到 `atom.xml` 文件，说明已经安装成功了。\n\n\n\n### 配置音乐播放器\n\n要支持音乐播放，就必须开启音乐的播放配置和音乐数据的文件。\n\n首先，在博客 `source` 目录下的 `_data` 目录（没有的话就新建一个）中新建 `musics.json` 文件，文件内容如下所示：\n\n```json\n[{\n\t\"name\": \"五月雨变奏电音\",\n\t\"artist\": \"AnimeVibe\",\n\t\"url\": \"http://xxx.com/music1.mp3\",\n\t\"cover\": \"http://xxx.com/music-cover1.png\"\n}, {\n\t\"name\": \"Take me hand\",\n\t\"artist\": \"DAISHI DANCE,Cecile Corbel\",\n\t\"url\": \"/medias/music/music2.mp3\",\n\t\"cover\": \"/medias/music/cover2.png\"\n}, {\n\t\"name\": \"Shape of You\",\n\t\"artist\": \"J.Fla\",\n\t\"url\": \"http://xxx.com/music3.mp3\",\n\t\"cover\": \"http://xxx.com/music-cover3.png\"\n}]\n```\n\n> **注**：以上 JSON 中的属性：`name`、`artist`、`url`、`cover` 分别表示音乐的名称、作者、音乐文件地址、音乐封面。\n\n然后，在主题的 `_config.yml` 配置文件中激活配置即可：\n\n```yaml\n# 是否在首页显示音乐.\nmusic:\n  enable: true\n  showTitle: false\n  title: 听听音乐\n  fixed: false # 是否开启吸底模式\n  autoplay: false # 是否自动播放\n  theme: '#42b983'\n  loop: 'all' # 音频循环播放, 可选值: 'all', 'one', 'none'\n  order: 'list' # 音频循环顺序, 可选值: 'list', 'random'\n  preload: 'auto' # 预加载，可选值: 'none', 'metadata', 'auto'\n  volume: 0.7 # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效\n  listFolded: false # 列表默认折叠\n  listMaxHeight: # 列表最大高度\n```\n","slug":"24_02_22Update for RSS subscription and music player","published":1,"updated":"2022-08-24T17:08:39.338Z","comments":1,"layout":"post","photos":[],"_id":"cuidoXl_oWdnoZuTCq66PU-LB","content":"<h3 id=\"RSS-subscription\"><a href=\"#RSS-subscription\" class=\"headerlink\" title=\"RSS subscription\"></a>RSS subscription</h3><p>本主题中还使用到了 <a href=\"https://github.com/hexojs/hexo-generator-feed\">hexo-generator-feed</a> 的 Hexo 插件来做 <code>RSS</code>，安装命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install hexo-generator-feed --save</span><br></pre></td></tr></table></figure>\n<p>发现先前版本已经存在相关文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm WARN read-shrinkwrap This version of npm is compatible with lockfileVersion@1, but package-lock.json was generated <span class=\"keyword\">for</span> lockfileVersion@2. I<span class=\"string\">&#x27;ll try to do my best with it!</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! path C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! code EEXIST</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! Refusing to delete C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd: is outside C:\\Users\\Makka Papa\\blog\\node_modules\\eslint and not a link</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! File exists: C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! Move it away, and try again.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">npm ERR! A complete log of this run can be found in:</span></span><br><span class=\"line\"><span class=\"string\">npm ERR!     C:\\Users\\Makka Papa\\AppData\\Roaming\\npm-cache\\_logs\\2022-02-24T20_10_57_129Z-debug.log</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br></pre></td></tr></table></figure>\n\n<p>删除之</p>\n<p>重试第一步</p>\n<p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">feed:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">atom</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">atom.xml</span></span><br><span class=\"line\">  <span class=\"attr\">limit:</span> <span class=\"number\">20</span></span><br><span class=\"line\">  <span class=\"attr\">hub:</span></span><br><span class=\"line\">  <span class=\"attr\">content:</span></span><br><span class=\"line\">  <span class=\"attr\">content_limit:</span> <span class=\"number\">140</span></span><br><span class=\"line\">  <span class=\"attr\">content_limit_delim:</span> <span class=\"string\">&#x27; &#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">order_by:</span> <span class=\"string\">-date</span></span><br></pre></td></tr></table></figure>\n\n<p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明已经安装成功了。</p>\n<h3 id=\"配置音乐播放器\"><a href=\"#配置音乐播放器\" class=\"headerlink\" title=\"配置音乐播放器\"></a>配置音乐播放器</h3><p>要支持音乐播放，就必须开启音乐的播放配置和音乐数据的文件。</p>\n<p>首先，在博客 <code>source</code> 目录下的 <code>_data</code> 目录（没有的话就新建一个）中新建 <code>musics.json</code> 文件，文件内容如下所示：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">[</span><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;五月雨变奏电音&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;artist&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;AnimeVibe&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;url&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music1.mp3&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;cover&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music-cover1.png&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Take me hand&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;artist&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;DAISHI DANCE,Cecile Corbel&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;url&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;/medias/music/music2.mp3&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;cover&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;/medias/music/cover2.png&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Shape of You&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;artist&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;J.Fla&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;url&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music3.mp3&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;cover&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music-cover3.png&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">]</span></span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p><strong>注</strong>：以上 JSON 中的属性：<code>name</code>、<code>artist</code>、<code>url</code>、<code>cover</code> 分别表示音乐的名称、作者、音乐文件地址、音乐封面。</p>\n</blockquote>\n<p>然后，在主题的 <code>_config.yml</code> 配置文件中激活配置即可：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 是否在首页显示音乐.</span></span><br><span class=\"line\"><span class=\"attr\">music:</span></span><br><span class=\"line\">  <span class=\"attr\">enable:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">showTitle:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">  <span class=\"attr\">title:</span> <span class=\"string\">听听音乐</span></span><br><span class=\"line\">  <span class=\"attr\">fixed:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 是否开启吸底模式</span></span><br><span class=\"line\">  <span class=\"attr\">autoplay:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 是否自动播放</span></span><br><span class=\"line\">  <span class=\"attr\">theme:</span> <span class=\"string\">&#x27;#42b983&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">loop:</span> <span class=\"string\">&#x27;all&#x27;</span> <span class=\"comment\"># 音频循环播放, 可选值: &#x27;all&#x27;, &#x27;one&#x27;, &#x27;none&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">order:</span> <span class=\"string\">&#x27;list&#x27;</span> <span class=\"comment\"># 音频循环顺序, 可选值: &#x27;list&#x27;, &#x27;random&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">preload:</span> <span class=\"string\">&#x27;auto&#x27;</span> <span class=\"comment\"># 预加载，可选值: &#x27;none&#x27;, &#x27;metadata&#x27;, &#x27;auto&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">volume:</span> <span class=\"number\">0.7</span> <span class=\"comment\"># 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span></span><br><span class=\"line\">  <span class=\"attr\">listFolded:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 列表默认折叠</span></span><br><span class=\"line\">  <span class=\"attr\">listMaxHeight:</span> <span class=\"comment\"># 列表最大高度</span></span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<h3 id=\"RSS-subscription\"><a href=\"#RSS-subscription\" class=\"headerlink\" title=\"RSS subscription\"></a>RSS subscription</h3><p>本主题中还使用到了 <a href=\"https://github.com/hexojs/hexo-generator-feed\">hexo-generator-feed</a> 的 Hexo 插件来做 <code>RSS</code>，安装命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install hexo-generator-feed --save</span><br></pre></td></tr></table></figure>\n<p>发现先前版本已经存在相关文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm WARN read-shrinkwrap This version of npm is compatible with lockfileVersion@1, but package-lock.json was generated <span class=\"keyword\">for</span> lockfileVersion@2. I<span class=\"string\">&#x27;ll try to do my best with it!</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! path C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! code EEXIST</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! Refusing to delete C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd: is outside C:\\Users\\Makka Papa\\blog\\node_modules\\eslint and not a link</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! File exists: C:\\Users\\Makka Papa\\blog\\node_modules\\.bin\\eslint.cmd</span></span><br><span class=\"line\"><span class=\"string\">npm ERR! Move it away, and try again.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">npm ERR! A complete log of this run can be found in:</span></span><br><span class=\"line\"><span class=\"string\">npm ERR!     C:\\Users\\Makka Papa\\AppData\\Roaming\\npm-cache\\_logs\\2022-02-24T20_10_57_129Z-debug.log</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br></pre></td></tr></table></figure>\n\n<p>删除之</p>\n<p>重试第一步</p>\n<p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">feed:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">atom</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">atom.xml</span></span><br><span class=\"line\">  <span class=\"attr\">limit:</span> <span class=\"number\">20</span></span><br><span class=\"line\">  <span class=\"attr\">hub:</span></span><br><span class=\"line\">  <span class=\"attr\">content:</span></span><br><span class=\"line\">  <span class=\"attr\">content_limit:</span> <span class=\"number\">140</span></span><br><span class=\"line\">  <span class=\"attr\">content_limit_delim:</span> <span class=\"string\">&#x27; &#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">order_by:</span> <span class=\"string\">-date</span></span><br></pre></td></tr></table></figure>\n\n<p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明已经安装成功了。</p>\n<h3 id=\"配置音乐播放器\"><a href=\"#配置音乐播放器\" class=\"headerlink\" title=\"配置音乐播放器\"></a>配置音乐播放器</h3><p>要支持音乐播放，就必须开启音乐的播放配置和音乐数据的文件。</p>\n<p>首先，在博客 <code>source</code> 目录下的 <code>_data</code> 目录（没有的话就新建一个）中新建 <code>musics.json</code> 文件，文件内容如下所示：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">[</span><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;五月雨变奏电音&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;artist&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;AnimeVibe&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;url&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music1.mp3&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;cover&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music-cover1.png&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Take me hand&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;artist&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;DAISHI DANCE,Cecile Corbel&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;url&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;/medias/music/music2.mp3&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;cover&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;/medias/music/cover2.png&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Shape of You&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;artist&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;J.Fla&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;url&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music3.mp3&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">\t<span class=\"attr\">&quot;cover&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;http://xxx.com/music-cover3.png&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">]</span></span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p><strong>注</strong>：以上 JSON 中的属性：<code>name</code>、<code>artist</code>、<code>url</code>、<code>cover</code> 分别表示音乐的名称、作者、音乐文件地址、音乐封面。</p>\n</blockquote>\n<p>然后，在主题的 <code>_config.yml</code> 配置文件中激活配置即可：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 是否在首页显示音乐.</span></span><br><span class=\"line\"><span class=\"attr\">music:</span></span><br><span class=\"line\">  <span class=\"attr\">enable:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">showTitle:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">  <span class=\"attr\">title:</span> <span class=\"string\">听听音乐</span></span><br><span class=\"line\">  <span class=\"attr\">fixed:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 是否开启吸底模式</span></span><br><span class=\"line\">  <span class=\"attr\">autoplay:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 是否自动播放</span></span><br><span class=\"line\">  <span class=\"attr\">theme:</span> <span class=\"string\">&#x27;#42b983&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">loop:</span> <span class=\"string\">&#x27;all&#x27;</span> <span class=\"comment\"># 音频循环播放, 可选值: &#x27;all&#x27;, &#x27;one&#x27;, &#x27;none&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">order:</span> <span class=\"string\">&#x27;list&#x27;</span> <span class=\"comment\"># 音频循环顺序, 可选值: &#x27;list&#x27;, &#x27;random&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">preload:</span> <span class=\"string\">&#x27;auto&#x27;</span> <span class=\"comment\"># 预加载，可选值: &#x27;none&#x27;, &#x27;metadata&#x27;, &#x27;auto&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">volume:</span> <span class=\"number\">0.7</span> <span class=\"comment\"># 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span></span><br><span class=\"line\">  <span class=\"attr\">listFolded:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 列表默认折叠</span></span><br><span class=\"line\">  <span class=\"attr\">listMaxHeight:</span> <span class=\"comment\"># 列表最大高度</span></span><br></pre></td></tr></table></figure>\n"},{"title":"Glossary","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-11-23T12:00:00.000Z","password":null,"summary":null,"_content":"## Glossary (sequenced by the first letter)\n\n**Accommodation:** Accommodation is a process of optical power changes of eyes for keeping a legible vision when the range between the observed and the observer shifts. The dynamic process of a lens’ morphological transformation is caused by the changes in the radius of the ciliary muscle (Helmholtz 1909), during which the curving covering diameters of the lens on both sides reduce, resulting in a raising power of refraction (Glasser 2006), then the lens will be accommodated (Figure 1).\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171345007.gif)\n\n**Figure 1.** Contraction of the ciliary muscle results to an accommodation (Land 2005)\n\n \n\n**Blind spot:** The blind spot is a small region in the field of vision correlating to the location of the optic disc (Figure 2) without image detection (Gamm, Albert & Daniel 2020), from which is the cranial nerve II penetrates so that there are no photoreceptors in the optic disc (Ramachandran 1992). \n\n![Find Your Blind Spot!](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171346685.jpg)\n\n**Figure 2.** Location of blind spot (Lohner 2020).\n\n\n\n**Cones and rods:** Cones and rods are the two kinds of photoreceptors (Figure 3) in the retina of the vertebrate retina (Schwiegerling 2004). The cones show responsibility to the bright light and colour sensitivity while cones are responsible for dim light (Schultze M 1866).\n\n![Differentiation between Cones and Rods (Ingram et al.2016)](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171348845.gif)\n\n**Figure 3.** Differentiation between Cones and Rods (Ingram et al. 2016)\n\n\n\n**Directionally selective ganglion cells:** Directionally selective ganglion cells are a group of retinal ganglion cells that can detect motions in different directions. They can respond actively to a movement from the chosen direction with a high postsynaptic potential after an inhibitory spike (Borst 2011) while active infrequently in response to opposite-direction movement of the same item (Barlow 1963). \n\n\n\n**Fovea Centralis:** Fovea Centralis is a tiny fossa in the centre of eyes (Figure 4) composed of cones densely located in the middle of the macula lutea (Iwasaki & Inomata 1986). Foveal vision is functioned by this area and is responsible for distinct item characteristics, such as form and location (Lettvin 1976).\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171350909.jpg)\n\n**Figure 4.** Fovea centralis anatomy in human eyes\n\n  \n\n**Photopigment:**  Photopigment is a transmembrane protein held inside photoreceptors functioning for light perception situated in plates of film in the external fragment of a pole or cone (Fu 2010). The purpose is to absorb incident light and afterwards produce a cascade reaction to change the electrical characters of the photoreceptors, in which case trigger the release of glutamate (Hart 2009). \n\n\n\n**Photoreception:** Photoreception is a process that photoreceptors for instance cones and rods retain light waves which are captured by eyes then convert the electromagnetic signs into electrochemical signs which are then shipped off the cerebrum for visual handling invertebrate animals (Foster et al. 1991). The whole process converts light stimulus to nerve impulse at last with help from specialised photoreceptors in the retina.\n\n \n\n**Phototransduction:** Phototransduction is an interaction by which electromagnetic energy is changed over into electrical chemical energy in cone cells, rod cells and retinal photosensitive ganglion cells in the eyes (Kusakabe et al. 2009). This process includes a series of primary biochemical and physiological actions, which is also known as “Wald's Visual Cycle” (Figure 5).\n\n![4: Wald&#39;s visual cycle. Blue color represents reactions in... | Download  Scientific Diagram](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351871.jpg)\n\n**Figure 5.** Wald's Visual Cycle (Vasudevan et al. 2017)\n\n \n\n**Retina:** The retina is the inverted tissue component toward the rear of the eyes (Figure 6) that detects light after cones and rods and sends processed information to the cerebrum. It is a photoreceptor and glial cells layer that catches approaching photons and sends them along neuronal pathways as both electrical and synthetic signs (Nguyen et al. 2021).\n\n \n\n![Illustration of retina anatomy](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351226.jpg)\n\n**Figure 6.** Retina anatomy (Heiting 2019)\n\n\n\n**Rhodopsin:** Rhodopsin is a kind of light-sensitive G-protein coupled receptor protein (GPCR) (Figure 7) (Lenaan et al. 2020) functioning during vision Wald's visual cycle. As a photo switchable opsin, one kind of photopigment found in retinal rods, it can be activated in a very low light environment (Litmann 1996).\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171352248.gif)\n\n**Figure 7.** 3D view of rhodopsin model (1F88)\n\n \n\n## **References:**\n\nHelmholtz, H. & Southall, J. P. C. (1962). Helmholtz's treatise on physiological optics. New York: Dover Publications.\n\nLand, M. (2015). Focusing by shape change in the lens of the eye: a commentary on Young (1801) 'On the mechanism of the eye'. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 370(1666), 20140308. https://doi.org/10.1098/rstb.2014.0308\n\nGlasser, A. (2006). Restoration of accommodation. Current opinion in ophthalmology, 17(1), 12–18. https://doi.org/10.1097/01.icu.0000193069.32369.e1\n\nGamm, D. M. Albert, and Daniel M. (2020). blind spot. Encyclopedia Britannica. https://www.britannica.com/science/blind-spot\n\nRamachandran, V. S. (1992). Blind spots. Scientific American, 266(5), 86–91. https://doi.org/10.1038/scientificamerican0592-86\n\nLohner, S., (2020). Find Your Blind Spot! Scientific American. \n\nSchwiegerling, J. Field Guide to Visual and Ophthalmic Optics, SPIE Press, Bellingham, WA (2004)\n\nSchultze M (1866). Zur Anatomie und Physiologie der Retina.Archiv f ̈ur mikroskopische Anatomie2, 175–286\n\nIngram, N. T., Sampath, A. P. & Fain, G. L. (2016). Why are rods more sensitive than cones? The journal of physiology, 594 (19), s. 5415–5426. doi:10.1113/jp272556\n\nBorst A, Euler T (2011). \"Seeing things in motion: models, circuits, and mechanisms\". Neuron. 71 (6): 974–94.\n\nBarlow, H. B. & Hill, R. M. (1963). Selective sensitivity to direction of movement in ganglion cells of rabbit retina. Science 139, 412–414.\n\nIwasaki, M., & Inomata, H. (1986). Relation between superficial capillaries and foveal structures in the human retina. Investigative Ophthalmology & Visual Science, 27(12), 1698-1705.\n\nLettvin J. Y. (1976). On seeing sidelong. The Sciences, 16(4), 10–20, 10.1002/j.2326-1951.1976. tb01231.x\n\nMyeyepage.weebly.com. 2021. myeyepage.weebly.com - Fovea Centralis.\n\nHart, N. S. (2009). Photopigments. In M. D. Binder, N. Hirokawa, & U. Windhorst (Eds.), Encyclopedia of Neuroscience (pp. 3148-3151). Berlin, Heidelberg: Springer Berlin Heidelberg.\n\nFoster, R.G.; Provencio, I.; Hudson, D.; Fiske, S.; Grip, W.; Menaker, M. (1991). \"Circadian photoreception in the retinally degenerate mouse (rd/rd)\". Journal of Comparative Physiology A. 169 (1): 39–50. doi:10.1007/BF00198171. PMID 1941717. S2CID 1124159.\n\nFu, Y. (2010). Phototransduction in Rods and Cones. In H. Kolb (Eds.) et. al., Webvision: The Organization of the Retina and Visual System. University of Utah Health Sciences Center.\n\nNguyen, K. H., Patel, B. C., & Tadi, P. (2021). Anatomy, Head and Neck, Eye Retina. In StatPearls. StatPearls Publishing.\n\nHeiting, G., (2019). How the Retina Works - Detailed Illustration. All About Vision. \n\nKusakabe, T. G., Takimoto, N., Jin, M., & Tsuda, M. (2009). Evolution and the origin of the visual retinoid cycle in vertebrates. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1531), 2897-2910. doi:10.1098/rstb.2009.0043\n\nVasudevan, Damodaran & S, Sreekumari & Vaidyanathan, Kannan. (2017). Chapter-15 Fat Soluble Vitamins. 10.5005/jp/books/13106_16.\n\nLenahan, C., Sanghavi, R., Huang, L., & Zhang, J. H. (2020). Rhodopsin: A Potential Biomarker for Neurodegenerative Diseases. Frontiers in neuroscience, 14, 326. https://doi.org/10.3389/fnins.2020.00326\n\nLitmann BJ, Mitchell DC (1996). \"Rhodopsin structure and function\". In Lee AG (ed.). Rhodopsin and G-Protein Linked Receptors, Part A (Vol 2, 1996) (2 Vol Set). Greenwich, Conn: JAI Press. pp. 1–32.","source":"_posts/23_11_21Glossary.md","raw":"---\ntitle: Glossary\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-11-23 12:00\npassword:\nsummary:\ntags:\n- glossary\ncategories:\n- Neuroscience\n---\n## Glossary (sequenced by the first letter)\n\n**Accommodation:** Accommodation is a process of optical power changes of eyes for keeping a legible vision when the range between the observed and the observer shifts. The dynamic process of a lens’ morphological transformation is caused by the changes in the radius of the ciliary muscle (Helmholtz 1909), during which the curving covering diameters of the lens on both sides reduce, resulting in a raising power of refraction (Glasser 2006), then the lens will be accommodated (Figure 1).\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171345007.gif)\n\n**Figure 1.** Contraction of the ciliary muscle results to an accommodation (Land 2005)\n\n \n\n**Blind spot:** The blind spot is a small region in the field of vision correlating to the location of the optic disc (Figure 2) without image detection (Gamm, Albert & Daniel 2020), from which is the cranial nerve II penetrates so that there are no photoreceptors in the optic disc (Ramachandran 1992). \n\n![Find Your Blind Spot!](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171346685.jpg)\n\n**Figure 2.** Location of blind spot (Lohner 2020).\n\n\n\n**Cones and rods:** Cones and rods are the two kinds of photoreceptors (Figure 3) in the retina of the vertebrate retina (Schwiegerling 2004). The cones show responsibility to the bright light and colour sensitivity while cones are responsible for dim light (Schultze M 1866).\n\n![Differentiation between Cones and Rods (Ingram et al.2016)](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171348845.gif)\n\n**Figure 3.** Differentiation between Cones and Rods (Ingram et al. 2016)\n\n\n\n**Directionally selective ganglion cells:** Directionally selective ganglion cells are a group of retinal ganglion cells that can detect motions in different directions. They can respond actively to a movement from the chosen direction with a high postsynaptic potential after an inhibitory spike (Borst 2011) while active infrequently in response to opposite-direction movement of the same item (Barlow 1963). \n\n\n\n**Fovea Centralis:** Fovea Centralis is a tiny fossa in the centre of eyes (Figure 4) composed of cones densely located in the middle of the macula lutea (Iwasaki & Inomata 1986). Foveal vision is functioned by this area and is responsible for distinct item characteristics, such as form and location (Lettvin 1976).\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171350909.jpg)\n\n**Figure 4.** Fovea centralis anatomy in human eyes\n\n  \n\n**Photopigment:**  Photopigment is a transmembrane protein held inside photoreceptors functioning for light perception situated in plates of film in the external fragment of a pole or cone (Fu 2010). The purpose is to absorb incident light and afterwards produce a cascade reaction to change the electrical characters of the photoreceptors, in which case trigger the release of glutamate (Hart 2009). \n\n\n\n**Photoreception:** Photoreception is a process that photoreceptors for instance cones and rods retain light waves which are captured by eyes then convert the electromagnetic signs into electrochemical signs which are then shipped off the cerebrum for visual handling invertebrate animals (Foster et al. 1991). The whole process converts light stimulus to nerve impulse at last with help from specialised photoreceptors in the retina.\n\n \n\n**Phototransduction:** Phototransduction is an interaction by which electromagnetic energy is changed over into electrical chemical energy in cone cells, rod cells and retinal photosensitive ganglion cells in the eyes (Kusakabe et al. 2009). This process includes a series of primary biochemical and physiological actions, which is also known as “Wald's Visual Cycle” (Figure 5).\n\n![4: Wald&#39;s visual cycle. Blue color represents reactions in... | Download  Scientific Diagram](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351871.jpg)\n\n**Figure 5.** Wald's Visual Cycle (Vasudevan et al. 2017)\n\n \n\n**Retina:** The retina is the inverted tissue component toward the rear of the eyes (Figure 6) that detects light after cones and rods and sends processed information to the cerebrum. It is a photoreceptor and glial cells layer that catches approaching photons and sends them along neuronal pathways as both electrical and synthetic signs (Nguyen et al. 2021).\n\n \n\n![Illustration of retina anatomy](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351226.jpg)\n\n**Figure 6.** Retina anatomy (Heiting 2019)\n\n\n\n**Rhodopsin:** Rhodopsin is a kind of light-sensitive G-protein coupled receptor protein (GPCR) (Figure 7) (Lenaan et al. 2020) functioning during vision Wald's visual cycle. As a photo switchable opsin, one kind of photopigment found in retinal rods, it can be activated in a very low light environment (Litmann 1996).\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171352248.gif)\n\n**Figure 7.** 3D view of rhodopsin model (1F88)\n\n \n\n## **References:**\n\nHelmholtz, H. & Southall, J. P. C. (1962). Helmholtz's treatise on physiological optics. New York: Dover Publications.\n\nLand, M. (2015). Focusing by shape change in the lens of the eye: a commentary on Young (1801) 'On the mechanism of the eye'. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 370(1666), 20140308. https://doi.org/10.1098/rstb.2014.0308\n\nGlasser, A. (2006). Restoration of accommodation. Current opinion in ophthalmology, 17(1), 12–18. https://doi.org/10.1097/01.icu.0000193069.32369.e1\n\nGamm, D. M. Albert, and Daniel M. (2020). blind spot. Encyclopedia Britannica. https://www.britannica.com/science/blind-spot\n\nRamachandran, V. S. (1992). Blind spots. Scientific American, 266(5), 86–91. https://doi.org/10.1038/scientificamerican0592-86\n\nLohner, S., (2020). Find Your Blind Spot! Scientific American. \n\nSchwiegerling, J. Field Guide to Visual and Ophthalmic Optics, SPIE Press, Bellingham, WA (2004)\n\nSchultze M (1866). Zur Anatomie und Physiologie der Retina.Archiv f ̈ur mikroskopische Anatomie2, 175–286\n\nIngram, N. T., Sampath, A. P. & Fain, G. L. (2016). Why are rods more sensitive than cones? The journal of physiology, 594 (19), s. 5415–5426. doi:10.1113/jp272556\n\nBorst A, Euler T (2011). \"Seeing things in motion: models, circuits, and mechanisms\". Neuron. 71 (6): 974–94.\n\nBarlow, H. B. & Hill, R. M. (1963). Selective sensitivity to direction of movement in ganglion cells of rabbit retina. Science 139, 412–414.\n\nIwasaki, M., & Inomata, H. (1986). Relation between superficial capillaries and foveal structures in the human retina. Investigative Ophthalmology & Visual Science, 27(12), 1698-1705.\n\nLettvin J. Y. (1976). On seeing sidelong. The Sciences, 16(4), 10–20, 10.1002/j.2326-1951.1976. tb01231.x\n\nMyeyepage.weebly.com. 2021. myeyepage.weebly.com - Fovea Centralis.\n\nHart, N. S. (2009). Photopigments. In M. D. Binder, N. Hirokawa, & U. Windhorst (Eds.), Encyclopedia of Neuroscience (pp. 3148-3151). Berlin, Heidelberg: Springer Berlin Heidelberg.\n\nFoster, R.G.; Provencio, I.; Hudson, D.; Fiske, S.; Grip, W.; Menaker, M. (1991). \"Circadian photoreception in the retinally degenerate mouse (rd/rd)\". Journal of Comparative Physiology A. 169 (1): 39–50. doi:10.1007/BF00198171. PMID 1941717. S2CID 1124159.\n\nFu, Y. (2010). Phototransduction in Rods and Cones. In H. Kolb (Eds.) et. al., Webvision: The Organization of the Retina and Visual System. University of Utah Health Sciences Center.\n\nNguyen, K. H., Patel, B. C., & Tadi, P. (2021). Anatomy, Head and Neck, Eye Retina. In StatPearls. StatPearls Publishing.\n\nHeiting, G., (2019). How the Retina Works - Detailed Illustration. All About Vision. \n\nKusakabe, T. G., Takimoto, N., Jin, M., & Tsuda, M. (2009). Evolution and the origin of the visual retinoid cycle in vertebrates. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1531), 2897-2910. doi:10.1098/rstb.2009.0043\n\nVasudevan, Damodaran & S, Sreekumari & Vaidyanathan, Kannan. (2017). Chapter-15 Fat Soluble Vitamins. 10.5005/jp/books/13106_16.\n\nLenahan, C., Sanghavi, R., Huang, L., & Zhang, J. H. (2020). Rhodopsin: A Potential Biomarker for Neurodegenerative Diseases. Frontiers in neuroscience, 14, 326. https://doi.org/10.3389/fnins.2020.00326\n\nLitmann BJ, Mitchell DC (1996). \"Rhodopsin structure and function\". In Lee AG (ed.). Rhodopsin and G-Protein Linked Receptors, Part A (Vol 2, 1996) (2 Vol Set). Greenwich, Conn: JAI Press. pp. 1–32.","slug":"23_11_21Glossary","published":1,"updated":"2022-08-24T17:08:39.337Z","comments":1,"layout":"post","photos":[],"_id":"cuidR_xbwPn_dz3fhzCxoqPwz","content":"<h2 id=\"Glossary-sequenced-by-the-first-letter\"><a href=\"#Glossary-sequenced-by-the-first-letter\" class=\"headerlink\" title=\"Glossary (sequenced by the first letter)\"></a>Glossary (sequenced by the first letter)</h2><p><strong>Accommodation:</strong> Accommodation is a process of optical power changes of eyes for keeping a legible vision when the range between the observed and the observer shifts. The dynamic process of a lens’ morphological transformation is caused by the changes in the radius of the ciliary muscle (Helmholtz 1909), during which the curving covering diameters of the lens on both sides reduce, resulting in a raising power of refraction (Glasser 2006), then the lens will be accommodated (Figure 1).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171345007.gif\" alt=\"img\"></p>\n<p><strong>Figure 1.</strong> Contraction of the ciliary muscle results to an accommodation (Land 2005)</p>\n<p><strong>Blind spot:</strong> The blind spot is a small region in the field of vision correlating to the location of the optic disc (Figure 2) without image detection (Gamm, Albert &amp; Daniel 2020), from which is the cranial nerve II penetrates so that there are no photoreceptors in the optic disc (Ramachandran 1992). </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171346685.jpg\" alt=\"Find Your Blind Spot!\"></p>\n<p><strong>Figure 2.</strong> Location of blind spot (Lohner 2020).</p>\n<p><strong>Cones and rods:</strong> Cones and rods are the two kinds of photoreceptors (Figure 3) in the retina of the vertebrate retina (Schwiegerling 2004). The cones show responsibility to the bright light and colour sensitivity while cones are responsible for dim light (Schultze M 1866).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171348845.gif\" alt=\"Differentiation between Cones and Rods (Ingram et al.2016)\"></p>\n<p><strong>Figure 3.</strong> Differentiation between Cones and Rods (Ingram et al. 2016)</p>\n<p><strong>Directionally selective ganglion cells:</strong> Directionally selective ganglion cells are a group of retinal ganglion cells that can detect motions in different directions. They can respond actively to a movement from the chosen direction with a high postsynaptic potential after an inhibitory spike (Borst 2011) while active infrequently in response to opposite-direction movement of the same item (Barlow 1963). </p>\n<p><strong>Fovea Centralis:</strong> Fovea Centralis is a tiny fossa in the centre of eyes (Figure 4) composed of cones densely located in the middle of the macula lutea (Iwasaki &amp; Inomata 1986). Foveal vision is functioned by this area and is responsible for distinct item characteristics, such as form and location (Lettvin 1976).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171350909.jpg\" alt=\"img\"></p>\n<p><strong>Figure 4.</strong> Fovea centralis anatomy in human eyes</p>\n<p><strong>Photopigment:</strong>  Photopigment is a transmembrane protein held inside photoreceptors functioning for light perception situated in plates of film in the external fragment of a pole or cone (Fu 2010). The purpose is to absorb incident light and afterwards produce a cascade reaction to change the electrical characters of the photoreceptors, in which case trigger the release of glutamate (Hart 2009). </p>\n<p><strong>Photoreception:</strong> Photoreception is a process that photoreceptors for instance cones and rods retain light waves which are captured by eyes then convert the electromagnetic signs into electrochemical signs which are then shipped off the cerebrum for visual handling invertebrate animals (Foster et al. 1991). The whole process converts light stimulus to nerve impulse at last with help from specialised photoreceptors in the retina.</p>\n<p><strong>Phototransduction:</strong> Phototransduction is an interaction by which electromagnetic energy is changed over into electrical chemical energy in cone cells, rod cells and retinal photosensitive ganglion cells in the eyes (Kusakabe et al. 2009). This process includes a series of primary biochemical and physiological actions, which is also known as “Wald’s Visual Cycle” (Figure 5).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351871.jpg\" alt=\"4: Wald&#39;s visual cycle. Blue color represents reactions in... | Download  Scientific Diagram\"></p>\n<p><strong>Figure 5.</strong> Wald’s Visual Cycle (Vasudevan et al. 2017)</p>\n<p><strong>Retina:</strong> The retina is the inverted tissue component toward the rear of the eyes (Figure 6) that detects light after cones and rods and sends processed information to the cerebrum. It is a photoreceptor and glial cells layer that catches approaching photons and sends them along neuronal pathways as both electrical and synthetic signs (Nguyen et al. 2021).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351226.jpg\" alt=\"Illustration of retina anatomy\"></p>\n<p><strong>Figure 6.</strong> Retina anatomy (Heiting 2019)</p>\n<p><strong>Rhodopsin:</strong> Rhodopsin is a kind of light-sensitive G-protein coupled receptor protein (GPCR) (Figure 7) (Lenaan et al. 2020) functioning during vision Wald’s visual cycle. As a photo switchable opsin, one kind of photopigment found in retinal rods, it can be activated in a very low light environment (Litmann 1996).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171352248.gif\" alt=\"img\"></p>\n<p><strong>Figure 7.</strong> 3D view of rhodopsin model (1F88)</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References:\"></a><strong>References:</strong></h2><p>Helmholtz, H. &amp; Southall, J. P. C. (1962). Helmholtz’s treatise on physiological optics. New York: Dover Publications.</p>\n<p>Land, M. (2015). Focusing by shape change in the lens of the eye: a commentary on Young (1801) ‘On the mechanism of the eye’. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 370(1666), 20140308. <a href=\"https://doi.org/10.1098/rstb.2014.0308\">https://doi.org/10.1098/rstb.2014.0308</a></p>\n<p>Glasser, A. (2006). Restoration of accommodation. Current opinion in ophthalmology, 17(1), 12–18. <a href=\"https://doi.org/10.1097/01.icu.0000193069.32369.e1\">https://doi.org/10.1097/01.icu.0000193069.32369.e1</a></p>\n<p>Gamm, D. M. Albert, and Daniel M. (2020). blind spot. Encyclopedia Britannica. <a href=\"https://www.britannica.com/science/blind-spot\">https://www.britannica.com/science/blind-spot</a></p>\n<p>Ramachandran, V. S. (1992). Blind spots. Scientific American, 266(5), 86–91. <a href=\"https://doi.org/10.1038/scientificamerican0592-86\">https://doi.org/10.1038/scientificamerican0592-86</a></p>\n<p>Lohner, S., (2020). Find Your Blind Spot! Scientific American. </p>\n<p>Schwiegerling, J. Field Guide to Visual and Ophthalmic Optics, SPIE Press, Bellingham, WA (2004)</p>\n<p>Schultze M (1866). Zur Anatomie und Physiologie der Retina.Archiv f ̈ur mikroskopische Anatomie2, 175–286</p>\n<p>Ingram, N. T., Sampath, A. P. &amp; Fain, G. L. (2016). Why are rods more sensitive than cones? The journal of physiology, 594 (19), s. 5415–5426. doi:10.1113/jp272556</p>\n<p>Borst A, Euler T (2011). “Seeing things in motion: models, circuits, and mechanisms”. Neuron. 71 (6): 974–94.</p>\n<p>Barlow, H. B. &amp; Hill, R. M. (1963). Selective sensitivity to direction of movement in ganglion cells of rabbit retina. Science 139, 412–414.</p>\n<p>Iwasaki, M., &amp; Inomata, H. (1986). Relation between superficial capillaries and foveal structures in the human retina. Investigative Ophthalmology &amp; Visual Science, 27(12), 1698-1705.</p>\n<p>Lettvin J. Y. (1976). On seeing sidelong. The Sciences, 16(4), 10–20, 10.1002/j.2326-1951.1976. tb01231.x</p>\n<p>Myeyepage.weebly.com. 2021. myeyepage.weebly.com - Fovea Centralis.</p>\n<p>Hart, N. S. (2009). Photopigments. In M. D. Binder, N. Hirokawa, &amp; U. Windhorst (Eds.), Encyclopedia of Neuroscience (pp. 3148-3151). Berlin, Heidelberg: Springer Berlin Heidelberg.</p>\n<p>Foster, R.G.; Provencio, I.; Hudson, D.; Fiske, S.; Grip, W.; Menaker, M. (1991). “Circadian photoreception in the retinally degenerate mouse (rd/rd)”. Journal of Comparative Physiology A. 169 (1): 39–50. doi:10.1007/BF00198171. PMID 1941717. S2CID 1124159.</p>\n<p>Fu, Y. (2010). Phototransduction in Rods and Cones. In H. Kolb (Eds.) et. al., Webvision: The Organization of the Retina and Visual System. University of Utah Health Sciences Center.</p>\n<p>Nguyen, K. H., Patel, B. C., &amp; Tadi, P. (2021). Anatomy, Head and Neck, Eye Retina. In StatPearls. StatPearls Publishing.</p>\n<p>Heiting, G., (2019). How the Retina Works - Detailed Illustration. All About Vision. </p>\n<p>Kusakabe, T. G., Takimoto, N., Jin, M., &amp; Tsuda, M. (2009). Evolution and the origin of the visual retinoid cycle in vertebrates. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1531), 2897-2910. doi:10.1098/rstb.2009.0043</p>\n<p>Vasudevan, Damodaran &amp; S, Sreekumari &amp; Vaidyanathan, Kannan. (2017). Chapter-15 Fat Soluble Vitamins. 10.5005/jp/books/13106_16.</p>\n<p>Lenahan, C., Sanghavi, R., Huang, L., &amp; Zhang, J. H. (2020). Rhodopsin: A Potential Biomarker for Neurodegenerative Diseases. Frontiers in neuroscience, 14, 326. <a href=\"https://doi.org/10.3389/fnins.2020.00326\">https://doi.org/10.3389/fnins.2020.00326</a></p>\n<p>Litmann BJ, Mitchell DC (1996). “Rhodopsin structure and function”. In Lee AG (ed.). Rhodopsin and G-Protein Linked Receptors, Part A (Vol 2, 1996) (2 Vol Set). Greenwich, Conn: JAI Press. pp. 1–32.</p>\n","excerpt":"","more":"<h2 id=\"Glossary-sequenced-by-the-first-letter\"><a href=\"#Glossary-sequenced-by-the-first-letter\" class=\"headerlink\" title=\"Glossary (sequenced by the first letter)\"></a>Glossary (sequenced by the first letter)</h2><p><strong>Accommodation:</strong> Accommodation is a process of optical power changes of eyes for keeping a legible vision when the range between the observed and the observer shifts. The dynamic process of a lens’ morphological transformation is caused by the changes in the radius of the ciliary muscle (Helmholtz 1909), during which the curving covering diameters of the lens on both sides reduce, resulting in a raising power of refraction (Glasser 2006), then the lens will be accommodated (Figure 1).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171345007.gif\" alt=\"img\"></p>\n<p><strong>Figure 1.</strong> Contraction of the ciliary muscle results to an accommodation (Land 2005)</p>\n<p><strong>Blind spot:</strong> The blind spot is a small region in the field of vision correlating to the location of the optic disc (Figure 2) without image detection (Gamm, Albert &amp; Daniel 2020), from which is the cranial nerve II penetrates so that there are no photoreceptors in the optic disc (Ramachandran 1992). </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171346685.jpg\" alt=\"Find Your Blind Spot!\"></p>\n<p><strong>Figure 2.</strong> Location of blind spot (Lohner 2020).</p>\n<p><strong>Cones and rods:</strong> Cones and rods are the two kinds of photoreceptors (Figure 3) in the retina of the vertebrate retina (Schwiegerling 2004). The cones show responsibility to the bright light and colour sensitivity while cones are responsible for dim light (Schultze M 1866).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171348845.gif\" alt=\"Differentiation between Cones and Rods (Ingram et al.2016)\"></p>\n<p><strong>Figure 3.</strong> Differentiation between Cones and Rods (Ingram et al. 2016)</p>\n<p><strong>Directionally selective ganglion cells:</strong> Directionally selective ganglion cells are a group of retinal ganglion cells that can detect motions in different directions. They can respond actively to a movement from the chosen direction with a high postsynaptic potential after an inhibitory spike (Borst 2011) while active infrequently in response to opposite-direction movement of the same item (Barlow 1963). </p>\n<p><strong>Fovea Centralis:</strong> Fovea Centralis is a tiny fossa in the centre of eyes (Figure 4) composed of cones densely located in the middle of the macula lutea (Iwasaki &amp; Inomata 1986). Foveal vision is functioned by this area and is responsible for distinct item characteristics, such as form and location (Lettvin 1976).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171350909.jpg\" alt=\"img\"></p>\n<p><strong>Figure 4.</strong> Fovea centralis anatomy in human eyes</p>\n<p><strong>Photopigment:</strong>  Photopigment is a transmembrane protein held inside photoreceptors functioning for light perception situated in plates of film in the external fragment of a pole or cone (Fu 2010). The purpose is to absorb incident light and afterwards produce a cascade reaction to change the electrical characters of the photoreceptors, in which case trigger the release of glutamate (Hart 2009). </p>\n<p><strong>Photoreception:</strong> Photoreception is a process that photoreceptors for instance cones and rods retain light waves which are captured by eyes then convert the electromagnetic signs into electrochemical signs which are then shipped off the cerebrum for visual handling invertebrate animals (Foster et al. 1991). The whole process converts light stimulus to nerve impulse at last with help from specialised photoreceptors in the retina.</p>\n<p><strong>Phototransduction:</strong> Phototransduction is an interaction by which electromagnetic energy is changed over into electrical chemical energy in cone cells, rod cells and retinal photosensitive ganglion cells in the eyes (Kusakabe et al. 2009). This process includes a series of primary biochemical and physiological actions, which is also known as “Wald’s Visual Cycle” (Figure 5).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351871.jpg\" alt=\"4: Wald&#39;s visual cycle. Blue color represents reactions in... | Download  Scientific Diagram\"></p>\n<p><strong>Figure 5.</strong> Wald’s Visual Cycle (Vasudevan et al. 2017)</p>\n<p><strong>Retina:</strong> The retina is the inverted tissue component toward the rear of the eyes (Figure 6) that detects light after cones and rods and sends processed information to the cerebrum. It is a photoreceptor and glial cells layer that catches approaching photons and sends them along neuronal pathways as both electrical and synthetic signs (Nguyen et al. 2021).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171351226.jpg\" alt=\"Illustration of retina anatomy\"></p>\n<p><strong>Figure 6.</strong> Retina anatomy (Heiting 2019)</p>\n<p><strong>Rhodopsin:</strong> Rhodopsin is a kind of light-sensitive G-protein coupled receptor protein (GPCR) (Figure 7) (Lenaan et al. 2020) functioning during vision Wald’s visual cycle. As a photo switchable opsin, one kind of photopigment found in retinal rods, it can be activated in a very low light environment (Litmann 1996).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202202171352248.gif\" alt=\"img\"></p>\n<p><strong>Figure 7.</strong> 3D view of rhodopsin model (1F88)</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References:\"></a><strong>References:</strong></h2><p>Helmholtz, H. &amp; Southall, J. P. C. (1962). Helmholtz’s treatise on physiological optics. New York: Dover Publications.</p>\n<p>Land, M. (2015). Focusing by shape change in the lens of the eye: a commentary on Young (1801) ‘On the mechanism of the eye’. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 370(1666), 20140308. <a href=\"https://doi.org/10.1098/rstb.2014.0308\">https://doi.org/10.1098/rstb.2014.0308</a></p>\n<p>Glasser, A. (2006). Restoration of accommodation. Current opinion in ophthalmology, 17(1), 12–18. <a href=\"https://doi.org/10.1097/01.icu.0000193069.32369.e1\">https://doi.org/10.1097/01.icu.0000193069.32369.e1</a></p>\n<p>Gamm, D. M. Albert, and Daniel M. (2020). blind spot. Encyclopedia Britannica. <a href=\"https://www.britannica.com/science/blind-spot\">https://www.britannica.com/science/blind-spot</a></p>\n<p>Ramachandran, V. S. (1992). Blind spots. Scientific American, 266(5), 86–91. <a href=\"https://doi.org/10.1038/scientificamerican0592-86\">https://doi.org/10.1038/scientificamerican0592-86</a></p>\n<p>Lohner, S., (2020). Find Your Blind Spot! Scientific American. </p>\n<p>Schwiegerling, J. Field Guide to Visual and Ophthalmic Optics, SPIE Press, Bellingham, WA (2004)</p>\n<p>Schultze M (1866). Zur Anatomie und Physiologie der Retina.Archiv f ̈ur mikroskopische Anatomie2, 175–286</p>\n<p>Ingram, N. T., Sampath, A. P. &amp; Fain, G. L. (2016). Why are rods more sensitive than cones? The journal of physiology, 594 (19), s. 5415–5426. doi:10.1113/jp272556</p>\n<p>Borst A, Euler T (2011). “Seeing things in motion: models, circuits, and mechanisms”. Neuron. 71 (6): 974–94.</p>\n<p>Barlow, H. B. &amp; Hill, R. M. (1963). Selective sensitivity to direction of movement in ganglion cells of rabbit retina. Science 139, 412–414.</p>\n<p>Iwasaki, M., &amp; Inomata, H. (1986). Relation between superficial capillaries and foveal structures in the human retina. Investigative Ophthalmology &amp; Visual Science, 27(12), 1698-1705.</p>\n<p>Lettvin J. Y. (1976). On seeing sidelong. The Sciences, 16(4), 10–20, 10.1002/j.2326-1951.1976. tb01231.x</p>\n<p>Myeyepage.weebly.com. 2021. myeyepage.weebly.com - Fovea Centralis.</p>\n<p>Hart, N. S. (2009). Photopigments. In M. D. Binder, N. Hirokawa, &amp; U. Windhorst (Eds.), Encyclopedia of Neuroscience (pp. 3148-3151). Berlin, Heidelberg: Springer Berlin Heidelberg.</p>\n<p>Foster, R.G.; Provencio, I.; Hudson, D.; Fiske, S.; Grip, W.; Menaker, M. (1991). “Circadian photoreception in the retinally degenerate mouse (rd/rd)”. Journal of Comparative Physiology A. 169 (1): 39–50. doi:10.1007/BF00198171. PMID 1941717. S2CID 1124159.</p>\n<p>Fu, Y. (2010). Phototransduction in Rods and Cones. In H. Kolb (Eds.) et. al., Webvision: The Organization of the Retina and Visual System. University of Utah Health Sciences Center.</p>\n<p>Nguyen, K. H., Patel, B. C., &amp; Tadi, P. (2021). Anatomy, Head and Neck, Eye Retina. In StatPearls. StatPearls Publishing.</p>\n<p>Heiting, G., (2019). How the Retina Works - Detailed Illustration. All About Vision. </p>\n<p>Kusakabe, T. G., Takimoto, N., Jin, M., &amp; Tsuda, M. (2009). Evolution and the origin of the visual retinoid cycle in vertebrates. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1531), 2897-2910. doi:10.1098/rstb.2009.0043</p>\n<p>Vasudevan, Damodaran &amp; S, Sreekumari &amp; Vaidyanathan, Kannan. (2017). Chapter-15 Fat Soluble Vitamins. 10.5005/jp/books/13106_16.</p>\n<p>Lenahan, C., Sanghavi, R., Huang, L., &amp; Zhang, J. H. (2020). Rhodopsin: A Potential Biomarker for Neurodegenerative Diseases. Frontiers in neuroscience, 14, 326. <a href=\"https://doi.org/10.3389/fnins.2020.00326\">https://doi.org/10.3389/fnins.2020.00326</a></p>\n<p>Litmann BJ, Mitchell DC (1996). “Rhodopsin structure and function”. In Lee AG (ed.). Rhodopsin and G-Protein Linked Receptors, Part A (Vol 2, 1996) (2 Vol Set). Greenwich, Conn: JAI Press. pp. 1–32.</p>\n"},{"title":"Chengdu 5 days","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2023-03-20T14:11:00.000Z","password":null,"summary":null,"_content":"\n# 成都市区两天行程\n\n![image-20230320141741938](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202303201417198.png)\n\n## 第一天\n\n- 早上8:00-中午12:00：熊猫基地\n- 下午：春熙路、太古里（购物中心）\n\n### 购票\n\n- 关注“成都大熊猫繁育研究基地”公众号即可购门票+园区内观光车票\n- 关注“景区直通车”公众号，可以购买直达熊猫基地的公交车票，上车点包括春熙路IFS，武侯祠/锦里，宽窄巷子\n- 也可以购买从熊猫基地返回春熙路、武侯祠、宽窄巷子的公交车票，去熊猫基地推荐公交车\n\n### 地图路线\n\n![第一天地图路线](https://source.unsplash.com/1280x720/?成都市熊猫基地)\n\n## 第二天\n\n- 上午：宽窄巷子、锦里/武侯祠、杜甫草堂（打卡景区）\n\n### 购票\n\n- 宽窄巷子免门票、武侯祠需门票、杜甫草堂需门票，可以通过其他APP购买，或者“景区直通车”购买\n\n### 交通\n\n- 支付宝开通“天府通”乘坐地铁前往或者打车也可以，同时“景区直通车”上面也有不同景之间的车票\n\n### 地图路线\n\n![第二天地图路线](https://source.unsplash.com/1280x720/?成都市宽窄巷子)\n\n## 住宿\n\n推荐住在市中心，春熙路附近，交通便利，可以逛街\n\n## 美食\n\n- 烤鱼：烤匠\n- 火锅：都差不多，挑一家评价不错的就行\n- 其他小吃：宽窄巷子和锦里不建议吃，建设路（春熙路附近）小吃挺多，可以尝一尝兔子：双流老妈兔头\n","source":"_posts/Chengdu.md","raw":"---\ntitle: Chengdu 5 days\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2023-03-20 14:11\npassword:\nsummary:\ntags:\n- Chengdu\ncategories:\n- Traveling\n---\n\n# 成都市区两天行程\n\n![image-20230320141741938](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202303201417198.png)\n\n## 第一天\n\n- 早上8:00-中午12:00：熊猫基地\n- 下午：春熙路、太古里（购物中心）\n\n### 购票\n\n- 关注“成都大熊猫繁育研究基地”公众号即可购门票+园区内观光车票\n- 关注“景区直通车”公众号，可以购买直达熊猫基地的公交车票，上车点包括春熙路IFS，武侯祠/锦里，宽窄巷子\n- 也可以购买从熊猫基地返回春熙路、武侯祠、宽窄巷子的公交车票，去熊猫基地推荐公交车\n\n### 地图路线\n\n![第一天地图路线](https://source.unsplash.com/1280x720/?成都市熊猫基地)\n\n## 第二天\n\n- 上午：宽窄巷子、锦里/武侯祠、杜甫草堂（打卡景区）\n\n### 购票\n\n- 宽窄巷子免门票、武侯祠需门票、杜甫草堂需门票，可以通过其他APP购买，或者“景区直通车”购买\n\n### 交通\n\n- 支付宝开通“天府通”乘坐地铁前往或者打车也可以，同时“景区直通车”上面也有不同景之间的车票\n\n### 地图路线\n\n![第二天地图路线](https://source.unsplash.com/1280x720/?成都市宽窄巷子)\n\n## 住宿\n\n推荐住在市中心，春熙路附近，交通便利，可以逛街\n\n## 美食\n\n- 烤鱼：烤匠\n- 火锅：都差不多，挑一家评价不错的就行\n- 其他小吃：宽窄巷子和锦里不建议吃，建设路（春熙路附近）小吃挺多，可以尝一尝兔子：双流老妈兔头\n","slug":"Chengdu","published":1,"updated":"2023-03-20T06:18:48.306Z","comments":1,"layout":"post","photos":[],"_id":"cuidVvpPQRPfirPO4IeOLtsJC","content":"<h1 id=\"成都市区两天行程\"><a href=\"#成都市区两天行程\" class=\"headerlink\" title=\"成都市区两天行程\"></a>成都市区两天行程</h1><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202303201417198.png\" alt=\"image-20230320141741938\"></p>\n<h2 id=\"第一天\"><a href=\"#第一天\" class=\"headerlink\" title=\"第一天\"></a>第一天</h2><ul>\n<li>早上8:00-中午12:00：熊猫基地</li>\n<li>下午：春熙路、太古里（购物中心）</li>\n</ul>\n<h3 id=\"购票\"><a href=\"#购票\" class=\"headerlink\" title=\"购票\"></a>购票</h3><ul>\n<li>关注“成都大熊猫繁育研究基地”公众号即可购门票+园区内观光车票</li>\n<li>关注“景区直通车”公众号，可以购买直达熊猫基地的公交车票，上车点包括春熙路IFS，武侯祠/锦里，宽窄巷子</li>\n<li>也可以购买从熊猫基地返回春熙路、武侯祠、宽窄巷子的公交车票，去熊猫基地推荐公交车</li>\n</ul>\n<h3 id=\"地图路线\"><a href=\"#地图路线\" class=\"headerlink\" title=\"地图路线\"></a>地图路线</h3><p><img src=\"https://source.unsplash.com/1280x720/?%E6%88%90%E9%83%BD%E5%B8%82%E7%86%8A%E7%8C%AB%E5%9F%BA%E5%9C%B0\" alt=\"第一天地图路线\"></p>\n<h2 id=\"第二天\"><a href=\"#第二天\" class=\"headerlink\" title=\"第二天\"></a>第二天</h2><ul>\n<li>上午：宽窄巷子、锦里/武侯祠、杜甫草堂（打卡景区）</li>\n</ul>\n<h3 id=\"购票-1\"><a href=\"#购票-1\" class=\"headerlink\" title=\"购票\"></a>购票</h3><ul>\n<li>宽窄巷子免门票、武侯祠需门票、杜甫草堂需门票，可以通过其他APP购买，或者“景区直通车”购买</li>\n</ul>\n<h3 id=\"交通\"><a href=\"#交通\" class=\"headerlink\" title=\"交通\"></a>交通</h3><ul>\n<li>支付宝开通“天府通”乘坐地铁前往或者打车也可以，同时“景区直通车”上面也有不同景之间的车票</li>\n</ul>\n<h3 id=\"地图路线-1\"><a href=\"#地图路线-1\" class=\"headerlink\" title=\"地图路线\"></a>地图路线</h3><p><img src=\"https://source.unsplash.com/1280x720/?%E6%88%90%E9%83%BD%E5%B8%82%E5%AE%BD%E7%AA%84%E5%B7%B7%E5%AD%90\" alt=\"第二天地图路线\"></p>\n<h2 id=\"住宿\"><a href=\"#住宿\" class=\"headerlink\" title=\"住宿\"></a>住宿</h2><p>推荐住在市中心，春熙路附近，交通便利，可以逛街</p>\n<h2 id=\"美食\"><a href=\"#美食\" class=\"headerlink\" title=\"美食\"></a>美食</h2><ul>\n<li>烤鱼：烤匠</li>\n<li>火锅：都差不多，挑一家评价不错的就行</li>\n<li>其他小吃：宽窄巷子和锦里不建议吃，建设路（春熙路附近）小吃挺多，可以尝一尝兔子：双流老妈兔头</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"成都市区两天行程\"><a href=\"#成都市区两天行程\" class=\"headerlink\" title=\"成都市区两天行程\"></a>成都市区两天行程</h1><p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202303201417198.png\" alt=\"image-20230320141741938\"></p>\n<h2 id=\"第一天\"><a href=\"#第一天\" class=\"headerlink\" title=\"第一天\"></a>第一天</h2><ul>\n<li>早上8:00-中午12:00：熊猫基地</li>\n<li>下午：春熙路、太古里（购物中心）</li>\n</ul>\n<h3 id=\"购票\"><a href=\"#购票\" class=\"headerlink\" title=\"购票\"></a>购票</h3><ul>\n<li>关注“成都大熊猫繁育研究基地”公众号即可购门票+园区内观光车票</li>\n<li>关注“景区直通车”公众号，可以购买直达熊猫基地的公交车票，上车点包括春熙路IFS，武侯祠/锦里，宽窄巷子</li>\n<li>也可以购买从熊猫基地返回春熙路、武侯祠、宽窄巷子的公交车票，去熊猫基地推荐公交车</li>\n</ul>\n<h3 id=\"地图路线\"><a href=\"#地图路线\" class=\"headerlink\" title=\"地图路线\"></a>地图路线</h3><p><img src=\"https://source.unsplash.com/1280x720/?%E6%88%90%E9%83%BD%E5%B8%82%E7%86%8A%E7%8C%AB%E5%9F%BA%E5%9C%B0\" alt=\"第一天地图路线\"></p>\n<h2 id=\"第二天\"><a href=\"#第二天\" class=\"headerlink\" title=\"第二天\"></a>第二天</h2><ul>\n<li>上午：宽窄巷子、锦里/武侯祠、杜甫草堂（打卡景区）</li>\n</ul>\n<h3 id=\"购票-1\"><a href=\"#购票-1\" class=\"headerlink\" title=\"购票\"></a>购票</h3><ul>\n<li>宽窄巷子免门票、武侯祠需门票、杜甫草堂需门票，可以通过其他APP购买，或者“景区直通车”购买</li>\n</ul>\n<h3 id=\"交通\"><a href=\"#交通\" class=\"headerlink\" title=\"交通\"></a>交通</h3><ul>\n<li>支付宝开通“天府通”乘坐地铁前往或者打车也可以，同时“景区直通车”上面也有不同景之间的车票</li>\n</ul>\n<h3 id=\"地图路线-1\"><a href=\"#地图路线-1\" class=\"headerlink\" title=\"地图路线\"></a>地图路线</h3><p><img src=\"https://source.unsplash.com/1280x720/?%E6%88%90%E9%83%BD%E5%B8%82%E5%AE%BD%E7%AA%84%E5%B7%B7%E5%AD%90\" alt=\"第二天地图路线\"></p>\n<h2 id=\"住宿\"><a href=\"#住宿\" class=\"headerlink\" title=\"住宿\"></a>住宿</h2><p>推荐住在市中心，春熙路附近，交通便利，可以逛街</p>\n<h2 id=\"美食\"><a href=\"#美食\" class=\"headerlink\" title=\"美食\"></a>美食</h2><ul>\n<li>烤鱼：烤匠</li>\n<li>火锅：都差不多，挑一家评价不错的就行</li>\n<li>其他小吃：宽窄巷子和锦里不建议吃，建设路（春熙路附近）小吃挺多，可以尝一尝兔子：双流老妈兔头</li>\n</ul>\n"},{"title":"Cpp Learning","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-04-05T21:32:00.000Z","password":null,"summary":null,"_content":"\n## OpenCV\n\nOpenCV is a good computer vision and machine learning library\n\nEnvironment: Windows 10; Visual Studio 2019; OpenCV 4.3.2\n\nVersion corresponding table\n\n| Visual Studio version | Visual C++ version |\n| --------------------- | ------------------ |\n| VS 6.0                | VC 6.0             |\n| VS 2013               | VC 12              |\n| VS 2015               | VC 14              |\n| VS 2017               | VC 15              |\n| VS 2019               | VC 16              |\n\nSteps:\n\n1. download and extract OpenCV files. https://opencv.org/releases/\n\n2. add the `bin` (here is `D:\\OpenCV\\build\\x64\\vc15`) folder into `Path`, \n\n   for example: \n\n   ![Environmental Variables](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052216076.png)\n\n   Note: Select the folder corresponding to vc15\n\n3. There are 2 ways to config: one is for current project, another is for current user. Here we config for current project.\n\n   1. right click `Resource Files` → `Add` → `New Item` to creat the `main.cpp` file\n\n   2. Set the platform as`x64` which is because `OpenCV4.3.0` only support`x64`\n\n   3. right click`OpenCV` → `Properties` → `VC++ Directories`\n\n   4. Config include directories: edit `include Directories`，add directories `D:\\OpenCV\\build\\include` and `D:\\OpenCV\\build\\include\\opencv2`\n\n      ![image-20220405222743692](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052227727.png)\n\n   5. Config `library directories`，add `D:\\OpenCV\\build\\x64\\vc15\\lib`\n   \n      ![image-20220405222844373](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052228406.png)\n   \n   6. Go back to `OpenCV Property Pages`, click`Linker` → `Input`，select `Additional Dependencies`，edit. Add `opencv_world432d.lib` from `D:\\OpenCV\\build\\x64\\vc15\\lib`\n   \n      ![image-20220405222926886](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052229924.png)\n   \n   7. Apply or OK\n\n## For beginners\n\n","source":"_posts/Cpp learning.md","raw":"---\ntitle: Cpp Learning\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-04-05 22:32\npassword:\nsummary:\ntags:\n- Cpp\ncategories:\n- programming\n---\n\n## OpenCV\n\nOpenCV is a good computer vision and machine learning library\n\nEnvironment: Windows 10; Visual Studio 2019; OpenCV 4.3.2\n\nVersion corresponding table\n\n| Visual Studio version | Visual C++ version |\n| --------------------- | ------------------ |\n| VS 6.0                | VC 6.0             |\n| VS 2013               | VC 12              |\n| VS 2015               | VC 14              |\n| VS 2017               | VC 15              |\n| VS 2019               | VC 16              |\n\nSteps:\n\n1. download and extract OpenCV files. https://opencv.org/releases/\n\n2. add the `bin` (here is `D:\\OpenCV\\build\\x64\\vc15`) folder into `Path`, \n\n   for example: \n\n   ![Environmental Variables](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052216076.png)\n\n   Note: Select the folder corresponding to vc15\n\n3. There are 2 ways to config: one is for current project, another is for current user. Here we config for current project.\n\n   1. right click `Resource Files` → `Add` → `New Item` to creat the `main.cpp` file\n\n   2. Set the platform as`x64` which is because `OpenCV4.3.0` only support`x64`\n\n   3. right click`OpenCV` → `Properties` → `VC++ Directories`\n\n   4. Config include directories: edit `include Directories`，add directories `D:\\OpenCV\\build\\include` and `D:\\OpenCV\\build\\include\\opencv2`\n\n      ![image-20220405222743692](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052227727.png)\n\n   5. Config `library directories`，add `D:\\OpenCV\\build\\x64\\vc15\\lib`\n   \n      ![image-20220405222844373](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052228406.png)\n   \n   6. Go back to `OpenCV Property Pages`, click`Linker` → `Input`，select `Additional Dependencies`，edit. Add `opencv_world432d.lib` from `D:\\OpenCV\\build\\x64\\vc15\\lib`\n   \n      ![image-20220405222926886](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052229924.png)\n   \n   7. Apply or OK\n\n## For beginners\n\n","slug":"Cpp learning","published":1,"updated":"2022-08-24T17:48:38.611Z","comments":1,"layout":"post","photos":[],"_id":"cuidF1MTNTkhUJ2pw1ild8dRR","content":"<h2 id=\"OpenCV\"><a href=\"#OpenCV\" class=\"headerlink\" title=\"OpenCV\"></a>OpenCV</h2><p>OpenCV is a good computer vision and machine learning library</p>\n<p>Environment: Windows 10; Visual Studio 2019; OpenCV 4.3.2</p>\n<p>Version corresponding table</p>\n<table>\n<thead>\n<tr>\n<th>Visual Studio version</th>\n<th>Visual C++ version</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>VS 6.0</td>\n<td>VC 6.0</td>\n</tr>\n<tr>\n<td>VS 2013</td>\n<td>VC 12</td>\n</tr>\n<tr>\n<td>VS 2015</td>\n<td>VC 14</td>\n</tr>\n<tr>\n<td>VS 2017</td>\n<td>VC 15</td>\n</tr>\n<tr>\n<td>VS 2019</td>\n<td>VC 16</td>\n</tr>\n</tbody></table>\n<p>Steps:</p>\n<ol>\n<li><p>download and extract OpenCV files. <a href=\"https://opencv.org/releases/\">https://opencv.org/releases/</a></p>\n</li>\n<li><p>add the <code>bin</code> (here is <code>D:\\OpenCV\\build\\x64\\vc15</code>) folder into <code>Path</code>, </p>\n<p>for example: </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052216076.png\" alt=\"Environmental Variables\"></p>\n<p>Note: Select the folder corresponding to vc15</p>\n</li>\n<li><p>There are 2 ways to config: one is for current project, another is for current user. Here we config for current project.</p>\n<ol>\n<li><p>right click <code>Resource Files</code> → <code>Add</code> → <code>New Item</code> to creat the <code>main.cpp</code> file</p>\n</li>\n<li><p>Set the platform as<code>x64</code> which is because <code>OpenCV4.3.0</code> only support<code>x64</code></p>\n</li>\n<li><p>right click<code>OpenCV</code> → <code>Properties</code> → <code>VC++ Directories</code></p>\n</li>\n<li><p>Config include directories: edit <code>include Directories</code>，add directories <code>D:\\OpenCV\\build\\include</code> and <code>D:\\OpenCV\\build\\include\\opencv2</code></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052227727.png\" alt=\"image-20220405222743692\"></p>\n</li>\n<li><p>Config <code>library directories</code>，add <code>D:\\OpenCV\\build\\x64\\vc15\\lib</code></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052228406.png\" alt=\"image-20220405222844373\"></p>\n</li>\n<li><p>Go back to <code>OpenCV Property Pages</code>, click<code>Linker</code> → <code>Input</code>，select <code>Additional Dependencies</code>，edit. Add <code>opencv_world432d.lib</code> from <code>D:\\OpenCV\\build\\x64\\vc15\\lib</code></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052229924.png\" alt=\"image-20220405222926886\"></p>\n</li>\n<li><p>Apply or OK</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"For-beginners\"><a href=\"#For-beginners\" class=\"headerlink\" title=\"For beginners\"></a>For beginners</h2>","excerpt":"","more":"<h2 id=\"OpenCV\"><a href=\"#OpenCV\" class=\"headerlink\" title=\"OpenCV\"></a>OpenCV</h2><p>OpenCV is a good computer vision and machine learning library</p>\n<p>Environment: Windows 10; Visual Studio 2019; OpenCV 4.3.2</p>\n<p>Version corresponding table</p>\n<table>\n<thead>\n<tr>\n<th>Visual Studio version</th>\n<th>Visual C++ version</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>VS 6.0</td>\n<td>VC 6.0</td>\n</tr>\n<tr>\n<td>VS 2013</td>\n<td>VC 12</td>\n</tr>\n<tr>\n<td>VS 2015</td>\n<td>VC 14</td>\n</tr>\n<tr>\n<td>VS 2017</td>\n<td>VC 15</td>\n</tr>\n<tr>\n<td>VS 2019</td>\n<td>VC 16</td>\n</tr>\n</tbody></table>\n<p>Steps:</p>\n<ol>\n<li><p>download and extract OpenCV files. <a href=\"https://opencv.org/releases/\">https://opencv.org/releases/</a></p>\n</li>\n<li><p>add the <code>bin</code> (here is <code>D:\\OpenCV\\build\\x64\\vc15</code>) folder into <code>Path</code>, </p>\n<p>for example: </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052216076.png\" alt=\"Environmental Variables\"></p>\n<p>Note: Select the folder corresponding to vc15</p>\n</li>\n<li><p>There are 2 ways to config: one is for current project, another is for current user. Here we config for current project.</p>\n<ol>\n<li><p>right click <code>Resource Files</code> → <code>Add</code> → <code>New Item</code> to creat the <code>main.cpp</code> file</p>\n</li>\n<li><p>Set the platform as<code>x64</code> which is because <code>OpenCV4.3.0</code> only support<code>x64</code></p>\n</li>\n<li><p>right click<code>OpenCV</code> → <code>Properties</code> → <code>VC++ Directories</code></p>\n</li>\n<li><p>Config include directories: edit <code>include Directories</code>，add directories <code>D:\\OpenCV\\build\\include</code> and <code>D:\\OpenCV\\build\\include\\opencv2</code></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052227727.png\" alt=\"image-20220405222743692\"></p>\n</li>\n<li><p>Config <code>library directories</code>，add <code>D:\\OpenCV\\build\\x64\\vc15\\lib</code></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052228406.png\" alt=\"image-20220405222844373\"></p>\n</li>\n<li><p>Go back to <code>OpenCV Property Pages</code>, click<code>Linker</code> → <code>Input</code>，select <code>Additional Dependencies</code>，edit. Add <code>opencv_world432d.lib</code> from <code>D:\\OpenCV\\build\\x64\\vc15\\lib</code></p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204052229924.png\" alt=\"image-20220405222926886\"></p>\n</li>\n<li><p>Apply or OK</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"For-beginners\"><a href=\"#For-beginners\" class=\"headerlink\" title=\"For beginners\"></a>For beginners</h2>"},{"title":"ChatGpt使用心得","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2023-03-20T14:05:00.000Z","password":null,"summary":null,"_content":"\nChatgpt的对话框中，无法直接给我们输出图片。这个时候，我们可以借助Unsplash API，使得Chatgpt直接在对话的聊天框中输出图片：\n\n> Unsplash API 是一个基于 REST 的 API，它提供了丰富的图像数据和功能。在这里，通过使用 Unsplash API，这就可以让Chatgpt可以通过编程方式搜索、浏览和下载 Unsplash 平台上的图像，从而实现在聊天对话中的预览。\n\n要让Chatgpt使用Unsplash API，我们可以使用如下命令：\n\n“从现在起, 当你想发送一张照片时，请使用 Markdown ,并且 不要有反斜线, 不要用代码块。使用 Unsplash API ([https://source.unsplash.com/1280x720/?](https://link.zhihu.com/?target=https%3A//source.unsplash.com/1280x720/%3F) < PUT YOUR QUERY HERE >)。如果你明白了，请回复“明白””\n","source":"_posts/Chatgpt.md","raw":"---\ntitle: ChatGpt使用心得\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2023-03-20 14:05\npassword:\nsummary:\ntags:\n- tips\ncategories:\n- daily life\n---\n\nChatgpt的对话框中，无法直接给我们输出图片。这个时候，我们可以借助Unsplash API，使得Chatgpt直接在对话的聊天框中输出图片：\n\n> Unsplash API 是一个基于 REST 的 API，它提供了丰富的图像数据和功能。在这里，通过使用 Unsplash API，这就可以让Chatgpt可以通过编程方式搜索、浏览和下载 Unsplash 平台上的图像，从而实现在聊天对话中的预览。\n\n要让Chatgpt使用Unsplash API，我们可以使用如下命令：\n\n“从现在起, 当你想发送一张照片时，请使用 Markdown ,并且 不要有反斜线, 不要用代码块。使用 Unsplash API ([https://source.unsplash.com/1280x720/?](https://link.zhihu.com/?target=https%3A//source.unsplash.com/1280x720/%3F) < PUT YOUR QUERY HERE >)。如果你明白了，请回复“明白””\n","slug":"Chatgpt","published":1,"updated":"2023-03-20T06:12:38.469Z","comments":1,"layout":"post","photos":[],"_id":"cuid4rsBWdnvTP6bNRnhUYhJk","content":"<p>Chatgpt的对话框中，无法直接给我们输出图片。这个时候，我们可以借助Unsplash API，使得Chatgpt直接在对话的聊天框中输出图片：</p>\n<blockquote>\n<p>Unsplash API 是一个基于 REST 的 API，它提供了丰富的图像数据和功能。在这里，通过使用 Unsplash API，这就可以让Chatgpt可以通过编程方式搜索、浏览和下载 Unsplash 平台上的图像，从而实现在聊天对话中的预览。</p>\n</blockquote>\n<p>要让Chatgpt使用Unsplash API，我们可以使用如下命令：</p>\n<p>“从现在起, 当你想发送一张照片时，请使用 Markdown ,并且 不要有反斜线, 不要用代码块。使用 Unsplash API (<a href=\"https://link.zhihu.com/?target=https%3A//source.unsplash.com/1280x720/%3F\">https://source.unsplash.com/1280x720/?</a> &lt; PUT YOUR QUERY HERE &gt;)。如果你明白了，请回复“明白””</p>\n","excerpt":"","more":"<p>Chatgpt的对话框中，无法直接给我们输出图片。这个时候，我们可以借助Unsplash API，使得Chatgpt直接在对话的聊天框中输出图片：</p>\n<blockquote>\n<p>Unsplash API 是一个基于 REST 的 API，它提供了丰富的图像数据和功能。在这里，通过使用 Unsplash API，这就可以让Chatgpt可以通过编程方式搜索、浏览和下载 Unsplash 平台上的图像，从而实现在聊天对话中的预览。</p>\n</blockquote>\n<p>要让Chatgpt使用Unsplash API，我们可以使用如下命令：</p>\n<p>“从现在起, 当你想发送一张照片时，请使用 Markdown ,并且 不要有反斜线, 不要用代码块。使用 Unsplash API (<a href=\"https://link.zhihu.com/?target=https%3A//source.unsplash.com/1280x720/%3F\">https://source.unsplash.com/1280x720/?</a> &lt; PUT YOUR QUERY HERE &gt;)。如果你明白了，请回复“明白””</p>\n"},{"title":"Albania 7 days","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-09-08T00:41:00.000Z","password":null,"summary":null,"_content":"\n# 阿尔巴尼亚\n\n## 前期准备\n\n- 机票 EasyJet\n- [租车](https://www.ryanair.com/cn/zh/trip/getting-around/car-hire?tpAdults=1&tpTeens=0&tpChildren=0&tpInfants=0&tpStartDate=2022-09-14&tpEndDate=2022-09-19&tpDestinationIata=TIA&tpDiscount=0&pickUpDateTime=2022-09-14T12:00&dropOffDateTime=2022-09-19T20:00&clientId=633558&driversAge=30)\n- [住宿 萨兰达](https://www.booking.com/hotel/al/kosta-apartments.zh-cn.html?group_adults=4&hapos=22&no_rooms=1&req_adults=4&highlighted_blocks=757341403_332688869_5_0_0&hpos=22&checkin=2022-09-14&sid=6947186e67e52dd059a6056e83b71b5f&sr_order=popularity&all_sr_blocks=757341403_332688869_5_0_0&group_children=0&dest_id=-107914&matching_block_id=757341403_332688869_5_0_0&sb_price_type=total&req_children=0&room1=A%2CA%2CA%2CA&ucfs=1&srepoch=1662504884&aid=1486641&label=white-residence-luxury-apartments-ZH-CN-S618434408106%3Apl%3Ata%3Ap1%3Ap2%3Aac%3Aap%3Aneg%3Afi237004683880%3Atikwd-1379927232362%3Alp9045889%3Ali9070407%3Adec%3Adm&dest_type=city&sr_pri_blocks=757341403_332688869_5_0_0__10800&activeTab=main&checkout=2022-09-16&srpvid=b258a10e0d76006f&nflt=sth%3D1%3Bhotelfacility%3D2%3Bhotelfacility%3D107%3Bhotelfacility%3D46&dist=0&type=total#map_closed)\n- [住宿 都拉斯](https://www.booking.com/searchresults.zh-cn.html?aid=1188619&label=6317c5f1c0606502acbb9307&lang=zh-cn&sid=7c06b5a442ec544ee5783089a09dbfe2&sb=1&src=hotel&src_elem=sb&error_url=https%3A%2F%2Fwww.booking.com%2Fhotel%2Fal%2Fina-apartament-4.zh-cn.html%3Faid%3D1188619%3Blabel%3D6317c5f1c0606502acbb9307%3Bsid%3D7c06b5a442ec544ee5783089a09dbfe2%3BactiveTab%3Dmain%3Ball_sr_blocks%3D500349807_169296156_5_2_0%3Bcheckin%3D2022-09-14%3Bcheckout%3D2022-09-16%3Bdest_id%3D-107914%3Bdest_type%3Dcity%3Bgroup_adults%3D4%3Bgroup_children%3D0%3Bhapos%3D27%3Bhighlighted_blocks%3D500349807_169296156_5_2_0%3Bhpos%3D2%3Bmatching_block_id%3D500349807_169296156_5_2_0%3Bnflt%3Dprice%253DUSD-min-100-1%253Bhotelfacility%253D2%253Bhotelfacility%253D46%253Bhotelfacility%253D107%3Bno_rooms%3D1%3Breq_adults%3D4%3Breq_children%3D0%3Broom1%3DA%252CA%252CA%252CA%3Bsb_price_type%3Dtotal%3Bsr_order%3Dpopularity%3Bsr_pri_blocks%3D500349807_169296156_5_2_0__11000%3Bsrepoch%3D1662503582%3Bsrpvid%3Db2a49cd1997800e7%3Btype%3Dtotal%3Bucfs%3D1%26%3B&highlighted_hotels=5003498&hp_sbox=1&ss=%E5%B8%95%E6%8B%89%E6%96%AF%E6%B8%A9%E6%B3%89%E9%85%92%E5%BA%97%2C+%E9%83%BD%E6%8B%89%E6%96%AF%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%98%BF%E5%B0%94%E5%B7%B4%E5%B0%BC%E4%BA%9A&is_ski_area=&ssne=%E8%90%A8%E5%85%B0%E8%BE%BE&ssne_untouched=%E8%90%A8%E5%85%B0%E8%BE%BE&checkin_year=2022&checkin_month=9&checkin_monthday=16&checkout_year=2022&checkout_month=9&checkout_monthday=17&group_adults=3&group_children=0&no_rooms=1&from_sf=1&ss_raw=%E9%83%BD%E6%8B%89%E6%96%AF&ac_position=3&ac_langcode=zh&ac_click_type=b&dest_id=636591&dest_type=hotel&place_id_lat=41.31397&place_id_lon=19.474684&search_pageview_id=2a3da440bc4f0027&search_selected=true&search_pageview_id=2a3da440bc4f0027&ac_suggestion_list_length=5&ac_suggestion_theme_list_length=0)\n- [住宿 蒂瓦特](https://www.booking.com/searchresults.zh-cn.html?ss=%E6%B3%A2%E5%B0%94%E5%9B%BE%E9%BB%91%E5%B1%B1%E4%B8%BD%E6%99%B6%E9%85%92%E5%BA%97%2C+%E8%92%82%E7%93%A6%E7%89%B9%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%BB%91%E5%B1%B1&ssne=%E9%83%BD%E6%8B%89%E6%96%AF&ssne_untouched=%E9%83%BD%E6%8B%89%E6%96%AF&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=1015528&dest_type=hotel&ac_position=4&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=c6afa45c0bf8005f&checkin=2022-09-17&checkout=2022-09-18&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure)\n- [住宿 佩拉斯特](https://www.booking.com/searchresults.zh-cn.html?label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&ss=%E4%BD%A9%E6%8B%89%E6%96%AF%E7%89%B9%2C+%E4%BA%9E%E5%BE%97%E9%87%8C%E4%BA%9E%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E8%92%99%E7%89%B9%E5%85%A7%E5%93%A5%E7%BE%85&ssne=%E8%92%82%E7%93%A6%E7%89%B9&ssne_untouched=%E8%92%82%E7%93%A6%E7%89%B9&highlighted_hotels=5003498&lang=zh-cn&src=searchresults&dest_id=-91673&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=xt&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=0f0d0145943d003a&checkin=2022-09-18&checkout=2022-09-19&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure&nflt=hotelfacility%3D46)\n- [住宿 地拉那](https://www.booking.com/searchresults.zh-cn.html?ss=%E5%9C%B0%E6%8B%89%E9%82%A3&ssne=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&ssne_untouched=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=-108649&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=e87b0248d9cb0186&checkin=2022-09-19&checkout=2022-09-20&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure)\n- 换汇？（列克）\n\nHint: \n\n1. 在访问与科索沃北部边境的山区城镇时，您应该谨慎行事，并注意有关未爆地雷和其他未爆弹药的警告标志\n\n> [Foreign travel advice Albania][https://www.gov.uk/foreign-travel-advice/albania]\n\n2. a shake of the head means “yes” and a nod “no”.\n3. 阿尔巴尼亚人非常好客，很可能会为您提供咖啡、糖果等。接受并主动分享您拥有的任何东西都是一种礼貌。\n4. 羊肉和鱼很好吃，沿海的海鲜很棒\n\n[路线图](https://www.google.com/maps/d/edit?hl=en&hl=en&mid=1aknYGVaPEn1lvnRAhbiaoIW8IBNmVYU&ll=40.792607903029115%2C18.94627905947007&z=8)\n\n## 9.14     \n\n- 7：35-11：45飞机\n- 斯坎德贝格广场开始，追踪**共产主义时代的建筑**和纪念碑\n- 提车\n- 地拉那—萨兰达（3h30min）\n- 住宿\n\n## 9.15\n\n- 萨兰达一日游\n- 住一晚 \n\n\n## 9.16     \n\n- 萨兰达—泽尔米乌—都拉斯（1h40min+2h50min）\n- 住一晚 \n\n\n## 9.17     \n\n- 都拉斯—黑山（圣斯特凡岛）（3h21min）\n- 住一晚 \n\n\n## 9.18\n\n- 佩拉斯特 \n- 住一晚 \n\n\n## 9.19\n\n- 佩拉斯特—地拉那国际机场（4h30min）还车  \n- 住一晚 \n\n\n## 9.20\n\n- 回伦敦     （18：35-20：45 3h10min）\n","source":"_posts/Albania.md","raw":"---\ntitle: Albania 7 days\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-09-08 01:41\npassword:\nsummary:\ntags:\n- Albania\ncategories:\n- Traveling\n---\n\n# 阿尔巴尼亚\n\n## 前期准备\n\n- 机票 EasyJet\n- [租车](https://www.ryanair.com/cn/zh/trip/getting-around/car-hire?tpAdults=1&tpTeens=0&tpChildren=0&tpInfants=0&tpStartDate=2022-09-14&tpEndDate=2022-09-19&tpDestinationIata=TIA&tpDiscount=0&pickUpDateTime=2022-09-14T12:00&dropOffDateTime=2022-09-19T20:00&clientId=633558&driversAge=30)\n- [住宿 萨兰达](https://www.booking.com/hotel/al/kosta-apartments.zh-cn.html?group_adults=4&hapos=22&no_rooms=1&req_adults=4&highlighted_blocks=757341403_332688869_5_0_0&hpos=22&checkin=2022-09-14&sid=6947186e67e52dd059a6056e83b71b5f&sr_order=popularity&all_sr_blocks=757341403_332688869_5_0_0&group_children=0&dest_id=-107914&matching_block_id=757341403_332688869_5_0_0&sb_price_type=total&req_children=0&room1=A%2CA%2CA%2CA&ucfs=1&srepoch=1662504884&aid=1486641&label=white-residence-luxury-apartments-ZH-CN-S618434408106%3Apl%3Ata%3Ap1%3Ap2%3Aac%3Aap%3Aneg%3Afi237004683880%3Atikwd-1379927232362%3Alp9045889%3Ali9070407%3Adec%3Adm&dest_type=city&sr_pri_blocks=757341403_332688869_5_0_0__10800&activeTab=main&checkout=2022-09-16&srpvid=b258a10e0d76006f&nflt=sth%3D1%3Bhotelfacility%3D2%3Bhotelfacility%3D107%3Bhotelfacility%3D46&dist=0&type=total#map_closed)\n- [住宿 都拉斯](https://www.booking.com/searchresults.zh-cn.html?aid=1188619&label=6317c5f1c0606502acbb9307&lang=zh-cn&sid=7c06b5a442ec544ee5783089a09dbfe2&sb=1&src=hotel&src_elem=sb&error_url=https%3A%2F%2Fwww.booking.com%2Fhotel%2Fal%2Fina-apartament-4.zh-cn.html%3Faid%3D1188619%3Blabel%3D6317c5f1c0606502acbb9307%3Bsid%3D7c06b5a442ec544ee5783089a09dbfe2%3BactiveTab%3Dmain%3Ball_sr_blocks%3D500349807_169296156_5_2_0%3Bcheckin%3D2022-09-14%3Bcheckout%3D2022-09-16%3Bdest_id%3D-107914%3Bdest_type%3Dcity%3Bgroup_adults%3D4%3Bgroup_children%3D0%3Bhapos%3D27%3Bhighlighted_blocks%3D500349807_169296156_5_2_0%3Bhpos%3D2%3Bmatching_block_id%3D500349807_169296156_5_2_0%3Bnflt%3Dprice%253DUSD-min-100-1%253Bhotelfacility%253D2%253Bhotelfacility%253D46%253Bhotelfacility%253D107%3Bno_rooms%3D1%3Breq_adults%3D4%3Breq_children%3D0%3Broom1%3DA%252CA%252CA%252CA%3Bsb_price_type%3Dtotal%3Bsr_order%3Dpopularity%3Bsr_pri_blocks%3D500349807_169296156_5_2_0__11000%3Bsrepoch%3D1662503582%3Bsrpvid%3Db2a49cd1997800e7%3Btype%3Dtotal%3Bucfs%3D1%26%3B&highlighted_hotels=5003498&hp_sbox=1&ss=%E5%B8%95%E6%8B%89%E6%96%AF%E6%B8%A9%E6%B3%89%E9%85%92%E5%BA%97%2C+%E9%83%BD%E6%8B%89%E6%96%AF%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%98%BF%E5%B0%94%E5%B7%B4%E5%B0%BC%E4%BA%9A&is_ski_area=&ssne=%E8%90%A8%E5%85%B0%E8%BE%BE&ssne_untouched=%E8%90%A8%E5%85%B0%E8%BE%BE&checkin_year=2022&checkin_month=9&checkin_monthday=16&checkout_year=2022&checkout_month=9&checkout_monthday=17&group_adults=3&group_children=0&no_rooms=1&from_sf=1&ss_raw=%E9%83%BD%E6%8B%89%E6%96%AF&ac_position=3&ac_langcode=zh&ac_click_type=b&dest_id=636591&dest_type=hotel&place_id_lat=41.31397&place_id_lon=19.474684&search_pageview_id=2a3da440bc4f0027&search_selected=true&search_pageview_id=2a3da440bc4f0027&ac_suggestion_list_length=5&ac_suggestion_theme_list_length=0)\n- [住宿 蒂瓦特](https://www.booking.com/searchresults.zh-cn.html?ss=%E6%B3%A2%E5%B0%94%E5%9B%BE%E9%BB%91%E5%B1%B1%E4%B8%BD%E6%99%B6%E9%85%92%E5%BA%97%2C+%E8%92%82%E7%93%A6%E7%89%B9%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%BB%91%E5%B1%B1&ssne=%E9%83%BD%E6%8B%89%E6%96%AF&ssne_untouched=%E9%83%BD%E6%8B%89%E6%96%AF&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=1015528&dest_type=hotel&ac_position=4&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=c6afa45c0bf8005f&checkin=2022-09-17&checkout=2022-09-18&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure)\n- [住宿 佩拉斯特](https://www.booking.com/searchresults.zh-cn.html?label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&ss=%E4%BD%A9%E6%8B%89%E6%96%AF%E7%89%B9%2C+%E4%BA%9E%E5%BE%97%E9%87%8C%E4%BA%9E%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E8%92%99%E7%89%B9%E5%85%A7%E5%93%A5%E7%BE%85&ssne=%E8%92%82%E7%93%A6%E7%89%B9&ssne_untouched=%E8%92%82%E7%93%A6%E7%89%B9&highlighted_hotels=5003498&lang=zh-cn&src=searchresults&dest_id=-91673&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=xt&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=0f0d0145943d003a&checkin=2022-09-18&checkout=2022-09-19&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure&nflt=hotelfacility%3D46)\n- [住宿 地拉那](https://www.booking.com/searchresults.zh-cn.html?ss=%E5%9C%B0%E6%8B%89%E9%82%A3&ssne=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&ssne_untouched=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=-108649&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=e87b0248d9cb0186&checkin=2022-09-19&checkout=2022-09-20&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure)\n- 换汇？（列克）\n\nHint: \n\n1. 在访问与科索沃北部边境的山区城镇时，您应该谨慎行事，并注意有关未爆地雷和其他未爆弹药的警告标志\n\n> [Foreign travel advice Albania][https://www.gov.uk/foreign-travel-advice/albania]\n\n2. a shake of the head means “yes” and a nod “no”.\n3. 阿尔巴尼亚人非常好客，很可能会为您提供咖啡、糖果等。接受并主动分享您拥有的任何东西都是一种礼貌。\n4. 羊肉和鱼很好吃，沿海的海鲜很棒\n\n[路线图](https://www.google.com/maps/d/edit?hl=en&hl=en&mid=1aknYGVaPEn1lvnRAhbiaoIW8IBNmVYU&ll=40.792607903029115%2C18.94627905947007&z=8)\n\n## 9.14     \n\n- 7：35-11：45飞机\n- 斯坎德贝格广场开始，追踪**共产主义时代的建筑**和纪念碑\n- 提车\n- 地拉那—萨兰达（3h30min）\n- 住宿\n\n## 9.15\n\n- 萨兰达一日游\n- 住一晚 \n\n\n## 9.16     \n\n- 萨兰达—泽尔米乌—都拉斯（1h40min+2h50min）\n- 住一晚 \n\n\n## 9.17     \n\n- 都拉斯—黑山（圣斯特凡岛）（3h21min）\n- 住一晚 \n\n\n## 9.18\n\n- 佩拉斯特 \n- 住一晚 \n\n\n## 9.19\n\n- 佩拉斯特—地拉那国际机场（4h30min）还车  \n- 住一晚 \n\n\n## 9.20\n\n- 回伦敦     （18：35-20：45 3h10min）\n","slug":"Albania","published":1,"updated":"2022-09-08T15:21:22.016Z","comments":1,"layout":"post","photos":[],"_id":"cuidA9ZHNEITXPtGdbmIXuoqd","content":"<h1 id=\"阿尔巴尼亚\"><a href=\"#阿尔巴尼亚\" class=\"headerlink\" title=\"阿尔巴尼亚\"></a>阿尔巴尼亚</h1><h2 id=\"前期准备\"><a href=\"#前期准备\" class=\"headerlink\" title=\"前期准备\"></a>前期准备</h2><ul>\n<li>机票 EasyJet</li>\n<li><a href=\"https://www.ryanair.com/cn/zh/trip/getting-around/car-hire?tpAdults=1&tpTeens=0&tpChildren=0&tpInfants=0&tpStartDate=2022-09-14&tpEndDate=2022-09-19&tpDestinationIata=TIA&tpDiscount=0&pickUpDateTime=2022-09-14T12:00&dropOffDateTime=2022-09-19T20:00&clientId=633558&driversAge=30\">租车</a></li>\n<li><a href=\"https://www.booking.com/hotel/al/kosta-apartments.zh-cn.html?group_adults=4&hapos=22&no_rooms=1&req_adults=4&highlighted_blocks=757341403_332688869_5_0_0&hpos=22&checkin=2022-09-14&sid=6947186e67e52dd059a6056e83b71b5f&sr_order=popularity&all_sr_blocks=757341403_332688869_5_0_0&group_children=0&dest_id=-107914&matching_block_id=757341403_332688869_5_0_0&sb_price_type=total&req_children=0&room1=A%2CA%2CA%2CA&ucfs=1&srepoch=1662504884&aid=1486641&label=white-residence-luxury-apartments-ZH-CN-S618434408106%3Apl%3Ata%3Ap1%3Ap2%3Aac%3Aap%3Aneg%3Afi237004683880%3Atikwd-1379927232362%3Alp9045889%3Ali9070407%3Adec%3Adm&dest_type=city&sr_pri_blocks=757341403_332688869_5_0_0__10800&activeTab=main&checkout=2022-09-16&srpvid=b258a10e0d76006f&nflt=sth%3D1%3Bhotelfacility%3D2%3Bhotelfacility%3D107%3Bhotelfacility%3D46&dist=0&type=total#map_closed\">住宿 萨兰达</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?aid=1188619&label=6317c5f1c0606502acbb9307&lang=zh-cn&sid=7c06b5a442ec544ee5783089a09dbfe2&sb=1&src=hotel&src_elem=sb&error_url=https%3A%2F%2Fwww.booking.com%2Fhotel%2Fal%2Fina-apartament-4.zh-cn.html%3Faid%3D1188619%3Blabel%3D6317c5f1c0606502acbb9307%3Bsid%3D7c06b5a442ec544ee5783089a09dbfe2%3BactiveTab%3Dmain%3Ball_sr_blocks%3D500349807_169296156_5_2_0%3Bcheckin%3D2022-09-14%3Bcheckout%3D2022-09-16%3Bdest_id%3D-107914%3Bdest_type%3Dcity%3Bgroup_adults%3D4%3Bgroup_children%3D0%3Bhapos%3D27%3Bhighlighted_blocks%3D500349807_169296156_5_2_0%3Bhpos%3D2%3Bmatching_block_id%3D500349807_169296156_5_2_0%3Bnflt%3Dprice%253DUSD-min-100-1%253Bhotelfacility%253D2%253Bhotelfacility%253D46%253Bhotelfacility%253D107%3Bno_rooms%3D1%3Breq_adults%3D4%3Breq_children%3D0%3Broom1%3DA%252CA%252CA%252CA%3Bsb_price_type%3Dtotal%3Bsr_order%3Dpopularity%3Bsr_pri_blocks%3D500349807_169296156_5_2_0__11000%3Bsrepoch%3D1662503582%3Bsrpvid%3Db2a49cd1997800e7%3Btype%3Dtotal%3Bucfs%3D1%26%3B&highlighted_hotels=5003498&hp_sbox=1&ss=%E5%B8%95%E6%8B%89%E6%96%AF%E6%B8%A9%E6%B3%89%E9%85%92%E5%BA%97%2C+%E9%83%BD%E6%8B%89%E6%96%AF%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%98%BF%E5%B0%94%E5%B7%B4%E5%B0%BC%E4%BA%9A&is_ski_area=&ssne=%E8%90%A8%E5%85%B0%E8%BE%BE&ssne_untouched=%E8%90%A8%E5%85%B0%E8%BE%BE&checkin_year=2022&checkin_month=9&checkin_monthday=16&checkout_year=2022&checkout_month=9&checkout_monthday=17&group_adults=3&group_children=0&no_rooms=1&from_sf=1&ss_raw=%E9%83%BD%E6%8B%89%E6%96%AF&ac_position=3&ac_langcode=zh&ac_click_type=b&dest_id=636591&dest_type=hotel&place_id_lat=41.31397&place_id_lon=19.474684&search_pageview_id=2a3da440bc4f0027&search_selected=true&search_pageview_id=2a3da440bc4f0027&ac_suggestion_list_length=5&ac_suggestion_theme_list_length=0\">住宿 都拉斯</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?ss=%E6%B3%A2%E5%B0%94%E5%9B%BE%E9%BB%91%E5%B1%B1%E4%B8%BD%E6%99%B6%E9%85%92%E5%BA%97%2C+%E8%92%82%E7%93%A6%E7%89%B9%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%BB%91%E5%B1%B1&ssne=%E9%83%BD%E6%8B%89%E6%96%AF&ssne_untouched=%E9%83%BD%E6%8B%89%E6%96%AF&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=1015528&dest_type=hotel&ac_position=4&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=c6afa45c0bf8005f&checkin=2022-09-17&checkout=2022-09-18&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure\">住宿 蒂瓦特</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&ss=%E4%BD%A9%E6%8B%89%E6%96%AF%E7%89%B9%2C+%E4%BA%9E%E5%BE%97%E9%87%8C%E4%BA%9E%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E8%92%99%E7%89%B9%E5%85%A7%E5%93%A5%E7%BE%85&ssne=%E8%92%82%E7%93%A6%E7%89%B9&ssne_untouched=%E8%92%82%E7%93%A6%E7%89%B9&highlighted_hotels=5003498&lang=zh-cn&src=searchresults&dest_id=-91673&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=xt&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=0f0d0145943d003a&checkin=2022-09-18&checkout=2022-09-19&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure&nflt=hotelfacility%3D46\">住宿 佩拉斯特</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?ss=%E5%9C%B0%E6%8B%89%E9%82%A3&ssne=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&ssne_untouched=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=-108649&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=e87b0248d9cb0186&checkin=2022-09-19&checkout=2022-09-20&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure\">住宿 地拉那</a></li>\n<li>换汇？（列克）</li>\n</ul>\n<p>Hint: </p>\n<ol>\n<li>在访问与科索沃北部边境的山区城镇时，您应该谨慎行事，并注意有关未爆地雷和其他未爆弹药的警告标志</li>\n</ol>\n<blockquote>\n<p>[Foreign travel advice Albania][<a href=\"https://www.gov.uk/foreign-travel-advice/albania]\">https://www.gov.uk/foreign-travel-advice/albania]</a></p>\n</blockquote>\n<ol start=\"2\">\n<li>a shake of the head means “yes” and a nod “no”.</li>\n<li>阿尔巴尼亚人非常好客，很可能会为您提供咖啡、糖果等。接受并主动分享您拥有的任何东西都是一种礼貌。</li>\n<li>羊肉和鱼很好吃，沿海的海鲜很棒</li>\n</ol>\n<p><a href=\"https://www.google.com/maps/d/edit?hl=en&hl=en&mid=1aknYGVaPEn1lvnRAhbiaoIW8IBNmVYU&ll=40.792607903029115%2C18.94627905947007&z=8\">路线图</a></p>\n<h2 id=\"9-14\"><a href=\"#9-14\" class=\"headerlink\" title=\"9.14\"></a>9.14</h2><ul>\n<li>7：35-11：45飞机</li>\n<li>斯坎德贝格广场开始，追踪<strong>共产主义时代的建筑</strong>和纪念碑</li>\n<li>提车</li>\n<li>地拉那—萨兰达（3h30min）</li>\n<li>住宿</li>\n</ul>\n<h2 id=\"9-15\"><a href=\"#9-15\" class=\"headerlink\" title=\"9.15\"></a>9.15</h2><ul>\n<li>萨兰达一日游</li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-16\"><a href=\"#9-16\" class=\"headerlink\" title=\"9.16\"></a>9.16</h2><ul>\n<li>萨兰达—泽尔米乌—都拉斯（1h40min+2h50min）</li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-17\"><a href=\"#9-17\" class=\"headerlink\" title=\"9.17\"></a>9.17</h2><ul>\n<li>都拉斯—黑山（圣斯特凡岛）（3h21min）</li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-18\"><a href=\"#9-18\" class=\"headerlink\" title=\"9.18\"></a>9.18</h2><ul>\n<li>佩拉斯特 </li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-19\"><a href=\"#9-19\" class=\"headerlink\" title=\"9.19\"></a>9.19</h2><ul>\n<li>佩拉斯特—地拉那国际机场（4h30min）还车  </li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-20\"><a href=\"#9-20\" class=\"headerlink\" title=\"9.20\"></a>9.20</h2><ul>\n<li>回伦敦     （18：35-20：45 3h10min）</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"阿尔巴尼亚\"><a href=\"#阿尔巴尼亚\" class=\"headerlink\" title=\"阿尔巴尼亚\"></a>阿尔巴尼亚</h1><h2 id=\"前期准备\"><a href=\"#前期准备\" class=\"headerlink\" title=\"前期准备\"></a>前期准备</h2><ul>\n<li>机票 EasyJet</li>\n<li><a href=\"https://www.ryanair.com/cn/zh/trip/getting-around/car-hire?tpAdults=1&tpTeens=0&tpChildren=0&tpInfants=0&tpStartDate=2022-09-14&tpEndDate=2022-09-19&tpDestinationIata=TIA&tpDiscount=0&pickUpDateTime=2022-09-14T12:00&dropOffDateTime=2022-09-19T20:00&clientId=633558&driversAge=30\">租车</a></li>\n<li><a href=\"https://www.booking.com/hotel/al/kosta-apartments.zh-cn.html?group_adults=4&hapos=22&no_rooms=1&req_adults=4&highlighted_blocks=757341403_332688869_5_0_0&hpos=22&checkin=2022-09-14&sid=6947186e67e52dd059a6056e83b71b5f&sr_order=popularity&all_sr_blocks=757341403_332688869_5_0_0&group_children=0&dest_id=-107914&matching_block_id=757341403_332688869_5_0_0&sb_price_type=total&req_children=0&room1=A%2CA%2CA%2CA&ucfs=1&srepoch=1662504884&aid=1486641&label=white-residence-luxury-apartments-ZH-CN-S618434408106%3Apl%3Ata%3Ap1%3Ap2%3Aac%3Aap%3Aneg%3Afi237004683880%3Atikwd-1379927232362%3Alp9045889%3Ali9070407%3Adec%3Adm&dest_type=city&sr_pri_blocks=757341403_332688869_5_0_0__10800&activeTab=main&checkout=2022-09-16&srpvid=b258a10e0d76006f&nflt=sth%3D1%3Bhotelfacility%3D2%3Bhotelfacility%3D107%3Bhotelfacility%3D46&dist=0&type=total#map_closed\">住宿 萨兰达</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?aid=1188619&label=6317c5f1c0606502acbb9307&lang=zh-cn&sid=7c06b5a442ec544ee5783089a09dbfe2&sb=1&src=hotel&src_elem=sb&error_url=https%3A%2F%2Fwww.booking.com%2Fhotel%2Fal%2Fina-apartament-4.zh-cn.html%3Faid%3D1188619%3Blabel%3D6317c5f1c0606502acbb9307%3Bsid%3D7c06b5a442ec544ee5783089a09dbfe2%3BactiveTab%3Dmain%3Ball_sr_blocks%3D500349807_169296156_5_2_0%3Bcheckin%3D2022-09-14%3Bcheckout%3D2022-09-16%3Bdest_id%3D-107914%3Bdest_type%3Dcity%3Bgroup_adults%3D4%3Bgroup_children%3D0%3Bhapos%3D27%3Bhighlighted_blocks%3D500349807_169296156_5_2_0%3Bhpos%3D2%3Bmatching_block_id%3D500349807_169296156_5_2_0%3Bnflt%3Dprice%253DUSD-min-100-1%253Bhotelfacility%253D2%253Bhotelfacility%253D46%253Bhotelfacility%253D107%3Bno_rooms%3D1%3Breq_adults%3D4%3Breq_children%3D0%3Broom1%3DA%252CA%252CA%252CA%3Bsb_price_type%3Dtotal%3Bsr_order%3Dpopularity%3Bsr_pri_blocks%3D500349807_169296156_5_2_0__11000%3Bsrepoch%3D1662503582%3Bsrpvid%3Db2a49cd1997800e7%3Btype%3Dtotal%3Bucfs%3D1%26%3B&highlighted_hotels=5003498&hp_sbox=1&ss=%E5%B8%95%E6%8B%89%E6%96%AF%E6%B8%A9%E6%B3%89%E9%85%92%E5%BA%97%2C+%E9%83%BD%E6%8B%89%E6%96%AF%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%98%BF%E5%B0%94%E5%B7%B4%E5%B0%BC%E4%BA%9A&is_ski_area=&ssne=%E8%90%A8%E5%85%B0%E8%BE%BE&ssne_untouched=%E8%90%A8%E5%85%B0%E8%BE%BE&checkin_year=2022&checkin_month=9&checkin_monthday=16&checkout_year=2022&checkout_month=9&checkout_monthday=17&group_adults=3&group_children=0&no_rooms=1&from_sf=1&ss_raw=%E9%83%BD%E6%8B%89%E6%96%AF&ac_position=3&ac_langcode=zh&ac_click_type=b&dest_id=636591&dest_type=hotel&place_id_lat=41.31397&place_id_lon=19.474684&search_pageview_id=2a3da440bc4f0027&search_selected=true&search_pageview_id=2a3da440bc4f0027&ac_suggestion_list_length=5&ac_suggestion_theme_list_length=0\">住宿 都拉斯</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?ss=%E6%B3%A2%E5%B0%94%E5%9B%BE%E9%BB%91%E5%B1%B1%E4%B8%BD%E6%99%B6%E9%85%92%E5%BA%97%2C+%E8%92%82%E7%93%A6%E7%89%B9%2C+%E4%BA%9A%E5%BE%97%E9%87%8C%E4%BA%9A%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E9%BB%91%E5%B1%B1&ssne=%E9%83%BD%E6%8B%89%E6%96%AF&ssne_untouched=%E9%83%BD%E6%8B%89%E6%96%AF&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=1015528&dest_type=hotel&ac_position=4&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=c6afa45c0bf8005f&checkin=2022-09-17&checkout=2022-09-18&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure\">住宿 蒂瓦特</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&ss=%E4%BD%A9%E6%8B%89%E6%96%AF%E7%89%B9%2C+%E4%BA%9E%E5%BE%97%E9%87%8C%E4%BA%9E%E6%B5%B7%E6%B5%B7%E5%B2%B8%2C+%E8%92%99%E7%89%B9%E5%85%A7%E5%93%A5%E7%BE%85&ssne=%E8%92%82%E7%93%A6%E7%89%B9&ssne_untouched=%E8%92%82%E7%93%A6%E7%89%B9&highlighted_hotels=5003498&lang=zh-cn&src=searchresults&dest_id=-91673&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=xt&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=0f0d0145943d003a&checkin=2022-09-18&checkout=2022-09-19&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure&nflt=hotelfacility%3D46\">住宿 佩拉斯特</a></li>\n<li><a href=\"https://www.booking.com/searchresults.zh-cn.html?ss=%E5%9C%B0%E6%8B%89%E9%82%A3&ssne=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&ssne_untouched=%E5%B8%95%E9%87%8C%E6%96%AF%E7%89%B9&label=6317c5f1c0606502acbb9307&sid=7c06b5a442ec544ee5783089a09dbfe2&aid=1188619&highlighted_hotels=5003498&lang=zh-cn&sb=1&src_elem=sb&src=searchresults&dest_id=-108649&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=zh&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=e87b0248d9cb0186&checkin=2022-09-19&checkout=2022-09-20&group_adults=3&no_rooms=1&group_children=0&sb_travel_purpose=leisure\">住宿 地拉那</a></li>\n<li>换汇？（列克）</li>\n</ul>\n<p>Hint: </p>\n<ol>\n<li>在访问与科索沃北部边境的山区城镇时，您应该谨慎行事，并注意有关未爆地雷和其他未爆弹药的警告标志</li>\n</ol>\n<blockquote>\n<p>[Foreign travel advice Albania][<a href=\"https://www.gov.uk/foreign-travel-advice/albania]\">https://www.gov.uk/foreign-travel-advice/albania]</a></p>\n</blockquote>\n<ol start=\"2\">\n<li>a shake of the head means “yes” and a nod “no”.</li>\n<li>阿尔巴尼亚人非常好客，很可能会为您提供咖啡、糖果等。接受并主动分享您拥有的任何东西都是一种礼貌。</li>\n<li>羊肉和鱼很好吃，沿海的海鲜很棒</li>\n</ol>\n<p><a href=\"https://www.google.com/maps/d/edit?hl=en&hl=en&mid=1aknYGVaPEn1lvnRAhbiaoIW8IBNmVYU&ll=40.792607903029115%2C18.94627905947007&z=8\">路线图</a></p>\n<h2 id=\"9-14\"><a href=\"#9-14\" class=\"headerlink\" title=\"9.14\"></a>9.14</h2><ul>\n<li>7：35-11：45飞机</li>\n<li>斯坎德贝格广场开始，追踪<strong>共产主义时代的建筑</strong>和纪念碑</li>\n<li>提车</li>\n<li>地拉那—萨兰达（3h30min）</li>\n<li>住宿</li>\n</ul>\n<h2 id=\"9-15\"><a href=\"#9-15\" class=\"headerlink\" title=\"9.15\"></a>9.15</h2><ul>\n<li>萨兰达一日游</li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-16\"><a href=\"#9-16\" class=\"headerlink\" title=\"9.16\"></a>9.16</h2><ul>\n<li>萨兰达—泽尔米乌—都拉斯（1h40min+2h50min）</li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-17\"><a href=\"#9-17\" class=\"headerlink\" title=\"9.17\"></a>9.17</h2><ul>\n<li>都拉斯—黑山（圣斯特凡岛）（3h21min）</li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-18\"><a href=\"#9-18\" class=\"headerlink\" title=\"9.18\"></a>9.18</h2><ul>\n<li>佩拉斯特 </li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-19\"><a href=\"#9-19\" class=\"headerlink\" title=\"9.19\"></a>9.19</h2><ul>\n<li>佩拉斯特—地拉那国际机场（4h30min）还车  </li>\n<li>住一晚 </li>\n</ul>\n<h2 id=\"9-20\"><a href=\"#9-20\" class=\"headerlink\" title=\"9.20\"></a>9.20</h2><ul>\n<li>回伦敦     （18：35-20：45 3h10min）</li>\n</ul>\n"},{"title":"machine learning","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-04-03T03:04:00.000Z","password":null,"summary":null,"_content":"\n# Machine Learning for League of Legend mini-map\n\n## Technical Details:\n\nGeneral idea: Use node script to detect whenever the Mysterious Web Socket is open, listen to the incoming data and save the result as JSON file.\n\n1. In order to run a supervised learning, another problem is how to **label** dataset:\n\n   solve the problem of organizing CSV files and JPG files:\n\n   Save the data into a **.npz** file which save all stuff as **raw numpy arrays**\n\n2. During labelling, another problem is the data bias:\n\n   A misrecognition could happen if there is not enough data for a certain champ.\n\n   To avoid overfitting and underfitting for different champs: code to balance the dataset under the function check_champs\n\n   [**Focal loss**](https://arxiv.org/abs/1708.02002) could be used to balance the dataset\n\n3. However, how to get the time which is labelled timestamps:\n\n   OCR: use computer vision to get the timestamp (**YOLO**), another option is Google Cloud Vision API (but need paying)\n\n4. data augmentation could be a good method (flip the frame)but may cause confusion of the model (also flip the champs’ icon).\n\n5. One limitation is that the RAM is supposed to storage many images at once.\n\n## Concept\n\n[SSD](https://arxiv.org/abs/1512.02325), [R-CNNs](https://github.com/rbgirshick/rcnn), [Faster R-CNN](https://arxiv.org/abs/1506.01497), and [YOLO9000](https://pjreddie.com/media/files/papers/YOLO9000.pdf)","source":"_posts/Machine Learning.md","raw":"---\ntitle: machine learning\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-04-03 04:04\npassword:\nsummary:\ntags:\n- ML\ncategories:\n- programming\n---\n\n# Machine Learning for League of Legend mini-map\n\n## Technical Details:\n\nGeneral idea: Use node script to detect whenever the Mysterious Web Socket is open, listen to the incoming data and save the result as JSON file.\n\n1. In order to run a supervised learning, another problem is how to **label** dataset:\n\n   solve the problem of organizing CSV files and JPG files:\n\n   Save the data into a **.npz** file which save all stuff as **raw numpy arrays**\n\n2. During labelling, another problem is the data bias:\n\n   A misrecognition could happen if there is not enough data for a certain champ.\n\n   To avoid overfitting and underfitting for different champs: code to balance the dataset under the function check_champs\n\n   [**Focal loss**](https://arxiv.org/abs/1708.02002) could be used to balance the dataset\n\n3. However, how to get the time which is labelled timestamps:\n\n   OCR: use computer vision to get the timestamp (**YOLO**), another option is Google Cloud Vision API (but need paying)\n\n4. data augmentation could be a good method (flip the frame)but may cause confusion of the model (also flip the champs’ icon).\n\n5. One limitation is that the RAM is supposed to storage many images at once.\n\n## Concept\n\n[SSD](https://arxiv.org/abs/1512.02325), [R-CNNs](https://github.com/rbgirshick/rcnn), [Faster R-CNN](https://arxiv.org/abs/1506.01497), and [YOLO9000](https://pjreddie.com/media/files/papers/YOLO9000.pdf)","slug":"Machine Learning","published":1,"updated":"2022-08-24T17:51:38.399Z","comments":1,"layout":"post","photos":[],"_id":"cuid67Rc1YXk_ygkd5jSkevIF","content":"<h1 id=\"Machine-Learning-for-League-of-Legend-mini-map\"><a href=\"#Machine-Learning-for-League-of-Legend-mini-map\" class=\"headerlink\" title=\"Machine Learning for League of Legend mini-map\"></a>Machine Learning for League of Legend mini-map</h1><h2 id=\"Technical-Details\"><a href=\"#Technical-Details\" class=\"headerlink\" title=\"Technical Details:\"></a>Technical Details:</h2><p>General idea: Use node script to detect whenever the Mysterious Web Socket is open, listen to the incoming data and save the result as JSON file.</p>\n<ol>\n<li><p>In order to run a supervised learning, another problem is how to <strong>label</strong> dataset:</p>\n<p>solve the problem of organizing CSV files and JPG files:</p>\n<p>Save the data into a <strong>.npz</strong> file which save all stuff as <strong>raw numpy arrays</strong></p>\n</li>\n<li><p>During labelling, another problem is the data bias:</p>\n<p>A misrecognition could happen if there is not enough data for a certain champ.</p>\n<p>To avoid overfitting and underfitting for different champs: code to balance the dataset under the function check_champs</p>\n<p><a href=\"https://arxiv.org/abs/1708.02002\"><strong>Focal loss</strong></a> could be used to balance the dataset</p>\n</li>\n<li><p>However, how to get the time which is labelled timestamps:</p>\n<p>OCR: use computer vision to get the timestamp (<strong>YOLO</strong>), another option is Google Cloud Vision API (but need paying)</p>\n</li>\n<li><p>data augmentation could be a good method (flip the frame)but may cause confusion of the model (also flip the champs’ icon).</p>\n</li>\n<li><p>One limitation is that the RAM is supposed to storage many images at once.</p>\n</li>\n</ol>\n<h2 id=\"Concept\"><a href=\"#Concept\" class=\"headerlink\" title=\"Concept\"></a>Concept</h2><p><a href=\"https://arxiv.org/abs/1512.02325\">SSD</a>, <a href=\"https://github.com/rbgirshick/rcnn\">R-CNNs</a>, <a href=\"https://arxiv.org/abs/1506.01497\">Faster R-CNN</a>, and <a href=\"https://pjreddie.com/media/files/papers/YOLO9000.pdf\">YOLO9000</a></p>\n","excerpt":"","more":"<h1 id=\"Machine-Learning-for-League-of-Legend-mini-map\"><a href=\"#Machine-Learning-for-League-of-Legend-mini-map\" class=\"headerlink\" title=\"Machine Learning for League of Legend mini-map\"></a>Machine Learning for League of Legend mini-map</h1><h2 id=\"Technical-Details\"><a href=\"#Technical-Details\" class=\"headerlink\" title=\"Technical Details:\"></a>Technical Details:</h2><p>General idea: Use node script to detect whenever the Mysterious Web Socket is open, listen to the incoming data and save the result as JSON file.</p>\n<ol>\n<li><p>In order to run a supervised learning, another problem is how to <strong>label</strong> dataset:</p>\n<p>solve the problem of organizing CSV files and JPG files:</p>\n<p>Save the data into a <strong>.npz</strong> file which save all stuff as <strong>raw numpy arrays</strong></p>\n</li>\n<li><p>During labelling, another problem is the data bias:</p>\n<p>A misrecognition could happen if there is not enough data for a certain champ.</p>\n<p>To avoid overfitting and underfitting for different champs: code to balance the dataset under the function check_champs</p>\n<p><a href=\"https://arxiv.org/abs/1708.02002\"><strong>Focal loss</strong></a> could be used to balance the dataset</p>\n</li>\n<li><p>However, how to get the time which is labelled timestamps:</p>\n<p>OCR: use computer vision to get the timestamp (<strong>YOLO</strong>), another option is Google Cloud Vision API (but need paying)</p>\n</li>\n<li><p>data augmentation could be a good method (flip the frame)but may cause confusion of the model (also flip the champs’ icon).</p>\n</li>\n<li><p>One limitation is that the RAM is supposed to storage many images at once.</p>\n</li>\n</ol>\n<h2 id=\"Concept\"><a href=\"#Concept\" class=\"headerlink\" title=\"Concept\"></a>Concept</h2><p><a href=\"https://arxiv.org/abs/1512.02325\">SSD</a>, <a href=\"https://github.com/rbgirshick/rcnn\">R-CNNs</a>, <a href=\"https://arxiv.org/abs/1506.01497\">Faster R-CNN</a>, and <a href=\"https://pjreddie.com/media/files/papers/YOLO9000.pdf\">YOLO9000</a></p>\n"},{"title":"DLL injection","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-04-04T06:17:00.000Z","password":null,"summary":null,"_content":"\n# DLL injection\n\nCommonly used by hackers and malware authors\n\nPurpose: \n\nForce some other process  into running your own code\n\nOnce it is injected, you can do any thing the main process can\n","source":"_posts/DLL injection.md","raw":"---\ntitle: DLL injection\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-04-04 07:17\npassword:\nsummary:\ntags:\n- DLL\ncategories:\n- Neuroscience programming\n---\n\n# DLL injection\n\nCommonly used by hackers and malware authors\n\nPurpose: \n\nForce some other process  into running your own code\n\nOnce it is injected, you can do any thing the main process can\n","slug":"DLL injection","published":1,"updated":"2022-08-24T17:49:30.811Z","comments":1,"layout":"post","photos":[],"_id":"cuidjh3CMAtDJy7B6n36UGctG","content":"<h1 id=\"DLL-injection\"><a href=\"#DLL-injection\" class=\"headerlink\" title=\"DLL injection\"></a>DLL injection</h1><p>Commonly used by hackers and malware authors</p>\n<p>Purpose: </p>\n<p>Force some other process  into running your own code</p>\n<p>Once it is injected, you can do any thing the main process can</p>\n","excerpt":"","more":"<h1 id=\"DLL-injection\"><a href=\"#DLL-injection\" class=\"headerlink\" title=\"DLL injection\"></a>DLL injection</h1><p>Commonly used by hackers and malware authors</p>\n<p>Purpose: </p>\n<p>Force some other process  into running your own code</p>\n<p>Once it is injected, you can do any thing the main process can</p>\n"},{"title":"Installing Jupyter lab","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-07-12T13:51:00.000Z","password":null,"summary":null,"_content":"\n## Installing Jupyter lab\n\n1.  If you haven't already, install anaconda/miniconda\n\n```\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nchmod +x Miniconda3-latest-Linux-x86_64.sh\n./Miniconda3-latest-Linux-x86_64.sh\n```\n\n2.  Create a new environment \n\n```\nconda create -n CNN\n```\n\n3.  Activate the environment and install Jupyter lab\n\n`bash` to restart the shell\n\n```\nconda activate CNN\npip install jupyterlab\n```\n\n### Connecting to Jupyter Lab through an SSH tunnel\n\n4.  Start an interactive session\n\n``` \nsrun -p gpu --pty -t 8:00:00 --mem=30GB --gres=gpu /bin/bash\n```\n\n**Make a note of the node you're connected to, e.g. erc-hpc-comp001**\n\n5.  Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)\n\n```\nconda activate CNN\njupyter lab --no-browser --port=9998 --ip=\"*\"\npython -m notebook --no-browser --port=9998 --ip=\"*\" # if the above line does not work\n```\n\n6.  **Open a separate connection** to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)\n\n```\nssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk\" -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk\n```\n\n**Note:**\n\n- k12345678 should be replaced with your username.\n- erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running\n- 9998 should be replaced with the port you specified when running Jupyter lab (using e.g. `--port=9998`)\n- authorize via https://portal.er.kcl.ac.uk/mfa/\n\n7.  Go to http://localhost:9998/lab (assuming you had specified port 9998 earlier, if not replace this with the port you used)\n\n![image-20220711015129051](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207110151407.png)\n","source":"_posts/Installing Jupyter lab.md","raw":"---\ntitle: Installing Jupyter lab\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-07-12 14:51\npassword:\nsummary:\ntags:\n- project\ncategories:\n- Neruroscience programming\n---\n\n## Installing Jupyter lab\n\n1.  If you haven't already, install anaconda/miniconda\n\n```\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nchmod +x Miniconda3-latest-Linux-x86_64.sh\n./Miniconda3-latest-Linux-x86_64.sh\n```\n\n2.  Create a new environment \n\n```\nconda create -n CNN\n```\n\n3.  Activate the environment and install Jupyter lab\n\n`bash` to restart the shell\n\n```\nconda activate CNN\npip install jupyterlab\n```\n\n### Connecting to Jupyter Lab through an SSH tunnel\n\n4.  Start an interactive session\n\n``` \nsrun -p gpu --pty -t 8:00:00 --mem=30GB --gres=gpu /bin/bash\n```\n\n**Make a note of the node you're connected to, e.g. erc-hpc-comp001**\n\n5.  Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)\n\n```\nconda activate CNN\njupyter lab --no-browser --port=9998 --ip=\"*\"\npython -m notebook --no-browser --port=9998 --ip=\"*\" # if the above line does not work\n```\n\n6.  **Open a separate connection** to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)\n\n```\nssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk\" -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk\n```\n\n**Note:**\n\n- k12345678 should be replaced with your username.\n- erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running\n- 9998 should be replaced with the port you specified when running Jupyter lab (using e.g. `--port=9998`)\n- authorize via https://portal.er.kcl.ac.uk/mfa/\n\n7.  Go to http://localhost:9998/lab (assuming you had specified port 9998 earlier, if not replace this with the port you used)\n\n![image-20220711015129051](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207110151407.png)\n","slug":"Installing Jupyter lab","published":1,"updated":"2022-08-24T17:08:39.362Z","comments":1,"layout":"post","photos":[],"_id":"cuidID30usOvAOeS3sIFv4IJB","content":"<h2 id=\"Installing-Jupyter-lab\"><a href=\"#Installing-Jupyter-lab\" class=\"headerlink\" title=\"Installing Jupyter lab\"></a>Installing Jupyter lab</h2><ol>\n<li>If you haven’t already, install anaconda/miniconda</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class=\"line\">chmod +x Miniconda3-latest-Linux-x86_64.sh</span><br><span class=\"line\">./Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>Create a new environment </li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda create -n CNN</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>Activate the environment and install Jupyter lab</li>\n</ol>\n<p><code>bash</code> to restart the shell</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate CNN</span><br><span class=\"line\">pip install jupyterlab</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\"><a href=\"#Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\" class=\"headerlink\" title=\"Connecting to Jupyter Lab through an SSH tunnel\"></a>Connecting to Jupyter Lab through an SSH tunnel</h3><ol start=\"4\">\n<li>Start an interactive session</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">srun -p gpu --pty -t 8:00:00 --mem=30GB --gres=gpu /bin/bash</span><br></pre></td></tr></table></figure>\n\n<p><strong>Make a note of the node you’re connected to, e.g. erc-hpc-comp001</strong></p>\n<ol start=\"5\">\n<li>Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate CNN</span><br><span class=\"line\">jupyter lab --no-browser --port=9998 --ip=&quot;*&quot;</span><br><span class=\"line\">python -m notebook --no-browser --port=9998 --ip=&quot;*&quot; # if the above line does not work</span><br></pre></td></tr></table></figure>\n\n<ol start=\"6\">\n<li><strong>Open a separate connection</strong> to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 -o ProxyCommand=&quot;ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk&quot; -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk</span><br></pre></td></tr></table></figure>\n\n<p><strong>Note:</strong></p>\n<ul>\n<li>k12345678 should be replaced with your username.</li>\n<li>erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running</li>\n<li>9998 should be replaced with the port you specified when running Jupyter lab (using e.g. <code>--port=9998</code>)</li>\n<li>authorize via <a href=\"https://portal.er.kcl.ac.uk/mfa/\">https://portal.er.kcl.ac.uk/mfa/</a></li>\n</ul>\n<ol start=\"7\">\n<li>Go to <a href=\"http://localhost:9998/lab\">http://localhost:9998/lab</a> (assuming you had specified port 9998 earlier, if not replace this with the port you used)</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207110151407.png\" alt=\"image-20220711015129051\"></p>\n","excerpt":"","more":"<h2 id=\"Installing-Jupyter-lab\"><a href=\"#Installing-Jupyter-lab\" class=\"headerlink\" title=\"Installing Jupyter lab\"></a>Installing Jupyter lab</h2><ol>\n<li>If you haven’t already, install anaconda/miniconda</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class=\"line\">chmod +x Miniconda3-latest-Linux-x86_64.sh</span><br><span class=\"line\">./Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>Create a new environment </li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda create -n CNN</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>Activate the environment and install Jupyter lab</li>\n</ol>\n<p><code>bash</code> to restart the shell</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate CNN</span><br><span class=\"line\">pip install jupyterlab</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\"><a href=\"#Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\" class=\"headerlink\" title=\"Connecting to Jupyter Lab through an SSH tunnel\"></a>Connecting to Jupyter Lab through an SSH tunnel</h3><ol start=\"4\">\n<li>Start an interactive session</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">srun -p gpu --pty -t 8:00:00 --mem=30GB --gres=gpu /bin/bash</span><br></pre></td></tr></table></figure>\n\n<p><strong>Make a note of the node you’re connected to, e.g. erc-hpc-comp001</strong></p>\n<ol start=\"5\">\n<li>Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate CNN</span><br><span class=\"line\">jupyter lab --no-browser --port=9998 --ip=&quot;*&quot;</span><br><span class=\"line\">python -m notebook --no-browser --port=9998 --ip=&quot;*&quot; # if the above line does not work</span><br></pre></td></tr></table></figure>\n\n<ol start=\"6\">\n<li><strong>Open a separate connection</strong> to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 -o ProxyCommand=&quot;ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk&quot; -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk</span><br></pre></td></tr></table></figure>\n\n<p><strong>Note:</strong></p>\n<ul>\n<li>k12345678 should be replaced with your username.</li>\n<li>erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running</li>\n<li>9998 should be replaced with the port you specified when running Jupyter lab (using e.g. <code>--port=9998</code>)</li>\n<li>authorize via <a href=\"https://portal.er.kcl.ac.uk/mfa/\">https://portal.er.kcl.ac.uk/mfa/</a></li>\n</ul>\n<ol start=\"7\">\n<li>Go to <a href=\"http://localhost:9998/lab\">http://localhost:9998/lab</a> (assuming you had specified port 9998 earlier, if not replace this with the port you used)</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207110151407.png\" alt=\"image-20220711015129051\"></p>\n"},{"title":"Tutorial for PyCharm","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-04-06T21:58:00.000Z","password":null,"summary":null,"_content":"\n## Tutorial for PyCharm\n\n`Alt` `Enter` preview the warning and apply a quick fix.\n\n`Ctrl` `Shift` `A` is the shortcut of Find Action. Alternatively search Everywhere can be invoked by pressing `Shift` twice.\n\n`Ctrl` `W`, once to select the word under the caret, twice to select the whole string, tree times to include quotes, four times to select the whole call. If the caret is at the beginning of a statement, twice pressing is used to select it \n\n`Ctrl` `Shift` `W`, to shrink selection back to the arguments. \n\n`Ctrl` `/`， to comment the code. Also `#` before code or `“”“ ”“”` or`‘'' '''` between the block\n\n`ctrl` `P` to give the values a method expects\n\n## For beginner\n\n### Variables\n\nBoolean data type is using “True” and “False”. Python is sensitive with lowercase and uppercase letters\n\nString concatenation: \n\n```python\nprint(“Text ” + data_name)\n```\n\nInput function: \n\n```python\nname = input (“What is your name”)\n```\n\nWhen you want to name a variable, it is not required to add the type of it. So, if we want to convert the variable from one type to another, we can use:\n\n```python\nint(name)\nfloat()\nbool()\nstr()\n```\n\n### Operators\n\nComparison operators:\n\n```python\n>\n<\n<=\n>=\n==\n!=\n```\n\nlogical operators:\n\n```python\nprint(price>1 and price <2)\nprint(price>1 or price<0)\nprint(not price>1)\n```\n\na Boolean value will be output\n\n### Lists\n\n```python\nnames = ['John', 'Mary', 'Bob', 'Jack']\nprint(names[0:2]) #output will be John Mary\nprint(names[-1]) #output will be Jack\n```\n\n.append(): add element into the lists\n\n.insert(): insert an element\n\n.remove(): remove an element\n\n.clear(): empty a list\n\nlen(): give the numbers of elements\n\n```\nfor items in numbers:\nprint(items)\n```\n\nEach items can automatically hold one elements\n\n### Range\n\nrange(a, b , c): give a sequence of numbers. a for beginning number, b for ending number and c for step. a, c can be default to be 0 and 1\n\n### Tuples\n\n```\nnumbers =(1, 2, 3, 4)\n```\n\nit is immutable, we can not change elements\n\n# Tricks \n\n## and 和 or 的短路效应：\n\n当or表达式里的所有值为真，会选择第一个值\n\n当and表达式里所有值为真，会选择第二个值\n\n## intern 机制\n\nintern（字符串驻留）的机制在Python解释器中被使用，\n\n当有空格，或者字符串长度超过20个字符，则不启动intern机制\n\n```Python\ns1=\"hello\"\ns2=\"hello\"\ns1 is s2 # True\n\ns1=\"hell o\"\ns2=\"hell o\"\ns1 is s2 # False\n\ns1=\"hello\"*4\ns2=\"hello\"*4\ns1 is s2 # False\n\ns1=\"hello\"*5\ns2=\"hello\"*5\ns1 is s2 # True\n```\n\n## argument 和 parameter 的区别\n\nparameter：形参（formal parameter），体现在函数内部，作用域是这个函数体。\nargument ：实参（actual parameter），调用函数实际传递的参数。\n\n## return不一定都是函数的终点\n\n在try…finally…语句中，try中的 return 会被直接忽视（这里的 return 不是函数的终点），因为要保证 finally 能够执行。\n\n```python\ndef func():\n\ttry:\n\t\treturn 'try'\n\tfinally:\n\t\treturn 'finally'\nfunc() #'finally'\n\ndef func1():\n\ttry:\n\t\treturn 'try'\n\tfinally:\n\t\tprint('finally')\nfunc1() \n#finally\n#'try'\n```\n\n如果 finally 里有显式的 return，那么这个 return 会直接覆盖 try 里的 return，而如果 finally 里没有 显式的 return，那么 try 里的 return 仍然有效。\n","source":"_posts/Python learning.md","raw":"---\ntitle: Tutorial for PyCharm\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-04-06 22:58\npassword:\nsummary:\ntags:\n- python\ncategories:\n- programming\n---\n\n## Tutorial for PyCharm\n\n`Alt` `Enter` preview the warning and apply a quick fix.\n\n`Ctrl` `Shift` `A` is the shortcut of Find Action. Alternatively search Everywhere can be invoked by pressing `Shift` twice.\n\n`Ctrl` `W`, once to select the word under the caret, twice to select the whole string, tree times to include quotes, four times to select the whole call. If the caret is at the beginning of a statement, twice pressing is used to select it \n\n`Ctrl` `Shift` `W`, to shrink selection back to the arguments. \n\n`Ctrl` `/`， to comment the code. Also `#` before code or `“”“ ”“”` or`‘'' '''` between the block\n\n`ctrl` `P` to give the values a method expects\n\n## For beginner\n\n### Variables\n\nBoolean data type is using “True” and “False”. Python is sensitive with lowercase and uppercase letters\n\nString concatenation: \n\n```python\nprint(“Text ” + data_name)\n```\n\nInput function: \n\n```python\nname = input (“What is your name”)\n```\n\nWhen you want to name a variable, it is not required to add the type of it. So, if we want to convert the variable from one type to another, we can use:\n\n```python\nint(name)\nfloat()\nbool()\nstr()\n```\n\n### Operators\n\nComparison operators:\n\n```python\n>\n<\n<=\n>=\n==\n!=\n```\n\nlogical operators:\n\n```python\nprint(price>1 and price <2)\nprint(price>1 or price<0)\nprint(not price>1)\n```\n\na Boolean value will be output\n\n### Lists\n\n```python\nnames = ['John', 'Mary', 'Bob', 'Jack']\nprint(names[0:2]) #output will be John Mary\nprint(names[-1]) #output will be Jack\n```\n\n.append(): add element into the lists\n\n.insert(): insert an element\n\n.remove(): remove an element\n\n.clear(): empty a list\n\nlen(): give the numbers of elements\n\n```\nfor items in numbers:\nprint(items)\n```\n\nEach items can automatically hold one elements\n\n### Range\n\nrange(a, b , c): give a sequence of numbers. a for beginning number, b for ending number and c for step. a, c can be default to be 0 and 1\n\n### Tuples\n\n```\nnumbers =(1, 2, 3, 4)\n```\n\nit is immutable, we can not change elements\n\n# Tricks \n\n## and 和 or 的短路效应：\n\n当or表达式里的所有值为真，会选择第一个值\n\n当and表达式里所有值为真，会选择第二个值\n\n## intern 机制\n\nintern（字符串驻留）的机制在Python解释器中被使用，\n\n当有空格，或者字符串长度超过20个字符，则不启动intern机制\n\n```Python\ns1=\"hello\"\ns2=\"hello\"\ns1 is s2 # True\n\ns1=\"hell o\"\ns2=\"hell o\"\ns1 is s2 # False\n\ns1=\"hello\"*4\ns2=\"hello\"*4\ns1 is s2 # False\n\ns1=\"hello\"*5\ns2=\"hello\"*5\ns1 is s2 # True\n```\n\n## argument 和 parameter 的区别\n\nparameter：形参（formal parameter），体现在函数内部，作用域是这个函数体。\nargument ：实参（actual parameter），调用函数实际传递的参数。\n\n## return不一定都是函数的终点\n\n在try…finally…语句中，try中的 return 会被直接忽视（这里的 return 不是函数的终点），因为要保证 finally 能够执行。\n\n```python\ndef func():\n\ttry:\n\t\treturn 'try'\n\tfinally:\n\t\treturn 'finally'\nfunc() #'finally'\n\ndef func1():\n\ttry:\n\t\treturn 'try'\n\tfinally:\n\t\tprint('finally')\nfunc1() \n#finally\n#'try'\n```\n\n如果 finally 里有显式的 return，那么这个 return 会直接覆盖 try 里的 return，而如果 finally 里没有 显式的 return，那么 try 里的 return 仍然有效。\n","slug":"Python learning","published":1,"updated":"2022-08-24T17:08:39.375Z","comments":1,"layout":"post","photos":[],"_id":"cuiddrYPM97ofY4Sk7bi11UVJ","content":"<h2 id=\"Tutorial-for-PyCharm\"><a href=\"#Tutorial-for-PyCharm\" class=\"headerlink\" title=\"Tutorial for PyCharm\"></a>Tutorial for PyCharm</h2><p><code>Alt</code> <code>Enter</code> preview the warning and apply a quick fix.</p>\n<p><code>Ctrl</code> <code>Shift</code> <code>A</code> is the shortcut of Find Action. Alternatively search Everywhere can be invoked by pressing <code>Shift</code> twice.</p>\n<p><code>Ctrl</code> <code>W</code>, once to select the word under the caret, twice to select the whole string, tree times to include quotes, four times to select the whole call. If the caret is at the beginning of a statement, twice pressing is used to select it </p>\n<p><code>Ctrl</code> <code>Shift</code> <code>W</code>, to shrink selection back to the arguments. </p>\n<p><code>Ctrl</code> <code>/</code>， to comment the code. Also <code>#</code> before code or <code>“”“ ”“”</code> or<code>‘&#39;&#39; &#39;&#39;&#39;</code> between the block</p>\n<p><code>ctrl</code> <code>P</code> to give the values a method expects</p>\n<h2 id=\"For-beginner\"><a href=\"#For-beginner\" class=\"headerlink\" title=\"For beginner\"></a>For beginner</h2><h3 id=\"Variables\"><a href=\"#Variables\" class=\"headerlink\" title=\"Variables\"></a>Variables</h3><p>Boolean data type is using “True” and “False”. Python is sensitive with lowercase and uppercase letters</p>\n<p>String concatenation: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(“Text ” + data_name)</span><br></pre></td></tr></table></figure>\n\n<p>Input function: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">name = <span class=\"built_in\">input</span> (“What <span class=\"keyword\">is</span> your name”)</span><br></pre></td></tr></table></figure>\n\n<p>When you want to name a variable, it is not required to add the type of it. So, if we want to convert the variable from one type to another, we can use:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">int</span>(name)</span><br><span class=\"line\"><span class=\"built_in\">float</span>()</span><br><span class=\"line\"><span class=\"built_in\">bool</span>()</span><br><span class=\"line\"><span class=\"built_in\">str</span>()</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Operators\"><a href=\"#Operators\" class=\"headerlink\" title=\"Operators\"></a>Operators</h3><p>Comparison operators:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;</span><br><span class=\"line\">&lt;</span><br><span class=\"line\">&lt;=</span><br><span class=\"line\">&gt;=</span><br><span class=\"line\">==</span><br><span class=\"line\">!=</span><br></pre></td></tr></table></figure>\n\n<p>logical operators:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(price&gt;<span class=\"number\">1</span> <span class=\"keyword\">and</span> price &lt;<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(price&gt;<span class=\"number\">1</span> <span class=\"keyword\">or</span> price&lt;<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"keyword\">not</span> price&gt;<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<p>a Boolean value will be output</p>\n<h3 id=\"Lists\"><a href=\"#Lists\" class=\"headerlink\" title=\"Lists\"></a>Lists</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">names = [<span class=\"string\">&#x27;John&#x27;</span>, <span class=\"string\">&#x27;Mary&#x27;</span>, <span class=\"string\">&#x27;Bob&#x27;</span>, <span class=\"string\">&#x27;Jack&#x27;</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(names[<span class=\"number\">0</span>:<span class=\"number\">2</span>]) <span class=\"comment\">#output will be John Mary</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(names[-<span class=\"number\">1</span>]) <span class=\"comment\">#output will be Jack</span></span><br></pre></td></tr></table></figure>\n\n<p>.append(): add element into the lists</p>\n<p>.insert(): insert an element</p>\n<p>.remove(): remove an element</p>\n<p>.clear(): empty a list</p>\n<p>len(): give the numbers of elements</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">for items in numbers:</span><br><span class=\"line\">print(items)</span><br></pre></td></tr></table></figure>\n\n<p>Each items can automatically hold one elements</p>\n<h3 id=\"Range\"><a href=\"#Range\" class=\"headerlink\" title=\"Range\"></a>Range</h3><p>range(a, b , c): give a sequence of numbers. a for beginning number, b for ending number and c for step. a, c can be default to be 0 and 1</p>\n<h3 id=\"Tuples\"><a href=\"#Tuples\" class=\"headerlink\" title=\"Tuples\"></a>Tuples</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">numbers =(1, 2, 3, 4)</span><br></pre></td></tr></table></figure>\n\n<p>it is immutable, we can not change elements</p>\n<h1 id=\"Tricks\"><a href=\"#Tricks\" class=\"headerlink\" title=\"Tricks\"></a>Tricks</h1><h2 id=\"and-和-or-的短路效应：\"><a href=\"#and-和-or-的短路效应：\" class=\"headerlink\" title=\"and 和 or 的短路效应：\"></a>and 和 or 的短路效应：</h2><p>当or表达式里的所有值为真，会选择第一个值</p>\n<p>当and表达式里所有值为真，会选择第二个值</p>\n<h2 id=\"intern-机制\"><a href=\"#intern-机制\" class=\"headerlink\" title=\"intern 机制\"></a>intern 机制</h2><p>intern（字符串驻留）的机制在Python解释器中被使用，</p>\n<p>当有空格，或者字符串长度超过20个字符，则不启动intern机制</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">s1=<span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># True</span></span><br><span class=\"line\"></span><br><span class=\"line\">s1=<span class=\"string\">&quot;hell o&quot;</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hell o&quot;</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># False</span></span><br><span class=\"line\"></span><br><span class=\"line\">s1=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">4</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">4</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># False</span></span><br><span class=\"line\"></span><br><span class=\"line\">s1=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">5</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">5</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># True</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"argument-和-parameter-的区别\"><a href=\"#argument-和-parameter-的区别\" class=\"headerlink\" title=\"argument 和 parameter 的区别\"></a>argument 和 parameter 的区别</h2><p>parameter：形参（formal parameter），体现在函数内部，作用域是这个函数体。<br>argument ：实参（actual parameter），调用函数实际传递的参数。</p>\n<h2 id=\"return不一定都是函数的终点\"><a href=\"#return不一定都是函数的终点\" class=\"headerlink\" title=\"return不一定都是函数的终点\"></a>return不一定都是函数的终点</h2><p>在try…finally…语句中，try中的 return 会被直接忽视（这里的 return 不是函数的终点），因为要保证 finally 能够执行。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">func</span>():</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"string\">&#x27;try&#x27;</span></span><br><span class=\"line\">\t<span class=\"keyword\">finally</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"string\">&#x27;finally&#x27;</span></span><br><span class=\"line\">func() <span class=\"comment\">#&#x27;finally&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">func1</span>():</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"string\">&#x27;try&#x27;</span></span><br><span class=\"line\">\t<span class=\"keyword\">finally</span>:</span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&#x27;finally&#x27;</span>)</span><br><span class=\"line\">func1() </span><br><span class=\"line\"><span class=\"comment\">#finally</span></span><br><span class=\"line\"><span class=\"comment\">#&#x27;try&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>如果 finally 里有显式的 return，那么这个 return 会直接覆盖 try 里的 return，而如果 finally 里没有 显式的 return，那么 try 里的 return 仍然有效。</p>\n","excerpt":"","more":"<h2 id=\"Tutorial-for-PyCharm\"><a href=\"#Tutorial-for-PyCharm\" class=\"headerlink\" title=\"Tutorial for PyCharm\"></a>Tutorial for PyCharm</h2><p><code>Alt</code> <code>Enter</code> preview the warning and apply a quick fix.</p>\n<p><code>Ctrl</code> <code>Shift</code> <code>A</code> is the shortcut of Find Action. Alternatively search Everywhere can be invoked by pressing <code>Shift</code> twice.</p>\n<p><code>Ctrl</code> <code>W</code>, once to select the word under the caret, twice to select the whole string, tree times to include quotes, four times to select the whole call. If the caret is at the beginning of a statement, twice pressing is used to select it </p>\n<p><code>Ctrl</code> <code>Shift</code> <code>W</code>, to shrink selection back to the arguments. </p>\n<p><code>Ctrl</code> <code>/</code>， to comment the code. Also <code>#</code> before code or <code>“”“ ”“”</code> or<code>‘&#39;&#39; &#39;&#39;&#39;</code> between the block</p>\n<p><code>ctrl</code> <code>P</code> to give the values a method expects</p>\n<h2 id=\"For-beginner\"><a href=\"#For-beginner\" class=\"headerlink\" title=\"For beginner\"></a>For beginner</h2><h3 id=\"Variables\"><a href=\"#Variables\" class=\"headerlink\" title=\"Variables\"></a>Variables</h3><p>Boolean data type is using “True” and “False”. Python is sensitive with lowercase and uppercase letters</p>\n<p>String concatenation: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(“Text ” + data_name)</span><br></pre></td></tr></table></figure>\n\n<p>Input function: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">name = <span class=\"built_in\">input</span> (“What <span class=\"keyword\">is</span> your name”)</span><br></pre></td></tr></table></figure>\n\n<p>When you want to name a variable, it is not required to add the type of it. So, if we want to convert the variable from one type to another, we can use:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">int</span>(name)</span><br><span class=\"line\"><span class=\"built_in\">float</span>()</span><br><span class=\"line\"><span class=\"built_in\">bool</span>()</span><br><span class=\"line\"><span class=\"built_in\">str</span>()</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Operators\"><a href=\"#Operators\" class=\"headerlink\" title=\"Operators\"></a>Operators</h3><p>Comparison operators:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;</span><br><span class=\"line\">&lt;</span><br><span class=\"line\">&lt;=</span><br><span class=\"line\">&gt;=</span><br><span class=\"line\">==</span><br><span class=\"line\">!=</span><br></pre></td></tr></table></figure>\n\n<p>logical operators:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(price&gt;<span class=\"number\">1</span> <span class=\"keyword\">and</span> price &lt;<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(price&gt;<span class=\"number\">1</span> <span class=\"keyword\">or</span> price&lt;<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"keyword\">not</span> price&gt;<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<p>a Boolean value will be output</p>\n<h3 id=\"Lists\"><a href=\"#Lists\" class=\"headerlink\" title=\"Lists\"></a>Lists</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">names = [<span class=\"string\">&#x27;John&#x27;</span>, <span class=\"string\">&#x27;Mary&#x27;</span>, <span class=\"string\">&#x27;Bob&#x27;</span>, <span class=\"string\">&#x27;Jack&#x27;</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(names[<span class=\"number\">0</span>:<span class=\"number\">2</span>]) <span class=\"comment\">#output will be John Mary</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(names[-<span class=\"number\">1</span>]) <span class=\"comment\">#output will be Jack</span></span><br></pre></td></tr></table></figure>\n\n<p>.append(): add element into the lists</p>\n<p>.insert(): insert an element</p>\n<p>.remove(): remove an element</p>\n<p>.clear(): empty a list</p>\n<p>len(): give the numbers of elements</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">for items in numbers:</span><br><span class=\"line\">print(items)</span><br></pre></td></tr></table></figure>\n\n<p>Each items can automatically hold one elements</p>\n<h3 id=\"Range\"><a href=\"#Range\" class=\"headerlink\" title=\"Range\"></a>Range</h3><p>range(a, b , c): give a sequence of numbers. a for beginning number, b for ending number and c for step. a, c can be default to be 0 and 1</p>\n<h3 id=\"Tuples\"><a href=\"#Tuples\" class=\"headerlink\" title=\"Tuples\"></a>Tuples</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">numbers =(1, 2, 3, 4)</span><br></pre></td></tr></table></figure>\n\n<p>it is immutable, we can not change elements</p>\n<h1 id=\"Tricks\"><a href=\"#Tricks\" class=\"headerlink\" title=\"Tricks\"></a>Tricks</h1><h2 id=\"and-和-or-的短路效应：\"><a href=\"#and-和-or-的短路效应：\" class=\"headerlink\" title=\"and 和 or 的短路效应：\"></a>and 和 or 的短路效应：</h2><p>当or表达式里的所有值为真，会选择第一个值</p>\n<p>当and表达式里所有值为真，会选择第二个值</p>\n<h2 id=\"intern-机制\"><a href=\"#intern-机制\" class=\"headerlink\" title=\"intern 机制\"></a>intern 机制</h2><p>intern（字符串驻留）的机制在Python解释器中被使用，</p>\n<p>当有空格，或者字符串长度超过20个字符，则不启动intern机制</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">s1=<span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># True</span></span><br><span class=\"line\"></span><br><span class=\"line\">s1=<span class=\"string\">&quot;hell o&quot;</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hell o&quot;</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># False</span></span><br><span class=\"line\"></span><br><span class=\"line\">s1=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">4</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">4</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># False</span></span><br><span class=\"line\"></span><br><span class=\"line\">s1=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">5</span></span><br><span class=\"line\">s2=<span class=\"string\">&quot;hello&quot;</span>*<span class=\"number\">5</span></span><br><span class=\"line\">s1 <span class=\"keyword\">is</span> s2 <span class=\"comment\"># True</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"argument-和-parameter-的区别\"><a href=\"#argument-和-parameter-的区别\" class=\"headerlink\" title=\"argument 和 parameter 的区别\"></a>argument 和 parameter 的区别</h2><p>parameter：形参（formal parameter），体现在函数内部，作用域是这个函数体。<br>argument ：实参（actual parameter），调用函数实际传递的参数。</p>\n<h2 id=\"return不一定都是函数的终点\"><a href=\"#return不一定都是函数的终点\" class=\"headerlink\" title=\"return不一定都是函数的终点\"></a>return不一定都是函数的终点</h2><p>在try…finally…语句中，try中的 return 会被直接忽视（这里的 return 不是函数的终点），因为要保证 finally 能够执行。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">func</span>():</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"string\">&#x27;try&#x27;</span></span><br><span class=\"line\">\t<span class=\"keyword\">finally</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"string\">&#x27;finally&#x27;</span></span><br><span class=\"line\">func() <span class=\"comment\">#&#x27;finally&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">func1</span>():</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"string\">&#x27;try&#x27;</span></span><br><span class=\"line\">\t<span class=\"keyword\">finally</span>:</span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&#x27;finally&#x27;</span>)</span><br><span class=\"line\">func1() </span><br><span class=\"line\"><span class=\"comment\">#finally</span></span><br><span class=\"line\"><span class=\"comment\">#&#x27;try&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>如果 finally 里有显式的 return，那么这个 return 会直接覆盖 try 里的 return，而如果 finally 里没有 显式的 return，那么 try 里的 return 仍然有效。</p>\n"},{"title":"Pandas","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-08-22T13:37:00.000Z","password":null,"summary":null,"_content":"\nThe objective is to calculate power spectrum for each frequencies and output data to excel files.\n\nFirst load packages:\n\n```python\nimport os\nimport sys\nsys.path.append('Code/code/')\nfrom load_data import load_MEG_dataset\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.autograd import Variable\nfrom torch.cuda import amp\nimport torch.nn.functional as F\nimport math\nfrom scipy.integrate import simps\nfrom mne.time_frequency import psd_array_welch\nfrom band_power import (\n    bandpower_multi_bands,\n    standard_scaling_sklearn,\n)\nimport sklearn\nimport pandas as pd\n\n```\nThen calculate power spectrum for each subject and frequency:\n```python\n# for sub in [sub for sub in range (1,29) if sub not in [6, 12, 14 ,23]]:\nfor sub in range(1,2):\n    exec('abs_{} = []'.format(sub))\n    exec('rel_{} = []'.format(sub))\n    Split = 0.90\n    X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(sub,sub+1)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)#, pca_n_components =30)\n    X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(sub,sub+1)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)#, pca_n_components =30)\n\n    X_train, X_test = (X_train-X_train.mean())/X_train.std(), (X_test-X_test.mean())/X_test.std()\n\n    X_train = X_train[:, None, ...]\n    X_test = X_test[:, None, ...]\n\n    y_train = (y_train / 2) - 1\n    y_test = (y_test / 2) - 1\n\n    X = np.swapaxes(X_train, 2, -1).squeeze()\n    data = X[X.shape[0]-1, 70, :]\n    psd_mne, freqs_mne = psd_array_welch(data, 100, 1., 70., n_per_seg=None,\n                            n_overlap=0, n_jobs=1)\n    for low, high in [(0.5, 4), (4, 8), (8, 10), (10, 12), (12, 30),\n                    (30, 70)]:\n        print(\"processing bands (low, high) : ({},{})\".format(low, high))\n        # Find intersecting values in frequency vector\n        idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n        # Frequency resolution\n        freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n\n        # Compute the absolute power by approximating the area under the curve\n        power = simps(psd_mne[idx_delta], dx=freq_res)\n        exec('abs_{}.append(power)'.format(sub))\n        # print('Absolute power: {:.4f} uV^2'.format(power))\n        \n        total_power = simps(psd_mne, dx=freq_res)\n        rel_power = power / total_power\n        exec('rel_{}.append(rel_power)'.format(sub))\n        # print('Relative power: {:.4f}'.format(rel_power))\n```\nLast, output calculated power spectrum as xmlx files:\n```python\ndf1 = pd.DataFrame({'sub1':abs_1,\n                        'sub2':abs_2,\n                        'sub3':abs_3,\n                       'sub4':abs_4,\n                       'sub5':abs_5,\n                       'sub7':abs_7,\n                       'sub8':abs_8,\n                       'sub9':abs_9,\n                       'sub10':abs_10,\n                       'sub11':abs_11,\n                       'sub13':abs_13,\n                       'sub15':abs_15,\n                       'sub16':abs_16,\n                       'sub17':abs_17,\n                       'sub18':abs_18,\n                       'sub19':abs_19,\n                       'sub20':abs_20,\n                       'sub21':abs_21,\n                      'sub22':abs_22,\n                      'sub24':abs_24,\n                      'sub25':abs_25,\n                      'sub26':abs_26,\n                      'sub27':abs_27,\n                      'sub28':abs_28},)\ndf1.to_excel('models/abs.xlsx', sheet_name='sheet1', index=False)\n```\n\n```python\ndf2 = pd.DataFrame({'sub1':rel_1,\n                        'sub2':rel_2,\n                        'sub3':rel_3,\n                       'sub4':rel_4,\n                       'sub5':rel_5,\n                       'sub7':rel_7,\n                       'sub8':rel_8,\n                       'sub9':rel_9,\n                       'sub10':rel_10,\n                       'sub11':rel_11,\n                       'sub13':rel_13,\n                       'sub15':rel_15,\n                       'sub16':rel_16,\n                       'sub17':rel_17,\n                       'sub18':rel_18,\n                       'sub19':rel_19,\n                       'sub20':rel_20,\n                       'sub21':rel_21,\n                      'sub22':rel_22,\n                      'sub24':rel_24,\n                      'sub25':rel_25,\n                      'sub26':rel_26,\n                      'sub27':rel_27,\n                      'sub28':rel_28},)\ndf2.to_excel('models/rel.xlsx', sheet_name='sheet1', index=False)\n```\n\nHint: potential promotions are:\n\n1. to use wavelet instead of Fourier transformation;\n2. to use loop somehow pass data to DataFrame instead of listing them.\n","source":"_posts/Pandas.md","raw":"---\ntitle: Pandas\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-08-22 14:37\npassword:\nsummary:\ntags:\n- Pandas\ncategories:\n- programming\n---\n\nThe objective is to calculate power spectrum for each frequencies and output data to excel files.\n\nFirst load packages:\n\n```python\nimport os\nimport sys\nsys.path.append('Code/code/')\nfrom load_data import load_MEG_dataset\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.autograd import Variable\nfrom torch.cuda import amp\nimport torch.nn.functional as F\nimport math\nfrom scipy.integrate import simps\nfrom mne.time_frequency import psd_array_welch\nfrom band_power import (\n    bandpower_multi_bands,\n    standard_scaling_sklearn,\n)\nimport sklearn\nimport pandas as pd\n\n```\nThen calculate power spectrum for each subject and frequency:\n```python\n# for sub in [sub for sub in range (1,29) if sub not in [6, 12, 14 ,23]]:\nfor sub in range(1,2):\n    exec('abs_{} = []'.format(sub))\n    exec('rel_{} = []'.format(sub))\n    Split = 0.90\n    X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(sub,sub+1)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)#, pca_n_components =30)\n    X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(sub,sub+1)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)#, pca_n_components =30)\n\n    X_train, X_test = (X_train-X_train.mean())/X_train.std(), (X_test-X_test.mean())/X_test.std()\n\n    X_train = X_train[:, None, ...]\n    X_test = X_test[:, None, ...]\n\n    y_train = (y_train / 2) - 1\n    y_test = (y_test / 2) - 1\n\n    X = np.swapaxes(X_train, 2, -1).squeeze()\n    data = X[X.shape[0]-1, 70, :]\n    psd_mne, freqs_mne = psd_array_welch(data, 100, 1., 70., n_per_seg=None,\n                            n_overlap=0, n_jobs=1)\n    for low, high in [(0.5, 4), (4, 8), (8, 10), (10, 12), (12, 30),\n                    (30, 70)]:\n        print(\"processing bands (low, high) : ({},{})\".format(low, high))\n        # Find intersecting values in frequency vector\n        idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n        # Frequency resolution\n        freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n\n        # Compute the absolute power by approximating the area under the curve\n        power = simps(psd_mne[idx_delta], dx=freq_res)\n        exec('abs_{}.append(power)'.format(sub))\n        # print('Absolute power: {:.4f} uV^2'.format(power))\n        \n        total_power = simps(psd_mne, dx=freq_res)\n        rel_power = power / total_power\n        exec('rel_{}.append(rel_power)'.format(sub))\n        # print('Relative power: {:.4f}'.format(rel_power))\n```\nLast, output calculated power spectrum as xmlx files:\n```python\ndf1 = pd.DataFrame({'sub1':abs_1,\n                        'sub2':abs_2,\n                        'sub3':abs_3,\n                       'sub4':abs_4,\n                       'sub5':abs_5,\n                       'sub7':abs_7,\n                       'sub8':abs_8,\n                       'sub9':abs_9,\n                       'sub10':abs_10,\n                       'sub11':abs_11,\n                       'sub13':abs_13,\n                       'sub15':abs_15,\n                       'sub16':abs_16,\n                       'sub17':abs_17,\n                       'sub18':abs_18,\n                       'sub19':abs_19,\n                       'sub20':abs_20,\n                       'sub21':abs_21,\n                      'sub22':abs_22,\n                      'sub24':abs_24,\n                      'sub25':abs_25,\n                      'sub26':abs_26,\n                      'sub27':abs_27,\n                      'sub28':abs_28},)\ndf1.to_excel('models/abs.xlsx', sheet_name='sheet1', index=False)\n```\n\n```python\ndf2 = pd.DataFrame({'sub1':rel_1,\n                        'sub2':rel_2,\n                        'sub3':rel_3,\n                       'sub4':rel_4,\n                       'sub5':rel_5,\n                       'sub7':rel_7,\n                       'sub8':rel_8,\n                       'sub9':rel_9,\n                       'sub10':rel_10,\n                       'sub11':rel_11,\n                       'sub13':rel_13,\n                       'sub15':rel_15,\n                       'sub16':rel_16,\n                       'sub17':rel_17,\n                       'sub18':rel_18,\n                       'sub19':rel_19,\n                       'sub20':rel_20,\n                       'sub21':rel_21,\n                      'sub22':rel_22,\n                      'sub24':rel_24,\n                      'sub25':rel_25,\n                      'sub26':rel_26,\n                      'sub27':rel_27,\n                      'sub28':rel_28},)\ndf2.to_excel('models/rel.xlsx', sheet_name='sheet1', index=False)\n```\n\nHint: potential promotions are:\n\n1. to use wavelet instead of Fourier transformation;\n2. to use loop somehow pass data to DataFrame instead of listing them.\n","slug":"Pandas","published":1,"updated":"2022-08-25T13:18:04.757Z","comments":1,"layout":"post","photos":[],"_id":"cuidE4qV4KVFSutCCD7bxQyAK","content":"<p>The objective is to calculate power spectrum for each frequencies and output data to excel files.</p>\n<p>First load packages:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">sys.path.append(<span class=\"string\">&#x27;Code/code/&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">from</span> load_data <span class=\"keyword\">import</span> load_MEG_dataset</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.cuda <span class=\"keyword\">import</span> amp</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.integrate <span class=\"keyword\">import</span> simps</span><br><span class=\"line\"><span class=\"keyword\">from</span> mne.time_frequency <span class=\"keyword\">import</span> psd_array_welch</span><br><span class=\"line\"><span class=\"keyword\">from</span> band_power <span class=\"keyword\">import</span> (</span><br><span class=\"line\">    bandpower_multi_bands,</span><br><span class=\"line\">    standard_scaling_sklearn,</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>Then calculate power spectrum for each subject and frequency:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># for sub in [sub for sub in range (1,29) if sub not in [6, 12, 14 ,23]]:</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> sub <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>):</span><br><span class=\"line\">    <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;abs_&#123;&#125; = []&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">    <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;rel_&#123;&#125; = []&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">    Split = <span class=\"number\">0.90</span></span><br><span class=\"line\">    X_train, y_train = load_MEG_dataset([<span class=\"built_in\">str</span>(i).zfill(<span class=\"number\">3</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(sub,sub+<span class=\"number\">1</span>)], mode = <span class=\"string\">&#x27;concatenate&#x27;</span>, output_format=<span class=\"string\">&#x27;numpy&#x27;</span>,shuffle = <span class=\"literal\">False</span>, training=<span class=\"literal\">True</span>, train_test_split=Split, batch_size=<span class=\"number\">500</span>)<span class=\"comment\">#, pca_n_components =30)</span></span><br><span class=\"line\">    X_test, y_test = load_MEG_dataset([<span class=\"built_in\">str</span>(i).zfill(<span class=\"number\">3</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(sub,sub+<span class=\"number\">1</span>)], mode = <span class=\"string\">&#x27;concatenate&#x27;</span>, output_format=<span class=\"string\">&#x27;numpy&#x27;</span>,shuffle = <span class=\"literal\">False</span>, training=<span class=\"literal\">False</span>, train_test_split=Split, batch_size=<span class=\"number\">500</span>)<span class=\"comment\">#, pca_n_components =30)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    X_train, X_test = (X_train-X_train.mean())/X_train.std(), (X_test-X_test.mean())/X_test.std()</span><br><span class=\"line\"></span><br><span class=\"line\">    X_train = X_train[:, <span class=\"literal\">None</span>, ...]</span><br><span class=\"line\">    X_test = X_test[:, <span class=\"literal\">None</span>, ...]</span><br><span class=\"line\"></span><br><span class=\"line\">    y_train = (y_train / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br><span class=\"line\">    y_test = (y_test / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    X = np.swapaxes(X_train, <span class=\"number\">2</span>, -<span class=\"number\">1</span>).squeeze()</span><br><span class=\"line\">    data = X[X.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>, <span class=\"number\">70</span>, :]</span><br><span class=\"line\">    psd_mne, freqs_mne = psd_array_welch(data, <span class=\"number\">100</span>, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                            n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> low, high <span class=\"keyword\">in</span> [(<span class=\"number\">0.5</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">12</span>), (<span class=\"number\">12</span>, <span class=\"number\">30</span>),</span><br><span class=\"line\">                    (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;processing bands (low, high) : (&#123;&#125;,&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(low, high))</span><br><span class=\"line\">        <span class=\"comment\"># Find intersecting values in frequency vector</span></span><br><span class=\"line\">        idx_delta = np.logical_and(freqs_mne &gt;= low, freqs_mne &lt;= high)</span><br><span class=\"line\">        <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">        freq_res = freqs_mne[<span class=\"number\">1</span>] - freqs_mne[<span class=\"number\">0</span>]  <span class=\"comment\"># = 1 / 4 = 0.25</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Compute the absolute power by approximating the area under the curve</span></span><br><span class=\"line\">        power = simps(psd_mne[idx_delta], dx=freq_res)</span><br><span class=\"line\">        <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;abs_&#123;&#125;.append(power)&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;Absolute power: &#123;:.4f&#125; uV^2&#x27;.format(power))</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        total_power = simps(psd_mne, dx=freq_res)</span><br><span class=\"line\">        rel_power = power / total_power</span><br><span class=\"line\">        <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;rel_&#123;&#125;.append(rel_power)&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;Relative power: &#123;:.4f&#125;&#x27;.format(rel_power))</span></span><br></pre></td></tr></table></figure>\n<p>Last, output calculated power spectrum as xmlx files:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(&#123;<span class=\"string\">&#x27;sub1&#x27;</span>:abs_1,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub2&#x27;</span>:abs_2,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub3&#x27;</span>:abs_3,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub4&#x27;</span>:abs_4,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub5&#x27;</span>:abs_5,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub7&#x27;</span>:abs_7,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub8&#x27;</span>:abs_8,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub9&#x27;</span>:abs_9,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub10&#x27;</span>:abs_10,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub11&#x27;</span>:abs_11,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub13&#x27;</span>:abs_13,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub15&#x27;</span>:abs_15,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub16&#x27;</span>:abs_16,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub17&#x27;</span>:abs_17,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub18&#x27;</span>:abs_18,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub19&#x27;</span>:abs_19,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub20&#x27;</span>:abs_20,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub21&#x27;</span>:abs_21,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub22&#x27;</span>:abs_22,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub24&#x27;</span>:abs_24,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub25&#x27;</span>:abs_25,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub26&#x27;</span>:abs_26,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub27&#x27;</span>:abs_27,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub28&#x27;</span>:abs_28&#125;,)</span><br><span class=\"line\">df1.to_excel(<span class=\"string\">&#x27;models/abs.xlsx&#x27;</span>, sheet_name=<span class=\"string\">&#x27;sheet1&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">df2 = pd.DataFrame(&#123;<span class=\"string\">&#x27;sub1&#x27;</span>:rel_1,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub2&#x27;</span>:rel_2,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub3&#x27;</span>:rel_3,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub4&#x27;</span>:rel_4,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub5&#x27;</span>:rel_5,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub7&#x27;</span>:rel_7,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub8&#x27;</span>:rel_8,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub9&#x27;</span>:rel_9,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub10&#x27;</span>:rel_10,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub11&#x27;</span>:rel_11,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub13&#x27;</span>:rel_13,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub15&#x27;</span>:rel_15,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub16&#x27;</span>:rel_16,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub17&#x27;</span>:rel_17,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub18&#x27;</span>:rel_18,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub19&#x27;</span>:rel_19,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub20&#x27;</span>:rel_20,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub21&#x27;</span>:rel_21,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub22&#x27;</span>:rel_22,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub24&#x27;</span>:rel_24,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub25&#x27;</span>:rel_25,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub26&#x27;</span>:rel_26,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub27&#x27;</span>:rel_27,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub28&#x27;</span>:rel_28&#125;,)</span><br><span class=\"line\">df2.to_excel(<span class=\"string\">&#x27;models/rel.xlsx&#x27;</span>, sheet_name=<span class=\"string\">&#x27;sheet1&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p>Hint: potential promotions are:</p>\n<ol>\n<li>to use wavelet instead of Fourier transformation;</li>\n<li>to use loop somehow pass data to DataFrame instead of listing them.</li>\n</ol>\n","excerpt":"","more":"<p>The objective is to calculate power spectrum for each frequencies and output data to excel files.</p>\n<p>First load packages:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">sys.path.append(<span class=\"string\">&#x27;Code/code/&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">from</span> load_data <span class=\"keyword\">import</span> load_MEG_dataset</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.cuda <span class=\"keyword\">import</span> amp</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.integrate <span class=\"keyword\">import</span> simps</span><br><span class=\"line\"><span class=\"keyword\">from</span> mne.time_frequency <span class=\"keyword\">import</span> psd_array_welch</span><br><span class=\"line\"><span class=\"keyword\">from</span> band_power <span class=\"keyword\">import</span> (</span><br><span class=\"line\">    bandpower_multi_bands,</span><br><span class=\"line\">    standard_scaling_sklearn,</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>Then calculate power spectrum for each subject and frequency:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># for sub in [sub for sub in range (1,29) if sub not in [6, 12, 14 ,23]]:</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> sub <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>):</span><br><span class=\"line\">    <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;abs_&#123;&#125; = []&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">    <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;rel_&#123;&#125; = []&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">    Split = <span class=\"number\">0.90</span></span><br><span class=\"line\">    X_train, y_train = load_MEG_dataset([<span class=\"built_in\">str</span>(i).zfill(<span class=\"number\">3</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(sub,sub+<span class=\"number\">1</span>)], mode = <span class=\"string\">&#x27;concatenate&#x27;</span>, output_format=<span class=\"string\">&#x27;numpy&#x27;</span>,shuffle = <span class=\"literal\">False</span>, training=<span class=\"literal\">True</span>, train_test_split=Split, batch_size=<span class=\"number\">500</span>)<span class=\"comment\">#, pca_n_components =30)</span></span><br><span class=\"line\">    X_test, y_test = load_MEG_dataset([<span class=\"built_in\">str</span>(i).zfill(<span class=\"number\">3</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(sub,sub+<span class=\"number\">1</span>)], mode = <span class=\"string\">&#x27;concatenate&#x27;</span>, output_format=<span class=\"string\">&#x27;numpy&#x27;</span>,shuffle = <span class=\"literal\">False</span>, training=<span class=\"literal\">False</span>, train_test_split=Split, batch_size=<span class=\"number\">500</span>)<span class=\"comment\">#, pca_n_components =30)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    X_train, X_test = (X_train-X_train.mean())/X_train.std(), (X_test-X_test.mean())/X_test.std()</span><br><span class=\"line\"></span><br><span class=\"line\">    X_train = X_train[:, <span class=\"literal\">None</span>, ...]</span><br><span class=\"line\">    X_test = X_test[:, <span class=\"literal\">None</span>, ...]</span><br><span class=\"line\"></span><br><span class=\"line\">    y_train = (y_train / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br><span class=\"line\">    y_test = (y_test / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    X = np.swapaxes(X_train, <span class=\"number\">2</span>, -<span class=\"number\">1</span>).squeeze()</span><br><span class=\"line\">    data = X[X.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>, <span class=\"number\">70</span>, :]</span><br><span class=\"line\">    psd_mne, freqs_mne = psd_array_welch(data, <span class=\"number\">100</span>, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                            n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> low, high <span class=\"keyword\">in</span> [(<span class=\"number\">0.5</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">12</span>), (<span class=\"number\">12</span>, <span class=\"number\">30</span>),</span><br><span class=\"line\">                    (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;processing bands (low, high) : (&#123;&#125;,&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(low, high))</span><br><span class=\"line\">        <span class=\"comment\"># Find intersecting values in frequency vector</span></span><br><span class=\"line\">        idx_delta = np.logical_and(freqs_mne &gt;= low, freqs_mne &lt;= high)</span><br><span class=\"line\">        <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">        freq_res = freqs_mne[<span class=\"number\">1</span>] - freqs_mne[<span class=\"number\">0</span>]  <span class=\"comment\"># = 1 / 4 = 0.25</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Compute the absolute power by approximating the area under the curve</span></span><br><span class=\"line\">        power = simps(psd_mne[idx_delta], dx=freq_res)</span><br><span class=\"line\">        <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;abs_&#123;&#125;.append(power)&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;Absolute power: &#123;:.4f&#125; uV^2&#x27;.format(power))</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        total_power = simps(psd_mne, dx=freq_res)</span><br><span class=\"line\">        rel_power = power / total_power</span><br><span class=\"line\">        <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;rel_&#123;&#125;.append(rel_power)&#x27;</span>.<span class=\"built_in\">format</span>(sub))</span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;Relative power: &#123;:.4f&#125;&#x27;.format(rel_power))</span></span><br></pre></td></tr></table></figure>\n<p>Last, output calculated power spectrum as xmlx files:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(&#123;<span class=\"string\">&#x27;sub1&#x27;</span>:abs_1,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub2&#x27;</span>:abs_2,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub3&#x27;</span>:abs_3,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub4&#x27;</span>:abs_4,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub5&#x27;</span>:abs_5,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub7&#x27;</span>:abs_7,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub8&#x27;</span>:abs_8,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub9&#x27;</span>:abs_9,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub10&#x27;</span>:abs_10,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub11&#x27;</span>:abs_11,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub13&#x27;</span>:abs_13,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub15&#x27;</span>:abs_15,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub16&#x27;</span>:abs_16,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub17&#x27;</span>:abs_17,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub18&#x27;</span>:abs_18,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub19&#x27;</span>:abs_19,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub20&#x27;</span>:abs_20,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub21&#x27;</span>:abs_21,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub22&#x27;</span>:abs_22,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub24&#x27;</span>:abs_24,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub25&#x27;</span>:abs_25,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub26&#x27;</span>:abs_26,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub27&#x27;</span>:abs_27,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub28&#x27;</span>:abs_28&#125;,)</span><br><span class=\"line\">df1.to_excel(<span class=\"string\">&#x27;models/abs.xlsx&#x27;</span>, sheet_name=<span class=\"string\">&#x27;sheet1&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">df2 = pd.DataFrame(&#123;<span class=\"string\">&#x27;sub1&#x27;</span>:rel_1,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub2&#x27;</span>:rel_2,</span><br><span class=\"line\">                        <span class=\"string\">&#x27;sub3&#x27;</span>:rel_3,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub4&#x27;</span>:rel_4,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub5&#x27;</span>:rel_5,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub7&#x27;</span>:rel_7,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub8&#x27;</span>:rel_8,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub9&#x27;</span>:rel_9,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub10&#x27;</span>:rel_10,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub11&#x27;</span>:rel_11,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub13&#x27;</span>:rel_13,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub15&#x27;</span>:rel_15,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub16&#x27;</span>:rel_16,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub17&#x27;</span>:rel_17,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub18&#x27;</span>:rel_18,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub19&#x27;</span>:rel_19,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub20&#x27;</span>:rel_20,</span><br><span class=\"line\">                       <span class=\"string\">&#x27;sub21&#x27;</span>:rel_21,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub22&#x27;</span>:rel_22,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub24&#x27;</span>:rel_24,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub25&#x27;</span>:rel_25,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub26&#x27;</span>:rel_26,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub27&#x27;</span>:rel_27,</span><br><span class=\"line\">                      <span class=\"string\">&#x27;sub28&#x27;</span>:rel_28&#125;,)</span><br><span class=\"line\">df2.to_excel(<span class=\"string\">&#x27;models/rel.xlsx&#x27;</span>, sheet_name=<span class=\"string\">&#x27;sheet1&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p>Hint: potential promotions are:</p>\n<ol>\n<li>to use wavelet instead of Fourier transformation;</li>\n<li>to use loop somehow pass data to DataFrame instead of listing them.</li>\n</ol>\n"},{"title":"Mylove","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2023-10-17T04:42:00.000Z","password":"a66e7fb30f0d62dca0b678e8e5d16c4534802344fb13913dee6ab080ac53bebf","summary":null,"_content":"\n# 梦境\n\n**内容：**苏州旅游 听周密的livehouse 他又忘词了但是全场很嗨中场休息大家去自助奶茶区打饮料(茉沏) 遇到一个小姐姐是本地人 对我起级好 给我打奶茶加料超丰富 还加了很多奶盖 就这样认识了后面逛街又遇到 她邀请我一起去吃饭到了饭桌上 把我的朋友安置好 她带我出去买当地小吃 还吃了一种活的虫子 有点可怕 我不太敢 还沾到了手上 后来我们回到餐桌上 发现她爸妈来找 让她相亲她拿我当挡箭牌 说我俩已经在一起了(?)她爸妈也接受 但是那位相亲对象不同意了 开始砸场子 我俩就往外面跑冲上了一辆公交车 她还在公交车上被非礼 我想要帮忙却发现自己动不了只好大声呼救 大家好像都听不见也看不见后来有一位男士制止了 但是我们下了车之后就一直被他尾随 我偷偷用手机拨了紧急呼救 然后拉着她逃入小区的一栋单元楼一楼好像是监狱一样的地方 窗户密不透风 还被磨砂纸贴上 我隐约感觉这是那位尾随者的老巢(怎么这么巧) 二楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避 进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且会暴露我们的行踪，于是借由卫生间逃离 奇怪的是卫生间的窗外就有一架木质电梯木板有些老旧 发出咯吱咯吱的声音 我们上去之后发现只有唯一一个关门的按钮电梯中途停在了6813楼每层都有一个面目狰狞的男人盯着我们并想要进来 我们疯狂按关门的按钮最终电梯停在了一楼这时 她的父母赶来与她发生了争执 从他们的话语中我了解到所有的这一切都是她妈妈安排的(?)后面记不得了 最终警方追踪我的定位 将她妈妈抓获\n\n根据弗洛伊德的梦境分析理论，你的梦境可能包含了一些象征和隐含的意义，可能反映了你内心的欲望、冲突和焦虑。让我们逐步分析这个梦境的各个元素：\n\n1. **苏州旅游和Livehouse：** 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐和享乐的渴望，而歌手忘词可能表示你对一些不完美或困难情况的担忧。\n2. **自助奶茶区和小姐姐：** 自助奶茶区可能象征着你对选择和控制的欲望。小姐姐可能代表你在新环境中遇到的友好支持，可能反映了你的社交需求。\n3. **吃活虫子：** 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。\n4. **相亲和挡箭牌：** 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌可能表示你可能被卷入一些关系中，而你不太愿意。\n5. **被尾随和危险追踪：** 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。\n6. **电梯和6813楼：** 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。\n7. **她的父母和警方：** 这个部分可能反映了你对权威和保护的需求，也可能涉及到你与家庭和社会的关系。\n\n最终，根据弗洛伊德的理论，梦境是一种表达潜意识冲突和欲望的方式。这个梦境可能反映了你在情感和社交方面的一些内心挣扎和焦虑。要更深入地理解这个梦境，你可以考虑与心理专业人士交谈，他们可以帮助你探索与梦境相关的情感和体验，以及它们在你生活中的潜在意义。\n\n1. 苏州旅游和Livehouse： 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐的渴望和音乐的兴趣，而歌手忘词可能表示你对一些不完美或困难情况的担忧。\n2. 自助奶茶区和小姐姐： 自助奶茶区可能象征着你对选择和控制的欲望。陌生小姐姐在新环境中提供了友好支持，可能反映了你的社交需求，在陌生环境中寻找帮助和指导的渴望。\n3. 吃活虫子： 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。\n4. 相亲和挡箭牌： 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌表示你可能被卷入一些关系中，而你也许不太愿意。\n5. 被尾随和危险追踪： 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。\n6. 电梯和6813楼： 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。\n7. 她的父母和警方： 这个部分可能反映了你对权威和保护的需求，或者你感到有人会为你解决问题。也可能涉及到你与家庭和社会的关系。\n\n# 给我的宝宝画心形图：\n\n## 绘制心形图的轨迹\n\n用Python的标准库中包含的Turtle绘图模块绘制：\n\n```python\nimport turtle as t\n\n# 设置画布属性\nt.bgcolor(\"green\")\nt.title(\"爱心\")\nsentence1 = [\"雷\",\"雷\",'爱','小','满',\"\",\"\"]\nsentence2 = ['小','满','爱',\"雷\",\"雷\",\"\",\"\"]\n\nrd = 0\n\n# 设置画笔属性\nt.color(\"red\")\nt.pensize(2)\nt.speed(0)\nt.hideturtle()\n# 移动画笔到起始位置\nt.up()\nt.goto(0, -200)\nt.down()\n\n# 记录轨迹的坐标\ntrack = []\n\n# 开始绘制爱心\nt.begin_fill()\nt.fillcolor(\"red\")\nt.left(140)\nt.forward(224)\nfor _ in range(200):\n    t.right(1)\n    t.forward(2)\n    track.append(t.pos())  # 记录当前坐标\n    if _ %30 ==10 and _ > 20:\n        t.color(\"orange\")\n        t.write(sentence1[rd], align=\"right\",font=(\"楷体\", 20, \"normal\"))\n        rd +=1\n        t.color(\"red\")\nt.left(120)\nrd =0\nfor _ in range(200):\n    t.right(1)\n    t.forward(2)\n    track.append(t.pos())  # 记录当前坐标\n    if _ %30 ==8 and _> 20:\n        t.color(\"orange\")\n        t.write(sentence2[rd], align=\"left\", font=(\"楷体\", 20, \"normal\"))\n        rd +=1\n        t.color(\"red\")  \nt.forward(224)\nt.end_fill()\n \nt.exitonclick()\n```\n\n## 用文字构成心形图案\n\n简单的文字构成图\n\n```python\nprint('\\n'.join([' '.join([('DoDo'[(x-y) % 4]if((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3<=0 else' ')for x in range(-60,60)])for y in range(30,-30,-1)]))\n```\n输出如下：\n\n![心形文字图](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202310170813904.png)\n\n## 用图片构成心形图\n\n首先要裁剪图片到相同大小：\n\n```python\nfrom PIL import Image\n\n# 指定包含图片的文件夹路径\ninput_folder = \"e:\\\\Learning\\\\pic\"  # 用实际的文件夹路径替换\noutput_folder = \"e:\\\\Learning\\\\pics\"  # 用实际的输出文件夹路径替换\n\n# 获取文件夹中所有图片文件的路径\nimage_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n\nfor image_file in image_files:\n    # 构建输入文件的完整路径\n    input_file_path = os.path.join(input_folder, image_file)\n\n    # 打开原始图像\n    original_image = Image.open(input_file_path)\n    # 获取原始图像的宽度和高度\n    width, height = original_image.size\n\n    # 确定截取的正方形尺寸\n    if width > height:\n        new_size = (height, height)\n    else:\n        new_size = (width, width)\n\n    # 截取中央部分\n    left = (width - new_size[0]) / 2\n    top = (height - new_size[1]) / 2\n    right = (width + new_size[0]) / 2\n    bottom = (height + new_size[1]) / 2\n\n    cropped_image = original_image.crop((left, top, right, bottom))\n\n    # 调整图像大小为（128，128）\n    cropped_image = cropped_image.resize((128, 128))\n\n    # 获取输出文件的完整路径\n    output_file_path = os.path.join(output_folder, image_file)\n\n    # 保存处理后的图像\n    cropped_image.save(output_file_path)\n```\n\n然后将图片排列在大的画布上\n\n```python\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport os\n\n# Define the number of rows and columns\nrow = 6\ncol = 6\n\n# Define the size of each small image\nsmall_pic_size = (128, 128)\n\n# Make sure you have a list of image file paths in file_paths\nfolder_path = os.path.join(os.getcwd(),\"pics\")  # 用实际的文件夹路径替换\n\n# 使用os.listdir()获取文件夹中的所有文件和子文件夹\nfile_paths = []\nfor root, dirs, files in os.walk(folder_path):\n    for file in files:\n        file_paths.append(os.path.join(root, file))\n\n# Initialize a list to store small images\nimages = []\nfor file_path in file_paths:\n    small_image = Image.open(file_path)\n    images.append(small_image)\n\n# Generate an empty heart-shaped image\nheart = np.zeros((128*10, 128*10, 3), dtype=np.uint8)\n\nfor epoch, pic in enumerate(images):\n    block_x = int(small_pic_size[0] * (epoch // row))\n    block_y = int(small_pic_size[1] * (epoch % col))\n    heart[block_x:block_x + small_pic_size[0], block_y:block_y + small_pic_size[1], :] = pic\n\n# Save the generated heart-shaped mosaic image\ncv2.imwrite('1234.png', cv2.cvtColor(heart, cv2.COLOR_BGR2RGB))\n```\n\n## 用列表绘制心形\n\n```python\nfrom PIL import Image\nimport os\nimport math\nmap = [\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n]\n\n# 这个是图片的所在路径\nimg_dir = r\"E:\\Learning\\pics\"\n# 获取这个文件下的所有文件，因为没有过滤其他类型文件，所以不要放非图片文件\n# 返回的是一个列表\nimgs = os.listdir(img_dir)\n# 设置图片的尺寸，所有图片尺寸要保持统一，要有组织有纪律\nimg_h = img_w = 128\n# 计算行数，即子列表的个数\nrows = len(map)\n# 计算列数，即子列表中元素的个数\ncolumns = len(map[0])\n# 第一个参数照着写\n# 第二个参数需要传入一个元组，元组的第一个参数是画布的宽，第二个是高\n# 第三个参数传入的是画布的颜色\n# 使用Image.new()方法创建一个画布\nfigure = Image.new(\"RGB\", (img_w*columns, img_h*rows),\"white\")\n# 表示图片的下标\ncount = 0\n# 遍历行\nfor i in range(len(map)):\n    # 遍历每行中的所有元素\n    for j in range(len(map[i])):\n        # 如果元素是1，就不管它\n        if map[i][j] == 1:\n            continue\n        # 如果元素是非1，即0就放图片上去\n        else:\n            # 做个异常处理，防止有些图片打开失败，导致程序中断\n            try:\n                # 使用Image.open(\"图片路径\")方法获取图片对象\n                image = Image.open(os.path.join(img_dir, imgs[count]))\n            except:\n                continue\n            # resize((新的宽，新的高))用来改变图片的尺寸,接收一个元组\n            image = image.resize((img_w, img_h))\n            # 将修改尺寸后的图片(image)粘贴(paste)到画布(figure)上\n            # 第一个参数 是图片对象\n            # 第二个参数是 图片在画布上的位置，相当于单元格的位置\n            figure.paste(image, (img_w*j, img_h*i))\n            # 使用完一张图片就要记录下来，并开始使用下一张图片\n            count += 1\n# 将画好的画布显示出来\nfigure.show()\n# 图片保存的路径\nfigure.save('Man.png')\n```\n\n## 待完成：\n\n- [x] 将大画布改为心形，\n- [ ] 并且使图片边缘裁剪平滑\n\n# 找房子（香港）\n\n香港粤海酒店 Oasis Avenue, 18 Prat Ave, Tsim Sha Tsui, Hong Kong\n\n","source":"_posts/Mylove.md","raw":"---\ntitle: Mylove\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2023-10-17 05:42\npassword: a66e7fb30f0d62dca0b678e8e5d16c4534802344fb13913dee6ab080ac53bebf\nsummary:\ntags:\n- Mylove\ncategories:\n- life\n---\n\n# 梦境\n\n**内容：**苏州旅游 听周密的livehouse 他又忘词了但是全场很嗨中场休息大家去自助奶茶区打饮料(茉沏) 遇到一个小姐姐是本地人 对我起级好 给我打奶茶加料超丰富 还加了很多奶盖 就这样认识了后面逛街又遇到 她邀请我一起去吃饭到了饭桌上 把我的朋友安置好 她带我出去买当地小吃 还吃了一种活的虫子 有点可怕 我不太敢 还沾到了手上 后来我们回到餐桌上 发现她爸妈来找 让她相亲她拿我当挡箭牌 说我俩已经在一起了(?)她爸妈也接受 但是那位相亲对象不同意了 开始砸场子 我俩就往外面跑冲上了一辆公交车 她还在公交车上被非礼 我想要帮忙却发现自己动不了只好大声呼救 大家好像都听不见也看不见后来有一位男士制止了 但是我们下了车之后就一直被他尾随 我偷偷用手机拨了紧急呼救 然后拉着她逃入小区的一栋单元楼一楼好像是监狱一样的地方 窗户密不透风 还被磨砂纸贴上 我隐约感觉这是那位尾随者的老巢(怎么这么巧) 二楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避 进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且会暴露我们的行踪，于是借由卫生间逃离 奇怪的是卫生间的窗外就有一架木质电梯木板有些老旧 发出咯吱咯吱的声音 我们上去之后发现只有唯一一个关门的按钮电梯中途停在了6813楼每层都有一个面目狰狞的男人盯着我们并想要进来 我们疯狂按关门的按钮最终电梯停在了一楼这时 她的父母赶来与她发生了争执 从他们的话语中我了解到所有的这一切都是她妈妈安排的(?)后面记不得了 最终警方追踪我的定位 将她妈妈抓获\n\n根据弗洛伊德的梦境分析理论，你的梦境可能包含了一些象征和隐含的意义，可能反映了你内心的欲望、冲突和焦虑。让我们逐步分析这个梦境的各个元素：\n\n1. **苏州旅游和Livehouse：** 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐和享乐的渴望，而歌手忘词可能表示你对一些不完美或困难情况的担忧。\n2. **自助奶茶区和小姐姐：** 自助奶茶区可能象征着你对选择和控制的欲望。小姐姐可能代表你在新环境中遇到的友好支持，可能反映了你的社交需求。\n3. **吃活虫子：** 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。\n4. **相亲和挡箭牌：** 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌可能表示你可能被卷入一些关系中，而你不太愿意。\n5. **被尾随和危险追踪：** 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。\n6. **电梯和6813楼：** 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。\n7. **她的父母和警方：** 这个部分可能反映了你对权威和保护的需求，也可能涉及到你与家庭和社会的关系。\n\n最终，根据弗洛伊德的理论，梦境是一种表达潜意识冲突和欲望的方式。这个梦境可能反映了你在情感和社交方面的一些内心挣扎和焦虑。要更深入地理解这个梦境，你可以考虑与心理专业人士交谈，他们可以帮助你探索与梦境相关的情感和体验，以及它们在你生活中的潜在意义。\n\n1. 苏州旅游和Livehouse： 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐的渴望和音乐的兴趣，而歌手忘词可能表示你对一些不完美或困难情况的担忧。\n2. 自助奶茶区和小姐姐： 自助奶茶区可能象征着你对选择和控制的欲望。陌生小姐姐在新环境中提供了友好支持，可能反映了你的社交需求，在陌生环境中寻找帮助和指导的渴望。\n3. 吃活虫子： 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。\n4. 相亲和挡箭牌： 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌表示你可能被卷入一些关系中，而你也许不太愿意。\n5. 被尾随和危险追踪： 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。\n6. 电梯和6813楼： 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。\n7. 她的父母和警方： 这个部分可能反映了你对权威和保护的需求，或者你感到有人会为你解决问题。也可能涉及到你与家庭和社会的关系。\n\n# 给我的宝宝画心形图：\n\n## 绘制心形图的轨迹\n\n用Python的标准库中包含的Turtle绘图模块绘制：\n\n```python\nimport turtle as t\n\n# 设置画布属性\nt.bgcolor(\"green\")\nt.title(\"爱心\")\nsentence1 = [\"雷\",\"雷\",'爱','小','满',\"\",\"\"]\nsentence2 = ['小','满','爱',\"雷\",\"雷\",\"\",\"\"]\n\nrd = 0\n\n# 设置画笔属性\nt.color(\"red\")\nt.pensize(2)\nt.speed(0)\nt.hideturtle()\n# 移动画笔到起始位置\nt.up()\nt.goto(0, -200)\nt.down()\n\n# 记录轨迹的坐标\ntrack = []\n\n# 开始绘制爱心\nt.begin_fill()\nt.fillcolor(\"red\")\nt.left(140)\nt.forward(224)\nfor _ in range(200):\n    t.right(1)\n    t.forward(2)\n    track.append(t.pos())  # 记录当前坐标\n    if _ %30 ==10 and _ > 20:\n        t.color(\"orange\")\n        t.write(sentence1[rd], align=\"right\",font=(\"楷体\", 20, \"normal\"))\n        rd +=1\n        t.color(\"red\")\nt.left(120)\nrd =0\nfor _ in range(200):\n    t.right(1)\n    t.forward(2)\n    track.append(t.pos())  # 记录当前坐标\n    if _ %30 ==8 and _> 20:\n        t.color(\"orange\")\n        t.write(sentence2[rd], align=\"left\", font=(\"楷体\", 20, \"normal\"))\n        rd +=1\n        t.color(\"red\")  \nt.forward(224)\nt.end_fill()\n \nt.exitonclick()\n```\n\n## 用文字构成心形图案\n\n简单的文字构成图\n\n```python\nprint('\\n'.join([' '.join([('DoDo'[(x-y) % 4]if((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3<=0 else' ')for x in range(-60,60)])for y in range(30,-30,-1)]))\n```\n输出如下：\n\n![心形文字图](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202310170813904.png)\n\n## 用图片构成心形图\n\n首先要裁剪图片到相同大小：\n\n```python\nfrom PIL import Image\n\n# 指定包含图片的文件夹路径\ninput_folder = \"e:\\\\Learning\\\\pic\"  # 用实际的文件夹路径替换\noutput_folder = \"e:\\\\Learning\\\\pics\"  # 用实际的输出文件夹路径替换\n\n# 获取文件夹中所有图片文件的路径\nimage_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n\nfor image_file in image_files:\n    # 构建输入文件的完整路径\n    input_file_path = os.path.join(input_folder, image_file)\n\n    # 打开原始图像\n    original_image = Image.open(input_file_path)\n    # 获取原始图像的宽度和高度\n    width, height = original_image.size\n\n    # 确定截取的正方形尺寸\n    if width > height:\n        new_size = (height, height)\n    else:\n        new_size = (width, width)\n\n    # 截取中央部分\n    left = (width - new_size[0]) / 2\n    top = (height - new_size[1]) / 2\n    right = (width + new_size[0]) / 2\n    bottom = (height + new_size[1]) / 2\n\n    cropped_image = original_image.crop((left, top, right, bottom))\n\n    # 调整图像大小为（128，128）\n    cropped_image = cropped_image.resize((128, 128))\n\n    # 获取输出文件的完整路径\n    output_file_path = os.path.join(output_folder, image_file)\n\n    # 保存处理后的图像\n    cropped_image.save(output_file_path)\n```\n\n然后将图片排列在大的画布上\n\n```python\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport os\n\n# Define the number of rows and columns\nrow = 6\ncol = 6\n\n# Define the size of each small image\nsmall_pic_size = (128, 128)\n\n# Make sure you have a list of image file paths in file_paths\nfolder_path = os.path.join(os.getcwd(),\"pics\")  # 用实际的文件夹路径替换\n\n# 使用os.listdir()获取文件夹中的所有文件和子文件夹\nfile_paths = []\nfor root, dirs, files in os.walk(folder_path):\n    for file in files:\n        file_paths.append(os.path.join(root, file))\n\n# Initialize a list to store small images\nimages = []\nfor file_path in file_paths:\n    small_image = Image.open(file_path)\n    images.append(small_image)\n\n# Generate an empty heart-shaped image\nheart = np.zeros((128*10, 128*10, 3), dtype=np.uint8)\n\nfor epoch, pic in enumerate(images):\n    block_x = int(small_pic_size[0] * (epoch // row))\n    block_y = int(small_pic_size[1] * (epoch % col))\n    heart[block_x:block_x + small_pic_size[0], block_y:block_y + small_pic_size[1], :] = pic\n\n# Save the generated heart-shaped mosaic image\ncv2.imwrite('1234.png', cv2.cvtColor(heart, cv2.COLOR_BGR2RGB))\n```\n\n## 用列表绘制心形\n\n```python\nfrom PIL import Image\nimport os\nimport math\nmap = [\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n]\n\n# 这个是图片的所在路径\nimg_dir = r\"E:\\Learning\\pics\"\n# 获取这个文件下的所有文件，因为没有过滤其他类型文件，所以不要放非图片文件\n# 返回的是一个列表\nimgs = os.listdir(img_dir)\n# 设置图片的尺寸，所有图片尺寸要保持统一，要有组织有纪律\nimg_h = img_w = 128\n# 计算行数，即子列表的个数\nrows = len(map)\n# 计算列数，即子列表中元素的个数\ncolumns = len(map[0])\n# 第一个参数照着写\n# 第二个参数需要传入一个元组，元组的第一个参数是画布的宽，第二个是高\n# 第三个参数传入的是画布的颜色\n# 使用Image.new()方法创建一个画布\nfigure = Image.new(\"RGB\", (img_w*columns, img_h*rows),\"white\")\n# 表示图片的下标\ncount = 0\n# 遍历行\nfor i in range(len(map)):\n    # 遍历每行中的所有元素\n    for j in range(len(map[i])):\n        # 如果元素是1，就不管它\n        if map[i][j] == 1:\n            continue\n        # 如果元素是非1，即0就放图片上去\n        else:\n            # 做个异常处理，防止有些图片打开失败，导致程序中断\n            try:\n                # 使用Image.open(\"图片路径\")方法获取图片对象\n                image = Image.open(os.path.join(img_dir, imgs[count]))\n            except:\n                continue\n            # resize((新的宽，新的高))用来改变图片的尺寸,接收一个元组\n            image = image.resize((img_w, img_h))\n            # 将修改尺寸后的图片(image)粘贴(paste)到画布(figure)上\n            # 第一个参数 是图片对象\n            # 第二个参数是 图片在画布上的位置，相当于单元格的位置\n            figure.paste(image, (img_w*j, img_h*i))\n            # 使用完一张图片就要记录下来，并开始使用下一张图片\n            count += 1\n# 将画好的画布显示出来\nfigure.show()\n# 图片保存的路径\nfigure.save('Man.png')\n```\n\n## 待完成：\n\n- [x] 将大画布改为心形，\n- [ ] 并且使图片边缘裁剪平滑\n\n# 找房子（香港）\n\n香港粤海酒店 Oasis Avenue, 18 Prat Ave, Tsim Sha Tsui, Hong Kong\n\n","slug":"Mylove","published":1,"updated":"2024-10-27T09:24:20.467Z","comments":1,"layout":"post","photos":[],"_id":"cuid1-tD-LESet6mSuhBXiMZX","content":"<h1 id=\"梦境\"><a href=\"#梦境\" class=\"headerlink\" title=\"梦境\"></a>梦境</h1><p><strong>内容：</strong>苏州旅游 听周密的livehouse 他又忘词了但是全场很嗨中场休息大家去自助奶茶区打饮料(茉沏) 遇到一个小姐姐是本地人 对我起级好 给我打奶茶加料超丰富 还加了很多奶盖 就这样认识了后面逛街又遇到 她邀请我一起去吃饭到了饭桌上 把我的朋友安置好 她带我出去买当地小吃 还吃了一种活的虫子 有点可怕 我不太敢 还沾到了手上 后来我们回到餐桌上 发现她爸妈来找 让她相亲她拿我当挡箭牌 说我俩已经在一起了(?)她爸妈也接受 但是那位相亲对象不同意了 开始砸场子 我俩就往外面跑冲上了一辆公交车 她还在公交车上被非礼 我想要帮忙却发现自己动不了只好大声呼救 大家好像都听不见也看不见后来有一位男士制止了 但是我们下了车之后就一直被他尾随 我偷偷用手机拨了紧急呼救 然后拉着她逃入小区的一栋单元楼一楼好像是监狱一样的地方 窗户密不透风 还被磨砂纸贴上 我隐约感觉这是那位尾随者的老巢(怎么这么巧) 二楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避 进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且会暴露我们的行踪，于是借由卫生间逃离 奇怪的是卫生间的窗外就有一架木质电梯木板有些老旧 发出咯吱咯吱的声音 我们上去之后发现只有唯一一个关门的按钮电梯中途停在了6813楼每层都有一个面目狰狞的男人盯着我们并想要进来 我们疯狂按关门的按钮最终电梯停在了一楼这时 她的父母赶来与她发生了争执 从他们的话语中我了解到所有的这一切都是她妈妈安排的(?)后面记不得了 最终警方追踪我的定位 将她妈妈抓获</p>\n<p>根据弗洛伊德的梦境分析理论，你的梦境可能包含了一些象征和隐含的意义，可能反映了你内心的欲望、冲突和焦虑。让我们逐步分析这个梦境的各个元素：</p>\n<ol>\n<li><strong>苏州旅游和Livehouse：</strong> 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐和享乐的渴望，而歌手忘词可能表示你对一些不完美或困难情况的担忧。</li>\n<li><strong>自助奶茶区和小姐姐：</strong> 自助奶茶区可能象征着你对选择和控制的欲望。小姐姐可能代表你在新环境中遇到的友好支持，可能反映了你的社交需求。</li>\n<li><strong>吃活虫子：</strong> 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。</li>\n<li><strong>相亲和挡箭牌：</strong> 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌可能表示你可能被卷入一些关系中，而你不太愿意。</li>\n<li><strong>被尾随和危险追踪：</strong> 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。</li>\n<li><strong>电梯和6813楼：</strong> 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。</li>\n<li><strong>她的父母和警方：</strong> 这个部分可能反映了你对权威和保护的需求，也可能涉及到你与家庭和社会的关系。</li>\n</ol>\n<p>最终，根据弗洛伊德的理论，梦境是一种表达潜意识冲突和欲望的方式。这个梦境可能反映了你在情感和社交方面的一些内心挣扎和焦虑。要更深入地理解这个梦境，你可以考虑与心理专业人士交谈，他们可以帮助你探索与梦境相关的情感和体验，以及它们在你生活中的潜在意义。</p>\n<ol>\n<li>苏州旅游和Livehouse： 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐的渴望和音乐的兴趣，而歌手忘词可能表示你对一些不完美或困难情况的担忧。</li>\n<li>自助奶茶区和小姐姐： 自助奶茶区可能象征着你对选择和控制的欲望。陌生小姐姐在新环境中提供了友好支持，可能反映了你的社交需求，在陌生环境中寻找帮助和指导的渴望。</li>\n<li>吃活虫子： 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。</li>\n<li>相亲和挡箭牌： 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌表示你可能被卷入一些关系中，而你也许不太愿意。</li>\n<li>被尾随和危险追踪： 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。</li>\n<li>电梯和6813楼： 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。</li>\n<li>她的父母和警方： 这个部分可能反映了你对权威和保护的需求，或者你感到有人会为你解决问题。也可能涉及到你与家庭和社会的关系。</li>\n</ol>\n<h1 id=\"给我的宝宝画心形图：\"><a href=\"#给我的宝宝画心形图：\" class=\"headerlink\" title=\"给我的宝宝画心形图：\"></a>给我的宝宝画心形图：</h1><h2 id=\"绘制心形图的轨迹\"><a href=\"#绘制心形图的轨迹\" class=\"headerlink\" title=\"绘制心形图的轨迹\"></a>绘制心形图的轨迹</h2><p>用Python的标准库中包含的Turtle绘图模块绘制：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> turtle <span class=\"keyword\">as</span> t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置画布属性</span></span><br><span class=\"line\">t.bgcolor(<span class=\"string\">&quot;green&quot;</span>)</span><br><span class=\"line\">t.title(<span class=\"string\">&quot;爱心&quot;</span>)</span><br><span class=\"line\">sentence1 = [<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&#x27;爱&#x27;</span>,<span class=\"string\">&#x27;小&#x27;</span>,<span class=\"string\">&#x27;满&#x27;</span>,<span class=\"string\">&quot;&quot;</span>,<span class=\"string\">&quot;&quot;</span>]</span><br><span class=\"line\">sentence2 = [<span class=\"string\">&#x27;小&#x27;</span>,<span class=\"string\">&#x27;满&#x27;</span>,<span class=\"string\">&#x27;爱&#x27;</span>,<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&quot;&quot;</span>,<span class=\"string\">&quot;&quot;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">rd = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置画笔属性</span></span><br><span class=\"line\">t.color(<span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">t.pensize(<span class=\"number\">2</span>)</span><br><span class=\"line\">t.speed(<span class=\"number\">0</span>)</span><br><span class=\"line\">t.hideturtle()</span><br><span class=\"line\"><span class=\"comment\"># 移动画笔到起始位置</span></span><br><span class=\"line\">t.up()</span><br><span class=\"line\">t.goto(<span class=\"number\">0</span>, -<span class=\"number\">200</span>)</span><br><span class=\"line\">t.down()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 记录轨迹的坐标</span></span><br><span class=\"line\">track = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 开始绘制爱心</span></span><br><span class=\"line\">t.begin_fill()</span><br><span class=\"line\">t.fillcolor(<span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">t.left(<span class=\"number\">140</span>)</span><br><span class=\"line\">t.forward(<span class=\"number\">224</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">200</span>):</span><br><span class=\"line\">    t.right(<span class=\"number\">1</span>)</span><br><span class=\"line\">    t.forward(<span class=\"number\">2</span>)</span><br><span class=\"line\">    track.append(t.pos())  <span class=\"comment\"># 记录当前坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> _ %<span class=\"number\">30</span> ==<span class=\"number\">10</span> <span class=\"keyword\">and</span> _ &gt; <span class=\"number\">20</span>:</span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;orange&quot;</span>)</span><br><span class=\"line\">        t.write(sentence1[rd], align=<span class=\"string\">&quot;right&quot;</span>,font=(<span class=\"string\">&quot;楷体&quot;</span>, <span class=\"number\">20</span>, <span class=\"string\">&quot;normal&quot;</span>))</span><br><span class=\"line\">        rd +=<span class=\"number\">1</span></span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">t.left(<span class=\"number\">120</span>)</span><br><span class=\"line\">rd =<span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">200</span>):</span><br><span class=\"line\">    t.right(<span class=\"number\">1</span>)</span><br><span class=\"line\">    t.forward(<span class=\"number\">2</span>)</span><br><span class=\"line\">    track.append(t.pos())  <span class=\"comment\"># 记录当前坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> _ %<span class=\"number\">30</span> ==<span class=\"number\">8</span> <span class=\"keyword\">and</span> _&gt; <span class=\"number\">20</span>:</span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;orange&quot;</span>)</span><br><span class=\"line\">        t.write(sentence2[rd], align=<span class=\"string\">&quot;left&quot;</span>, font=(<span class=\"string\">&quot;楷体&quot;</span>, <span class=\"number\">20</span>, <span class=\"string\">&quot;normal&quot;</span>))</span><br><span class=\"line\">        rd +=<span class=\"number\">1</span></span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;red&quot;</span>)  </span><br><span class=\"line\">t.forward(<span class=\"number\">224</span>)</span><br><span class=\"line\">t.end_fill()</span><br><span class=\"line\"> </span><br><span class=\"line\">t.exitonclick()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"用文字构成心形图案\"><a href=\"#用文字构成心形图案\" class=\"headerlink\" title=\"用文字构成心形图案\"></a>用文字构成心形图案</h2><p>简单的文字构成图</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;\\n&#x27;</span>.join([<span class=\"string\">&#x27; &#x27;</span>.join([(<span class=\"string\">&#x27;DoDo&#x27;</span>[(x-y) % <span class=\"number\">4</span>]<span class=\"keyword\">if</span>((x*<span class=\"number\">0.05</span>)**<span class=\"number\">2</span>+(y*<span class=\"number\">0.1</span>)**<span class=\"number\">2</span>-<span class=\"number\">1</span>)**<span class=\"number\">3</span>-(x*<span class=\"number\">0.05</span>)**<span class=\"number\">2</span>*(y*<span class=\"number\">0.1</span>)**<span class=\"number\">3</span>&lt;=<span class=\"number\">0</span> <span class=\"keyword\">else</span><span class=\"string\">&#x27; &#x27;</span>)<span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(-<span class=\"number\">60</span>,<span class=\"number\">60</span>)])<span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">30</span>,-<span class=\"number\">30</span>,-<span class=\"number\">1</span>)]))</span><br></pre></td></tr></table></figure>\n<p>输出如下：</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202310170813904.png\" alt=\"心形文字图\"></p>\n<h2 id=\"用图片构成心形图\"><a href=\"#用图片构成心形图\" class=\"headerlink\" title=\"用图片构成心形图\"></a>用图片构成心形图</h2><p>首先要裁剪图片到相同大小：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定包含图片的文件夹路径</span></span><br><span class=\"line\">input_folder = <span class=\"string\">&quot;e:\\\\Learning\\\\pic&quot;</span>  <span class=\"comment\"># 用实际的文件夹路径替换</span></span><br><span class=\"line\">output_folder = <span class=\"string\">&quot;e:\\\\Learning\\\\pics&quot;</span>  <span class=\"comment\"># 用实际的输出文件夹路径替换</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取文件夹中所有图片文件的路径</span></span><br><span class=\"line\">image_files = [f <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> os.listdir(input_folder) <span class=\"keyword\">if</span> f.lower().endswith((<span class=\"string\">&#x27;.png&#x27;</span>, <span class=\"string\">&#x27;.jpg&#x27;</span>, <span class=\"string\">&#x27;.jpeg&#x27;</span>, <span class=\"string\">&#x27;.gif&#x27;</span>, <span class=\"string\">&#x27;.bmp&#x27;</span>))]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> image_file <span class=\"keyword\">in</span> image_files:</span><br><span class=\"line\">    <span class=\"comment\"># 构建输入文件的完整路径</span></span><br><span class=\"line\">    input_file_path = os.path.join(input_folder, image_file)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 打开原始图像</span></span><br><span class=\"line\">    original_image = Image.<span class=\"built_in\">open</span>(input_file_path)</span><br><span class=\"line\">    <span class=\"comment\"># 获取原始图像的宽度和高度</span></span><br><span class=\"line\">    width, height = original_image.size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 确定截取的正方形尺寸</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> width &gt; height:</span><br><span class=\"line\">        new_size = (height, height)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        new_size = (width, width)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 截取中央部分</span></span><br><span class=\"line\">    left = (width - new_size[<span class=\"number\">0</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\">    top = (height - new_size[<span class=\"number\">1</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\">    right = (width + new_size[<span class=\"number\">0</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\">    bottom = (height + new_size[<span class=\"number\">1</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">    cropped_image = original_image.crop((left, top, right, bottom))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 调整图像大小为（128，128）</span></span><br><span class=\"line\">    cropped_image = cropped_image.resize((<span class=\"number\">128</span>, <span class=\"number\">128</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获取输出文件的完整路径</span></span><br><span class=\"line\">    output_file_path = os.path.join(output_folder, image_file)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 保存处理后的图像</span></span><br><span class=\"line\">    cropped_image.save(output_file_path)</span><br></pre></td></tr></table></figure>\n\n<p>然后将图片排列在大的画布上</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the number of rows and columns</span></span><br><span class=\"line\">row = <span class=\"number\">6</span></span><br><span class=\"line\">col = <span class=\"number\">6</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the size of each small image</span></span><br><span class=\"line\">small_pic_size = (<span class=\"number\">128</span>, <span class=\"number\">128</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Make sure you have a list of image file paths in file_paths</span></span><br><span class=\"line\">folder_path = os.path.join(os.getcwd(),<span class=\"string\">&quot;pics&quot;</span>)  <span class=\"comment\"># 用实际的文件夹路径替换</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用os.listdir()获取文件夹中的所有文件和子文件夹</span></span><br><span class=\"line\">file_paths = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> root, dirs, files <span class=\"keyword\">in</span> os.walk(folder_path):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">        file_paths.append(os.path.join(root, file))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize a list to store small images</span></span><br><span class=\"line\">images = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> file_path <span class=\"keyword\">in</span> file_paths:</span><br><span class=\"line\">    small_image = Image.<span class=\"built_in\">open</span>(file_path)</span><br><span class=\"line\">    images.append(small_image)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate an empty heart-shaped image</span></span><br><span class=\"line\">heart = np.zeros((<span class=\"number\">128</span>*<span class=\"number\">10</span>, <span class=\"number\">128</span>*<span class=\"number\">10</span>, <span class=\"number\">3</span>), dtype=np.uint8)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch, pic <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(images):</span><br><span class=\"line\">    block_x = <span class=\"built_in\">int</span>(small_pic_size[<span class=\"number\">0</span>] * (epoch // row))</span><br><span class=\"line\">    block_y = <span class=\"built_in\">int</span>(small_pic_size[<span class=\"number\">1</span>] * (epoch % col))</span><br><span class=\"line\">    heart[block_x:block_x + small_pic_size[<span class=\"number\">0</span>], block_y:block_y + small_pic_size[<span class=\"number\">1</span>], :] = pic</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the generated heart-shaped mosaic image</span></span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">&#x27;1234.png&#x27;</span>, cv2.cvtColor(heart, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"用列表绘制心形\"><a href=\"#用列表绘制心形\" class=\"headerlink\" title=\"用列表绘制心形\"></a>用列表绘制心形</h2><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"built_in\">map</span> = [</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这个是图片的所在路径</span></span><br><span class=\"line\">img_dir = <span class=\"string\">r&quot;E:\\Learning\\pics&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 获取这个文件下的所有文件，因为没有过滤其他类型文件，所以不要放非图片文件</span></span><br><span class=\"line\"><span class=\"comment\"># 返回的是一个列表</span></span><br><span class=\"line\">imgs = os.listdir(img_dir)</span><br><span class=\"line\"><span class=\"comment\"># 设置图片的尺寸，所有图片尺寸要保持统一，要有组织有纪律</span></span><br><span class=\"line\">img_h = img_w = <span class=\"number\">128</span></span><br><span class=\"line\"><span class=\"comment\"># 计算行数，即子列表的个数</span></span><br><span class=\"line\">rows = <span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>)</span><br><span class=\"line\"><span class=\"comment\"># 计算列数，即子列表中元素的个数</span></span><br><span class=\"line\">columns = <span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"comment\"># 第一个参数照着写</span></span><br><span class=\"line\"><span class=\"comment\"># 第二个参数需要传入一个元组，元组的第一个参数是画布的宽，第二个是高</span></span><br><span class=\"line\"><span class=\"comment\"># 第三个参数传入的是画布的颜色</span></span><br><span class=\"line\"><span class=\"comment\"># 使用Image.new()方法创建一个画布</span></span><br><span class=\"line\">figure = Image.new(<span class=\"string\">&quot;RGB&quot;</span>, (img_w*columns, img_h*rows),<span class=\"string\">&quot;white&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 表示图片的下标</span></span><br><span class=\"line\">count = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"comment\"># 遍历行</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>)):</span><br><span class=\"line\">    <span class=\"comment\"># 遍历每行中的所有元素</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>[i])):</span><br><span class=\"line\">        <span class=\"comment\"># 如果元素是1，就不管它</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">map</span>[i][j] == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        <span class=\"comment\"># 如果元素是非1，即0就放图片上去</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 做个异常处理，防止有些图片打开失败，导致程序中断</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 使用Image.open(&quot;图片路径&quot;)方法获取图片对象</span></span><br><span class=\"line\">                image = Image.<span class=\"built_in\">open</span>(os.path.join(img_dir, imgs[count]))</span><br><span class=\"line\">            <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\">            <span class=\"comment\"># resize((新的宽，新的高))用来改变图片的尺寸,接收一个元组</span></span><br><span class=\"line\">            image = image.resize((img_w, img_h))</span><br><span class=\"line\">            <span class=\"comment\"># 将修改尺寸后的图片(image)粘贴(paste)到画布(figure)上</span></span><br><span class=\"line\">            <span class=\"comment\"># 第一个参数 是图片对象</span></span><br><span class=\"line\">            <span class=\"comment\"># 第二个参数是 图片在画布上的位置，相当于单元格的位置</span></span><br><span class=\"line\">            figure.paste(image, (img_w*j, img_h*i))</span><br><span class=\"line\">            <span class=\"comment\"># 使用完一张图片就要记录下来，并开始使用下一张图片</span></span><br><span class=\"line\">            count += <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"comment\"># 将画好的画布显示出来</span></span><br><span class=\"line\">figure.show()</span><br><span class=\"line\"><span class=\"comment\"># 图片保存的路径</span></span><br><span class=\"line\">figure.save(<span class=\"string\">&#x27;Man.png&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"待完成：\"><a href=\"#待完成：\" class=\"headerlink\" title=\"待完成：\"></a>待完成：</h2><ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 将大画布改为心形，</li>\n<li><input disabled=\"\" type=\"checkbox\"> 并且使图片边缘裁剪平滑</li>\n</ul>\n<h1 id=\"找房子（香港）\"><a href=\"#找房子（香港）\" class=\"headerlink\" title=\"找房子（香港）\"></a>找房子（香港）</h1><p>香港粤海酒店 Oasis Avenue, 18 Prat Ave, Tsim Sha Tsui, Hong Kong</p>\n","excerpt":"","more":"<h1 id=\"梦境\"><a href=\"#梦境\" class=\"headerlink\" title=\"梦境\"></a>梦境</h1><p><strong>内容：</strong>苏州旅游 听周密的livehouse 他又忘词了但是全场很嗨中场休息大家去自助奶茶区打饮料(茉沏) 遇到一个小姐姐是本地人 对我起级好 给我打奶茶加料超丰富 还加了很多奶盖 就这样认识了后面逛街又遇到 她邀请我一起去吃饭到了饭桌上 把我的朋友安置好 她带我出去买当地小吃 还吃了一种活的虫子 有点可怕 我不太敢 还沾到了手上 后来我们回到餐桌上 发现她爸妈来找 让她相亲她拿我当挡箭牌 说我俩已经在一起了(?)她爸妈也接受 但是那位相亲对象不同意了 开始砸场子 我俩就往外面跑冲上了一辆公交车 她还在公交车上被非礼 我想要帮忙却发现自己动不了只好大声呼救 大家好像都听不见也看不见后来有一位男士制止了 但是我们下了车之后就一直被他尾随 我偷偷用手机拨了紧急呼救 然后拉着她逃入小区的一栋单元楼一楼好像是监狱一样的地方 窗户密不透风 还被磨砂纸贴上 我隐约感觉这是那位尾随者的老巢(怎么这么巧) 二楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避 进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且楼像是一个农家饭店门虚掩着 推开进去后有一位老板躺在沙发上睡觉 我们假装提出要吃饭 想在此避避进入包厢后 外面响起敲门声第六感告诉我这位老板和尾随者认识并且会暴露我们的行踪，于是借由卫生间逃离 奇怪的是卫生间的窗外就有一架木质电梯木板有些老旧 发出咯吱咯吱的声音 我们上去之后发现只有唯一一个关门的按钮电梯中途停在了6813楼每层都有一个面目狰狞的男人盯着我们并想要进来 我们疯狂按关门的按钮最终电梯停在了一楼这时 她的父母赶来与她发生了争执 从他们的话语中我了解到所有的这一切都是她妈妈安排的(?)后面记不得了 最终警方追踪我的定位 将她妈妈抓获</p>\n<p>根据弗洛伊德的梦境分析理论，你的梦境可能包含了一些象征和隐含的意义，可能反映了你内心的欲望、冲突和焦虑。让我们逐步分析这个梦境的各个元素：</p>\n<ol>\n<li><strong>苏州旅游和Livehouse：</strong> 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐和享乐的渴望，而歌手忘词可能表示你对一些不完美或困难情况的担忧。</li>\n<li><strong>自助奶茶区和小姐姐：</strong> 自助奶茶区可能象征着你对选择和控制的欲望。小姐姐可能代表你在新环境中遇到的友好支持，可能反映了你的社交需求。</li>\n<li><strong>吃活虫子：</strong> 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。</li>\n<li><strong>相亲和挡箭牌：</strong> 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌可能表示你可能被卷入一些关系中，而你不太愿意。</li>\n<li><strong>被尾随和危险追踪：</strong> 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。</li>\n<li><strong>电梯和6813楼：</strong> 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。</li>\n<li><strong>她的父母和警方：</strong> 这个部分可能反映了你对权威和保护的需求，也可能涉及到你与家庭和社会的关系。</li>\n</ol>\n<p>最终，根据弗洛伊德的理论，梦境是一种表达潜意识冲突和欲望的方式。这个梦境可能反映了你在情感和社交方面的一些内心挣扎和焦虑。要更深入地理解这个梦境，你可以考虑与心理专业人士交谈，他们可以帮助你探索与梦境相关的情感和体验，以及它们在你生活中的潜在意义。</p>\n<ol>\n<li>苏州旅游和Livehouse： 这个部分可能代表你对冒险和新经历的渴望。Livehouse的现场可能反映了你对娱乐的渴望和音乐的兴趣，而歌手忘词可能表示你对一些不完美或困难情况的担忧。</li>\n<li>自助奶茶区和小姐姐： 自助奶茶区可能象征着你对选择和控制的欲望。陌生小姐姐在新环境中提供了友好支持，可能反映了你的社交需求，在陌生环境中寻找帮助和指导的渴望。</li>\n<li>吃活虫子： 这个情节可能反映了你对某些事情的不安和抵触，可能与某些经验或情感有关。</li>\n<li>相亲和挡箭牌： 这一部分可能涉及到你对亲密关系和承诺的恐惧或矛盾。被当作挡箭牌表示你可能被卷入一些关系中，而你也许不太愿意。</li>\n<li>被尾随和危险追踪： 这部分可能反映了你的不安全感和对威胁的担忧，可能是来自外部或内部的威胁。</li>\n<li>电梯和6813楼： 电梯和楼层的变化可能代表你情感上的波动和内心冲突。6813楼的数字可能有特殊的象征意义，也可能与你生活中的某些事件或经验有关。</li>\n<li>她的父母和警方： 这个部分可能反映了你对权威和保护的需求，或者你感到有人会为你解决问题。也可能涉及到你与家庭和社会的关系。</li>\n</ol>\n<h1 id=\"给我的宝宝画心形图：\"><a href=\"#给我的宝宝画心形图：\" class=\"headerlink\" title=\"给我的宝宝画心形图：\"></a>给我的宝宝画心形图：</h1><h2 id=\"绘制心形图的轨迹\"><a href=\"#绘制心形图的轨迹\" class=\"headerlink\" title=\"绘制心形图的轨迹\"></a>绘制心形图的轨迹</h2><p>用Python的标准库中包含的Turtle绘图模块绘制：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> turtle <span class=\"keyword\">as</span> t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置画布属性</span></span><br><span class=\"line\">t.bgcolor(<span class=\"string\">&quot;green&quot;</span>)</span><br><span class=\"line\">t.title(<span class=\"string\">&quot;爱心&quot;</span>)</span><br><span class=\"line\">sentence1 = [<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&#x27;爱&#x27;</span>,<span class=\"string\">&#x27;小&#x27;</span>,<span class=\"string\">&#x27;满&#x27;</span>,<span class=\"string\">&quot;&quot;</span>,<span class=\"string\">&quot;&quot;</span>]</span><br><span class=\"line\">sentence2 = [<span class=\"string\">&#x27;小&#x27;</span>,<span class=\"string\">&#x27;满&#x27;</span>,<span class=\"string\">&#x27;爱&#x27;</span>,<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&quot;雷&quot;</span>,<span class=\"string\">&quot;&quot;</span>,<span class=\"string\">&quot;&quot;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">rd = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置画笔属性</span></span><br><span class=\"line\">t.color(<span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">t.pensize(<span class=\"number\">2</span>)</span><br><span class=\"line\">t.speed(<span class=\"number\">0</span>)</span><br><span class=\"line\">t.hideturtle()</span><br><span class=\"line\"><span class=\"comment\"># 移动画笔到起始位置</span></span><br><span class=\"line\">t.up()</span><br><span class=\"line\">t.goto(<span class=\"number\">0</span>, -<span class=\"number\">200</span>)</span><br><span class=\"line\">t.down()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 记录轨迹的坐标</span></span><br><span class=\"line\">track = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 开始绘制爱心</span></span><br><span class=\"line\">t.begin_fill()</span><br><span class=\"line\">t.fillcolor(<span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">t.left(<span class=\"number\">140</span>)</span><br><span class=\"line\">t.forward(<span class=\"number\">224</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">200</span>):</span><br><span class=\"line\">    t.right(<span class=\"number\">1</span>)</span><br><span class=\"line\">    t.forward(<span class=\"number\">2</span>)</span><br><span class=\"line\">    track.append(t.pos())  <span class=\"comment\"># 记录当前坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> _ %<span class=\"number\">30</span> ==<span class=\"number\">10</span> <span class=\"keyword\">and</span> _ &gt; <span class=\"number\">20</span>:</span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;orange&quot;</span>)</span><br><span class=\"line\">        t.write(sentence1[rd], align=<span class=\"string\">&quot;right&quot;</span>,font=(<span class=\"string\">&quot;楷体&quot;</span>, <span class=\"number\">20</span>, <span class=\"string\">&quot;normal&quot;</span>))</span><br><span class=\"line\">        rd +=<span class=\"number\">1</span></span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">t.left(<span class=\"number\">120</span>)</span><br><span class=\"line\">rd =<span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">200</span>):</span><br><span class=\"line\">    t.right(<span class=\"number\">1</span>)</span><br><span class=\"line\">    t.forward(<span class=\"number\">2</span>)</span><br><span class=\"line\">    track.append(t.pos())  <span class=\"comment\"># 记录当前坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> _ %<span class=\"number\">30</span> ==<span class=\"number\">8</span> <span class=\"keyword\">and</span> _&gt; <span class=\"number\">20</span>:</span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;orange&quot;</span>)</span><br><span class=\"line\">        t.write(sentence2[rd], align=<span class=\"string\">&quot;left&quot;</span>, font=(<span class=\"string\">&quot;楷体&quot;</span>, <span class=\"number\">20</span>, <span class=\"string\">&quot;normal&quot;</span>))</span><br><span class=\"line\">        rd +=<span class=\"number\">1</span></span><br><span class=\"line\">        t.color(<span class=\"string\">&quot;red&quot;</span>)  </span><br><span class=\"line\">t.forward(<span class=\"number\">224</span>)</span><br><span class=\"line\">t.end_fill()</span><br><span class=\"line\"> </span><br><span class=\"line\">t.exitonclick()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"用文字构成心形图案\"><a href=\"#用文字构成心形图案\" class=\"headerlink\" title=\"用文字构成心形图案\"></a>用文字构成心形图案</h2><p>简单的文字构成图</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;\\n&#x27;</span>.join([<span class=\"string\">&#x27; &#x27;</span>.join([(<span class=\"string\">&#x27;DoDo&#x27;</span>[(x-y) % <span class=\"number\">4</span>]<span class=\"keyword\">if</span>((x*<span class=\"number\">0.05</span>)**<span class=\"number\">2</span>+(y*<span class=\"number\">0.1</span>)**<span class=\"number\">2</span>-<span class=\"number\">1</span>)**<span class=\"number\">3</span>-(x*<span class=\"number\">0.05</span>)**<span class=\"number\">2</span>*(y*<span class=\"number\">0.1</span>)**<span class=\"number\">3</span>&lt;=<span class=\"number\">0</span> <span class=\"keyword\">else</span><span class=\"string\">&#x27; &#x27;</span>)<span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(-<span class=\"number\">60</span>,<span class=\"number\">60</span>)])<span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">30</span>,-<span class=\"number\">30</span>,-<span class=\"number\">1</span>)]))</span><br></pre></td></tr></table></figure>\n<p>输出如下：</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202310170813904.png\" alt=\"心形文字图\"></p>\n<h2 id=\"用图片构成心形图\"><a href=\"#用图片构成心形图\" class=\"headerlink\" title=\"用图片构成心形图\"></a>用图片构成心形图</h2><p>首先要裁剪图片到相同大小：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定包含图片的文件夹路径</span></span><br><span class=\"line\">input_folder = <span class=\"string\">&quot;e:\\\\Learning\\\\pic&quot;</span>  <span class=\"comment\"># 用实际的文件夹路径替换</span></span><br><span class=\"line\">output_folder = <span class=\"string\">&quot;e:\\\\Learning\\\\pics&quot;</span>  <span class=\"comment\"># 用实际的输出文件夹路径替换</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取文件夹中所有图片文件的路径</span></span><br><span class=\"line\">image_files = [f <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> os.listdir(input_folder) <span class=\"keyword\">if</span> f.lower().endswith((<span class=\"string\">&#x27;.png&#x27;</span>, <span class=\"string\">&#x27;.jpg&#x27;</span>, <span class=\"string\">&#x27;.jpeg&#x27;</span>, <span class=\"string\">&#x27;.gif&#x27;</span>, <span class=\"string\">&#x27;.bmp&#x27;</span>))]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> image_file <span class=\"keyword\">in</span> image_files:</span><br><span class=\"line\">    <span class=\"comment\"># 构建输入文件的完整路径</span></span><br><span class=\"line\">    input_file_path = os.path.join(input_folder, image_file)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 打开原始图像</span></span><br><span class=\"line\">    original_image = Image.<span class=\"built_in\">open</span>(input_file_path)</span><br><span class=\"line\">    <span class=\"comment\"># 获取原始图像的宽度和高度</span></span><br><span class=\"line\">    width, height = original_image.size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 确定截取的正方形尺寸</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> width &gt; height:</span><br><span class=\"line\">        new_size = (height, height)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        new_size = (width, width)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 截取中央部分</span></span><br><span class=\"line\">    left = (width - new_size[<span class=\"number\">0</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\">    top = (height - new_size[<span class=\"number\">1</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\">    right = (width + new_size[<span class=\"number\">0</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\">    bottom = (height + new_size[<span class=\"number\">1</span>]) / <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">    cropped_image = original_image.crop((left, top, right, bottom))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 调整图像大小为（128，128）</span></span><br><span class=\"line\">    cropped_image = cropped_image.resize((<span class=\"number\">128</span>, <span class=\"number\">128</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获取输出文件的完整路径</span></span><br><span class=\"line\">    output_file_path = os.path.join(output_folder, image_file)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 保存处理后的图像</span></span><br><span class=\"line\">    cropped_image.save(output_file_path)</span><br></pre></td></tr></table></figure>\n\n<p>然后将图片排列在大的画布上</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the number of rows and columns</span></span><br><span class=\"line\">row = <span class=\"number\">6</span></span><br><span class=\"line\">col = <span class=\"number\">6</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the size of each small image</span></span><br><span class=\"line\">small_pic_size = (<span class=\"number\">128</span>, <span class=\"number\">128</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Make sure you have a list of image file paths in file_paths</span></span><br><span class=\"line\">folder_path = os.path.join(os.getcwd(),<span class=\"string\">&quot;pics&quot;</span>)  <span class=\"comment\"># 用实际的文件夹路径替换</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用os.listdir()获取文件夹中的所有文件和子文件夹</span></span><br><span class=\"line\">file_paths = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> root, dirs, files <span class=\"keyword\">in</span> os.walk(folder_path):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">        file_paths.append(os.path.join(root, file))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize a list to store small images</span></span><br><span class=\"line\">images = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> file_path <span class=\"keyword\">in</span> file_paths:</span><br><span class=\"line\">    small_image = Image.<span class=\"built_in\">open</span>(file_path)</span><br><span class=\"line\">    images.append(small_image)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate an empty heart-shaped image</span></span><br><span class=\"line\">heart = np.zeros((<span class=\"number\">128</span>*<span class=\"number\">10</span>, <span class=\"number\">128</span>*<span class=\"number\">10</span>, <span class=\"number\">3</span>), dtype=np.uint8)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch, pic <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(images):</span><br><span class=\"line\">    block_x = <span class=\"built_in\">int</span>(small_pic_size[<span class=\"number\">0</span>] * (epoch // row))</span><br><span class=\"line\">    block_y = <span class=\"built_in\">int</span>(small_pic_size[<span class=\"number\">1</span>] * (epoch % col))</span><br><span class=\"line\">    heart[block_x:block_x + small_pic_size[<span class=\"number\">0</span>], block_y:block_y + small_pic_size[<span class=\"number\">1</span>], :] = pic</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the generated heart-shaped mosaic image</span></span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">&#x27;1234.png&#x27;</span>, cv2.cvtColor(heart, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"用列表绘制心形\"><a href=\"#用列表绘制心形\" class=\"headerlink\" title=\"用列表绘制心形\"></a>用列表绘制心形</h2><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"built_in\">map</span> = [</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这个是图片的所在路径</span></span><br><span class=\"line\">img_dir = <span class=\"string\">r&quot;E:\\Learning\\pics&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 获取这个文件下的所有文件，因为没有过滤其他类型文件，所以不要放非图片文件</span></span><br><span class=\"line\"><span class=\"comment\"># 返回的是一个列表</span></span><br><span class=\"line\">imgs = os.listdir(img_dir)</span><br><span class=\"line\"><span class=\"comment\"># 设置图片的尺寸，所有图片尺寸要保持统一，要有组织有纪律</span></span><br><span class=\"line\">img_h = img_w = <span class=\"number\">128</span></span><br><span class=\"line\"><span class=\"comment\"># 计算行数，即子列表的个数</span></span><br><span class=\"line\">rows = <span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>)</span><br><span class=\"line\"><span class=\"comment\"># 计算列数，即子列表中元素的个数</span></span><br><span class=\"line\">columns = <span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"comment\"># 第一个参数照着写</span></span><br><span class=\"line\"><span class=\"comment\"># 第二个参数需要传入一个元组，元组的第一个参数是画布的宽，第二个是高</span></span><br><span class=\"line\"><span class=\"comment\"># 第三个参数传入的是画布的颜色</span></span><br><span class=\"line\"><span class=\"comment\"># 使用Image.new()方法创建一个画布</span></span><br><span class=\"line\">figure = Image.new(<span class=\"string\">&quot;RGB&quot;</span>, (img_w*columns, img_h*rows),<span class=\"string\">&quot;white&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 表示图片的下标</span></span><br><span class=\"line\">count = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"comment\"># 遍历行</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>)):</span><br><span class=\"line\">    <span class=\"comment\"># 遍历每行中的所有元素</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(<span class=\"built_in\">map</span>[i])):</span><br><span class=\"line\">        <span class=\"comment\"># 如果元素是1，就不管它</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">map</span>[i][j] == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        <span class=\"comment\"># 如果元素是非1，即0就放图片上去</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 做个异常处理，防止有些图片打开失败，导致程序中断</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 使用Image.open(&quot;图片路径&quot;)方法获取图片对象</span></span><br><span class=\"line\">                image = Image.<span class=\"built_in\">open</span>(os.path.join(img_dir, imgs[count]))</span><br><span class=\"line\">            <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\">            <span class=\"comment\"># resize((新的宽，新的高))用来改变图片的尺寸,接收一个元组</span></span><br><span class=\"line\">            image = image.resize((img_w, img_h))</span><br><span class=\"line\">            <span class=\"comment\"># 将修改尺寸后的图片(image)粘贴(paste)到画布(figure)上</span></span><br><span class=\"line\">            <span class=\"comment\"># 第一个参数 是图片对象</span></span><br><span class=\"line\">            <span class=\"comment\"># 第二个参数是 图片在画布上的位置，相当于单元格的位置</span></span><br><span class=\"line\">            figure.paste(image, (img_w*j, img_h*i))</span><br><span class=\"line\">            <span class=\"comment\"># 使用完一张图片就要记录下来，并开始使用下一张图片</span></span><br><span class=\"line\">            count += <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"comment\"># 将画好的画布显示出来</span></span><br><span class=\"line\">figure.show()</span><br><span class=\"line\"><span class=\"comment\"># 图片保存的路径</span></span><br><span class=\"line\">figure.save(<span class=\"string\">&#x27;Man.png&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"待完成：\"><a href=\"#待完成：\" class=\"headerlink\" title=\"待完成：\"></a>待完成：</h2><ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 将大画布改为心形，</li>\n<li><input disabled=\"\" type=\"checkbox\"> 并且使图片边缘裁剪平滑</li>\n</ul>\n<h1 id=\"找房子（香港）\"><a href=\"#找房子（香港）\" class=\"headerlink\" title=\"找房子（香港）\"></a>找房子（香港）</h1><p>香港粤海酒店 Oasis Avenue, 18 Prat Ave, Tsim Sha Tsui, Hong Kong</p>\n"},{"title":"Tips for programming","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-04-04T05:41:00.000Z","password":null,"summary":null,"_content":"\n# Packaging\n\n## Aim: \n\nAs we all know, Python scripts cannot be run on computer without Python installed. If there is a computer without Python compiler, we can run a exe file which all files of the Python programme are packaged into.\n\n## Solution: \n\nThe files are from github\n\n`git clone -recursive https://github.com/xx/xx`\n\nFirst of all, install Pyinstaller, which is a tool for packaging.\n\nrun cmd\n\n`pip install pyinstaller `\n\nHold `Shift` + right click, run the cmd command.\n\n`cd /d X:` to switch to the directory where the programme is.\n\nRun the command Pyinstaller -F xxx.py\n\nFor example:\n\n```\nPS D:\\xxx\\xxx Pyinstaller -F xxx.py\n94 INFO: PyInstaller: 4.10\n94 INFO: Python: 3.9.6\n102 INFO: Platform: Windows-10-10.0.19044-SP0\n102 INFO: wrote D:\\xxx\\xxx\\assist.spec\n105 INFO: UPX is not available.\n110 INFO: Extending PYTHONPATH with paths\n['D:\\\\xxx\\\\xxx']\n281 INFO: checking Analysis\n314 INFO: checking PYZ\n344 INFO: checking PKG\n352 INFO: Bootloader d:\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\run.exe\n352 INFO: checking EXE\n358 INFO: Rebuilding EXE-00.toc because assist.exe missing\n358 INFO: Building EXE from EXE-00.toc\n358 INFO: Copying bootloader EXE to D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable\n438 INFO: Copying icon to EXE\n438 INFO: Copying icons from ['d:\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-console.ico']\n443 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes\n443 INFO: Writing RT_ICON 1 resource with 3752 bytes\n443 INFO: Writing RT_ICON 2 resource with 2216 bytes\n443 INFO: Writing RT_ICON 3 resource with 1384 bytes\n443 INFO: Writing RT_ICON 4 resource with 37019 bytes\n443 INFO: Writing RT_ICON 5 resource with 9640 bytes\n443 INFO: Writing RT_ICON 6 resource with 4264 bytes\n443 INFO: Writing RT_ICON 7 resource with 1128 bytes\n445 INFO: Copying 0 resources to EXE\n445 INFO: Emedding manifest in EXE\n445 INFO: Updating manifest in D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable\n521 INFO: Updating resource type 24 name 1 language 0\n525 INFO: Appending PKG archive to EXE\n2369 INFO: Building EXE from EXE-00.toc completed successfully.\n```\n\n","source":"_posts/Tips for programming.md","raw":"---\ntitle: Tips for programming\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-04-04 06:41\npassword:\nsummary:\ntags:\n- tips\ncategories:\n- programming\n---\n\n# Packaging\n\n## Aim: \n\nAs we all know, Python scripts cannot be run on computer without Python installed. If there is a computer without Python compiler, we can run a exe file which all files of the Python programme are packaged into.\n\n## Solution: \n\nThe files are from github\n\n`git clone -recursive https://github.com/xx/xx`\n\nFirst of all, install Pyinstaller, which is a tool for packaging.\n\nrun cmd\n\n`pip install pyinstaller `\n\nHold `Shift` + right click, run the cmd command.\n\n`cd /d X:` to switch to the directory where the programme is.\n\nRun the command Pyinstaller -F xxx.py\n\nFor example:\n\n```\nPS D:\\xxx\\xxx Pyinstaller -F xxx.py\n94 INFO: PyInstaller: 4.10\n94 INFO: Python: 3.9.6\n102 INFO: Platform: Windows-10-10.0.19044-SP0\n102 INFO: wrote D:\\xxx\\xxx\\assist.spec\n105 INFO: UPX is not available.\n110 INFO: Extending PYTHONPATH with paths\n['D:\\\\xxx\\\\xxx']\n281 INFO: checking Analysis\n314 INFO: checking PYZ\n344 INFO: checking PKG\n352 INFO: Bootloader d:\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\run.exe\n352 INFO: checking EXE\n358 INFO: Rebuilding EXE-00.toc because assist.exe missing\n358 INFO: Building EXE from EXE-00.toc\n358 INFO: Copying bootloader EXE to D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable\n438 INFO: Copying icon to EXE\n438 INFO: Copying icons from ['d:\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-console.ico']\n443 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes\n443 INFO: Writing RT_ICON 1 resource with 3752 bytes\n443 INFO: Writing RT_ICON 2 resource with 2216 bytes\n443 INFO: Writing RT_ICON 3 resource with 1384 bytes\n443 INFO: Writing RT_ICON 4 resource with 37019 bytes\n443 INFO: Writing RT_ICON 5 resource with 9640 bytes\n443 INFO: Writing RT_ICON 6 resource with 4264 bytes\n443 INFO: Writing RT_ICON 7 resource with 1128 bytes\n445 INFO: Copying 0 resources to EXE\n445 INFO: Emedding manifest in EXE\n445 INFO: Updating manifest in D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable\n521 INFO: Updating resource type 24 name 1 language 0\n525 INFO: Appending PKG archive to EXE\n2369 INFO: Building EXE from EXE-00.toc completed successfully.\n```\n\n","slug":"Tips for programming","published":1,"updated":"2022-08-24T17:47:33.445Z","comments":1,"layout":"post","photos":[],"_id":"cuidij2QWFgdePH8lT5LXgsJ8","content":"<h1 id=\"Packaging\"><a href=\"#Packaging\" class=\"headerlink\" title=\"Packaging\"></a>Packaging</h1><h2 id=\"Aim\"><a href=\"#Aim\" class=\"headerlink\" title=\"Aim:\"></a>Aim:</h2><p>As we all know, Python scripts cannot be run on computer without Python installed. If there is a computer without Python compiler, we can run a exe file which all files of the Python programme are packaged into.</p>\n<h2 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution:\"></a>Solution:</h2><p>The files are from github</p>\n<p><code>git clone -recursive https://github.com/xx/xx</code></p>\n<p>First of all, install Pyinstaller, which is a tool for packaging.</p>\n<p>run cmd</p>\n<p><code>pip install pyinstaller</code></p>\n<p>Hold <code>Shift</code> + right click, run the cmd command.</p>\n<p><code>cd /d X:</code> to switch to the directory where the programme is.</p>\n<p>Run the command Pyinstaller -F xxx.py</p>\n<p>For example:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">PS D:\\xxx\\xxx Pyinstaller -F xxx.py</span><br><span class=\"line\">94 INFO: PyInstaller: 4.10</span><br><span class=\"line\">94 INFO: Python: 3.9.6</span><br><span class=\"line\">102 INFO: Platform: Windows-10-10.0.19044-SP0</span><br><span class=\"line\">102 INFO: wrote D:\\xxx\\xxx\\assist.spec</span><br><span class=\"line\">105 INFO: UPX is not available.</span><br><span class=\"line\">110 INFO: Extending PYTHONPATH with paths</span><br><span class=\"line\">[&#x27;D:\\\\xxx\\\\xxx&#x27;]</span><br><span class=\"line\">281 INFO: checking Analysis</span><br><span class=\"line\">314 INFO: checking PYZ</span><br><span class=\"line\">344 INFO: checking PKG</span><br><span class=\"line\">352 INFO: Bootloader d:\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\run.exe</span><br><span class=\"line\">352 INFO: checking EXE</span><br><span class=\"line\">358 INFO: Rebuilding EXE-00.toc because assist.exe missing</span><br><span class=\"line\">358 INFO: Building EXE from EXE-00.toc</span><br><span class=\"line\">358 INFO: Copying bootloader EXE to D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable</span><br><span class=\"line\">438 INFO: Copying icon to EXE</span><br><span class=\"line\">438 INFO: Copying icons from [&#x27;d:\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-console.ico&#x27;]</span><br><span class=\"line\">443 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 1 resource with 3752 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 2 resource with 2216 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 3 resource with 1384 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 4 resource with 37019 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 5 resource with 9640 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 6 resource with 4264 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 7 resource with 1128 bytes</span><br><span class=\"line\">445 INFO: Copying 0 resources to EXE</span><br><span class=\"line\">445 INFO: Emedding manifest in EXE</span><br><span class=\"line\">445 INFO: Updating manifest in D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable</span><br><span class=\"line\">521 INFO: Updating resource type 24 name 1 language 0</span><br><span class=\"line\">525 INFO: Appending PKG archive to EXE</span><br><span class=\"line\">2369 INFO: Building EXE from EXE-00.toc completed successfully.</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h1 id=\"Packaging\"><a href=\"#Packaging\" class=\"headerlink\" title=\"Packaging\"></a>Packaging</h1><h2 id=\"Aim\"><a href=\"#Aim\" class=\"headerlink\" title=\"Aim:\"></a>Aim:</h2><p>As we all know, Python scripts cannot be run on computer without Python installed. If there is a computer without Python compiler, we can run a exe file which all files of the Python programme are packaged into.</p>\n<h2 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution:\"></a>Solution:</h2><p>The files are from github</p>\n<p><code>git clone -recursive https://github.com/xx/xx</code></p>\n<p>First of all, install Pyinstaller, which is a tool for packaging.</p>\n<p>run cmd</p>\n<p><code>pip install pyinstaller</code></p>\n<p>Hold <code>Shift</code> + right click, run the cmd command.</p>\n<p><code>cd /d X:</code> to switch to the directory where the programme is.</p>\n<p>Run the command Pyinstaller -F xxx.py</p>\n<p>For example:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">PS D:\\xxx\\xxx Pyinstaller -F xxx.py</span><br><span class=\"line\">94 INFO: PyInstaller: 4.10</span><br><span class=\"line\">94 INFO: Python: 3.9.6</span><br><span class=\"line\">102 INFO: Platform: Windows-10-10.0.19044-SP0</span><br><span class=\"line\">102 INFO: wrote D:\\xxx\\xxx\\assist.spec</span><br><span class=\"line\">105 INFO: UPX is not available.</span><br><span class=\"line\">110 INFO: Extending PYTHONPATH with paths</span><br><span class=\"line\">[&#x27;D:\\\\xxx\\\\xxx&#x27;]</span><br><span class=\"line\">281 INFO: checking Analysis</span><br><span class=\"line\">314 INFO: checking PYZ</span><br><span class=\"line\">344 INFO: checking PKG</span><br><span class=\"line\">352 INFO: Bootloader d:\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\run.exe</span><br><span class=\"line\">352 INFO: checking EXE</span><br><span class=\"line\">358 INFO: Rebuilding EXE-00.toc because assist.exe missing</span><br><span class=\"line\">358 INFO: Building EXE from EXE-00.toc</span><br><span class=\"line\">358 INFO: Copying bootloader EXE to D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable</span><br><span class=\"line\">438 INFO: Copying icon to EXE</span><br><span class=\"line\">438 INFO: Copying icons from [&#x27;d:\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-console.ico&#x27;]</span><br><span class=\"line\">443 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 1 resource with 3752 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 2 resource with 2216 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 3 resource with 1384 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 4 resource with 37019 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 5 resource with 9640 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 6 resource with 4264 bytes</span><br><span class=\"line\">443 INFO: Writing RT_ICON 7 resource with 1128 bytes</span><br><span class=\"line\">445 INFO: Copying 0 resources to EXE</span><br><span class=\"line\">445 INFO: Emedding manifest in EXE</span><br><span class=\"line\">445 INFO: Updating manifest in D:\\xxx\\xxx\\dist\\assist.exe.notanexecutable</span><br><span class=\"line\">521 INFO: Updating resource type 24 name 1 language 0</span><br><span class=\"line\">525 INFO: Appending PKG archive to EXE</span><br><span class=\"line\">2369 INFO: Building EXE from EXE-00.toc completed successfully.</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Handbook","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2024-10-25T17:21:00.000Z","password":null,"summary":null,"_content":"\n# 1. CREATE cluster\n\n## Jupyter Connecting to Jupyter Lab through an SSH tunnel\n\n4.  Start an interactive session\n\n``` \nssh -m hmac-sha2-512 k21116947@hpc.create.kcl.ac.uk\nsrun -p gpu --pty -t 4:00:00 --mem=30GB --gres=gpu /bin/bash\n```\n\n**Make a note of the node you're connected to, e.g. erc-hpc-comp001**\n\n5.  Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)\n\n```\nconda activate PhD \njupyter lab --no-browser --port=9998 --ip=\"*\"\npython -mconda notebook --no-browser --port=9998 --ip=\"*\" # if the above line does not work\n```\n\n6.  **Open a separate connection** to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)\n\n```\nssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk\" -L 9998:erc-hpc-comp037:9998 k21116947@hpc.create.kcl.ac.uk\n```\n\n## SCP Transferring files\n\nDownload: use shift + right click to open PowerShell of the location, and use scp to copy files from the server to local, here is an example:\n\n```sh\nscp -o MACs=hmac-sha2-512 create:/users/k21116947/1.py /1/loc.py\n```\n\nUpload:\n\n`````````sh\nscp -o MACs=hmac-sha2-512 1.py create:/users/k21116947/1.py\n`````````\n\nIf it is a folder:\n\n```\nscp -o MACs=hmac-sha2-512 -r create:/users/k21116947/ABCD/trail4 /trail\nscp -o MACs=hmac-sha2-512 -r /trail create:/users/k21116947/Autoencoder\n```\n\nWhat else, `rm` is used to delete files.\n\n## Submitting a job via sbatch\n\ncd to the location, then use: \n\n```sh\nsbatch -p cpu helloworld.sh\n```\n\nor \n\n`````sh\nsbatch helloworld.sh\n`````\n\n### **Issue: SLURM Job Exits After a Few Seconds**\n\n#### **Symptom**\n\nWhen submitting the `sbatch run.sh` job using SLURM, the job runs for only a few seconds before exiting. However, running `bash run.sh` directly works fine.\n\n#### **Cause Analysis**\n\n1. **Working Directory Issue**:\n   - The default working directory for `sbatch` might be different from the expected one, causing files like `config.yml` and `search_space.json` to be inaccessible.\n2. **Conda Environment Not Activated Properly**:\n   - SLURM jobs do not automatically inherit environment variables from the interactive shell, which may result in `nnictl` being unable to find Python and its dependencies.\n3. **NNI Task Running in the Background Without Blocking the Process**:\n   - `nnictl create --config config.yml` starts the NNI task, but since `run.sh` completes execution immediately after, the SLURM job exits prematurely.\n\n#### **Solution**\n\nModify `run.sh` as follows:\n\n```shell\nbash复制编辑#!/bin/bash\n#SBATCH --job-name=batch_nni_experiment  # Job name\n#SBATCH --output=output/batch_output_%j.log  # Output file name\n#SBATCH --error=output/batch_error_%j.log    # Error file name\n#SBATCH --ntasks=1\n#SBATCH --partition=gpu\n#SBATCH --time=4:00:00\n#SBATCH --gpus=1\n#SBATCH --cpus-per-gpu=16\n#SBATCH --mem-per-gpu=32G\n\n# Ensure the correct working directory\ncd /users/k21116947/Autoencoder || exit 1\n\n# Activate Conda environment\nsource ~/miniconda3/bin/activate ABCD\n\n# Verify Python and NNI availability\nwhich python\npython --version\nwhich nnictl\n\n# Stop all previous NNI tasks (to avoid conflicts)\nnnictl stop --all\n\n# Start a new NNI task\nnnictl create --config config.yml\n\n# Retrieve experiment ID\nEXPERIMENT_ID=$(nnictl get | awk 'NR==2 {print $1}')\n\n# Prevent the SLURM job from exiting immediately\nwhile true; do\n    sleep Infinity \ndone\n```\n\nThis ensures:\n\n- The correct working directory is used.\n- The Conda environment is properly activated.\n- The script does not exit prematurely, allowing NNI to run until the SLURM job times out or is manually stopped.\n\n### Issue: shell contain \\n\n\n```\nsbatch: error: Batch script contains DOS line breaks (\\r\\n)\nsbatch: error: instead of expected UNIX line breaks (\\n).\n```\n\nSolution: dos2unix job.sh\n\n### Submit with nohup\n\nIt allows you to automatically submit your job in avoiding failure because of job numbers' limitation.\n\n```sh\nnohup bash -c '\nwhile true; do\n    echo \"Try submit at $(date)\" >> /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log\n    sbatch -p gpu /scratch/users/k21116947/project/trail/train_model-dimension3.sh && {\n        echo \"Submitted successfully at $(date)\" >> /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log\n        break\n    }\n    echo \"Submit failed, sleep 1800s...\" >> /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log\n    sleep 1800\ndone\n' >/dev/null 2>&1 &\n```\n\n\n\n## monitoring job\n\n``````\nsqueue -u k1234567\nscancel <job ID> #cancel the job\n``````\n\n## Setting working directory for the job\n\nadd the following commands in .sh file\n\n```````sh\n#!/bin/bash -l\n#SBATCH --output=/scratch/users/%u/%j.out\n#SBATCH --job-name=Job1\n#SBATCH --gres=gpu\n#SBATCH --time=0-2:00\n#SBATCH --chdir=/scratch/k21116947/PhD\n```````\n\n## Loading module\n\nsuch as with TensorFlow:\n\n```````sh\nmodule load python/3.11.6-gcc-13.2.0\nmodule load cuda/11.8.0-gcc-13.2.0\nmodule load cudnn/8.7.0.84-11.8-gcc-13.2.0\nmodule load py-tensorflow/2.14.0-gcc-11.4.0-cuda-python-3.11.6\nmodule load py-pandas/1.5.3-gcc-13.2.0-python-3.11.6\n```````\n\n## Singularity\n\ncheck BIDS:\n\n```sh\nsingularity run -B /scratch/users/k21116947:/mnt docker://bids/validator /mnt/abcd-mproc-release5\n```\n\nignore the motion.ts\n\n## Pipeline for running fmriprep in cluster\n\n```sh\ncd /scratch/users/k21116947 \nmodule load parallel\ncat subject_list.txt | parallel -j 4 sbatch run_fmriprep_one.sh {}\n```\n\n# 2. Jupyter\n\n## Install kernel for ipynb: \n\n`````\nconda activate NN\npip install jupyterlab\npip install ipykernel\npython -m ipykernel install --user --name NN --display-name \"Python3.11 NN\"\n`````\n\n# 3. Quick command\n\n`nano` can be used to edit file in command line\n\n# 4. Python\n\n`.iloc[]` is used to list a dataframe, such as:\n\n ![image-20241025120723937](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202410251207265.png)\n\nwhere : represent all rows, and 0 represent the first column\n\n`~` 是取反运算符：示例：对于 `[True, False, False, True]`，应用 `~` 后变成 `[False, True, True, False]`\n\n# 5. Github\n\n上传时忽略文件：\n\n在根目录下创建 .gitignore 文件，文件中添加要忽略的文件，如：\n\n`````sh\n# 忽略单个文件\nmy_secret_file.txt\n\n# 忽略文件夹\nmy_folder/\n\n# 忽略特定类型的文件（如所有的 .log 文件）\n*.log\n\n# 忽略多个文件夹中的特定文件\nmy_folder/*.tmp\n\n# 忽略某个文件夹内的所有文件，但不忽略其中的一个文件\nmy_folder/*\n!my_folder/keep_this_file.txt\n`````\n\n# 6. Graph\n\nPython graph gallery contains some examples\n\nif python does not work, you may turn to D3.js\n\n# 7. Tips for ChatGPT\n\nI’m writing a paper on 【topic】 for a leading 【discipline】 academic journal. What I tried to say in the following section is 【specific point】. Please rephrase it for clarity, coherence and conciseness, ensuring each paragraph flows into the next. Remove jargon. Use a professional tone\n\n","source":"_posts/handbook.md","raw":"---\ntitle: Handbook\ntop: True\ncover: false\ntoc: true\nmathjax: true\ndate: 2024-10-25 18:21\npassword:\nsummary:\ntags:\n- PhD\ncategories:\n- programming\n---\n\n# 1. CREATE cluster\n\n## Jupyter Connecting to Jupyter Lab through an SSH tunnel\n\n4.  Start an interactive session\n\n``` \nssh -m hmac-sha2-512 k21116947@hpc.create.kcl.ac.uk\nsrun -p gpu --pty -t 4:00:00 --mem=30GB --gres=gpu /bin/bash\n```\n\n**Make a note of the node you're connected to, e.g. erc-hpc-comp001**\n\n5.  Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)\n\n```\nconda activate PhD \njupyter lab --no-browser --port=9998 --ip=\"*\"\npython -mconda notebook --no-browser --port=9998 --ip=\"*\" # if the above line does not work\n```\n\n6.  **Open a separate connection** to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)\n\n```\nssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk\" -L 9998:erc-hpc-comp037:9998 k21116947@hpc.create.kcl.ac.uk\n```\n\n## SCP Transferring files\n\nDownload: use shift + right click to open PowerShell of the location, and use scp to copy files from the server to local, here is an example:\n\n```sh\nscp -o MACs=hmac-sha2-512 create:/users/k21116947/1.py /1/loc.py\n```\n\nUpload:\n\n`````````sh\nscp -o MACs=hmac-sha2-512 1.py create:/users/k21116947/1.py\n`````````\n\nIf it is a folder:\n\n```\nscp -o MACs=hmac-sha2-512 -r create:/users/k21116947/ABCD/trail4 /trail\nscp -o MACs=hmac-sha2-512 -r /trail create:/users/k21116947/Autoencoder\n```\n\nWhat else, `rm` is used to delete files.\n\n## Submitting a job via sbatch\n\ncd to the location, then use: \n\n```sh\nsbatch -p cpu helloworld.sh\n```\n\nor \n\n`````sh\nsbatch helloworld.sh\n`````\n\n### **Issue: SLURM Job Exits After a Few Seconds**\n\n#### **Symptom**\n\nWhen submitting the `sbatch run.sh` job using SLURM, the job runs for only a few seconds before exiting. However, running `bash run.sh` directly works fine.\n\n#### **Cause Analysis**\n\n1. **Working Directory Issue**:\n   - The default working directory for `sbatch` might be different from the expected one, causing files like `config.yml` and `search_space.json` to be inaccessible.\n2. **Conda Environment Not Activated Properly**:\n   - SLURM jobs do not automatically inherit environment variables from the interactive shell, which may result in `nnictl` being unable to find Python and its dependencies.\n3. **NNI Task Running in the Background Without Blocking the Process**:\n   - `nnictl create --config config.yml` starts the NNI task, but since `run.sh` completes execution immediately after, the SLURM job exits prematurely.\n\n#### **Solution**\n\nModify `run.sh` as follows:\n\n```shell\nbash复制编辑#!/bin/bash\n#SBATCH --job-name=batch_nni_experiment  # Job name\n#SBATCH --output=output/batch_output_%j.log  # Output file name\n#SBATCH --error=output/batch_error_%j.log    # Error file name\n#SBATCH --ntasks=1\n#SBATCH --partition=gpu\n#SBATCH --time=4:00:00\n#SBATCH --gpus=1\n#SBATCH --cpus-per-gpu=16\n#SBATCH --mem-per-gpu=32G\n\n# Ensure the correct working directory\ncd /users/k21116947/Autoencoder || exit 1\n\n# Activate Conda environment\nsource ~/miniconda3/bin/activate ABCD\n\n# Verify Python and NNI availability\nwhich python\npython --version\nwhich nnictl\n\n# Stop all previous NNI tasks (to avoid conflicts)\nnnictl stop --all\n\n# Start a new NNI task\nnnictl create --config config.yml\n\n# Retrieve experiment ID\nEXPERIMENT_ID=$(nnictl get | awk 'NR==2 {print $1}')\n\n# Prevent the SLURM job from exiting immediately\nwhile true; do\n    sleep Infinity \ndone\n```\n\nThis ensures:\n\n- The correct working directory is used.\n- The Conda environment is properly activated.\n- The script does not exit prematurely, allowing NNI to run until the SLURM job times out or is manually stopped.\n\n### Issue: shell contain \\n\n\n```\nsbatch: error: Batch script contains DOS line breaks (\\r\\n)\nsbatch: error: instead of expected UNIX line breaks (\\n).\n```\n\nSolution: dos2unix job.sh\n\n### Submit with nohup\n\nIt allows you to automatically submit your job in avoiding failure because of job numbers' limitation.\n\n```sh\nnohup bash -c '\nwhile true; do\n    echo \"Try submit at $(date)\" >> /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log\n    sbatch -p gpu /scratch/users/k21116947/project/trail/train_model-dimension3.sh && {\n        echo \"Submitted successfully at $(date)\" >> /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log\n        break\n    }\n    echo \"Submit failed, sleep 1800s...\" >> /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log\n    sleep 1800\ndone\n' >/dev/null 2>&1 &\n```\n\n\n\n## monitoring job\n\n``````\nsqueue -u k1234567\nscancel <job ID> #cancel the job\n``````\n\n## Setting working directory for the job\n\nadd the following commands in .sh file\n\n```````sh\n#!/bin/bash -l\n#SBATCH --output=/scratch/users/%u/%j.out\n#SBATCH --job-name=Job1\n#SBATCH --gres=gpu\n#SBATCH --time=0-2:00\n#SBATCH --chdir=/scratch/k21116947/PhD\n```````\n\n## Loading module\n\nsuch as with TensorFlow:\n\n```````sh\nmodule load python/3.11.6-gcc-13.2.0\nmodule load cuda/11.8.0-gcc-13.2.0\nmodule load cudnn/8.7.0.84-11.8-gcc-13.2.0\nmodule load py-tensorflow/2.14.0-gcc-11.4.0-cuda-python-3.11.6\nmodule load py-pandas/1.5.3-gcc-13.2.0-python-3.11.6\n```````\n\n## Singularity\n\ncheck BIDS:\n\n```sh\nsingularity run -B /scratch/users/k21116947:/mnt docker://bids/validator /mnt/abcd-mproc-release5\n```\n\nignore the motion.ts\n\n## Pipeline for running fmriprep in cluster\n\n```sh\ncd /scratch/users/k21116947 \nmodule load parallel\ncat subject_list.txt | parallel -j 4 sbatch run_fmriprep_one.sh {}\n```\n\n# 2. Jupyter\n\n## Install kernel for ipynb: \n\n`````\nconda activate NN\npip install jupyterlab\npip install ipykernel\npython -m ipykernel install --user --name NN --display-name \"Python3.11 NN\"\n`````\n\n# 3. Quick command\n\n`nano` can be used to edit file in command line\n\n# 4. Python\n\n`.iloc[]` is used to list a dataframe, such as:\n\n ![image-20241025120723937](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202410251207265.png)\n\nwhere : represent all rows, and 0 represent the first column\n\n`~` 是取反运算符：示例：对于 `[True, False, False, True]`，应用 `~` 后变成 `[False, True, True, False]`\n\n# 5. Github\n\n上传时忽略文件：\n\n在根目录下创建 .gitignore 文件，文件中添加要忽略的文件，如：\n\n`````sh\n# 忽略单个文件\nmy_secret_file.txt\n\n# 忽略文件夹\nmy_folder/\n\n# 忽略特定类型的文件（如所有的 .log 文件）\n*.log\n\n# 忽略多个文件夹中的特定文件\nmy_folder/*.tmp\n\n# 忽略某个文件夹内的所有文件，但不忽略其中的一个文件\nmy_folder/*\n!my_folder/keep_this_file.txt\n`````\n\n# 6. Graph\n\nPython graph gallery contains some examples\n\nif python does not work, you may turn to D3.js\n\n# 7. Tips for ChatGPT\n\nI’m writing a paper on 【topic】 for a leading 【discipline】 academic journal. What I tried to say in the following section is 【specific point】. Please rephrase it for clarity, coherence and conciseness, ensuring each paragraph flows into the next. Remove jargon. Use a professional tone\n\n","slug":"handbook","published":1,"updated":"2025-11-24T15:52:32.473Z","comments":1,"layout":"post","photos":[],"_id":"cuidPygZP_I2hVWgjwhQsrG41","content":"<h1 id=\"1-CREATE-cluster\"><a href=\"#1-CREATE-cluster\" class=\"headerlink\" title=\"1. CREATE cluster\"></a>1. CREATE cluster</h1><h2 id=\"Jupyter-Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\"><a href=\"#Jupyter-Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\" class=\"headerlink\" title=\"Jupyter Connecting to Jupyter Lab through an SSH tunnel\"></a>Jupyter Connecting to Jupyter Lab through an SSH tunnel</h2><ol start=\"4\">\n<li>Start an interactive session</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 k21116947@hpc.create.kcl.ac.uk</span><br><span class=\"line\">srun -p gpu --pty -t 4:00:00 --mem=30GB --gres=gpu /bin/bash</span><br></pre></td></tr></table></figure>\n\n<p><strong>Make a note of the node you’re connected to, e.g. erc-hpc-comp001</strong></p>\n<ol start=\"5\">\n<li>Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate PhD </span><br><span class=\"line\">jupyter lab --no-browser --port=9998 --ip=&quot;*&quot;</span><br><span class=\"line\">python -mconda notebook --no-browser --port=9998 --ip=&quot;*&quot; # if the above line does not work</span><br></pre></td></tr></table></figure>\n\n<ol start=\"6\">\n<li><strong>Open a separate connection</strong> to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 -o ProxyCommand=&quot;ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk&quot; -L 9998:erc-hpc-comp037:9998 k21116947@hpc.create.kcl.ac.uk</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"SCP-Transferring-files\"><a href=\"#SCP-Transferring-files\" class=\"headerlink\" title=\"SCP Transferring files\"></a>SCP Transferring files</h2><p>Download: use shift + right click to open PowerShell of the location, and use scp to copy files from the server to local, here is an example:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -o MACs=hmac-sha2-512 create:/users/k21116947/1.py /1/loc.py</span><br></pre></td></tr></table></figure>\n\n<p>Upload:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -o MACs=hmac-sha2-512 1.py create:/users/k21116947/1.py</span><br></pre></td></tr></table></figure>\n\n<p>If it is a folder:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -o MACs=hmac-sha2-512 -r create:/users/k21116947/ABCD/trail4 /trail</span><br><span class=\"line\">scp -o MACs=hmac-sha2-512 -r /trail create:/users/k21116947/Autoencoder</span><br></pre></td></tr></table></figure>\n\n<p>What else, <code>rm</code> is used to delete files.</p>\n<h2 id=\"Submitting-a-job-via-sbatch\"><a href=\"#Submitting-a-job-via-sbatch\" class=\"headerlink\" title=\"Submitting a job via sbatch\"></a>Submitting a job via sbatch</h2><p>cd to the location, then use: </p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">sbatch -p cpu helloworld.sh</span><br></pre></td></tr></table></figure>\n\n<p>or </p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">sbatch helloworld.sh</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Issue-SLURM-Job-Exits-After-a-Few-Seconds\"><a href=\"#Issue-SLURM-Job-Exits-After-a-Few-Seconds\" class=\"headerlink\" title=\"Issue: SLURM Job Exits After a Few Seconds\"></a><strong>Issue: SLURM Job Exits After a Few Seconds</strong></h3><h4 id=\"Symptom\"><a href=\"#Symptom\" class=\"headerlink\" title=\"Symptom\"></a><strong>Symptom</strong></h4><p>When submitting the <code>sbatch run.sh</code> job using SLURM, the job runs for only a few seconds before exiting. However, running <code>bash run.sh</code> directly works fine.</p>\n<h4 id=\"Cause-Analysis\"><a href=\"#Cause-Analysis\" class=\"headerlink\" title=\"Cause Analysis\"></a><strong>Cause Analysis</strong></h4><ol>\n<li><strong>Working Directory Issue</strong>:<ul>\n<li>The default working directory for <code>sbatch</code> might be different from the expected one, causing files like <code>config.yml</code> and <code>search_space.json</code> to be inaccessible.</li>\n</ul>\n</li>\n<li><strong>Conda Environment Not Activated Properly</strong>:<ul>\n<li>SLURM jobs do not automatically inherit environment variables from the interactive shell, which may result in <code>nnictl</code> being unable to find Python and its dependencies.</li>\n</ul>\n</li>\n<li><strong>NNI Task Running in the Background Without Blocking the Process</strong>:<ul>\n<li><code>nnictl create --config config.yml</code> starts the NNI task, but since <code>run.sh</code> completes execution immediately after, the SLURM job exits prematurely.</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution\"></a><strong>Solution</strong></h4><p>Modify <code>run.sh</code> as follows:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">bash复制编辑#!/bin/bash</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --job-name=batch_nni_experiment  <span class=\"comment\"># Job name</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --output=output/batch_output_%j.log  <span class=\"comment\"># Output file name</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --error=output/batch_error_%j.log    <span class=\"comment\"># Error file name</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --ntasks=1</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --partition=gpu</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --<span class=\"keyword\">time</span>=4:00:00</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --gpus=1</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --cpus-per-gpu=16</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --mem-per-gpu=32G</span></span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Ensure the correct working directory</span></span><br><span class=\"line\">cd /users/k21116947/Autoencoder || exit 1</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Activate Conda environment</span></span><br><span class=\"line\">source ~/miniconda3/bin/activate ABCD</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Verify Python and NNI availability</span></span><br><span class=\"line\">which python</span><br><span class=\"line\">python --version</span><br><span class=\"line\">which nnictl</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Stop all previous NNI tasks (to avoid conflicts)</span></span><br><span class=\"line\">nnictl stop --all</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Start a new NNI task</span></span><br><span class=\"line\">nnictl create --config config.yml</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Retrieve experiment ID</span></span><br><span class=\"line\">EXPERIMENT_ID=$(nnictl get | awk &#x27;NR==2 &#123;print $1&#125;&#x27;)</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Prevent the SLURM job from exiting immediately</span></span><br><span class=\"line\">while true; do</span><br><span class=\"line\">    sleep Infinity </span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n\n<p>This ensures:</p>\n<ul>\n<li>The correct working directory is used.</li>\n<li>The Conda environment is properly activated.</li>\n<li>The script does not exit prematurely, allowing NNI to run until the SLURM job times out or is manually stopped.</li>\n</ul>\n<h3 id=\"Issue-shell-contain-n\"><a href=\"#Issue-shell-contain-n\" class=\"headerlink\" title=\"Issue: shell contain \\n\"></a>Issue: shell contain \\n</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sbatch: error: Batch script contains DOS line breaks (\\r\\n)</span><br><span class=\"line\">sbatch: error: instead of expected UNIX line breaks (\\n).</span><br></pre></td></tr></table></figure>\n\n<p>Solution: dos2unix job.sh</p>\n<h3 id=\"Submit-with-nohup\"><a href=\"#Submit-with-nohup\" class=\"headerlink\" title=\"Submit with nohup\"></a>Submit with nohup</h3><p>It allows you to automatically submit your job in avoiding failure because of job numbers’ limitation.</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> bash -c <span class=\"string\">&#x27;</span></span><br><span class=\"line\"><span class=\"string\">while true; do</span></span><br><span class=\"line\"><span class=\"string\">    echo &quot;Try submit at $(date)&quot; &gt;&gt; /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log</span></span><br><span class=\"line\"><span class=\"string\">    sbatch -p gpu /scratch/users/k21116947/project/trail/train_model-dimension3.sh &amp;&amp; &#123;</span></span><br><span class=\"line\"><span class=\"string\">        echo &quot;Submitted successfully at $(date)&quot; &gt;&gt; /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log</span></span><br><span class=\"line\"><span class=\"string\">        break</span></span><br><span class=\"line\"><span class=\"string\">    &#125;</span></span><br><span class=\"line\"><span class=\"string\">    echo &quot;Submit failed, sleep 1800s...&quot; &gt;&gt; /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log</span></span><br><span class=\"line\"><span class=\"string\">    sleep 1800</span></span><br><span class=\"line\"><span class=\"string\">done</span></span><br><span class=\"line\"><span class=\"string\">&#x27;</span> &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"monitoring-job\"><a href=\"#monitoring-job\" class=\"headerlink\" title=\"monitoring job\"></a>monitoring job</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">squeue -u k1234567</span><br><span class=\"line\">scancel &lt;job ID&gt; #cancel the job</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Setting-working-directory-for-the-job\"><a href=\"#Setting-working-directory-for-the-job\" class=\"headerlink\" title=\"Setting working directory for the job\"></a>Setting working directory for the job</h2><p>add the following commands in .sh file</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash -l</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --output=/scratch/users/%u/%j.out</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --job-name=Job1</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --gres=gpu</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --time=0-2:00</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --chdir=/scratch/k21116947/PhD</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Loading-module\"><a href=\"#Loading-module\" class=\"headerlink\" title=\"Loading module\"></a>Loading module</h2><p>such as with TensorFlow:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">module load python/3.11.6-gcc-13.2.0</span><br><span class=\"line\">module load cuda/11.8.0-gcc-13.2.0</span><br><span class=\"line\">module load cudnn/8.7.0.84-11.8-gcc-13.2.0</span><br><span class=\"line\">module load py-tensorflow/2.14.0-gcc-11.4.0-cuda-python-3.11.6</span><br><span class=\"line\">module load py-pandas/1.5.3-gcc-13.2.0-python-3.11.6</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Singularity\"><a href=\"#Singularity\" class=\"headerlink\" title=\"Singularity\"></a>Singularity</h2><p>check BIDS:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">singularity run -B /scratch/users/k21116947:/mnt docker://bids/validator /mnt/abcd-mproc-release5</span><br></pre></td></tr></table></figure>\n\n<p>ignore the motion.ts</p>\n<h2 id=\"Pipeline-for-running-fmriprep-in-cluster\"><a href=\"#Pipeline-for-running-fmriprep-in-cluster\" class=\"headerlink\" title=\"Pipeline for running fmriprep in cluster\"></a>Pipeline for running fmriprep in cluster</h2><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /scratch/users/k21116947 </span><br><span class=\"line\">module load parallel</span><br><span class=\"line\"><span class=\"built_in\">cat</span> subject_list.txt | parallel -j 4 sbatch run_fmriprep_one.sh &#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-Jupyter\"><a href=\"#2-Jupyter\" class=\"headerlink\" title=\"2. Jupyter\"></a>2. Jupyter</h1><h2 id=\"Install-kernel-for-ipynb\"><a href=\"#Install-kernel-for-ipynb\" class=\"headerlink\" title=\"Install kernel for ipynb:\"></a>Install kernel for ipynb:</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate NN</span><br><span class=\"line\">pip install jupyterlab</span><br><span class=\"line\">pip install ipykernel</span><br><span class=\"line\">python -m ipykernel install --user --name NN --display-name &quot;Python3.11 NN&quot;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"3-Quick-command\"><a href=\"#3-Quick-command\" class=\"headerlink\" title=\"3. Quick command\"></a>3. Quick command</h1><p><code>nano</code> can be used to edit file in command line</p>\n<h1 id=\"4-Python\"><a href=\"#4-Python\" class=\"headerlink\" title=\"4. Python\"></a>4. Python</h1><p><code>.iloc[]</code> is used to list a dataframe, such as:</p>\n<p> <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202410251207265.png\" alt=\"image-20241025120723937\"></p>\n<p>where : represent all rows, and 0 represent the first column</p>\n<p><code>~</code> 是取反运算符：示例：对于 <code>[True, False, False, True]</code>，应用 <code>~</code> 后变成 <code>[False, True, True, False]</code></p>\n<h1 id=\"5-Github\"><a href=\"#5-Github\" class=\"headerlink\" title=\"5. Github\"></a>5. Github</h1><p>上传时忽略文件：</p>\n<p>在根目录下创建 .gitignore 文件，文件中添加要忽略的文件，如：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 忽略单个文件</span></span><br><span class=\"line\">my_secret_file.txt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略文件夹</span></span><br><span class=\"line\">my_folder/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略特定类型的文件（如所有的 .log 文件）</span></span><br><span class=\"line\">*.<span class=\"built_in\">log</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略多个文件夹中的特定文件</span></span><br><span class=\"line\">my_folder/*.tmp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略某个文件夹内的所有文件，但不忽略其中的一个文件</span></span><br><span class=\"line\">my_folder/*</span><br><span class=\"line\">!my_folder/keep_this_file.txt</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6-Graph\"><a href=\"#6-Graph\" class=\"headerlink\" title=\"6. Graph\"></a>6. Graph</h1><p>Python graph gallery contains some examples</p>\n<p>if python does not work, you may turn to D3.js</p>\n<h1 id=\"7-Tips-for-ChatGPT\"><a href=\"#7-Tips-for-ChatGPT\" class=\"headerlink\" title=\"7. Tips for ChatGPT\"></a>7. Tips for ChatGPT</h1><p>I’m writing a paper on 【topic】 for a leading 【discipline】 academic journal. What I tried to say in the following section is 【specific point】. Please rephrase it for clarity, coherence and conciseness, ensuring each paragraph flows into the next. Remove jargon. Use a professional tone</p>\n","excerpt":"","more":"<h1 id=\"1-CREATE-cluster\"><a href=\"#1-CREATE-cluster\" class=\"headerlink\" title=\"1. CREATE cluster\"></a>1. CREATE cluster</h1><h2 id=\"Jupyter-Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\"><a href=\"#Jupyter-Connecting-to-Jupyter-Lab-through-an-SSH-tunnel\" class=\"headerlink\" title=\"Jupyter Connecting to Jupyter Lab through an SSH tunnel\"></a>Jupyter Connecting to Jupyter Lab through an SSH tunnel</h2><ol start=\"4\">\n<li>Start an interactive session</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 k21116947@hpc.create.kcl.ac.uk</span><br><span class=\"line\">srun -p gpu --pty -t 4:00:00 --mem=30GB --gres=gpu /bin/bash</span><br></pre></td></tr></table></figure>\n\n<p><strong>Make a note of the node you’re connected to, e.g. erc-hpc-comp001</strong></p>\n<ol start=\"5\">\n<li>Within this session, start Jupyter lab without the display on a specific port (here this is port 9998)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate PhD </span><br><span class=\"line\">jupyter lab --no-browser --port=9998 --ip=&quot;*&quot;</span><br><span class=\"line\">python -mconda notebook --no-browser --port=9998 --ip=&quot;*&quot; # if the above line does not work</span><br></pre></td></tr></table></figure>\n\n<ol start=\"6\">\n<li><strong>Open a separate connection</strong> to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 -o ProxyCommand=&quot;ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk&quot; -L 9998:erc-hpc-comp037:9998 k21116947@hpc.create.kcl.ac.uk</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"SCP-Transferring-files\"><a href=\"#SCP-Transferring-files\" class=\"headerlink\" title=\"SCP Transferring files\"></a>SCP Transferring files</h2><p>Download: use shift + right click to open PowerShell of the location, and use scp to copy files from the server to local, here is an example:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -o MACs=hmac-sha2-512 create:/users/k21116947/1.py /1/loc.py</span><br></pre></td></tr></table></figure>\n\n<p>Upload:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -o MACs=hmac-sha2-512 1.py create:/users/k21116947/1.py</span><br></pre></td></tr></table></figure>\n\n<p>If it is a folder:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -o MACs=hmac-sha2-512 -r create:/users/k21116947/ABCD/trail4 /trail</span><br><span class=\"line\">scp -o MACs=hmac-sha2-512 -r /trail create:/users/k21116947/Autoencoder</span><br></pre></td></tr></table></figure>\n\n<p>What else, <code>rm</code> is used to delete files.</p>\n<h2 id=\"Submitting-a-job-via-sbatch\"><a href=\"#Submitting-a-job-via-sbatch\" class=\"headerlink\" title=\"Submitting a job via sbatch\"></a>Submitting a job via sbatch</h2><p>cd to the location, then use: </p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">sbatch -p cpu helloworld.sh</span><br></pre></td></tr></table></figure>\n\n<p>or </p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">sbatch helloworld.sh</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Issue-SLURM-Job-Exits-After-a-Few-Seconds\"><a href=\"#Issue-SLURM-Job-Exits-After-a-Few-Seconds\" class=\"headerlink\" title=\"Issue: SLURM Job Exits After a Few Seconds\"></a><strong>Issue: SLURM Job Exits After a Few Seconds</strong></h3><h4 id=\"Symptom\"><a href=\"#Symptom\" class=\"headerlink\" title=\"Symptom\"></a><strong>Symptom</strong></h4><p>When submitting the <code>sbatch run.sh</code> job using SLURM, the job runs for only a few seconds before exiting. However, running <code>bash run.sh</code> directly works fine.</p>\n<h4 id=\"Cause-Analysis\"><a href=\"#Cause-Analysis\" class=\"headerlink\" title=\"Cause Analysis\"></a><strong>Cause Analysis</strong></h4><ol>\n<li><strong>Working Directory Issue</strong>:<ul>\n<li>The default working directory for <code>sbatch</code> might be different from the expected one, causing files like <code>config.yml</code> and <code>search_space.json</code> to be inaccessible.</li>\n</ul>\n</li>\n<li><strong>Conda Environment Not Activated Properly</strong>:<ul>\n<li>SLURM jobs do not automatically inherit environment variables from the interactive shell, which may result in <code>nnictl</code> being unable to find Python and its dependencies.</li>\n</ul>\n</li>\n<li><strong>NNI Task Running in the Background Without Blocking the Process</strong>:<ul>\n<li><code>nnictl create --config config.yml</code> starts the NNI task, but since <code>run.sh</code> completes execution immediately after, the SLURM job exits prematurely.</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution\"></a><strong>Solution</strong></h4><p>Modify <code>run.sh</code> as follows:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">bash复制编辑#!/bin/bash</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --job-name=batch_nni_experiment  <span class=\"comment\"># Job name</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --output=output/batch_output_%j.log  <span class=\"comment\"># Output file name</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --error=output/batch_error_%j.log    <span class=\"comment\"># Error file name</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --ntasks=1</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --partition=gpu</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --<span class=\"keyword\">time</span>=4:00:00</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --gpus=1</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --cpus-per-gpu=16</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">SBATCH --mem-per-gpu=32G</span></span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Ensure the correct working directory</span></span><br><span class=\"line\">cd /users/k21116947/Autoencoder || exit 1</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Activate Conda environment</span></span><br><span class=\"line\">source ~/miniconda3/bin/activate ABCD</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Verify Python and NNI availability</span></span><br><span class=\"line\">which python</span><br><span class=\"line\">python --version</span><br><span class=\"line\">which nnictl</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Stop all previous NNI tasks (to avoid conflicts)</span></span><br><span class=\"line\">nnictl stop --all</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Start a new NNI task</span></span><br><span class=\"line\">nnictl create --config config.yml</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Retrieve experiment ID</span></span><br><span class=\"line\">EXPERIMENT_ID=$(nnictl get | awk &#x27;NR==2 &#123;print $1&#125;&#x27;)</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Prevent the SLURM job from exiting immediately</span></span><br><span class=\"line\">while true; do</span><br><span class=\"line\">    sleep Infinity </span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n\n<p>This ensures:</p>\n<ul>\n<li>The correct working directory is used.</li>\n<li>The Conda environment is properly activated.</li>\n<li>The script does not exit prematurely, allowing NNI to run until the SLURM job times out or is manually stopped.</li>\n</ul>\n<h3 id=\"Issue-shell-contain-n\"><a href=\"#Issue-shell-contain-n\" class=\"headerlink\" title=\"Issue: shell contain \\n\"></a>Issue: shell contain \\n</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sbatch: error: Batch script contains DOS line breaks (\\r\\n)</span><br><span class=\"line\">sbatch: error: instead of expected UNIX line breaks (\\n).</span><br></pre></td></tr></table></figure>\n\n<p>Solution: dos2unix job.sh</p>\n<h3 id=\"Submit-with-nohup\"><a href=\"#Submit-with-nohup\" class=\"headerlink\" title=\"Submit with nohup\"></a>Submit with nohup</h3><p>It allows you to automatically submit your job in avoiding failure because of job numbers’ limitation.</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> bash -c <span class=\"string\">&#x27;</span></span><br><span class=\"line\"><span class=\"string\">while true; do</span></span><br><span class=\"line\"><span class=\"string\">    echo &quot;Try submit at $(date)&quot; &gt;&gt; /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log</span></span><br><span class=\"line\"><span class=\"string\">    sbatch -p gpu /scratch/users/k21116947/project/trail/train_model-dimension3.sh &amp;&amp; &#123;</span></span><br><span class=\"line\"><span class=\"string\">        echo &quot;Submitted successfully at $(date)&quot; &gt;&gt; /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log</span></span><br><span class=\"line\"><span class=\"string\">        break</span></span><br><span class=\"line\"><span class=\"string\">    &#125;</span></span><br><span class=\"line\"><span class=\"string\">    echo &quot;Submit failed, sleep 1800s...&quot; &gt;&gt; /scratch/users/k21116947/project/trail/logs/auto_submit_dim3.log</span></span><br><span class=\"line\"><span class=\"string\">    sleep 1800</span></span><br><span class=\"line\"><span class=\"string\">done</span></span><br><span class=\"line\"><span class=\"string\">&#x27;</span> &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"monitoring-job\"><a href=\"#monitoring-job\" class=\"headerlink\" title=\"monitoring job\"></a>monitoring job</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">squeue -u k1234567</span><br><span class=\"line\">scancel &lt;job ID&gt; #cancel the job</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Setting-working-directory-for-the-job\"><a href=\"#Setting-working-directory-for-the-job\" class=\"headerlink\" title=\"Setting working directory for the job\"></a>Setting working directory for the job</h2><p>add the following commands in .sh file</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash -l</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --output=/scratch/users/%u/%j.out</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --job-name=Job1</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --gres=gpu</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --time=0-2:00</span></span><br><span class=\"line\"><span class=\"comment\">#SBATCH --chdir=/scratch/k21116947/PhD</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Loading-module\"><a href=\"#Loading-module\" class=\"headerlink\" title=\"Loading module\"></a>Loading module</h2><p>such as with TensorFlow:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">module load python/3.11.6-gcc-13.2.0</span><br><span class=\"line\">module load cuda/11.8.0-gcc-13.2.0</span><br><span class=\"line\">module load cudnn/8.7.0.84-11.8-gcc-13.2.0</span><br><span class=\"line\">module load py-tensorflow/2.14.0-gcc-11.4.0-cuda-python-3.11.6</span><br><span class=\"line\">module load py-pandas/1.5.3-gcc-13.2.0-python-3.11.6</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Singularity\"><a href=\"#Singularity\" class=\"headerlink\" title=\"Singularity\"></a>Singularity</h2><p>check BIDS:</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\">singularity run -B /scratch/users/k21116947:/mnt docker://bids/validator /mnt/abcd-mproc-release5</span><br></pre></td></tr></table></figure>\n\n<p>ignore the motion.ts</p>\n<h2 id=\"Pipeline-for-running-fmriprep-in-cluster\"><a href=\"#Pipeline-for-running-fmriprep-in-cluster\" class=\"headerlink\" title=\"Pipeline for running fmriprep in cluster\"></a>Pipeline for running fmriprep in cluster</h2><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /scratch/users/k21116947 </span><br><span class=\"line\">module load parallel</span><br><span class=\"line\"><span class=\"built_in\">cat</span> subject_list.txt | parallel -j 4 sbatch run_fmriprep_one.sh &#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-Jupyter\"><a href=\"#2-Jupyter\" class=\"headerlink\" title=\"2. Jupyter\"></a>2. Jupyter</h1><h2 id=\"Install-kernel-for-ipynb\"><a href=\"#Install-kernel-for-ipynb\" class=\"headerlink\" title=\"Install kernel for ipynb:\"></a>Install kernel for ipynb:</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda activate NN</span><br><span class=\"line\">pip install jupyterlab</span><br><span class=\"line\">pip install ipykernel</span><br><span class=\"line\">python -m ipykernel install --user --name NN --display-name &quot;Python3.11 NN&quot;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"3-Quick-command\"><a href=\"#3-Quick-command\" class=\"headerlink\" title=\"3. Quick command\"></a>3. Quick command</h1><p><code>nano</code> can be used to edit file in command line</p>\n<h1 id=\"4-Python\"><a href=\"#4-Python\" class=\"headerlink\" title=\"4. Python\"></a>4. Python</h1><p><code>.iloc[]</code> is used to list a dataframe, such as:</p>\n<p> <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202410251207265.png\" alt=\"image-20241025120723937\"></p>\n<p>where : represent all rows, and 0 represent the first column</p>\n<p><code>~</code> 是取反运算符：示例：对于 <code>[True, False, False, True]</code>，应用 <code>~</code> 后变成 <code>[False, True, True, False]</code></p>\n<h1 id=\"5-Github\"><a href=\"#5-Github\" class=\"headerlink\" title=\"5. Github\"></a>5. Github</h1><p>上传时忽略文件：</p>\n<p>在根目录下创建 .gitignore 文件，文件中添加要忽略的文件，如：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 忽略单个文件</span></span><br><span class=\"line\">my_secret_file.txt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略文件夹</span></span><br><span class=\"line\">my_folder/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略特定类型的文件（如所有的 .log 文件）</span></span><br><span class=\"line\">*.<span class=\"built_in\">log</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略多个文件夹中的特定文件</span></span><br><span class=\"line\">my_folder/*.tmp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽略某个文件夹内的所有文件，但不忽略其中的一个文件</span></span><br><span class=\"line\">my_folder/*</span><br><span class=\"line\">!my_folder/keep_this_file.txt</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6-Graph\"><a href=\"#6-Graph\" class=\"headerlink\" title=\"6. Graph\"></a>6. Graph</h1><p>Python graph gallery contains some examples</p>\n<p>if python does not work, you may turn to D3.js</p>\n<h1 id=\"7-Tips-for-ChatGPT\"><a href=\"#7-Tips-for-ChatGPT\" class=\"headerlink\" title=\"7. Tips for ChatGPT\"></a>7. Tips for ChatGPT</h1><p>I’m writing a paper on 【topic】 for a leading 【discipline】 academic journal. What I tried to say in the following section is 【specific point】. Please rephrase it for clarity, coherence and conciseness, ensuring each paragraph flows into the next. Remove jargon. Use a professional tone</p>\n"},{"title":"Taiwan 7 days","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2024-10-25T17:21:00.000Z","password":null,"summary":null,"_content":"\n# 台湾旅游攻略\n\n## To do list\n\n- [ ] 提前彩印\n- [ ] 机票\n- [ ] 住宿\n- [ ] 交通卡\n- [ ] 电话卡\n- [ ] 金福气\n\n## 地图\n\n<iframe \n    src=\"https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3747610.3074053475!2d116.8590153339058!3d23.4685542600518!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x346ef3065c07572f%3A0xe711f004bf9c5469!2z5Y-w5rm-!5e0!3m2!1szh-CN!2suk!4v1733071246704!5m2!1szh-CN!2suk\" \n    width=\"600\" \n    height=\"450\" \n    style=\"border:0;\" \n    allowfullscreen=\"\" \n    loading=\"lazy\" \n    referrerpolicy=\"no-referrer-when-downgrade\">\n</iframe>\n\n## 旅游地点\n\n| 地点 | 游玩项目 |\n| --- | --- |\n| 台北 | **台北101**：曾是世界最高建筑，设有观景台，可俯瞰台北全景。开放时间 9:00 - 22:00。<br>**国立故宫博物院**：收藏丰富的中华文物，包括翠玉白菜等珍品。开放时间 8:30 - 18:30。 |\n| 台中 | **逢甲夜市**：台湾最大的夜市之一，汇集各种美食和购物摊位。开放时间 17:00 - 00:00。 |\n| 高雄 | **爱河**：高雄市区的浪漫河流，可乘船游览。船只运营时间 10:00 - 22:00。 |\n| 垦丁 | **高雄市立美术馆**： |\n| 嘉义 | **日月潭**：游船运营时间 8:00 - 17:00。 |\n| 花莲 |  |\n\n","source":"_posts/台湾旅游攻略.md","raw":"---\ntitle: Taiwan 7 days\ntop: True\ncover: false\ntoc: true\nmathjax: true\ndate: 2024-10-25 18:21\npassword:\nsummary:\ntags:\n- Taiwan\ncategories:\n- Traveling\n---\n\n# 台湾旅游攻略\n\n## To do list\n\n- [ ] 提前彩印\n- [ ] 机票\n- [ ] 住宿\n- [ ] 交通卡\n- [ ] 电话卡\n- [ ] 金福气\n\n## 地图\n\n<iframe \n    src=\"https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3747610.3074053475!2d116.8590153339058!3d23.4685542600518!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x346ef3065c07572f%3A0xe711f004bf9c5469!2z5Y-w5rm-!5e0!3m2!1szh-CN!2suk!4v1733071246704!5m2!1szh-CN!2suk\" \n    width=\"600\" \n    height=\"450\" \n    style=\"border:0;\" \n    allowfullscreen=\"\" \n    loading=\"lazy\" \n    referrerpolicy=\"no-referrer-when-downgrade\">\n</iframe>\n\n## 旅游地点\n\n| 地点 | 游玩项目 |\n| --- | --- |\n| 台北 | **台北101**：曾是世界最高建筑，设有观景台，可俯瞰台北全景。开放时间 9:00 - 22:00。<br>**国立故宫博物院**：收藏丰富的中华文物，包括翠玉白菜等珍品。开放时间 8:30 - 18:30。 |\n| 台中 | **逢甲夜市**：台湾最大的夜市之一，汇集各种美食和购物摊位。开放时间 17:00 - 00:00。 |\n| 高雄 | **爱河**：高雄市区的浪漫河流，可乘船游览。船只运营时间 10:00 - 22:00。 |\n| 垦丁 | **高雄市立美术馆**： |\n| 嘉义 | **日月潭**：游船运营时间 8:00 - 17:00。 |\n| 花莲 |  |\n\n","slug":"台湾旅游攻略","published":1,"updated":"2024-12-01T17:39:17.557Z","comments":1,"layout":"post","photos":[],"_id":"cuidCX2GAfEhWTaKhL46U-bj9","content":"<h1 id=\"台湾旅游攻略\"><a href=\"#台湾旅游攻略\" class=\"headerlink\" title=\"台湾旅游攻略\"></a>台湾旅游攻略</h1><h2 id=\"To-do-list\"><a href=\"#To-do-list\" class=\"headerlink\" title=\"To do list\"></a>To do list</h2><ul>\n<li><input disabled=\"\" type=\"checkbox\"> 提前彩印</li>\n<li><input disabled=\"\" type=\"checkbox\"> 机票</li>\n<li><input disabled=\"\" type=\"checkbox\"> 住宿</li>\n<li><input disabled=\"\" type=\"checkbox\"> 交通卡</li>\n<li><input disabled=\"\" type=\"checkbox\"> 电话卡</li>\n<li><input disabled=\"\" type=\"checkbox\"> 金福气</li>\n</ul>\n<h2 id=\"地图\"><a href=\"#地图\" class=\"headerlink\" title=\"地图\"></a>地图</h2><iframe \n    src=\"https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3747610.3074053475!2d116.8590153339058!3d23.4685542600518!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x346ef3065c07572f%3A0xe711f004bf9c5469!2z5Y-w5rm-!5e0!3m2!1szh-CN!2suk!4v1733071246704!5m2!1szh-CN!2suk\" \n    width=\"600\" \n    height=\"450\" \n    style=\"border:0;\" \n    allowfullscreen=\"\" \n    loading=\"lazy\" \n    referrerpolicy=\"no-referrer-when-downgrade\">\n</iframe>\n\n<h2 id=\"旅游地点\"><a href=\"#旅游地点\" class=\"headerlink\" title=\"旅游地点\"></a>旅游地点</h2><table>\n<thead>\n<tr>\n<th>地点</th>\n<th>游玩项目</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>台北</td>\n<td><strong>台北101</strong>：曾是世界最高建筑，设有观景台，可俯瞰台北全景。开放时间 9:00 - 22:00。<br><strong>国立故宫博物院</strong>：收藏丰富的中华文物，包括翠玉白菜等珍品。开放时间 8:30 - 18:30。</td>\n</tr>\n<tr>\n<td>台中</td>\n<td><strong>逢甲夜市</strong>：台湾最大的夜市之一，汇集各种美食和购物摊位。开放时间 17:00 - 00:00。</td>\n</tr>\n<tr>\n<td>高雄</td>\n<td><strong>爱河</strong>：高雄市区的浪漫河流，可乘船游览。船只运营时间 10:00 - 22:00。</td>\n</tr>\n<tr>\n<td>垦丁</td>\n<td><strong>高雄市立美术馆</strong>：</td>\n</tr>\n<tr>\n<td>嘉义</td>\n<td><strong>日月潭</strong>：游船运营时间 8:00 - 17:00。</td>\n</tr>\n<tr>\n<td>花莲</td>\n<td></td>\n</tr>\n</tbody></table>\n","excerpt":"","more":"<h1 id=\"台湾旅游攻略\"><a href=\"#台湾旅游攻略\" class=\"headerlink\" title=\"台湾旅游攻略\"></a>台湾旅游攻略</h1><h2 id=\"To-do-list\"><a href=\"#To-do-list\" class=\"headerlink\" title=\"To do list\"></a>To do list</h2><ul>\n<li><input disabled=\"\" type=\"checkbox\"> 提前彩印</li>\n<li><input disabled=\"\" type=\"checkbox\"> 机票</li>\n<li><input disabled=\"\" type=\"checkbox\"> 住宿</li>\n<li><input disabled=\"\" type=\"checkbox\"> 交通卡</li>\n<li><input disabled=\"\" type=\"checkbox\"> 电话卡</li>\n<li><input disabled=\"\" type=\"checkbox\"> 金福气</li>\n</ul>\n<h2 id=\"地图\"><a href=\"#地图\" class=\"headerlink\" title=\"地图\"></a>地图</h2><iframe \n    src=\"https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3747610.3074053475!2d116.8590153339058!3d23.4685542600518!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x346ef3065c07572f%3A0xe711f004bf9c5469!2z5Y-w5rm-!5e0!3m2!1szh-CN!2suk!4v1733071246704!5m2!1szh-CN!2suk\" \n    width=\"600\" \n    height=\"450\" \n    style=\"border:0;\" \n    allowfullscreen=\"\" \n    loading=\"lazy\" \n    referrerpolicy=\"no-referrer-when-downgrade\">\n</iframe>\n\n<h2 id=\"旅游地点\"><a href=\"#旅游地点\" class=\"headerlink\" title=\"旅游地点\"></a>旅游地点</h2><table>\n<thead>\n<tr>\n<th>地点</th>\n<th>游玩项目</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>台北</td>\n<td><strong>台北101</strong>：曾是世界最高建筑，设有观景台，可俯瞰台北全景。开放时间 9:00 - 22:00。<br><strong>国立故宫博物院</strong>：收藏丰富的中华文物，包括翠玉白菜等珍品。开放时间 8:30 - 18:30。</td>\n</tr>\n<tr>\n<td>台中</td>\n<td><strong>逢甲夜市</strong>：台湾最大的夜市之一，汇集各种美食和购物摊位。开放时间 17:00 - 00:00。</td>\n</tr>\n<tr>\n<td>高雄</td>\n<td><strong>爱河</strong>：高雄市区的浪漫河流，可乘船游览。船只运营时间 10:00 - 22:00。</td>\n</tr>\n<tr>\n<td>垦丁</td>\n<td><strong>高雄市立美术馆</strong>：</td>\n</tr>\n<tr>\n<td>嘉义</td>\n<td><strong>日月潭</strong>：游船运营时间 8:00 - 17:00。</td>\n</tr>\n<tr>\n<td>花莲</td>\n<td></td>\n</tr>\n</tbody></table>\n"},{"title":"Thesis","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-08-24T16:29:00.000Z","password":"b1ab1e892617f210425f658cf1d361b5489028c8771b56d845fe1c62c1fbc8b0","summary":null,"_content":"\n![LuoLei_Poster2022_Page_2](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208251426116.png)\n\n**A novel convolutional neural network approach for classifying brain states under image stimuli**\n\nLei Luo\n\nDr. Toby Wise\n\nDepartment of Neuroimaging\nInstitute of Psychiatry, Psychology & Neuroscience\nKing's College London\nUniversity of London\n\n**Thesis in partial fulfilment for the degree of MSc in Neuroscience September, 2022.**\n\n# Personal Statement:\n\nThe study was designed by Lei Luo under the supervision of Dr. Toby Wise. MEG data was from Wise et al. (2021). The thesis was written entirely by Lei Luo, with language corrections and suggestions from Dr. Toby wise. Any research or work mentioned in the paper has been fully and accurately cited. Computation resource is provided by King\\'s Computational Research, Engineering and Technology Environment (CREATE) (King's College London, 2022). The neural network code is using machine learning library Pytorch (Paszke et al., 2017). Statistics are done with IBM Spss. Topographical maps are generated using library MNE-Python. Code availability: MEG data used in this research in available at https://openneuro.org/datasets/ds003682; and all analysis code in available at https://github.com/ReveRoyl/MT_ML_Decoding.\n\n# Abbreviations\n\nCBAM Convolutional block attention module\n\nCNN Convolutional neural network\n\nECoG Electrocorticography\n\nEEG Electroencephalography\n\nICA Independent Components Analysis\n\nMEG Magnetoencephalography\n\nMLP Multilayer perceptron\n\nMRI Magnetic resonance imaging\n\nfMRI Functional magnetic resonance imaging\n\nFC Fully connected\n\nLSTM Long short-term memory\n\nRNN Recurrent Neural Network\n\nRPS Relative power spectrum\n\nPCA principal component analysis\n\n# Abstract\n\nBackground: The mechanism of human neural responses to different stimuli has always been of interest to neuroscientists. In the clinical situation, tools to distinguish different diseases or states are required. However, classic classification methods have obvious shortcomings: traditional clinical categorical methods may not be competent for behaviour prediction or brain state classification and traditional machine learning models are improvable in classification accuracy. With the increasing use of convolutional neural networks (CNN) in neuroimaging computer-assisted classification, an ensemble classifier of CNNs might be able to mine hidden patterns from MEG signals. However, developing an effective brain state classifier is a difficult task owing to the non-Euclidean graphical nature of magnetoencephalography (MEG) signals.\n\nObjective: This project had two aims: 1) to develop a CNN-based model with better performance in classification than traditional machine learning models; 2) to test if the model can be improved with extra information adding relative power spectrum.\n\nMethods: To address this brain state classification modelling issue, I used MEG signals from 28 participants viewing 14 image stimuli to train the CNN. The CNN subsequently underwent 10-fold cross-validation to ensure proper classification of MEG. I also extracted the relative power spectrum and provided this to the network. The following main techniques were applied in this research, principal component analysis (PCA), convolutional block spatial and temporal features extracting modules, convolutional block attention module (CBAM) techniques, relative power spectrum (RPS) techniques, fully connected (FC) techniques.\n\nResults: In this research, my method was applied to the MEG dataset, the average classification accuracy is 23.07%±7.69%, which is much better than the baseline models: LSTM RNN model 15.38% (p = 6.8 × 10 ^--2^) and simple image classification CNN model 11.53% (p = 5.9 × 10 ^--2^). Relative power spectrum information (mainly beta and delta during this task) successfully informed the model improving its performance.\n\nConclusion: These results demonstrate that my method is feasible for the analysis and classification of brain states. It may help researchers diagnose people in the clinical situations and inform future neurological classification approaches in regard to higher specificity in identifying brain states.\n\n# Introduction\n\n## Machine learning in medical utilisation\n\nSince Donald Hebb first composed the cell assembly theory stating the consistency between neuronal activity and cognitive processes (Brown & Milner, 2003; Shaw, 1986), the idea of neural networks started to stand out in public visibility. Until Frank Rosenblatt first developed and explored the basic ingredients of deep learning (DL) (Tappert, 2019), the only constraint that can slow our steps are applications of math methods. The last past decades have seen the quick and great revolution of artificial intelligence as the development of computer science. What the big breakthrough takes us close to the scientific field are the powerful tools that teach machines to learn about the physical world. Even though machine learning techniques have gradually built their presence in recent decades, the application in medical utilisation lags.\n\nIn the past centuries, neuroscientists have always been attempting to classify and predict the brain's response to the visual world. Recently, with the rapid emergence of novel non-invasive techniques such as magnetoencephalography (MEG), electroencephalography (EEG) and magnetic resonance imaging (MRI), neuroscientists start to use these tools to solve the historical conundrum; and have made huge progress in the visual perceptual decoding or so-called \"brain-reading\" field (W. Huang et al., 2020). Each individual conscious experience is associated with a unique brain activity pattern so that it can be regarded as a fingerprint of specific brain activity. It is theoretically viable to read out one's current idea with a specifically designed computer vision and neuroimaging pattern (Haynes, 2012). In this case, it might be possible that these \"brain-reading\" techniques can tell us that could be helpful with regard to clinical applications. Nowadays, many neural mechanisms have been elucidated. Although the current studies are mostly on a reflective proof of concept track (Hedderich & Eickhoff, 2021), it is promising that these approaches will pave the way and build a solid foundation in regard to clinical applications. In contrast to the classic understanding of some mental mechanisms, more and more researchers believe that traditional categories systems may twist the real cause of diseases or behaviours (Bzdok & Meyer-Lindenberg, 2018). To fill this gap, deep learning techniques have been introduced into disease diagnosis and classification. It can avoid being affected by people's opinion bias but conversely get feedback from people so as to improve its learning ability from existing experience (Currie et al., 2019). Apart from disease classification, it is more profound to study human brain states under different conditions. Further studying of future state simulation has properly gained attention, especially on episodic future thought: the ability to rehearse events in mind, which may be going to happen in one's life trajectory (Schacter et al., 2017; Szpunar, 2010).\n\n## Aversive state reactivation and replay\n\nThe aversive state is critical for harm avoidance, playing a vital role in wilderness survival and social life (Terranova et al., 2022). As part of the aversive state, the observational fear process promotes one's capability of showing empathic fear when seeing other's aversive situations. This process may benefit from the neural replay and reactivation of individuals. The process that current state simulation reinforces the existing memory network is called \"reactivation\" while the neural activity activation is named \"neural replay\". The reactivation is based on past experience and in turn, promotes the storage of it, as well as facilitating the planning, inference and reward values updating (Wimmer & Shohamy, 2012; Wise et al., 2021). As mentioned in the previous section, one way to look at future thought simulation is to investigate memory reactivation.\n\nRecent works have shown that neural replay and reactivation are prior important in avoidance behaviour (Wu et al., 2017), which may provide individuals with a prospective prediction based on the possible consequence simulation (Doll et al., 2015). Since then, it is known \"which\" correlates to the aversive state, the following step is figuring out to what extent neuronal activity is associated with behaviour. Naturally, it encourages researchers to try predicting one's avoidance behaviour with the neuroimaging data recording. In recent years, more and more studies start to use neuroimaging classification to look for the inner mechanisms of brain states' reactivation (Belal et al., 2018; Eichenlaub et al., 2020; Roscow et al., 2021). If we want to look at memory reactivation, what we need is really good decoding methods with neuroimaging data recordings. So, it's important to optimise existing decoding methods as far as possible, which will set the scene for future related work.\n\n## Magnetoencephalography\n\nMagnetoencephalography (MEG) is useful for detecting brain states and evaluating the behavioural response. It allows us to map and locate specific brain areas and ongoing functions (Bunge & Kahn, 2009). The principle of MEG is based on magnetic induction. It is widely known that when neurons are activated, electrical signals will be generated synchronously. According to the magnetic induction principle, when the electrical fields change, secondary magnetic fields are generated. The brain-evoked magnetic field strength is usually in the range of femto-tesla to pico-tesla, i.e., 10--15 to 10-12 tesla (Singh, 2014). With the precise MEG device and mathematical preprocessing methods, these tiny signals are able to be separated from the noise and collected. MEG records magnetic fields, from which can be inferred changes in the transmission of postsynaptic current between cortical neurons.\n\nCompared to other neuroimaging methods, functional magnetic resonance imaging (fMRI) has high spatial resolution but a low temporal resolution (Dash, Sao, et al., 2019); electroencephalography (EEG) records the electrical field that may twist between skin and skull, and EEG is based to reference point location hence it is sensitive to small measurement error. Electrocorticography (ECoG) is an invasive method, so it is not suitable for healthy participants and some patients; MEG stands out for its higher spatial, temporal resolution and dynamic time sequentiality. At the same time, MEG, as a non-invasive method, has its specific advantage: low preparation time, which supports a possibility for most clinical conditions. Furthermore, as novel portable MEG devices come out, it creates opportunity for various ages participants and patients (Boto et al., 2018). MEG data records complex high-dimensional information about the brain network and the responding source locations, which is hard to collect with classic classification methods (Giovannetti et al., 2021). However, in the analysis period, it is a burden for researchers to do classification with MEG data: it is complex to correctly extract required signals during preprocessing, and lots of related experience is required when dealing with complex sensors and waveform patterns. Hence deep learning is expected to lighten the load of researchers, add the universal applicability of classification and increase the prediction accuracy. In this case, it is a challenge to choose the proper neural network.\n\n## Convolutional Neural Network\n\nThe CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018). The same as the real neural networks in the brain, neurons in CNN process limited input data in a restricted receptive field and cooperate with each other by overlapping to cover the whole visual space (the filter extracting the features is called kernels). It is an automatic feature extraction process. Thus, it is now necessary to manually design feature extraction algorithms, which is required in traditional machine learning algorithms. It is also the main advantage of CNN to learn features from input data: avoiding the impact of artificial artefact in the algorithm design step. The main specialization of CNN is clearly the convolution part, which is a linear mathematic operation allowing extracting the nearby features of input data. The convolutional operation generates a series of machine-recognizable output features. It is suggested that the convolutional layer can be considered as a graphical pattern mining or feature extraction process (Li et al., 2018). What is more, previous research has shown the ability of CNN as a tool for analysing MEG data, which is in detail classifying brain activity and identifying potential neural sources (Zubarev et al., 2019). The process of generating the features map is following the sequential architecture, which is not like a cyclical recurrent neural network. A CNN model is usually composed of the input layer (the first layer where input data is passed in), multiple convolutional layers (feature extraction layers), alternative pooling layers (downsampling layer for feature maps), fully connecting layers (used to map the feature vectors obtained from previous feature extraction layers to the next layer), and output layers (the final layer where predictions are made). Inside each layer, activation functions are optional. A simple CNN network is shown as an example in figure 1. The convolutional layer receives input data, apply the convolution process to the data, and passes data to the following step. In the convolution function shown in equation 1, the f stands for input data; k stands for kernel filter, m, n respectively stands for the result matrix rows and columns index:\n\n$$\\begin{matrix}\nG\\lbrack m,\\ n\\rbrack = \\ (f*k)\\lbrack m,\\ n\\rbrack = \\ \\sum_{i = 1}^{m}\\ \\sum_{j = 1}^{n}\\ \\ k\\lbrack i,\\ j\\rbrack f\\lbrack m - i,\\ n - j\\rbrack\\ \\ (1) \\\\\n\\end{matrix}$$\n\nAs shown in figure 2 (A), a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure 2 (B)) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well (Y. Huang et al., 2015).\n\n![image-20220824171734112](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717167.png)\n\n**Figure 1.** A simple CNN architecture illustration (5 convolutional layers and pooling layers, 3 fully connected layers)\n\n![image-20220824171744899](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717946.png)\n\n**Figure 2**. Convolution illustration (A), a 3\\*3 kernel filter (blue) is applied to a 6\\*6 input data (red) and give an output (green) as 4\\*4 (feature map). Max pooling illustration (B), data transformation is processed from 4\\*4 input to 2\\*2 output.\n\nIn previous research, sequence data were usually analysed with the recurrent neural network (RNN) while the convolutional neural network (CNN) was used for image prediction. However, recent works have demonstrated the effectiveness of CNN in time-sequential data (Bai et al., 2018) where CNN even have a longer effective memory. It provides us with the theoretical basis for utilizing various CNN models in behaviour prediction. CNN has also been used for MEG classification in recent years: previous research has successfully predicted different diseases such as brain tumours (Rajasree et al., 2021) and Alzheimer's disease (Aoe et al., 2019; Giovannetti et al., 2021). In fact, some studies have shown that CNN offers an unreplaceable advantage for patterns modelling those other techniques may not be disposed to reveal (Giovannetti et al., 2021). However, it is still an emergent topic to use deep learning instead of the classic machine learning method. As a special machine learning technique, deep learning benefits from the fast development of high-performance computation (HPC). One example is that deep learning can use the CUDA framework to accelerate training. As the GPU accelerators become more and more performance and energy-consuming effective (Faraji et al., 2016), the cheaper computation source becomes more and more available. Some evidence has shown that deep learning performs better than the classic machine learning methods when doing MEG classification (Aoe et al., 2019; RaviPrakash et al., 2020; Zheng et al., 2020). In addition to these the ability to recognize temporal and spatial data patterns, CNN has the unique character of sharing weight among neurons in a convolutional layer (Anelli et al., 2021). In this case, the parameters quantity reduces sharply which benefits analysing complex structured MEG data.\n\n## Band power and Transfer learning\n\nCNNs are expected to have good performance for extracting features from MEG data, but the performance can be boosted by augmenting the data we feed into them. Here are some ways I did this with MEG data. MEG signals reflect brain activity, in which the brainwave can be deposed into different frequency power bands, such as delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). And these different brainwave frequency bands usually are associated with different brain states, such as the alpha band has been implicated in visual attention (Rohenkohl & Nobre, 2011). and the beta band is usually associated with anxiety (Einöther et al., 2013). That is why I think particular frequency bands might be important in helping classify accurately. In order to understand if it is available to extract critical information from the aversive state, it may be viable to extract different power bands and analyse them as a neural activity representation. One drawback of this method is it may reduce the available temporal information in MEG data, but it can not be denied that it provides an excellent and reliable method to study brain states (Newson & Thiagarajan, 2019).\n\nHowever, the trained model may not be suitable for data collected under other conditions. Between the MEG device and its recording source location, there are the skull, skin and even air, which may all affect the signals we get: the deeper source is, the more affected it will be. In addition to these confounds, the geometric shape of the skull which varies a lot between different people, also affects a lot (Hagemann et al., 2008). In order to generalize the model, power spectrum standardization and relative power computation are necessary. Moreover, it is reported that transfer learning can help to improve learning efficiency by reusing or transferring learnt parameters (Karimpanal & Bouffanais, 2018). In this case, transfer learning may reduce the influence of these confound factors and increase the generality of models.\n\nTransfer learning is the machine learning technique which allows a network to learn in one condition and improve its performance under another relevant condition. It is an optimization method to inform new task learning with relative learnt knowledge (Soria Olivas & IGI Global., 2010). For the transfer learning process, only part of the model parameters is trained and adjusted, which is called \"tuning\". If all network parameters are opened for training, it is easy to fall into the state of overfitting the target training set, thereby reducing the generalization performance of the model. The first few layers of the network are generally used for feature extraction. If the difference between the source task and the target task is not quite significant and the model has achieved good performance in the source task, there is no need to perform training from the beginning (Karimpanal & Bouffanais, 2018). In this case, the transfer learning technique solves the small data availability problem: with a small amount of data, it helps eliminate the overfitting problem and reduce the model training time. Some evidence suggests that it can keep at a high accuracy level and saves 90% time (Dash, Ferrari, et al., 2019). It has been widely used to transfer the weight or bias of the current network to a newly trained network with the object of faster convergence and better performance.\n\nFor aversive state reactivation prediction, previous studies have provided an approach with logistic regression methods and get a good accuracy (Wise et al., 2021) With a different approach (CNN) we could probably detect brain state reactivation with much better accuracy and learn a lot more about it. My first aim is to optimize the model with new techniques such as CNN and apply spectrum power. The second aim is to generalize the model by informing one participant model with other participants' data. I assume that: first, the performance of the CNN model is better than traditional machine learning models; second, adding the power spectrum to augment data will improve the performance as well.\n\n# Materials and Methods\n\n## Dataset\n\nThe participants, study design, data collection and preprocessing sections and relevant information are included and published in the paper \\\"Model-based aversive learning in humans is supported by preferential task state reactivation\\\" (Wise et al., 2021). Open access to the original MEG data can be found in the public repository: https://openneuro.org/datasets/ds003682. In total 28 participants took the task. The task is designed as follows: participants were required to sit with the MEG device in front of a monitor, where 14 images were shown. The recording duration of each stimulus is 1.29 seconds (from 0.5 before to 0.79 after image is shown). MEG data were collected with CTF 275-channel axial gradiometer system (CTF Omega, VSM MedTech). In the preprocessing session, the Maxwell filter was applied to remove noise firstly. Then a high pass filter above 0.5 Hz and a low pass filter below 45 Hz were applied. Afterwards, signal components were separated with independent component analysis (ICA) to isolate noise-related components in the setting of finding components which explain 95% variance. To reduce information loss, MEG data was upsampled and the window width of data was set as 800 time points (Aoe et al., 2019) when training the model to get better performance.\n\n## Power spectrum extraction\n\nIn order to compute the relative power (percentage power) of MEG signals, the first step is to extract the power band with the specific frequency. The frequency bands were chosen to be delta (0.5-4 Hz), theta (4-8 Hz), low alpha (8-10 Hz), high alpha (8-12 Hz) beta (12-30 Hz), and gamma (above 30 Hz). Actually, the gamma frequency was below 50 Hz because it is impossible to detect any information above 50 Hz as the data are sampled at 100 Hz.\n\nFirstly the power spectral densities (PSD) and frequency of each band were derived using Welch's method with mne.time_frequency.psd_array_welch() function provided by MNE-Python (Percival & Walden, 1993; Slepian, 1978). The reason for choosing this function is this function gives a single value for each trial but other methods that give you power at each timepoint. Then the PSD of each band was integrated with the frequency as spacing point using composite Simpson's rule. The absolute power in a specific location is the average number of the power from several adjacent electrodes. The relative power is the ratio of the absolute power of a band to the total band power in all frequencies. As shown in equation 2, the r represents the relative power of a frequency band, the a stands for absolute power of the same frequency band, Pi 's are the absolute power in all frequency bands:\n\n$$\\begin{matrix}\nr = \\frac{a}{P_{t}} = \\ \\frac{a}{\\sum_{\\ }^{\\ }{P_{i}\\ }}\\ \\ (2) \\\\\n\\end{matrix}$$\n\nEventually, the absolute and relative power bands are transformed from input data in $\\mathbb{R}$C×T (where $\\mathbb{R}$ is a vector space) to $\\mathbb{R}$C×F, where C is the number of channels, T is time points and F is the number of frequency bands, i.e., 6 here.\n\n## Neural Network architecture\n\nIn order to classify different 14 categories brain states under 14 stimuli based on MEG signals, I proposed a CNN model ASRCNet-v1. The input data are MEG recordings from 24 subjects (4 were removed because of its information missing). In order to augment the data, the input of last fully connected layer was concatenated with relative power bands in all frequencies. The neural network structure of ASRCNet-v1 was developed based on the previously reported model EnvNet-v2 and MNet (Aoe et al., 2019; Tokozume et al., 2017; Tokozume & Harada, 2017), which was used to classify environmental sounds and Alzheimer's diseases. The detailed configuration of ASRNet-v1 is as demonstrated in figure 3 and the data processing is demonstrated in figure 4. There are three convolutional blocks in total: two feature extracting blocks: spatial and temporal blocks; and a CBAM block after them. In the first convolutional layer, the global features were extracted with a large filter, which has the same kernel width as the channel number of inputs. The kernel length of the first layer is set to be 64. The first layer generates a feature map in $\\mathbb{R}$S×1×T' from input data in $\\mathbb{R}$C×T, where the T is larger than T's. The C (number of channels) is larger than S (number of spatial filters) such that the channel dimension is reduced. The second convolutional layer in the spatial block generates a feature map in $\\mathbb{R}$S'×1×T'' with frequency features then. Afterwards, the data is downsampled with a max pooling layer and swapped along the axis between S and 1, i.e., from $\\mathbb{R}$S'×1×T'' to $\\mathbb{R}$`<!-- -->`{=html}1×S'×T''. This operation allows data being considered as the image changing the convolutional direction (Tokozume et al., 2017). The second block consists of eight convolutional layers and four max pooling layers. The kernel size of convolutional layers is small and decreases every two layers in order to extract local frequency temporal features from the output feature map from the previous layer. Relu is the activation function for all convolutional layers in the spatial block. Max pooling layers are attached after every two convolutional layers.\n\nThe attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images' edges. The outputs are passed to an MLP (multilayer perceptron) network with the same weight. The MLP layer has a bottleneck. The width and length or the number of neurons in this MLP layer are decided by a reduction ratio of 16. Then the sum of two outputs from the MLP layer is given to the sigmoid activation function in order to project values in features map into $\\mathbb{R \\in}(0,1)$. Finally, the channel attention module returns a feature map as the product of input and calculated scale. Compared with the channel attention module, spatial attention seems to be simpler, which includes one convolutional layer and the sigmoid activation function. The same as the channel attention module, the spatial attention module returns a feature map as the product of input from the previous module and calculated scale in this module.\n\nThen the first fully connected layer (FC) comes to play the role of classifier, which is projecting the \"distributed feature representation\" of the feature map to sample labels space $\\mathbb{R}$L, where L is the number of features. In the object of data augmentation, the input is concatenated with relative power bands in all frequencies. The following step is another FC layer, which finally generates 14 features corresponding to the number of categories. At last, data is passed to the softmax activation function to convert the numbers vector into the probabilities vector. To avoid overfitting, 30 % dropout is applied after the last 4 spatial convolutional layers and 50 % dropout is applied after the first fully connected layer (Srivastava et al., 2014); batch normalization is applied to boost the speed of learning (Ioffe & Szegedy, 2015).\n\n![image-20220824171834060](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718131.png)\n\n**Figure 3**. Detailed configuration of ASRCNet-v1. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply\n\n![image-20220824171849114](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718214.png)\n\n**Figure 4.** Chart flow of data processing. The original data is shaped as (64,1,272,800) where 64 is the number of batches, 272 is the number of channels and 800 is the number of time points.\n\n## Model training and testing\n\nThe input data is a total of 900 epochs of 800-time-point MEG signals from 272 channels. At the beginning, the data was separately processed directly with the neural network and the Fourier transformation. The latter process provides neural network with relative band power in frequency delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). The input data is shuffled and scaled with variance scaling method, which reasonably preserves the dynamic range of data, before being fed into the model. The first step is to normalize all input data for the reason that normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance. The normalization process is as shown in equation 3, where m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1:\n\n$$\\begin{matrix}\n{x_{i}}^{'} = \\frac{\\left| x_{i} - \\frac{1}{m}\\sum_{1}^{m}\\ x \\right|}{\\sqrt{\\sum_{1}^{m}\\ x^{2}}}\\ \\ (3) \\\\\n\\end{matrix}$$\n\nIn every training period, the input is one piece of a small segment of 64 batches of MEG signals segmented with non-overlapped 800-time-point time windows. The cross-entropy loss function was chosen to train the model because of its better performance in computing losses for discrete distributions. I chose SGD to be the optimizer because it is reported to have a better generalization capacity compared with Adam even though it may converge slower (Hardt et al., 2015). For the SGD optimizer, I set the initial learning rate as 0.0005, and momentum to 0.9. Specifically for the parameters in the second FF layer, a weight decay as 0.0005 is set keeping away from overfitting. The initial weight is randomized, which is because it is reported there is no obvious performance promotion with manually weight initialization (Hoshen et al., 2015). In order to improve training efficiency and avoid overfitting, I adapted the update step: I used the dynamic learning rate when the valid loss approaches a plateau (function 4, where $\\lambda$ represents learning decay and L represents valid loss). The patience of the dynamic learning rate is set to 1, the threshold is set to 0.001 and learning rate decay is set to 1e-8. Since there are a large number of features during training, in order to avert overfitting, I introduced L2 regularization (ridge regularization) with the regularization parameter lambda to 0.001. After the trial with model performance in different checkpoints, early stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting.\n\n$$\\begin{matrix}\n\\alpha_{t + 1}\\  = \\ \\left\\{ \\begin{matrix}\n\\alpha_{t} \\times \\lambda & if\\ L_{t + 1} > \\ \\ L_{t} \\\\\n\\alpha_{t} & if\\ L_{t + 1} \\leq \\ \\ L_{t} \\\\\n\\end{matrix} \\right.\\ \\ \\ (4) \\\\\n\\end{matrix}$$\n\nFinally, the possibility of each label is generated in the model. It eventually gives only one \"most possible\" label after comparing the possibility in all labels. In order to prove the validity of this CNN model. ASRCNet-v1's performance is evaluated with 10-fold cross-validation, where 1 in 10 sets is used as validating set every time.\n\n# Result\n\nThe key results of the article are summarised and given in this section. This section first offers auxiliary findings with the whole dataset and furthermore demonstrates results using a single MEG dataset (i.e., a single subject). The accuracy measure is utilized to compare the performance of various models. All models had previously undergone testing on participant 1 to provide an initial indication of performance. The suggested model solution is validated across all of the participants once all models have been evaluated on participant 1. Additional tests are specifically run on the best model ASRCNet and other two main baseline models (LSTM RNN and simple CNN). For models tested on all subjects, model training was done within each participant, trained and evaluated only using its individual recording MEG data. Additionally, I set the windows of input data to 800 ms enabling an accurate comparison of several test models. Relative power spectrum is introduced to the training improving performance of models. Moreover, average topographical maps are graphed as the representation of the MEG signals intensities in the anatomical brain, illustrating the general topographic maps of brain states from different stimuli in brain states reactivation tasks.\n\n## Topographical map\n\nThe global anatomical brain maps are generated with concatenated dataset and were back fitted to MEG recordings. The average MEG signals with different stimuli are calculated and graphed showing commons and differences among various brain states under different stimuli. In the brain states reactivation process, under the different stimuli, the topographical maps all look very similar. There are subtle differences but in general the pattern is the same: similar brain regions are activated while to the different extent (figure 5). This means we need some kind of algorithm that is sensitive to these very small differences between stimuli.\n\nThe result shows the rationality of extracting features of brain states under different stimuli. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, ASRCNet is an effective and reasonable approach to classifying these states.\n\n![image-20220824171924099](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241719153.png)\n\n**Figure 5**. brain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.\n\n## Power spectrum\n\nIn order to determine the effect of different brain wave frequencies, power spectral density (PSD) at all 272 channels is calculated. The 6 power bands are divided by the sum generating 1632 decoding features (272 channels for each of the 6 frequency bands). I analysed the power spectrum in all frequencies of input 800-time-point MEG signals for different participants. The results show that beta and delta waves are in the large and major proportion (figure 6). It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721133.gif)![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241720900.gif)\n\n**Figure 6.** Relative and absolute power spectrum (average of 24 subjects), beta (12 to 30 Hz) and delta (0.5 to 4 Hz) waves are in the major proportion\n\n## Classification of multiple brain states reactivations\n\nIn order to classify the brain states reactivation with different given image stimuli (figure 7), ASRCNet-v1, the classifier is developed. It is trained with MEG signals for each of the images. The representative MEG signals for each reactivation states that ASRCNet-v1 accurately identified is displayed in figure 8. A sample of an 800-time-point segment of the preprocessed MEG signals is displayed in the panel, where each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. Therefore, none of these signals are removed because of bad channels. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data. It is suggested that ASRCNet-v1 correctly categorised the MEG signals during aversive state by utilising features that not presents in the typical classification.\n\n![image-20220824172119017](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721069.png)\n\n**Figure 7.** image stimuli in different brain states reactivation tasks (Wise et al., 2021), from left to right, above to bottom are labelled as stimulus_i.\n\n![image-20220824172132497](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721550.png)\n\n**Figure 8.** representative MEG signal which is classified by the ASRCNet-v1 (from one sample participant)\n\nPrincipal component analysis (PCA) (30 to 50 out of 272 channels) was tested to be applied to the input data before feeding data into the model. But the result shows that PCA does not obviously improve the classification performance of ASRCNet-v1. The classification accuracy was not obviously affected when PCA was applied. In the beginning, I didn\\'t get satisfactory learning convergence results. When the input data values are clipped to be in of standardized bounds, the learning curves became smooth and the valid loss gradually decreased step by step.\n\nSince there are 14 stimuli and the chances for all stimuli are equal, the random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of ASRCNet-v1 is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. I compared the performance of different models (figure 9) and found it is suggested that ASRCNet-v1 outperformed any other simple approach (LSTM RNN, simple CNN with 2 convolutional layers and 1 pooling layer). Compared with the other classification approach, ASRCNet-v1 exhibits the best classification performance (p = 6.8 × 10 --2 for LSTM RNN, p = 5.9 × 10 --2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of ASRCNet-v1 is able to reach 33.33%. The classification accuracy variety between simple CNN and ASRCNet may suggest that the classification depends on some event-independent signal: the temporal and spatial features. To which extent the performance is a result of the detected differences in the temporal and spatial features of MEG signals, remained to be explored.\n\n![image-20220824172150882](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721928.png)\n\n**Figure 9.** performance of different model boxplot. The boxplot shows the classification accuracy of different models. The random chance baseline is 7.14% (1/14 = 7.14%). All models learned from MEG signals (all accuracies are above 7.14% and gives better predictions. ASRCNet gives the best classification accuracy as 23.07%±7.69% (mean ± standard deviation).\n\n# Discussion\n\nIn this section, I am going to discuss the experimental results, findings, and potential future work. The focus of this paper is to explore the potential of deep learning, especially CNN to classify the aversive brain states associated with visual images. The MEG signals are complex and have low signal-to-noise ratios data structures. What is more, the aversive brain states parameters are continuous variables. Therefore, the aim is to solve a complex classification task. To optimally address this problem, a CNN model ASRCNet (inspired by Mnet and EnvNet, which was used in MEG data) is proposed as the deep learning solution in this research because of its ability to extract complex patterns from raw input data. One focus is to understand whether the CNN model is able to perform the decoding task. The analysis has been evaluated in two distinct steps: First, two well-known architectures (LSTM RNN and CNN: the former model is known as a good fit for sequential data and the second model is usually used in image classification) were selected as baseline models for the purpose of understanding the potential of general-purpose DL models that are not specific to MEG analysis. Second, I test the prediction and classification ability of the CNN-based architecture specially designed for MEG recordings. The results show that ASRCNet provide better performance compared to the other two baseline models. Since the model is specifically designed to extract features from MEG recordings, it can be considered an option in the field of brain state classification.\n\nI trained a novel deep neural network ASRCNet to classify 14 brain states using data from MEG recordings. It can distinguish brain states under different image stimuli with an accuracy at least as good as, or even higher than the baseline pipeline. ASRCNet allows the extraction of spatial and temporal information from the informative MEG data. It is suggested that classification decisions are unlikely to be associated with activities that are unrelated to the task itself, for example, mind wandering. The trained ASRCNet successfully classifies brain states with relatively high accuracy and specificity. Previous research has been focusing on common symptoms of psychopathology, but less on the domain of aversive states. This is a study using MEG signals to classify different aversive brain states with a classifier. The high specificity for all states suggests that ASRCNet will help improve our understanding of the human cognitive image process. One thing we can do with such a CNN classifier is to look at state reactivation in cognitive tasks. Moreover, this classifier is expected to be applied in clinical studies in order to diagnose nonorganic neurological diseases. As shown in the topological map in the result section, these brain states are hard to classify with the naked eyes. The information from such computer-aided diagnosis may be a novel biomarker for these diseases in clinical practice.\n\nThe advantage of using this neural network is its comprehensive training process, entirely based on gradient descent-based optimization without intermediate steps. As research develops toward explainable artificial intelligence (XAI), the parameters of a model may be going to have a direct and explainable connection to their task. On the separate brain states classification task, ASRCNet also performs on par with state-of-the-art, potentially making it a general method for other neuroimaging data. What is more, as shown in the result section, the classification accuracy varies a lot between simple image classification CNN and ASRCNet. One reason the model is successful in classification is that the first part of the network learns to extract the correct features, while the last layer classifies the extracted features. It may suggest that the classification of such brain states depends on some event-independent temporal and spatial features signal. Some evidence suggests that using features automatically extracted with deep learning models rather than manually selected, is able to help achieve the highest levels of accuracy compared to other machine learning approaches. It is reported that most of the best ImageNet is achieved by using some kind of data augmentation, instead of feature engineering and dimensionality reduction (de Bardeci et al., 2021). However, it was reported that logistic regression may achieve better classification accuracy than ASRCNet (Wise et al., 2021). It may be because of the algorithmic Incompleteness of the current model. Future work on improving the algorithm may improve the performance of CNN models.\n\nASRCNet is a relatively robust approach among different subjects. In this research, 14 different stimuli were applied to 24 subjects (data from 4 subjects were removed because of the smaller segment length). ASRCNet successfully classifies states in 24 different subjects with high accuracy, demonstrating the robustness of the CNN model. However, the data itself used in the research has potential for improvement: the 13th stimulus is a face picture, which may be different from other stimuli reflecting brain states (Rapcsak, 2019). What is more, it is concerned that the trained model may have difficulty classifying brain states using data recorded by another MEG scanner. Improvements in current source estimation and alignment techniques may make the method adaptable to different MEG scanners (Pettersen et al., 2006). Apart from the robustness, the size of the data itself may also affect the classification accuracy. A limitation of this experiment is, the same as in most other studies, the cross-validation approach was performed during the validation process, rather than using a separate test dataset. It was reported that using a separate test set in the DL model may help yield the highest level of validity in the results (de Bardeci et al., 2021). Although superficially, it is a relatively advanced practice to use data from the same subject in the training and test sets, there is room for improvement. A possible improvement is to create additional test sets beyond the limited availability of data. Due to the high inter-individual specificity and intra-individual stability of MEG data, it is difficult for the network to learn common features between subjects. The current approach of the model is to recognize different subjects by identifying individual MEG features of different subjects. Therefore, even though the network can achieve high levels of accuracy, classification and prediction will be unpredictable when it is applied to entirely new datasets from different subjects. The application of transfer learning methods with the small tuning of part of model parameters may be a possible solution. However, when performing transfer learning, it is generally assumed that different tasks are related. In this case, how to define the correlation and mathematically describe the strength of the correlation between tasks are subjective decisions that are biased toward researchers. The image classification-related studies usually use ImageNet as a pre-trained model for transfer learning because the large dataset of ImageNet itself ensures that the trained model has high generalization. But when we use a small dataset such as in this experiment, transfer learning may not only fail to achieve the expected result but result in negative transferring which is even worse than training a network from nowhere. For example, AlphaGo Zero learned from zero without any supervision or using chess manual data but achieves higher performance than AlphaGo Lee which is based on chess manual replays (Silver et al., 2017). Therefore, how to perform correct and effective transfer learning is one of the focuses of future work.\n\nDeep learning from scratch is often difficult with limited amounts of data. However, even with the limited amount of data in this study, I successfully classified 14 types of brain states. One reason for this success is that I enlarged the dataset by dividing each subject\\'s 1170 seconds of data into 900 segments of 1.3-second time data, allowing me to train 14 classes using approximately 25200 segments. The data amount is slightly less than the amount of MNIST, a database of handwritten digits that is often used to train deep neural networks, but still shows that I have a reasonable amount of data to train a network of such size (Yann LeCun et al., 2012). However, during the training process, the training data generally has a tendency to overfit even though I applied dropout (randomly ignored neurons in network) and batch normalization (normalizes input mini-batches from last layer). The proposed CNN model ASRCNet may benefit from the increase in dataset size. It improves with more training data because deep learning performance is reported to improve significantly with larger datasets (Greenspan et al., 2016). Therefore, it can be taken into account to train this model with more data in hopes of improving model performance. In addition, more research has shown that MEG and EEG provide complementary information, and other modalities such as MRI also provide additional useful information. Using data from multiple method sources at the same time may improve model performance (Dale & Sereno, 1993; Sharon et al., 2007). In future work, combining MEG signal data with EEG to create a multimodal data input may help improve the accuracy of brain states classification.\n\nIn this ASRCNet, the integration of the relative power spectrum improves the CNN model's performance. Since the beta and delta waves mainly encode perceptual information, the relative power spectrum ensemble adds relevant information to the model so that the different band power values can inform the network. Therefore, the model can adjust the weights accordingly. Additionally, the relative power spectrum may also add valuable information about artefacts or ambient noise (Anelli et al., 2021). All these deep learning models overfit the training dataset more or less, even applied regularization techniques like dropout and batch normalization. The additional information provided by the relative power spectrum ensemble helps the model to generalize. There is still room to improve the model's performance as the aspect of power spectrum extraction. In the process of relative power spectrum extraction, the wavelet transform can be considered as an optional alternative to Fourier analysis for the reason that the wavelet transform has the multi-scale analysis ability to extract features from the dataset and generate input images for training the model. Compared with the Fourier transform, the wavelet transform is a local transform of temporal and frequency data, so it can more effectively extract information from the signal by performing multi-scale refinement analysis with operations like scaling and translation (Yu & Guowen, 1994), thus has the potential to solve some difficult problems that Fourier transform cannot deal with. Fourier transform can only get a frequency spectrum, but wavelet transform can get a temporal frequency spectrum which not only the frequency can be obtained, but also the time can be located. Some recent studies successfully use the wavelet packet decomposition method to extract time-frequency features and use a dynamic frequency feature selection algorithm to select the most accurate features for each subject (Luo et al., 2016). However, other studies have shown the drawback of wavelet packet decomposition: although this method improves the classification accuracy, it requires a lot of work to select the most suitable features for each subject, and the feature extraction for different target individuals is poorly general (Dai et al., 2020). Only considering the power spectrum is quite limiting at the current moment. The convolutional operation executed by most popular machine learning libraries in deep learning is actually computing the correlation measurement (Graves, 2012). Future work investigating state classification and reactivation should also take steps to measure event-related desynchronization and synchronization in the context of the data generated.\n\nAnother idea to optimize the model is to replace the fully connected layer with global average pooling. The model holds a redundancy of fully connected layer parameters where fully connected layer parameters can account for about 80% of the entire network parameters. Some recent network models with excellent performance, such as ResNet, are trying to use global average pooling (GAP) layer instead of a fully connected layer for fusion. For the learned deep features, loss functions such as SoftMax are still used as the network objective function to guide the learning process (Liu & Zeng, 2022) Some evidence suggests that networks that replace a fully connected layer with a GAP layer may have better classification performance (Wei et al., 2018). However, other studies have pointed out that when applying transfer learning, the fine-tuned results of networks without fully connected layers are worse than those with fully connected layers. Therefore, fully connected can be regarded as a guard for model representation capabilities, especially in the case that there are big differences between the source domain and the target domain, the redundant parameters of FC can maintain a fine model capacity to ensure the migration of model representation capabilities (Zhang et al., 2018). Future work can explore the role of the GAP layer and fully connected layer in detail.\n\nASRCNet can extract and analyze features that deep learning neural networks use for classification, which may help researchers understand brain states better. The inherent hidden patterns in brain states and related brain neural activity that deep learning may reveal some fundamental mechanisms behind human behaviour. To the extent these can be explained, researchers are encouraged to apply these sophisticated deep learning modelling techniques to obtain accurate classification and prediction results and to generalize the results more carefully in a wider range of conditions. Moreover, understanding the relevant studies that extract these hidden patterns can increase and deepen our understanding of the brain state electrophysiological characterization.\n\n# Reference\n\nAnelli, M., Lauri, S. P., Advisor, P., & Zubarev, M. I. (2021). *Using deep learning to predict continuous hand kinematics from magnetoencephalographic (MEG) measurements of electromagnetic brain activity.* www.aalto.fi\n\nAoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., & Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. *Scientific Reports*, *9*(1). https://doi.org/10.1038/S41598-019-41500-X\n\nBai, S., Kolter, J. Z., & Koltun, V. (2018). *An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling*. https://doi.org/10.48550/arxiv.1803.01271\n\nBaumeister, J., Barthel, T., Geiss, K. R., & Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. *Http://Dx.Doi.Org/10.1179/147683008X301478*, *11*(3), 103--110. https://doi.org/10.1179/147683008X301478\n\nBelal, S., Cousins, J., El-Deredy, W., Parkes, L., Schneider, J., Tsujimura, H., Zoumpoulaki, A., Perapoch, M., Santamaria, L., & Lewis, P. (2018). Identification of memory reactivation during sleep by EEG classification. *NeuroImage*, *176*, 203--214. https://doi.org/10.1016/J.NEUROIMAGE.2018.04.029\n\nBoto, E., Holmes, N., Leggett, J., Roberts, G., Shah, V., Meyer, S. S., Muñoz, L. D., Mullinger, K. J., Tierney, T. M., Bestmann, S., Barnes, G. R., Bowtell, R., & Brookes, M. J. (2018). Moving magnetoencephalography towards real-world applications with a wearable system. *Nature 2018 555:7698*, *555*(7698), 657--661. https://doi.org/10.1038/nature26147\n\nBrown, R. E., & Milner, P. M. (2003). The legacy of Donald O. Hebb: More than the Hebb Synapse. *Nature Reviews Neuroscience*, *4*(12), 1013--1019. https://doi.org/10.1038/NRN1257\n\nBunge, S. A., & Kahn, I. (2009). Cognition: An Overview of Neuroimaging Techniques. *Encyclopedia of Neuroscience*, 1063--1067. https://doi.org/10.1016/B978-008045046-9.00298-9\n\nBzdok, D., & Meyer-Lindenberg, A. (2018). Machine Learning for Precision Psychiatry: Opportunities and Challenges. *Biological Psychiatry. Cognitive Neuroscience and Neuroimaging*, *3*(3), 223--230. https://doi.org/10.1016/J.BPSC.2017.11.007\n\nCurrie, G., Hawk, K. E., Rohren, E., Vial, A., & Klein, R. (2019). Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging. *Journal of Medical Imaging and Radiation Sciences*, *50*(4), 477--487. https://doi.org/10.1016/j.jmir.2019.09.005\n\nDai, G., Zhou, J., Huang, J., & Wang, N. (2020). HS-CNN: a CNN with hybrid convolution scale for EEG motor imagery classification. *Journal of Neural Engineering*, *17*(1), 016025. https://doi.org/10.1088/1741-2552/AB405F\n\nDale, A. M., & Sereno, M. I. (1993). Improved Localizadon of Cortical Activity by Combining EEG and MEG with MRI Cortical Surface Reconstruction: A Linear Approach. *Journal of Cognitive Neuroscience*, *5*(2), 162--176. https://doi.org/10.1162/JOCN.1993.5.2.162\n\nDash, D., Ferrari, P., Heitzman, D., & Wang, J. (2019). Decoding Speech from Single Trial MEG Signals Using Convolutional Neural Networks and Transfer Learning. *Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS*, 5531--5535. https://doi.org/10.1109/EMBC.2019.8857874\n\nDash, D., Sao, A. K., Wang, J., & Biswal, B. (2019). How many fmri scans are necessary and sufficient for resting brain connectivity analysis? *2018 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2018 - Proceedings*, 494--498. https://doi.org/10.1109/GLOBALSIP.2018.8646415\n\nde Bardeci, M., Ip, C. T., & Olbrich, S. (2021). Deep learning applied to electroencephalogram data in mental disorders: A systematic review. *Biological Psychology*, *162*, 108117. https://doi.org/10.1016/J.BIOPSYCHO.2021.108117\n\nDoll, B. B., Duncan, K. D., Simon, D. A., Shohamy, D., & Daw, N. D. (2015). Model-based choices involve prospective neural activity. *Nature Neuroscience*, *18*(5), 767. https://doi.org/10.1038/NN.3981\n\nEichenlaub, J. B., Biswal, S., Peled, N., Rivilis, N., Golby, A. J., Lee, J. W., Westover, M. B., Halgren, E., & Cash, S. S. (2020). Reactivation of Motor-Related Gamma Activity in Human NREM Sleep. *Frontiers in Neuroscience*, *14*. https://doi.org/10.3389/FNINS.2020.00449\n\nEinöther, S. J. L., Giesbrecht, T., Walden, C. M., van Buren, L., van der Pijl, P. C., & de Bruin, E. A. (2013). Attention Benefits of Tea and Tea Ingredients: A Review of the Research to Date. *Tea in Health and Disease Prevention*, 1373--1384. https://doi.org/10.1016/B978-0-12-384937-3.00115-4\n\nFaraji, I., Mirsadeghi, S. H., & Afsahi, A. (2016). Topology-aware GPU selection on multi-GPU nodes. *Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016*, 712--720. https://doi.org/10.1109/IPDPSW.2016.44\n\nGiovannetti, A., Susi, G., Casti, P., Mencattini, A., Pusil, S., López, M. E., di Natale, C., & Martinelli, E. (2021). Deep-MEG: spatiotemporal CNN features and multiband ensemble classification for predicting the early signs of Alzheimer's disease with magnetoencephalography. *Neural Computing and Applications*, *33*(21), 14651--14667. https://doi.org/10.1007/S00521-021-06105-4/TABLES/4\n\nGramfort, A., Luessi, M., Larson, E., Engemann, D. A., Strohmeier, D., Brodbeck, C., Parkkonen, L., & Hämäläinen, M. S. (2014). MNE software for processing MEG and EEG data. *NeuroImage*, *86*, 446--460. https://doi.org/10.1016/J.NEUROIMAGE.2013.10.027\n\nGraves, A. (2012). *Supervised Sequence Labelling*. 5--13. https://doi.org/10.1007/978-3-642-24797-2_2\n\nGreenspan, H., van Ginneken, B., & Summers, R. M. (2016). Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique. *IEEE Transactions on Medical Imaging*, *35*(5), 1153--1159. https://doi.org/10.1109/TMI.2016.2553401\n\nHagemann, D., Hewig, J., Walter, C., & Naumann, E. (2008). Skull thickness and magnitude of EEG alpha activity. *Clinical Neurophysiology*, *119*(6), 1271--1280. https://doi.org/10.1016/J.CLINPH.2008.02.010\n\nHardt, M., Recht, B., & Singer, Y. (2015). Train faster, generalize better: Stability of stochastic gradient descent. *33rd International Conference on Machine Learning, ICML 2016*, *3*, 1868--1877. https://doi.org/10.48550/arxiv.1509.01240\n\nHaynes, J. D. (2012). Brain reading. *I Know What You're Thinking: Brain Imaging and Mental Privacy*. https://doi.org/10.1093/ACPROF:OSO/9780199596492.003.0003\n\nHedderich, D. M., & Eickhoff, S. B. (2021). Machine learning for psychiatry: getting doctors at the black box? *Molecular Psychiatry*, *26*(1), 23. https://doi.org/10.1038/S41380-020-00931-Z\n\nHoshen, Y., Weiss, R. J., & Wilson, K. W. (2015). Speech acoustic modeling from raw multichannel waveforms. *ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings*, *2015-August*, 4624--4628. https://doi.org/10.1109/ICASSP.2015.7178847\n\nHuang, W., Yan, H., Wang, C., Li, J., Yang, X., Li, L., Zuo, Z., Zhang, J., & Chen, H. (2020). Long short-term memory-based neural decoding of object categories evoked by natural images. *Human Brain Mapping*, *41*(15), 4442--4453. https://doi.org/10.1002/hbm.25136\n\nHuang, Y., Sun, X., Lu, M., & Xu, M. (2015). Channel-Max, Channel-Drop and Stochastic Max-pooling. *IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops*, *2015-October*, 9--17. https://doi.org/10.1109/CVPRW.2015.7301267\n\nIBM Corp. (2021). *IBM SPSS Statistics for Windows*. https://hadoop.apache.org\n\nIoffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. *32nd International Conference on Machine Learning, ICML 2015*, *1*, 448--456. https://doi.org/10.48550/arxiv.1502.03167\n\nKarimpanal, T. G., & Bouffanais, R. (2018). Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning. *Adaptive Behavior*, *27*(2), 111--126. https://doi.org/10.1177/1059712318818568\n\nKhan, S., Rahmani, H., Shah, S. A. A., & Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. *A Guide to Convolutional Neural Networks for Computer Vision*. https://doi.org/10.1007/978-3-031-01821-3\n\nKing's College London. (2022). *King's Computational Research, Engineering and Technology Environment (CREATE).*\n\nLi, H., Ellis, J. G., Zhang, L., & Chang, S. F. (2018). PatternNet: Visual pattern mining with deep neural network. *ICMR 2018 - Proceedings of the 2018 ACM International Conference on Multimedia Retrieval*, 291--299. https://doi.org/10.1145/3206025.3206039\n\nLiu, W., & Zeng, Y. (2022). Motor Imagery Tasks EEG Signals Classification Using ResNet with Multi-Time-Frequency Representation. *2022 7th International Conference on Intelligent Computing and Signal Processing, ICSP 2022*, 2026--2029. https://doi.org/10.1109/ICSP54964.2022.9778786\n\nLuo, J., Feng, Z., Zhang, J., & Lu, N. (2016). Dynamic frequency feature selection based approach for classification of motor imageries. *Computers in Biology and Medicine*, *75*, 45--53. https://doi.org/10.1016/J.COMPBIOMED.2016.03.004\n\nNewson, J. J., & Thiagarajan, T. C. (2019). EEG Frequency Bands in Psychiatric Disorders: A Review of Resting State Studies. *Frontiers in Human Neuroscience*, *12*, 521. https://doi.org/10.3389/FNHUM.2018.00521/BIBTEX\n\nPaszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., Facebook, Z. D., Research, A. I., Lin, Z., Desmaison, A., Antiga, L., Srl, O., & Lerer, A. (2017). *Automatic differentiation in PyTorch*.\n\nPercival, D. B., & Walden, A. T. (1993). Spectral Analysis for Physical Applications. *Spectral Analysis for Physical Applications*. https://doi.org/10.1017/CBO9780511622762\n\nPettersen, K. H., Devor, A., Ulbert, I., Dale, A. M., & Einevoll, G. T. (2006). Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities. *Journal of Neuroscience Methods*, *154*(1--2), 116--133. https://doi.org/10.1016/J.JNEUMETH.2005.12.005\n\nRajasree, R., Columbus, C. C., & Shilaja, C. (2021). Multiscale-based multimodal image classification of brain tumor using deep learning method. *Neural Computing and Applications*, *33*(11), 5543--5553. https://doi.org/10.1007/S00521-020-05332-5/FIGURES/9\n\nRapcsak, S. Z. (2019). Face Recognition. *Current Neurology and Neuroscience Reports*, *19*(7). https://doi.org/10.1007/S11910-019-0960-9\n\nRaviPrakash, H., Korostenskaja, M., Castillo, E. M., Lee, K. H., Salinas, C. M., Baumgartner, J., Anwar, S. M., Spampinato, C., & Bagci, U. (2020). Deep Learning Provides Exceptional Accuracy to ECoG-Based Functional Language Mapping for Epilepsy Surgery. *Frontiers in Neuroscience*, *14*. https://doi.org/10.3389/FNINS.2020.00409/FULL\n\nRohenkohl, G., & Nobre, A. C. (2011). Alpha Oscillations Related to Anticipatory Attention Follow Temporal Expectations. *The Journal of Neuroscience*, *31*(40), 14076. https://doi.org/10.1523/JNEUROSCI.3387-11.2011\n\nRoscow, E. L., Chua, R., Costa, R. P., Jones, M. W., & Lepora, N. (2021). Learning offline: memory replay in biological and artificial reinforcement learning. *Trends in Neurosciences*, *44*(10), 808--821. https://doi.org/10.1016/J.TINS.2021.07.007\n\nSchacter, D. L., Benoit, R. G., & Szpunar, K. K. (2017). Episodic Future Thinking: Mechanisms and Functions. *Current Opinion in Behavioral Sciences*, *17*, 41. https://doi.org/10.1016/J.COBEHA.2017.06.002\n\nSharon, D., Hämäläinen, M. S., Tootell, R. B. H., Halgren, E., & Belliveau, J. W. (2007). The advantage of combining MEG and EEG: Comparison to fMRI in focally stimulated visual cortex. *NeuroImage*, *36*(4), 1225--1235. https://doi.org/10.1016/J.NEUROIMAGE.2007.03.066\n\nShaw, G. L. (1986). Donald Hebb: The Organization of Behavior. *Brain Theory*, 231--233. https://doi.org/10.1007/978-3-642-70911-1_15\n\nSilver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui, F., Sifre, L., van den Driessche, G., Graepel, T., & Hassabis, D. (2017). Mastering the game of Go without human knowledge. *Nature 2017 550:7676*, *550*(7676), 354--359. https://doi.org/10.1038/nature24270\n\nSingh, S. P. (2014). Magnetoencephalography: Basic principles. *Annals of Indian Academy of Neurology*, *17*(Suppl 1), S107. https://doi.org/10.4103/0972-2327.128676\n\nSlepian, D. (1978). Prolate Spheroidal Wave Functions, Fourier Analysis, and Uncertainty---V: The Discrete Case. *Bell System Technical Journal*, *57*(5), 1371--1430. https://doi.org/10.1002/J.1538-7305.1978.TB02104.X\n\nSoria Olivas, E., & IGI Global. (2010). *Handbook of research on machine learning applications and trends : algorithms, methods, and techniques*. 83.\n\nSrivastava, N., Hinton, G., Krizhevsky, A., & Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. *Journal of Machine Learning Research*, *15*, 1929--1958. https://doi.org/10.5555/2627435\n\nSzpunar, K. K. (2010). Episodic Future Thought: An Emerging Concept. *Perspectives on Psychological Science : A Journal of the Association for Psychological Science*, *5*(2), 142--162. https://doi.org/10.1177/1745691610362350\n\nTappert, C. C. (2019). Who is the father of deep learning? *Proceedings - 6th Annual Conference on Computational Science and Computational Intelligence, CSCI 2019*, 343--348. https://doi.org/10.1109/CSCI49370.2019.00067\n\nTerranova, J. I., Yokose, J., Osanai, H., Marks, W. D., Yamamoto, J., Ogawa, S. K., & Kitamura, T. (2022). Hippocampal-amygdala memory circuits govern experience-dependent observational fear. *Neuron*, *110*(8), 1416-1431.e13. https://doi.org/10.1016/J.NEURON.2022.01.019\n\nTokozume, Y., & Harada, T. (2017). Learning environmental sounds with end-to-end convolutional neural network. *ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings*, 2721--2725. https://doi.org/10.1109/ICASSP.2017.7952651\n\nTokozume, Y., Ushiku, Y., & Harada, T. (2017). Learning from Between-class Examples for Deep Sound Recognition. *6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings*. https://doi.org/10.48550/arxiv.1711.10282\n\nValueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., & Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. *Mathematics and Computers in Simulation*, *177*, 232--243. https://doi.org/10.1016/J.MATCOM.2020.04.031\n\nWei, X. S., Zhang, C. L., Zhang, H., & Wu, J. (2018). Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences. *IEEE Transactions on Affective Computing*, *9*(3), 303--315. https://doi.org/10.1109/TAFFC.2017.2762299\n\nWimmer, G. E., & Shohamy, D. (2012). Preference by association: how memory mechanisms in the hippocampus bias decisions. *Science (New York, N.Y.)*, *338*(6104), 270--273. https://doi.org/10.1126/SCIENCE.1223252\n\nWise, T., Liu, Y., Chowdhury, F., & Dolan, R. J. (2021). Model-based aversive learning in humans is supported by preferential task state reactivation. *Science Advances*, *7*(31), 9616--9644. https://doi.org/10.1126/SCIADV.ABF9616\n\nWu, C. T., Haggerty, D., Kemere, C., & Ji, D. (2017). Hippocampal awake replay in fear memory retrieval. *Nature Neuroscience*, *20*(4), 571. https://doi.org/10.1038/NN.4507\n\nYann LeCun, Corinna Cortes, & Chris Burges. (2012). *MNIST handwritten digit database*. http://yann.lecun.com/exdb/mnist/\n\nYu, F. T. S., & Guowen, L. (1994). Short-time Fourier transform and wavelet transform with Fourier-domain processing. *Applied Optics*, *33*(23), 5262--5270. https://doi.org/10.1364/AO.33.005262\n\nZhang, C. L., Luo, J. H., Wei, X. S., & Wu, J. (2018). In defense of fully connected layers in visual representation transfer. *Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)*, *10736 LNCS*, 807--817. https://doi.org/10.1007/978-3-319-77383-4_79/TABLES/4\n\nZheng, L., Liao, P., Luo, S., Sheng, J., Teng, P., Luan, G., & Gao, J. H. (2020). EMS-Net: A Deep Learning Method for Autodetecting Epileptic Magnetoencephalography Spikes. *IEEE Transactions on Medical Imaging*, *39*(6), 1833--1844. https://doi.org/10.1109/TMI.2019.2958699\n\nZubarev, I., Zetter, R., Halme, H. L., & Parkkonen, L. (2019). Adaptive neural network classifier for decoding MEG signals. *NeuroImage*, *197*, 425--434. https://doi.org/10.1016/J.NEUROIMAGE.2019.04.068\n\n \n","source":"_posts/Thesis.md","raw":"---\ntitle: Thesis\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-08-24 17:29\npassword: b1ab1e892617f210425f658cf1d361b5489028c8771b56d845fe1c62c1fbc8b0\nsummary:\ntags:\n- project\ncategories:\n- Neuroscience programming\n---\n\n![LuoLei_Poster2022_Page_2](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208251426116.png)\n\n**A novel convolutional neural network approach for classifying brain states under image stimuli**\n\nLei Luo\n\nDr. Toby Wise\n\nDepartment of Neuroimaging\nInstitute of Psychiatry, Psychology & Neuroscience\nKing's College London\nUniversity of London\n\n**Thesis in partial fulfilment for the degree of MSc in Neuroscience September, 2022.**\n\n# Personal Statement:\n\nThe study was designed by Lei Luo under the supervision of Dr. Toby Wise. MEG data was from Wise et al. (2021). The thesis was written entirely by Lei Luo, with language corrections and suggestions from Dr. Toby wise. Any research or work mentioned in the paper has been fully and accurately cited. Computation resource is provided by King\\'s Computational Research, Engineering and Technology Environment (CREATE) (King's College London, 2022). The neural network code is using machine learning library Pytorch (Paszke et al., 2017). Statistics are done with IBM Spss. Topographical maps are generated using library MNE-Python. Code availability: MEG data used in this research in available at https://openneuro.org/datasets/ds003682; and all analysis code in available at https://github.com/ReveRoyl/MT_ML_Decoding.\n\n# Abbreviations\n\nCBAM Convolutional block attention module\n\nCNN Convolutional neural network\n\nECoG Electrocorticography\n\nEEG Electroencephalography\n\nICA Independent Components Analysis\n\nMEG Magnetoencephalography\n\nMLP Multilayer perceptron\n\nMRI Magnetic resonance imaging\n\nfMRI Functional magnetic resonance imaging\n\nFC Fully connected\n\nLSTM Long short-term memory\n\nRNN Recurrent Neural Network\n\nRPS Relative power spectrum\n\nPCA principal component analysis\n\n# Abstract\n\nBackground: The mechanism of human neural responses to different stimuli has always been of interest to neuroscientists. In the clinical situation, tools to distinguish different diseases or states are required. However, classic classification methods have obvious shortcomings: traditional clinical categorical methods may not be competent for behaviour prediction or brain state classification and traditional machine learning models are improvable in classification accuracy. With the increasing use of convolutional neural networks (CNN) in neuroimaging computer-assisted classification, an ensemble classifier of CNNs might be able to mine hidden patterns from MEG signals. However, developing an effective brain state classifier is a difficult task owing to the non-Euclidean graphical nature of magnetoencephalography (MEG) signals.\n\nObjective: This project had two aims: 1) to develop a CNN-based model with better performance in classification than traditional machine learning models; 2) to test if the model can be improved with extra information adding relative power spectrum.\n\nMethods: To address this brain state classification modelling issue, I used MEG signals from 28 participants viewing 14 image stimuli to train the CNN. The CNN subsequently underwent 10-fold cross-validation to ensure proper classification of MEG. I also extracted the relative power spectrum and provided this to the network. The following main techniques were applied in this research, principal component analysis (PCA), convolutional block spatial and temporal features extracting modules, convolutional block attention module (CBAM) techniques, relative power spectrum (RPS) techniques, fully connected (FC) techniques.\n\nResults: In this research, my method was applied to the MEG dataset, the average classification accuracy is 23.07%±7.69%, which is much better than the baseline models: LSTM RNN model 15.38% (p = 6.8 × 10 ^--2^) and simple image classification CNN model 11.53% (p = 5.9 × 10 ^--2^). Relative power spectrum information (mainly beta and delta during this task) successfully informed the model improving its performance.\n\nConclusion: These results demonstrate that my method is feasible for the analysis and classification of brain states. It may help researchers diagnose people in the clinical situations and inform future neurological classification approaches in regard to higher specificity in identifying brain states.\n\n# Introduction\n\n## Machine learning in medical utilisation\n\nSince Donald Hebb first composed the cell assembly theory stating the consistency between neuronal activity and cognitive processes (Brown & Milner, 2003; Shaw, 1986), the idea of neural networks started to stand out in public visibility. Until Frank Rosenblatt first developed and explored the basic ingredients of deep learning (DL) (Tappert, 2019), the only constraint that can slow our steps are applications of math methods. The last past decades have seen the quick and great revolution of artificial intelligence as the development of computer science. What the big breakthrough takes us close to the scientific field are the powerful tools that teach machines to learn about the physical world. Even though machine learning techniques have gradually built their presence in recent decades, the application in medical utilisation lags.\n\nIn the past centuries, neuroscientists have always been attempting to classify and predict the brain's response to the visual world. Recently, with the rapid emergence of novel non-invasive techniques such as magnetoencephalography (MEG), electroencephalography (EEG) and magnetic resonance imaging (MRI), neuroscientists start to use these tools to solve the historical conundrum; and have made huge progress in the visual perceptual decoding or so-called \"brain-reading\" field (W. Huang et al., 2020). Each individual conscious experience is associated with a unique brain activity pattern so that it can be regarded as a fingerprint of specific brain activity. It is theoretically viable to read out one's current idea with a specifically designed computer vision and neuroimaging pattern (Haynes, 2012). In this case, it might be possible that these \"brain-reading\" techniques can tell us that could be helpful with regard to clinical applications. Nowadays, many neural mechanisms have been elucidated. Although the current studies are mostly on a reflective proof of concept track (Hedderich & Eickhoff, 2021), it is promising that these approaches will pave the way and build a solid foundation in regard to clinical applications. In contrast to the classic understanding of some mental mechanisms, more and more researchers believe that traditional categories systems may twist the real cause of diseases or behaviours (Bzdok & Meyer-Lindenberg, 2018). To fill this gap, deep learning techniques have been introduced into disease diagnosis and classification. It can avoid being affected by people's opinion bias but conversely get feedback from people so as to improve its learning ability from existing experience (Currie et al., 2019). Apart from disease classification, it is more profound to study human brain states under different conditions. Further studying of future state simulation has properly gained attention, especially on episodic future thought: the ability to rehearse events in mind, which may be going to happen in one's life trajectory (Schacter et al., 2017; Szpunar, 2010).\n\n## Aversive state reactivation and replay\n\nThe aversive state is critical for harm avoidance, playing a vital role in wilderness survival and social life (Terranova et al., 2022). As part of the aversive state, the observational fear process promotes one's capability of showing empathic fear when seeing other's aversive situations. This process may benefit from the neural replay and reactivation of individuals. The process that current state simulation reinforces the existing memory network is called \"reactivation\" while the neural activity activation is named \"neural replay\". The reactivation is based on past experience and in turn, promotes the storage of it, as well as facilitating the planning, inference and reward values updating (Wimmer & Shohamy, 2012; Wise et al., 2021). As mentioned in the previous section, one way to look at future thought simulation is to investigate memory reactivation.\n\nRecent works have shown that neural replay and reactivation are prior important in avoidance behaviour (Wu et al., 2017), which may provide individuals with a prospective prediction based on the possible consequence simulation (Doll et al., 2015). Since then, it is known \"which\" correlates to the aversive state, the following step is figuring out to what extent neuronal activity is associated with behaviour. Naturally, it encourages researchers to try predicting one's avoidance behaviour with the neuroimaging data recording. In recent years, more and more studies start to use neuroimaging classification to look for the inner mechanisms of brain states' reactivation (Belal et al., 2018; Eichenlaub et al., 2020; Roscow et al., 2021). If we want to look at memory reactivation, what we need is really good decoding methods with neuroimaging data recordings. So, it's important to optimise existing decoding methods as far as possible, which will set the scene for future related work.\n\n## Magnetoencephalography\n\nMagnetoencephalography (MEG) is useful for detecting brain states and evaluating the behavioural response. It allows us to map and locate specific brain areas and ongoing functions (Bunge & Kahn, 2009). The principle of MEG is based on magnetic induction. It is widely known that when neurons are activated, electrical signals will be generated synchronously. According to the magnetic induction principle, when the electrical fields change, secondary magnetic fields are generated. The brain-evoked magnetic field strength is usually in the range of femto-tesla to pico-tesla, i.e., 10--15 to 10-12 tesla (Singh, 2014). With the precise MEG device and mathematical preprocessing methods, these tiny signals are able to be separated from the noise and collected. MEG records magnetic fields, from which can be inferred changes in the transmission of postsynaptic current between cortical neurons.\n\nCompared to other neuroimaging methods, functional magnetic resonance imaging (fMRI) has high spatial resolution but a low temporal resolution (Dash, Sao, et al., 2019); electroencephalography (EEG) records the electrical field that may twist between skin and skull, and EEG is based to reference point location hence it is sensitive to small measurement error. Electrocorticography (ECoG) is an invasive method, so it is not suitable for healthy participants and some patients; MEG stands out for its higher spatial, temporal resolution and dynamic time sequentiality. At the same time, MEG, as a non-invasive method, has its specific advantage: low preparation time, which supports a possibility for most clinical conditions. Furthermore, as novel portable MEG devices come out, it creates opportunity for various ages participants and patients (Boto et al., 2018). MEG data records complex high-dimensional information about the brain network and the responding source locations, which is hard to collect with classic classification methods (Giovannetti et al., 2021). However, in the analysis period, it is a burden for researchers to do classification with MEG data: it is complex to correctly extract required signals during preprocessing, and lots of related experience is required when dealing with complex sensors and waveform patterns. Hence deep learning is expected to lighten the load of researchers, add the universal applicability of classification and increase the prediction accuracy. In this case, it is a challenge to choose the proper neural network.\n\n## Convolutional Neural Network\n\nThe CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018). The same as the real neural networks in the brain, neurons in CNN process limited input data in a restricted receptive field and cooperate with each other by overlapping to cover the whole visual space (the filter extracting the features is called kernels). It is an automatic feature extraction process. Thus, it is now necessary to manually design feature extraction algorithms, which is required in traditional machine learning algorithms. It is also the main advantage of CNN to learn features from input data: avoiding the impact of artificial artefact in the algorithm design step. The main specialization of CNN is clearly the convolution part, which is a linear mathematic operation allowing extracting the nearby features of input data. The convolutional operation generates a series of machine-recognizable output features. It is suggested that the convolutional layer can be considered as a graphical pattern mining or feature extraction process (Li et al., 2018). What is more, previous research has shown the ability of CNN as a tool for analysing MEG data, which is in detail classifying brain activity and identifying potential neural sources (Zubarev et al., 2019). The process of generating the features map is following the sequential architecture, which is not like a cyclical recurrent neural network. A CNN model is usually composed of the input layer (the first layer where input data is passed in), multiple convolutional layers (feature extraction layers), alternative pooling layers (downsampling layer for feature maps), fully connecting layers (used to map the feature vectors obtained from previous feature extraction layers to the next layer), and output layers (the final layer where predictions are made). Inside each layer, activation functions are optional. A simple CNN network is shown as an example in figure 1. The convolutional layer receives input data, apply the convolution process to the data, and passes data to the following step. In the convolution function shown in equation 1, the f stands for input data; k stands for kernel filter, m, n respectively stands for the result matrix rows and columns index:\n\n$$\\begin{matrix}\nG\\lbrack m,\\ n\\rbrack = \\ (f*k)\\lbrack m,\\ n\\rbrack = \\ \\sum_{i = 1}^{m}\\ \\sum_{j = 1}^{n}\\ \\ k\\lbrack i,\\ j\\rbrack f\\lbrack m - i,\\ n - j\\rbrack\\ \\ (1) \\\\\n\\end{matrix}$$\n\nAs shown in figure 2 (A), a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure 2 (B)) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well (Y. Huang et al., 2015).\n\n![image-20220824171734112](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717167.png)\n\n**Figure 1.** A simple CNN architecture illustration (5 convolutional layers and pooling layers, 3 fully connected layers)\n\n![image-20220824171744899](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717946.png)\n\n**Figure 2**. Convolution illustration (A), a 3\\*3 kernel filter (blue) is applied to a 6\\*6 input data (red) and give an output (green) as 4\\*4 (feature map). Max pooling illustration (B), data transformation is processed from 4\\*4 input to 2\\*2 output.\n\nIn previous research, sequence data were usually analysed with the recurrent neural network (RNN) while the convolutional neural network (CNN) was used for image prediction. However, recent works have demonstrated the effectiveness of CNN in time-sequential data (Bai et al., 2018) where CNN even have a longer effective memory. It provides us with the theoretical basis for utilizing various CNN models in behaviour prediction. CNN has also been used for MEG classification in recent years: previous research has successfully predicted different diseases such as brain tumours (Rajasree et al., 2021) and Alzheimer's disease (Aoe et al., 2019; Giovannetti et al., 2021). In fact, some studies have shown that CNN offers an unreplaceable advantage for patterns modelling those other techniques may not be disposed to reveal (Giovannetti et al., 2021). However, it is still an emergent topic to use deep learning instead of the classic machine learning method. As a special machine learning technique, deep learning benefits from the fast development of high-performance computation (HPC). One example is that deep learning can use the CUDA framework to accelerate training. As the GPU accelerators become more and more performance and energy-consuming effective (Faraji et al., 2016), the cheaper computation source becomes more and more available. Some evidence has shown that deep learning performs better than the classic machine learning methods when doing MEG classification (Aoe et al., 2019; RaviPrakash et al., 2020; Zheng et al., 2020). In addition to these the ability to recognize temporal and spatial data patterns, CNN has the unique character of sharing weight among neurons in a convolutional layer (Anelli et al., 2021). In this case, the parameters quantity reduces sharply which benefits analysing complex structured MEG data.\n\n## Band power and Transfer learning\n\nCNNs are expected to have good performance for extracting features from MEG data, but the performance can be boosted by augmenting the data we feed into them. Here are some ways I did this with MEG data. MEG signals reflect brain activity, in which the brainwave can be deposed into different frequency power bands, such as delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). And these different brainwave frequency bands usually are associated with different brain states, such as the alpha band has been implicated in visual attention (Rohenkohl & Nobre, 2011). and the beta band is usually associated with anxiety (Einöther et al., 2013). That is why I think particular frequency bands might be important in helping classify accurately. In order to understand if it is available to extract critical information from the aversive state, it may be viable to extract different power bands and analyse them as a neural activity representation. One drawback of this method is it may reduce the available temporal information in MEG data, but it can not be denied that it provides an excellent and reliable method to study brain states (Newson & Thiagarajan, 2019).\n\nHowever, the trained model may not be suitable for data collected under other conditions. Between the MEG device and its recording source location, there are the skull, skin and even air, which may all affect the signals we get: the deeper source is, the more affected it will be. In addition to these confounds, the geometric shape of the skull which varies a lot between different people, also affects a lot (Hagemann et al., 2008). In order to generalize the model, power spectrum standardization and relative power computation are necessary. Moreover, it is reported that transfer learning can help to improve learning efficiency by reusing or transferring learnt parameters (Karimpanal & Bouffanais, 2018). In this case, transfer learning may reduce the influence of these confound factors and increase the generality of models.\n\nTransfer learning is the machine learning technique which allows a network to learn in one condition and improve its performance under another relevant condition. It is an optimization method to inform new task learning with relative learnt knowledge (Soria Olivas & IGI Global., 2010). For the transfer learning process, only part of the model parameters is trained and adjusted, which is called \"tuning\". If all network parameters are opened for training, it is easy to fall into the state of overfitting the target training set, thereby reducing the generalization performance of the model. The first few layers of the network are generally used for feature extraction. If the difference between the source task and the target task is not quite significant and the model has achieved good performance in the source task, there is no need to perform training from the beginning (Karimpanal & Bouffanais, 2018). In this case, the transfer learning technique solves the small data availability problem: with a small amount of data, it helps eliminate the overfitting problem and reduce the model training time. Some evidence suggests that it can keep at a high accuracy level and saves 90% time (Dash, Ferrari, et al., 2019). It has been widely used to transfer the weight or bias of the current network to a newly trained network with the object of faster convergence and better performance.\n\nFor aversive state reactivation prediction, previous studies have provided an approach with logistic regression methods and get a good accuracy (Wise et al., 2021) With a different approach (CNN) we could probably detect brain state reactivation with much better accuracy and learn a lot more about it. My first aim is to optimize the model with new techniques such as CNN and apply spectrum power. The second aim is to generalize the model by informing one participant model with other participants' data. I assume that: first, the performance of the CNN model is better than traditional machine learning models; second, adding the power spectrum to augment data will improve the performance as well.\n\n# Materials and Methods\n\n## Dataset\n\nThe participants, study design, data collection and preprocessing sections and relevant information are included and published in the paper \\\"Model-based aversive learning in humans is supported by preferential task state reactivation\\\" (Wise et al., 2021). Open access to the original MEG data can be found in the public repository: https://openneuro.org/datasets/ds003682. In total 28 participants took the task. The task is designed as follows: participants were required to sit with the MEG device in front of a monitor, where 14 images were shown. The recording duration of each stimulus is 1.29 seconds (from 0.5 before to 0.79 after image is shown). MEG data were collected with CTF 275-channel axial gradiometer system (CTF Omega, VSM MedTech). In the preprocessing session, the Maxwell filter was applied to remove noise firstly. Then a high pass filter above 0.5 Hz and a low pass filter below 45 Hz were applied. Afterwards, signal components were separated with independent component analysis (ICA) to isolate noise-related components in the setting of finding components which explain 95% variance. To reduce information loss, MEG data was upsampled and the window width of data was set as 800 time points (Aoe et al., 2019) when training the model to get better performance.\n\n## Power spectrum extraction\n\nIn order to compute the relative power (percentage power) of MEG signals, the first step is to extract the power band with the specific frequency. The frequency bands were chosen to be delta (0.5-4 Hz), theta (4-8 Hz), low alpha (8-10 Hz), high alpha (8-12 Hz) beta (12-30 Hz), and gamma (above 30 Hz). Actually, the gamma frequency was below 50 Hz because it is impossible to detect any information above 50 Hz as the data are sampled at 100 Hz.\n\nFirstly the power spectral densities (PSD) and frequency of each band were derived using Welch's method with mne.time_frequency.psd_array_welch() function provided by MNE-Python (Percival & Walden, 1993; Slepian, 1978). The reason for choosing this function is this function gives a single value for each trial but other methods that give you power at each timepoint. Then the PSD of each band was integrated with the frequency as spacing point using composite Simpson's rule. The absolute power in a specific location is the average number of the power from several adjacent electrodes. The relative power is the ratio of the absolute power of a band to the total band power in all frequencies. As shown in equation 2, the r represents the relative power of a frequency band, the a stands for absolute power of the same frequency band, Pi 's are the absolute power in all frequency bands:\n\n$$\\begin{matrix}\nr = \\frac{a}{P_{t}} = \\ \\frac{a}{\\sum_{\\ }^{\\ }{P_{i}\\ }}\\ \\ (2) \\\\\n\\end{matrix}$$\n\nEventually, the absolute and relative power bands are transformed from input data in $\\mathbb{R}$C×T (where $\\mathbb{R}$ is a vector space) to $\\mathbb{R}$C×F, where C is the number of channels, T is time points and F is the number of frequency bands, i.e., 6 here.\n\n## Neural Network architecture\n\nIn order to classify different 14 categories brain states under 14 stimuli based on MEG signals, I proposed a CNN model ASRCNet-v1. The input data are MEG recordings from 24 subjects (4 were removed because of its information missing). In order to augment the data, the input of last fully connected layer was concatenated with relative power bands in all frequencies. The neural network structure of ASRCNet-v1 was developed based on the previously reported model EnvNet-v2 and MNet (Aoe et al., 2019; Tokozume et al., 2017; Tokozume & Harada, 2017), which was used to classify environmental sounds and Alzheimer's diseases. The detailed configuration of ASRNet-v1 is as demonstrated in figure 3 and the data processing is demonstrated in figure 4. There are three convolutional blocks in total: two feature extracting blocks: spatial and temporal blocks; and a CBAM block after them. In the first convolutional layer, the global features were extracted with a large filter, which has the same kernel width as the channel number of inputs. The kernel length of the first layer is set to be 64. The first layer generates a feature map in $\\mathbb{R}$S×1×T' from input data in $\\mathbb{R}$C×T, where the T is larger than T's. The C (number of channels) is larger than S (number of spatial filters) such that the channel dimension is reduced. The second convolutional layer in the spatial block generates a feature map in $\\mathbb{R}$S'×1×T'' with frequency features then. Afterwards, the data is downsampled with a max pooling layer and swapped along the axis between S and 1, i.e., from $\\mathbb{R}$S'×1×T'' to $\\mathbb{R}$`<!-- -->`{=html}1×S'×T''. This operation allows data being considered as the image changing the convolutional direction (Tokozume et al., 2017). The second block consists of eight convolutional layers and four max pooling layers. The kernel size of convolutional layers is small and decreases every two layers in order to extract local frequency temporal features from the output feature map from the previous layer. Relu is the activation function for all convolutional layers in the spatial block. Max pooling layers are attached after every two convolutional layers.\n\nThe attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images' edges. The outputs are passed to an MLP (multilayer perceptron) network with the same weight. The MLP layer has a bottleneck. The width and length or the number of neurons in this MLP layer are decided by a reduction ratio of 16. Then the sum of two outputs from the MLP layer is given to the sigmoid activation function in order to project values in features map into $\\mathbb{R \\in}(0,1)$. Finally, the channel attention module returns a feature map as the product of input and calculated scale. Compared with the channel attention module, spatial attention seems to be simpler, which includes one convolutional layer and the sigmoid activation function. The same as the channel attention module, the spatial attention module returns a feature map as the product of input from the previous module and calculated scale in this module.\n\nThen the first fully connected layer (FC) comes to play the role of classifier, which is projecting the \"distributed feature representation\" of the feature map to sample labels space $\\mathbb{R}$L, where L is the number of features. In the object of data augmentation, the input is concatenated with relative power bands in all frequencies. The following step is another FC layer, which finally generates 14 features corresponding to the number of categories. At last, data is passed to the softmax activation function to convert the numbers vector into the probabilities vector. To avoid overfitting, 30 % dropout is applied after the last 4 spatial convolutional layers and 50 % dropout is applied after the first fully connected layer (Srivastava et al., 2014); batch normalization is applied to boost the speed of learning (Ioffe & Szegedy, 2015).\n\n![image-20220824171834060](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718131.png)\n\n**Figure 3**. Detailed configuration of ASRCNet-v1. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply\n\n![image-20220824171849114](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718214.png)\n\n**Figure 4.** Chart flow of data processing. The original data is shaped as (64,1,272,800) where 64 is the number of batches, 272 is the number of channels and 800 is the number of time points.\n\n## Model training and testing\n\nThe input data is a total of 900 epochs of 800-time-point MEG signals from 272 channels. At the beginning, the data was separately processed directly with the neural network and the Fourier transformation. The latter process provides neural network with relative band power in frequency delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). The input data is shuffled and scaled with variance scaling method, which reasonably preserves the dynamic range of data, before being fed into the model. The first step is to normalize all input data for the reason that normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance. The normalization process is as shown in equation 3, where m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1:\n\n$$\\begin{matrix}\n{x_{i}}^{'} = \\frac{\\left| x_{i} - \\frac{1}{m}\\sum_{1}^{m}\\ x \\right|}{\\sqrt{\\sum_{1}^{m}\\ x^{2}}}\\ \\ (3) \\\\\n\\end{matrix}$$\n\nIn every training period, the input is one piece of a small segment of 64 batches of MEG signals segmented with non-overlapped 800-time-point time windows. The cross-entropy loss function was chosen to train the model because of its better performance in computing losses for discrete distributions. I chose SGD to be the optimizer because it is reported to have a better generalization capacity compared with Adam even though it may converge slower (Hardt et al., 2015). For the SGD optimizer, I set the initial learning rate as 0.0005, and momentum to 0.9. Specifically for the parameters in the second FF layer, a weight decay as 0.0005 is set keeping away from overfitting. The initial weight is randomized, which is because it is reported there is no obvious performance promotion with manually weight initialization (Hoshen et al., 2015). In order to improve training efficiency and avoid overfitting, I adapted the update step: I used the dynamic learning rate when the valid loss approaches a plateau (function 4, where $\\lambda$ represents learning decay and L represents valid loss). The patience of the dynamic learning rate is set to 1, the threshold is set to 0.001 and learning rate decay is set to 1e-8. Since there are a large number of features during training, in order to avert overfitting, I introduced L2 regularization (ridge regularization) with the regularization parameter lambda to 0.001. After the trial with model performance in different checkpoints, early stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting.\n\n$$\\begin{matrix}\n\\alpha_{t + 1}\\  = \\ \\left\\{ \\begin{matrix}\n\\alpha_{t} \\times \\lambda & if\\ L_{t + 1} > \\ \\ L_{t} \\\\\n\\alpha_{t} & if\\ L_{t + 1} \\leq \\ \\ L_{t} \\\\\n\\end{matrix} \\right.\\ \\ \\ (4) \\\\\n\\end{matrix}$$\n\nFinally, the possibility of each label is generated in the model. It eventually gives only one \"most possible\" label after comparing the possibility in all labels. In order to prove the validity of this CNN model. ASRCNet-v1's performance is evaluated with 10-fold cross-validation, where 1 in 10 sets is used as validating set every time.\n\n# Result\n\nThe key results of the article are summarised and given in this section. This section first offers auxiliary findings with the whole dataset and furthermore demonstrates results using a single MEG dataset (i.e., a single subject). The accuracy measure is utilized to compare the performance of various models. All models had previously undergone testing on participant 1 to provide an initial indication of performance. The suggested model solution is validated across all of the participants once all models have been evaluated on participant 1. Additional tests are specifically run on the best model ASRCNet and other two main baseline models (LSTM RNN and simple CNN). For models tested on all subjects, model training was done within each participant, trained and evaluated only using its individual recording MEG data. Additionally, I set the windows of input data to 800 ms enabling an accurate comparison of several test models. Relative power spectrum is introduced to the training improving performance of models. Moreover, average topographical maps are graphed as the representation of the MEG signals intensities in the anatomical brain, illustrating the general topographic maps of brain states from different stimuli in brain states reactivation tasks.\n\n## Topographical map\n\nThe global anatomical brain maps are generated with concatenated dataset and were back fitted to MEG recordings. The average MEG signals with different stimuli are calculated and graphed showing commons and differences among various brain states under different stimuli. In the brain states reactivation process, under the different stimuli, the topographical maps all look very similar. There are subtle differences but in general the pattern is the same: similar brain regions are activated while to the different extent (figure 5). This means we need some kind of algorithm that is sensitive to these very small differences between stimuli.\n\nThe result shows the rationality of extracting features of brain states under different stimuli. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, ASRCNet is an effective and reasonable approach to classifying these states.\n\n![image-20220824171924099](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241719153.png)\n\n**Figure 5**. brain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.\n\n## Power spectrum\n\nIn order to determine the effect of different brain wave frequencies, power spectral density (PSD) at all 272 channels is calculated. The 6 power bands are divided by the sum generating 1632 decoding features (272 channels for each of the 6 frequency bands). I analysed the power spectrum in all frequencies of input 800-time-point MEG signals for different participants. The results show that beta and delta waves are in the large and major proportion (figure 6). It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721133.gif)![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241720900.gif)\n\n**Figure 6.** Relative and absolute power spectrum (average of 24 subjects), beta (12 to 30 Hz) and delta (0.5 to 4 Hz) waves are in the major proportion\n\n## Classification of multiple brain states reactivations\n\nIn order to classify the brain states reactivation with different given image stimuli (figure 7), ASRCNet-v1, the classifier is developed. It is trained with MEG signals for each of the images. The representative MEG signals for each reactivation states that ASRCNet-v1 accurately identified is displayed in figure 8. A sample of an 800-time-point segment of the preprocessed MEG signals is displayed in the panel, where each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. Therefore, none of these signals are removed because of bad channels. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data. It is suggested that ASRCNet-v1 correctly categorised the MEG signals during aversive state by utilising features that not presents in the typical classification.\n\n![image-20220824172119017](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721069.png)\n\n**Figure 7.** image stimuli in different brain states reactivation tasks (Wise et al., 2021), from left to right, above to bottom are labelled as stimulus_i.\n\n![image-20220824172132497](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721550.png)\n\n**Figure 8.** representative MEG signal which is classified by the ASRCNet-v1 (from one sample participant)\n\nPrincipal component analysis (PCA) (30 to 50 out of 272 channels) was tested to be applied to the input data before feeding data into the model. But the result shows that PCA does not obviously improve the classification performance of ASRCNet-v1. The classification accuracy was not obviously affected when PCA was applied. In the beginning, I didn\\'t get satisfactory learning convergence results. When the input data values are clipped to be in of standardized bounds, the learning curves became smooth and the valid loss gradually decreased step by step.\n\nSince there are 14 stimuli and the chances for all stimuli are equal, the random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of ASRCNet-v1 is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. I compared the performance of different models (figure 9) and found it is suggested that ASRCNet-v1 outperformed any other simple approach (LSTM RNN, simple CNN with 2 convolutional layers and 1 pooling layer). Compared with the other classification approach, ASRCNet-v1 exhibits the best classification performance (p = 6.8 × 10 --2 for LSTM RNN, p = 5.9 × 10 --2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of ASRCNet-v1 is able to reach 33.33%. The classification accuracy variety between simple CNN and ASRCNet may suggest that the classification depends on some event-independent signal: the temporal and spatial features. To which extent the performance is a result of the detected differences in the temporal and spatial features of MEG signals, remained to be explored.\n\n![image-20220824172150882](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721928.png)\n\n**Figure 9.** performance of different model boxplot. The boxplot shows the classification accuracy of different models. The random chance baseline is 7.14% (1/14 = 7.14%). All models learned from MEG signals (all accuracies are above 7.14% and gives better predictions. ASRCNet gives the best classification accuracy as 23.07%±7.69% (mean ± standard deviation).\n\n# Discussion\n\nIn this section, I am going to discuss the experimental results, findings, and potential future work. The focus of this paper is to explore the potential of deep learning, especially CNN to classify the aversive brain states associated with visual images. The MEG signals are complex and have low signal-to-noise ratios data structures. What is more, the aversive brain states parameters are continuous variables. Therefore, the aim is to solve a complex classification task. To optimally address this problem, a CNN model ASRCNet (inspired by Mnet and EnvNet, which was used in MEG data) is proposed as the deep learning solution in this research because of its ability to extract complex patterns from raw input data. One focus is to understand whether the CNN model is able to perform the decoding task. The analysis has been evaluated in two distinct steps: First, two well-known architectures (LSTM RNN and CNN: the former model is known as a good fit for sequential data and the second model is usually used in image classification) were selected as baseline models for the purpose of understanding the potential of general-purpose DL models that are not specific to MEG analysis. Second, I test the prediction and classification ability of the CNN-based architecture specially designed for MEG recordings. The results show that ASRCNet provide better performance compared to the other two baseline models. Since the model is specifically designed to extract features from MEG recordings, it can be considered an option in the field of brain state classification.\n\nI trained a novel deep neural network ASRCNet to classify 14 brain states using data from MEG recordings. It can distinguish brain states under different image stimuli with an accuracy at least as good as, or even higher than the baseline pipeline. ASRCNet allows the extraction of spatial and temporal information from the informative MEG data. It is suggested that classification decisions are unlikely to be associated with activities that are unrelated to the task itself, for example, mind wandering. The trained ASRCNet successfully classifies brain states with relatively high accuracy and specificity. Previous research has been focusing on common symptoms of psychopathology, but less on the domain of aversive states. This is a study using MEG signals to classify different aversive brain states with a classifier. The high specificity for all states suggests that ASRCNet will help improve our understanding of the human cognitive image process. One thing we can do with such a CNN classifier is to look at state reactivation in cognitive tasks. Moreover, this classifier is expected to be applied in clinical studies in order to diagnose nonorganic neurological diseases. As shown in the topological map in the result section, these brain states are hard to classify with the naked eyes. The information from such computer-aided diagnosis may be a novel biomarker for these diseases in clinical practice.\n\nThe advantage of using this neural network is its comprehensive training process, entirely based on gradient descent-based optimization without intermediate steps. As research develops toward explainable artificial intelligence (XAI), the parameters of a model may be going to have a direct and explainable connection to their task. On the separate brain states classification task, ASRCNet also performs on par with state-of-the-art, potentially making it a general method for other neuroimaging data. What is more, as shown in the result section, the classification accuracy varies a lot between simple image classification CNN and ASRCNet. One reason the model is successful in classification is that the first part of the network learns to extract the correct features, while the last layer classifies the extracted features. It may suggest that the classification of such brain states depends on some event-independent temporal and spatial features signal. Some evidence suggests that using features automatically extracted with deep learning models rather than manually selected, is able to help achieve the highest levels of accuracy compared to other machine learning approaches. It is reported that most of the best ImageNet is achieved by using some kind of data augmentation, instead of feature engineering and dimensionality reduction (de Bardeci et al., 2021). However, it was reported that logistic regression may achieve better classification accuracy than ASRCNet (Wise et al., 2021). It may be because of the algorithmic Incompleteness of the current model. Future work on improving the algorithm may improve the performance of CNN models.\n\nASRCNet is a relatively robust approach among different subjects. In this research, 14 different stimuli were applied to 24 subjects (data from 4 subjects were removed because of the smaller segment length). ASRCNet successfully classifies states in 24 different subjects with high accuracy, demonstrating the robustness of the CNN model. However, the data itself used in the research has potential for improvement: the 13th stimulus is a face picture, which may be different from other stimuli reflecting brain states (Rapcsak, 2019). What is more, it is concerned that the trained model may have difficulty classifying brain states using data recorded by another MEG scanner. Improvements in current source estimation and alignment techniques may make the method adaptable to different MEG scanners (Pettersen et al., 2006). Apart from the robustness, the size of the data itself may also affect the classification accuracy. A limitation of this experiment is, the same as in most other studies, the cross-validation approach was performed during the validation process, rather than using a separate test dataset. It was reported that using a separate test set in the DL model may help yield the highest level of validity in the results (de Bardeci et al., 2021). Although superficially, it is a relatively advanced practice to use data from the same subject in the training and test sets, there is room for improvement. A possible improvement is to create additional test sets beyond the limited availability of data. Due to the high inter-individual specificity and intra-individual stability of MEG data, it is difficult for the network to learn common features between subjects. The current approach of the model is to recognize different subjects by identifying individual MEG features of different subjects. Therefore, even though the network can achieve high levels of accuracy, classification and prediction will be unpredictable when it is applied to entirely new datasets from different subjects. The application of transfer learning methods with the small tuning of part of model parameters may be a possible solution. However, when performing transfer learning, it is generally assumed that different tasks are related. In this case, how to define the correlation and mathematically describe the strength of the correlation between tasks are subjective decisions that are biased toward researchers. The image classification-related studies usually use ImageNet as a pre-trained model for transfer learning because the large dataset of ImageNet itself ensures that the trained model has high generalization. But when we use a small dataset such as in this experiment, transfer learning may not only fail to achieve the expected result but result in negative transferring which is even worse than training a network from nowhere. For example, AlphaGo Zero learned from zero without any supervision or using chess manual data but achieves higher performance than AlphaGo Lee which is based on chess manual replays (Silver et al., 2017). Therefore, how to perform correct and effective transfer learning is one of the focuses of future work.\n\nDeep learning from scratch is often difficult with limited amounts of data. However, even with the limited amount of data in this study, I successfully classified 14 types of brain states. One reason for this success is that I enlarged the dataset by dividing each subject\\'s 1170 seconds of data into 900 segments of 1.3-second time data, allowing me to train 14 classes using approximately 25200 segments. The data amount is slightly less than the amount of MNIST, a database of handwritten digits that is often used to train deep neural networks, but still shows that I have a reasonable amount of data to train a network of such size (Yann LeCun et al., 2012). However, during the training process, the training data generally has a tendency to overfit even though I applied dropout (randomly ignored neurons in network) and batch normalization (normalizes input mini-batches from last layer). The proposed CNN model ASRCNet may benefit from the increase in dataset size. It improves with more training data because deep learning performance is reported to improve significantly with larger datasets (Greenspan et al., 2016). Therefore, it can be taken into account to train this model with more data in hopes of improving model performance. In addition, more research has shown that MEG and EEG provide complementary information, and other modalities such as MRI also provide additional useful information. Using data from multiple method sources at the same time may improve model performance (Dale & Sereno, 1993; Sharon et al., 2007). In future work, combining MEG signal data with EEG to create a multimodal data input may help improve the accuracy of brain states classification.\n\nIn this ASRCNet, the integration of the relative power spectrum improves the CNN model's performance. Since the beta and delta waves mainly encode perceptual information, the relative power spectrum ensemble adds relevant information to the model so that the different band power values can inform the network. Therefore, the model can adjust the weights accordingly. Additionally, the relative power spectrum may also add valuable information about artefacts or ambient noise (Anelli et al., 2021). All these deep learning models overfit the training dataset more or less, even applied regularization techniques like dropout and batch normalization. The additional information provided by the relative power spectrum ensemble helps the model to generalize. There is still room to improve the model's performance as the aspect of power spectrum extraction. In the process of relative power spectrum extraction, the wavelet transform can be considered as an optional alternative to Fourier analysis for the reason that the wavelet transform has the multi-scale analysis ability to extract features from the dataset and generate input images for training the model. Compared with the Fourier transform, the wavelet transform is a local transform of temporal and frequency data, so it can more effectively extract information from the signal by performing multi-scale refinement analysis with operations like scaling and translation (Yu & Guowen, 1994), thus has the potential to solve some difficult problems that Fourier transform cannot deal with. Fourier transform can only get a frequency spectrum, but wavelet transform can get a temporal frequency spectrum which not only the frequency can be obtained, but also the time can be located. Some recent studies successfully use the wavelet packet decomposition method to extract time-frequency features and use a dynamic frequency feature selection algorithm to select the most accurate features for each subject (Luo et al., 2016). However, other studies have shown the drawback of wavelet packet decomposition: although this method improves the classification accuracy, it requires a lot of work to select the most suitable features for each subject, and the feature extraction for different target individuals is poorly general (Dai et al., 2020). Only considering the power spectrum is quite limiting at the current moment. The convolutional operation executed by most popular machine learning libraries in deep learning is actually computing the correlation measurement (Graves, 2012). Future work investigating state classification and reactivation should also take steps to measure event-related desynchronization and synchronization in the context of the data generated.\n\nAnother idea to optimize the model is to replace the fully connected layer with global average pooling. The model holds a redundancy of fully connected layer parameters where fully connected layer parameters can account for about 80% of the entire network parameters. Some recent network models with excellent performance, such as ResNet, are trying to use global average pooling (GAP) layer instead of a fully connected layer for fusion. For the learned deep features, loss functions such as SoftMax are still used as the network objective function to guide the learning process (Liu & Zeng, 2022) Some evidence suggests that networks that replace a fully connected layer with a GAP layer may have better classification performance (Wei et al., 2018). However, other studies have pointed out that when applying transfer learning, the fine-tuned results of networks without fully connected layers are worse than those with fully connected layers. Therefore, fully connected can be regarded as a guard for model representation capabilities, especially in the case that there are big differences between the source domain and the target domain, the redundant parameters of FC can maintain a fine model capacity to ensure the migration of model representation capabilities (Zhang et al., 2018). Future work can explore the role of the GAP layer and fully connected layer in detail.\n\nASRCNet can extract and analyze features that deep learning neural networks use for classification, which may help researchers understand brain states better. The inherent hidden patterns in brain states and related brain neural activity that deep learning may reveal some fundamental mechanisms behind human behaviour. To the extent these can be explained, researchers are encouraged to apply these sophisticated deep learning modelling techniques to obtain accurate classification and prediction results and to generalize the results more carefully in a wider range of conditions. Moreover, understanding the relevant studies that extract these hidden patterns can increase and deepen our understanding of the brain state electrophysiological characterization.\n\n# Reference\n\nAnelli, M., Lauri, S. P., Advisor, P., & Zubarev, M. I. (2021). *Using deep learning to predict continuous hand kinematics from magnetoencephalographic (MEG) measurements of electromagnetic brain activity.* www.aalto.fi\n\nAoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., & Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. *Scientific Reports*, *9*(1). https://doi.org/10.1038/S41598-019-41500-X\n\nBai, S., Kolter, J. Z., & Koltun, V. (2018). *An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling*. https://doi.org/10.48550/arxiv.1803.01271\n\nBaumeister, J., Barthel, T., Geiss, K. R., & Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. *Http://Dx.Doi.Org/10.1179/147683008X301478*, *11*(3), 103--110. https://doi.org/10.1179/147683008X301478\n\nBelal, S., Cousins, J., El-Deredy, W., Parkes, L., Schneider, J., Tsujimura, H., Zoumpoulaki, A., Perapoch, M., Santamaria, L., & Lewis, P. (2018). Identification of memory reactivation during sleep by EEG classification. *NeuroImage*, *176*, 203--214. https://doi.org/10.1016/J.NEUROIMAGE.2018.04.029\n\nBoto, E., Holmes, N., Leggett, J., Roberts, G., Shah, V., Meyer, S. S., Muñoz, L. D., Mullinger, K. J., Tierney, T. M., Bestmann, S., Barnes, G. R., Bowtell, R., & Brookes, M. J. (2018). Moving magnetoencephalography towards real-world applications with a wearable system. *Nature 2018 555:7698*, *555*(7698), 657--661. https://doi.org/10.1038/nature26147\n\nBrown, R. E., & Milner, P. M. (2003). The legacy of Donald O. Hebb: More than the Hebb Synapse. *Nature Reviews Neuroscience*, *4*(12), 1013--1019. https://doi.org/10.1038/NRN1257\n\nBunge, S. A., & Kahn, I. (2009). Cognition: An Overview of Neuroimaging Techniques. *Encyclopedia of Neuroscience*, 1063--1067. https://doi.org/10.1016/B978-008045046-9.00298-9\n\nBzdok, D., & Meyer-Lindenberg, A. (2018). Machine Learning for Precision Psychiatry: Opportunities and Challenges. *Biological Psychiatry. Cognitive Neuroscience and Neuroimaging*, *3*(3), 223--230. https://doi.org/10.1016/J.BPSC.2017.11.007\n\nCurrie, G., Hawk, K. E., Rohren, E., Vial, A., & Klein, R. (2019). Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging. *Journal of Medical Imaging and Radiation Sciences*, *50*(4), 477--487. https://doi.org/10.1016/j.jmir.2019.09.005\n\nDai, G., Zhou, J., Huang, J., & Wang, N. (2020). HS-CNN: a CNN with hybrid convolution scale for EEG motor imagery classification. *Journal of Neural Engineering*, *17*(1), 016025. https://doi.org/10.1088/1741-2552/AB405F\n\nDale, A. M., & Sereno, M. I. (1993). Improved Localizadon of Cortical Activity by Combining EEG and MEG with MRI Cortical Surface Reconstruction: A Linear Approach. *Journal of Cognitive Neuroscience*, *5*(2), 162--176. https://doi.org/10.1162/JOCN.1993.5.2.162\n\nDash, D., Ferrari, P., Heitzman, D., & Wang, J. (2019). Decoding Speech from Single Trial MEG Signals Using Convolutional Neural Networks and Transfer Learning. *Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS*, 5531--5535. https://doi.org/10.1109/EMBC.2019.8857874\n\nDash, D., Sao, A. K., Wang, J., & Biswal, B. (2019). How many fmri scans are necessary and sufficient for resting brain connectivity analysis? *2018 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2018 - Proceedings*, 494--498. https://doi.org/10.1109/GLOBALSIP.2018.8646415\n\nde Bardeci, M., Ip, C. T., & Olbrich, S. (2021). Deep learning applied to electroencephalogram data in mental disorders: A systematic review. *Biological Psychology*, *162*, 108117. https://doi.org/10.1016/J.BIOPSYCHO.2021.108117\n\nDoll, B. B., Duncan, K. D., Simon, D. A., Shohamy, D., & Daw, N. D. (2015). Model-based choices involve prospective neural activity. *Nature Neuroscience*, *18*(5), 767. https://doi.org/10.1038/NN.3981\n\nEichenlaub, J. B., Biswal, S., Peled, N., Rivilis, N., Golby, A. J., Lee, J. W., Westover, M. B., Halgren, E., & Cash, S. S. (2020). Reactivation of Motor-Related Gamma Activity in Human NREM Sleep. *Frontiers in Neuroscience*, *14*. https://doi.org/10.3389/FNINS.2020.00449\n\nEinöther, S. J. L., Giesbrecht, T., Walden, C. M., van Buren, L., van der Pijl, P. C., & de Bruin, E. A. (2013). Attention Benefits of Tea and Tea Ingredients: A Review of the Research to Date. *Tea in Health and Disease Prevention*, 1373--1384. https://doi.org/10.1016/B978-0-12-384937-3.00115-4\n\nFaraji, I., Mirsadeghi, S. H., & Afsahi, A. (2016). Topology-aware GPU selection on multi-GPU nodes. *Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016*, 712--720. https://doi.org/10.1109/IPDPSW.2016.44\n\nGiovannetti, A., Susi, G., Casti, P., Mencattini, A., Pusil, S., López, M. E., di Natale, C., & Martinelli, E. (2021). Deep-MEG: spatiotemporal CNN features and multiband ensemble classification for predicting the early signs of Alzheimer's disease with magnetoencephalography. *Neural Computing and Applications*, *33*(21), 14651--14667. https://doi.org/10.1007/S00521-021-06105-4/TABLES/4\n\nGramfort, A., Luessi, M., Larson, E., Engemann, D. A., Strohmeier, D., Brodbeck, C., Parkkonen, L., & Hämäläinen, M. S. (2014). MNE software for processing MEG and EEG data. *NeuroImage*, *86*, 446--460. https://doi.org/10.1016/J.NEUROIMAGE.2013.10.027\n\nGraves, A. (2012). *Supervised Sequence Labelling*. 5--13. https://doi.org/10.1007/978-3-642-24797-2_2\n\nGreenspan, H., van Ginneken, B., & Summers, R. M. (2016). Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique. *IEEE Transactions on Medical Imaging*, *35*(5), 1153--1159. https://doi.org/10.1109/TMI.2016.2553401\n\nHagemann, D., Hewig, J., Walter, C., & Naumann, E. (2008). Skull thickness and magnitude of EEG alpha activity. *Clinical Neurophysiology*, *119*(6), 1271--1280. https://doi.org/10.1016/J.CLINPH.2008.02.010\n\nHardt, M., Recht, B., & Singer, Y. (2015). Train faster, generalize better: Stability of stochastic gradient descent. *33rd International Conference on Machine Learning, ICML 2016*, *3*, 1868--1877. https://doi.org/10.48550/arxiv.1509.01240\n\nHaynes, J. D. (2012). Brain reading. *I Know What You're Thinking: Brain Imaging and Mental Privacy*. https://doi.org/10.1093/ACPROF:OSO/9780199596492.003.0003\n\nHedderich, D. M., & Eickhoff, S. B. (2021). Machine learning for psychiatry: getting doctors at the black box? *Molecular Psychiatry*, *26*(1), 23. https://doi.org/10.1038/S41380-020-00931-Z\n\nHoshen, Y., Weiss, R. J., & Wilson, K. W. (2015). Speech acoustic modeling from raw multichannel waveforms. *ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings*, *2015-August*, 4624--4628. https://doi.org/10.1109/ICASSP.2015.7178847\n\nHuang, W., Yan, H., Wang, C., Li, J., Yang, X., Li, L., Zuo, Z., Zhang, J., & Chen, H. (2020). Long short-term memory-based neural decoding of object categories evoked by natural images. *Human Brain Mapping*, *41*(15), 4442--4453. https://doi.org/10.1002/hbm.25136\n\nHuang, Y., Sun, X., Lu, M., & Xu, M. (2015). Channel-Max, Channel-Drop and Stochastic Max-pooling. *IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops*, *2015-October*, 9--17. https://doi.org/10.1109/CVPRW.2015.7301267\n\nIBM Corp. (2021). *IBM SPSS Statistics for Windows*. https://hadoop.apache.org\n\nIoffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. *32nd International Conference on Machine Learning, ICML 2015*, *1*, 448--456. https://doi.org/10.48550/arxiv.1502.03167\n\nKarimpanal, T. G., & Bouffanais, R. (2018). Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning. *Adaptive Behavior*, *27*(2), 111--126. https://doi.org/10.1177/1059712318818568\n\nKhan, S., Rahmani, H., Shah, S. A. A., & Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. *A Guide to Convolutional Neural Networks for Computer Vision*. https://doi.org/10.1007/978-3-031-01821-3\n\nKing's College London. (2022). *King's Computational Research, Engineering and Technology Environment (CREATE).*\n\nLi, H., Ellis, J. G., Zhang, L., & Chang, S. F. (2018). PatternNet: Visual pattern mining with deep neural network. *ICMR 2018 - Proceedings of the 2018 ACM International Conference on Multimedia Retrieval*, 291--299. https://doi.org/10.1145/3206025.3206039\n\nLiu, W., & Zeng, Y. (2022). Motor Imagery Tasks EEG Signals Classification Using ResNet with Multi-Time-Frequency Representation. *2022 7th International Conference on Intelligent Computing and Signal Processing, ICSP 2022*, 2026--2029. https://doi.org/10.1109/ICSP54964.2022.9778786\n\nLuo, J., Feng, Z., Zhang, J., & Lu, N. (2016). Dynamic frequency feature selection based approach for classification of motor imageries. *Computers in Biology and Medicine*, *75*, 45--53. https://doi.org/10.1016/J.COMPBIOMED.2016.03.004\n\nNewson, J. J., & Thiagarajan, T. C. (2019). EEG Frequency Bands in Psychiatric Disorders: A Review of Resting State Studies. *Frontiers in Human Neuroscience*, *12*, 521. https://doi.org/10.3389/FNHUM.2018.00521/BIBTEX\n\nPaszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., Facebook, Z. D., Research, A. I., Lin, Z., Desmaison, A., Antiga, L., Srl, O., & Lerer, A. (2017). *Automatic differentiation in PyTorch*.\n\nPercival, D. B., & Walden, A. T. (1993). Spectral Analysis for Physical Applications. *Spectral Analysis for Physical Applications*. https://doi.org/10.1017/CBO9780511622762\n\nPettersen, K. H., Devor, A., Ulbert, I., Dale, A. M., & Einevoll, G. T. (2006). Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities. *Journal of Neuroscience Methods*, *154*(1--2), 116--133. https://doi.org/10.1016/J.JNEUMETH.2005.12.005\n\nRajasree, R., Columbus, C. C., & Shilaja, C. (2021). Multiscale-based multimodal image classification of brain tumor using deep learning method. *Neural Computing and Applications*, *33*(11), 5543--5553. https://doi.org/10.1007/S00521-020-05332-5/FIGURES/9\n\nRapcsak, S. Z. (2019). Face Recognition. *Current Neurology and Neuroscience Reports*, *19*(7). https://doi.org/10.1007/S11910-019-0960-9\n\nRaviPrakash, H., Korostenskaja, M., Castillo, E. M., Lee, K. H., Salinas, C. M., Baumgartner, J., Anwar, S. M., Spampinato, C., & Bagci, U. (2020). Deep Learning Provides Exceptional Accuracy to ECoG-Based Functional Language Mapping for Epilepsy Surgery. *Frontiers in Neuroscience*, *14*. https://doi.org/10.3389/FNINS.2020.00409/FULL\n\nRohenkohl, G., & Nobre, A. C. (2011). Alpha Oscillations Related to Anticipatory Attention Follow Temporal Expectations. *The Journal of Neuroscience*, *31*(40), 14076. https://doi.org/10.1523/JNEUROSCI.3387-11.2011\n\nRoscow, E. L., Chua, R., Costa, R. P., Jones, M. W., & Lepora, N. (2021). Learning offline: memory replay in biological and artificial reinforcement learning. *Trends in Neurosciences*, *44*(10), 808--821. https://doi.org/10.1016/J.TINS.2021.07.007\n\nSchacter, D. L., Benoit, R. G., & Szpunar, K. K. (2017). Episodic Future Thinking: Mechanisms and Functions. *Current Opinion in Behavioral Sciences*, *17*, 41. https://doi.org/10.1016/J.COBEHA.2017.06.002\n\nSharon, D., Hämäläinen, M. S., Tootell, R. B. H., Halgren, E., & Belliveau, J. W. (2007). The advantage of combining MEG and EEG: Comparison to fMRI in focally stimulated visual cortex. *NeuroImage*, *36*(4), 1225--1235. https://doi.org/10.1016/J.NEUROIMAGE.2007.03.066\n\nShaw, G. L. (1986). Donald Hebb: The Organization of Behavior. *Brain Theory*, 231--233. https://doi.org/10.1007/978-3-642-70911-1_15\n\nSilver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui, F., Sifre, L., van den Driessche, G., Graepel, T., & Hassabis, D. (2017). Mastering the game of Go without human knowledge. *Nature 2017 550:7676*, *550*(7676), 354--359. https://doi.org/10.1038/nature24270\n\nSingh, S. P. (2014). Magnetoencephalography: Basic principles. *Annals of Indian Academy of Neurology*, *17*(Suppl 1), S107. https://doi.org/10.4103/0972-2327.128676\n\nSlepian, D. (1978). Prolate Spheroidal Wave Functions, Fourier Analysis, and Uncertainty---V: The Discrete Case. *Bell System Technical Journal*, *57*(5), 1371--1430. https://doi.org/10.1002/J.1538-7305.1978.TB02104.X\n\nSoria Olivas, E., & IGI Global. (2010). *Handbook of research on machine learning applications and trends : algorithms, methods, and techniques*. 83.\n\nSrivastava, N., Hinton, G., Krizhevsky, A., & Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. *Journal of Machine Learning Research*, *15*, 1929--1958. https://doi.org/10.5555/2627435\n\nSzpunar, K. K. (2010). Episodic Future Thought: An Emerging Concept. *Perspectives on Psychological Science : A Journal of the Association for Psychological Science*, *5*(2), 142--162. https://doi.org/10.1177/1745691610362350\n\nTappert, C. C. (2019). Who is the father of deep learning? *Proceedings - 6th Annual Conference on Computational Science and Computational Intelligence, CSCI 2019*, 343--348. https://doi.org/10.1109/CSCI49370.2019.00067\n\nTerranova, J. I., Yokose, J., Osanai, H., Marks, W. D., Yamamoto, J., Ogawa, S. K., & Kitamura, T. (2022). Hippocampal-amygdala memory circuits govern experience-dependent observational fear. *Neuron*, *110*(8), 1416-1431.e13. https://doi.org/10.1016/J.NEURON.2022.01.019\n\nTokozume, Y., & Harada, T. (2017). Learning environmental sounds with end-to-end convolutional neural network. *ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings*, 2721--2725. https://doi.org/10.1109/ICASSP.2017.7952651\n\nTokozume, Y., Ushiku, Y., & Harada, T. (2017). Learning from Between-class Examples for Deep Sound Recognition. *6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings*. https://doi.org/10.48550/arxiv.1711.10282\n\nValueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., & Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. *Mathematics and Computers in Simulation*, *177*, 232--243. https://doi.org/10.1016/J.MATCOM.2020.04.031\n\nWei, X. S., Zhang, C. L., Zhang, H., & Wu, J. (2018). Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences. *IEEE Transactions on Affective Computing*, *9*(3), 303--315. https://doi.org/10.1109/TAFFC.2017.2762299\n\nWimmer, G. E., & Shohamy, D. (2012). Preference by association: how memory mechanisms in the hippocampus bias decisions. *Science (New York, N.Y.)*, *338*(6104), 270--273. https://doi.org/10.1126/SCIENCE.1223252\n\nWise, T., Liu, Y., Chowdhury, F., & Dolan, R. J. (2021). Model-based aversive learning in humans is supported by preferential task state reactivation. *Science Advances*, *7*(31), 9616--9644. https://doi.org/10.1126/SCIADV.ABF9616\n\nWu, C. T., Haggerty, D., Kemere, C., & Ji, D. (2017). Hippocampal awake replay in fear memory retrieval. *Nature Neuroscience*, *20*(4), 571. https://doi.org/10.1038/NN.4507\n\nYann LeCun, Corinna Cortes, & Chris Burges. (2012). *MNIST handwritten digit database*. http://yann.lecun.com/exdb/mnist/\n\nYu, F. T. S., & Guowen, L. (1994). Short-time Fourier transform and wavelet transform with Fourier-domain processing. *Applied Optics*, *33*(23), 5262--5270. https://doi.org/10.1364/AO.33.005262\n\nZhang, C. L., Luo, J. H., Wei, X. S., & Wu, J. (2018). In defense of fully connected layers in visual representation transfer. *Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)*, *10736 LNCS*, 807--817. https://doi.org/10.1007/978-3-319-77383-4_79/TABLES/4\n\nZheng, L., Liao, P., Luo, S., Sheng, J., Teng, P., Luan, G., & Gao, J. H. (2020). EMS-Net: A Deep Learning Method for Autodetecting Epileptic Magnetoencephalography Spikes. *IEEE Transactions on Medical Imaging*, *39*(6), 1833--1844. https://doi.org/10.1109/TMI.2019.2958699\n\nZubarev, I., Zetter, R., Halme, H. L., & Parkkonen, L. (2019). Adaptive neural network classifier for decoding MEG signals. *NeuroImage*, *197*, 425--434. https://doi.org/10.1016/J.NEUROIMAGE.2019.04.068\n\n \n","slug":"Thesis","published":1,"updated":"2022-08-25T13:27:07.127Z","comments":1,"layout":"post","photos":[],"_id":"cuidfkwlqYDtM34Q0zwmUn7wC","content":"<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208251426116.png\" alt=\"LuoLei_Poster2022_Page_2\"></p>\n<p><strong>A novel convolutional neural network approach for classifying brain states under image stimuli</strong></p>\n<p>Lei Luo</p>\n<p>Dr. Toby Wise</p>\n<p>Department of Neuroimaging<br>Institute of Psychiatry, Psychology &amp; Neuroscience<br>King’s College London<br>University of London</p>\n<p><strong>Thesis in partial fulfilment for the degree of MSc in Neuroscience September, 2022.</strong></p>\n<h1 id=\"Personal-Statement\"><a href=\"#Personal-Statement\" class=\"headerlink\" title=\"Personal Statement:\"></a>Personal Statement:</h1><p>The study was designed by Lei Luo under the supervision of Dr. Toby Wise. MEG data was from Wise et al. (2021). The thesis was written entirely by Lei Luo, with language corrections and suggestions from Dr. Toby wise. Any research or work mentioned in the paper has been fully and accurately cited. Computation resource is provided by King&#39;s Computational Research, Engineering and Technology Environment (CREATE) (King’s College London, 2022). The neural network code is using machine learning library Pytorch (Paszke et al., 2017). Statistics are done with IBM Spss. Topographical maps are generated using library MNE-Python. Code availability: MEG data used in this research in available at <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a>; and all analysis code in available at <a href=\"https://github.com/ReveRoyl/MT_ML_Decoding\">https://github.com/ReveRoyl/MT_ML_Decoding</a>.</p>\n<h1 id=\"Abbreviations\"><a href=\"#Abbreviations\" class=\"headerlink\" title=\"Abbreviations\"></a>Abbreviations</h1><p>CBAM Convolutional block attention module</p>\n<p>CNN Convolutional neural network</p>\n<p>ECoG Electrocorticography</p>\n<p>EEG Electroencephalography</p>\n<p>ICA Independent Components Analysis</p>\n<p>MEG Magnetoencephalography</p>\n<p>MLP Multilayer perceptron</p>\n<p>MRI Magnetic resonance imaging</p>\n<p>fMRI Functional magnetic resonance imaging</p>\n<p>FC Fully connected</p>\n<p>LSTM Long short-term memory</p>\n<p>RNN Recurrent Neural Network</p>\n<p>RPS Relative power spectrum</p>\n<p>PCA principal component analysis</p>\n<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Background: The mechanism of human neural responses to different stimuli has always been of interest to neuroscientists. In the clinical situation, tools to distinguish different diseases or states are required. However, classic classification methods have obvious shortcomings: traditional clinical categorical methods may not be competent for behaviour prediction or brain state classification and traditional machine learning models are improvable in classification accuracy. With the increasing use of convolutional neural networks (CNN) in neuroimaging computer-assisted classification, an ensemble classifier of CNNs might be able to mine hidden patterns from MEG signals. However, developing an effective brain state classifier is a difficult task owing to the non-Euclidean graphical nature of magnetoencephalography (MEG) signals.</p>\n<p>Objective: This project had two aims: 1) to develop a CNN-based model with better performance in classification than traditional machine learning models; 2) to test if the model can be improved with extra information adding relative power spectrum.</p>\n<p>Methods: To address this brain state classification modelling issue, I used MEG signals from 28 participants viewing 14 image stimuli to train the CNN. The CNN subsequently underwent 10-fold cross-validation to ensure proper classification of MEG. I also extracted the relative power spectrum and provided this to the network. The following main techniques were applied in this research, principal component analysis (PCA), convolutional block spatial and temporal features extracting modules, convolutional block attention module (CBAM) techniques, relative power spectrum (RPS) techniques, fully connected (FC) techniques.</p>\n<p>Results: In this research, my method was applied to the MEG dataset, the average classification accuracy is 23.07%±7.69%, which is much better than the baseline models: LSTM RNN model 15.38% (p = 6.8 × 10 ^–2^) and simple image classification CNN model 11.53% (p = 5.9 × 10 ^–2^). Relative power spectrum information (mainly beta and delta during this task) successfully informed the model improving its performance.</p>\n<p>Conclusion: These results demonstrate that my method is feasible for the analysis and classification of brain states. It may help researchers diagnose people in the clinical situations and inform future neurological classification approaches in regard to higher specificity in identifying brain states.</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><h2 id=\"Machine-learning-in-medical-utilisation\"><a href=\"#Machine-learning-in-medical-utilisation\" class=\"headerlink\" title=\"Machine learning in medical utilisation\"></a>Machine learning in medical utilisation</h2><p>Since Donald Hebb first composed the cell assembly theory stating the consistency between neuronal activity and cognitive processes (Brown &amp; Milner, 2003; Shaw, 1986), the idea of neural networks started to stand out in public visibility. Until Frank Rosenblatt first developed and explored the basic ingredients of deep learning (DL) (Tappert, 2019), the only constraint that can slow our steps are applications of math methods. The last past decades have seen the quick and great revolution of artificial intelligence as the development of computer science. What the big breakthrough takes us close to the scientific field are the powerful tools that teach machines to learn about the physical world. Even though machine learning techniques have gradually built their presence in recent decades, the application in medical utilisation lags.</p>\n<p>In the past centuries, neuroscientists have always been attempting to classify and predict the brain’s response to the visual world. Recently, with the rapid emergence of novel non-invasive techniques such as magnetoencephalography (MEG), electroencephalography (EEG) and magnetic resonance imaging (MRI), neuroscientists start to use these tools to solve the historical conundrum; and have made huge progress in the visual perceptual decoding or so-called “brain-reading” field (W. Huang et al., 2020). Each individual conscious experience is associated with a unique brain activity pattern so that it can be regarded as a fingerprint of specific brain activity. It is theoretically viable to read out one’s current idea with a specifically designed computer vision and neuroimaging pattern (Haynes, 2012). In this case, it might be possible that these “brain-reading” techniques can tell us that could be helpful with regard to clinical applications. Nowadays, many neural mechanisms have been elucidated. Although the current studies are mostly on a reflective proof of concept track (Hedderich &amp; Eickhoff, 2021), it is promising that these approaches will pave the way and build a solid foundation in regard to clinical applications. In contrast to the classic understanding of some mental mechanisms, more and more researchers believe that traditional categories systems may twist the real cause of diseases or behaviours (Bzdok &amp; Meyer-Lindenberg, 2018). To fill this gap, deep learning techniques have been introduced into disease diagnosis and classification. It can avoid being affected by people’s opinion bias but conversely get feedback from people so as to improve its learning ability from existing experience (Currie et al., 2019). Apart from disease classification, it is more profound to study human brain states under different conditions. Further studying of future state simulation has properly gained attention, especially on episodic future thought: the ability to rehearse events in mind, which may be going to happen in one’s life trajectory (Schacter et al., 2017; Szpunar, 2010).</p>\n<h2 id=\"Aversive-state-reactivation-and-replay\"><a href=\"#Aversive-state-reactivation-and-replay\" class=\"headerlink\" title=\"Aversive state reactivation and replay\"></a>Aversive state reactivation and replay</h2><p>The aversive state is critical for harm avoidance, playing a vital role in wilderness survival and social life (Terranova et al., 2022). As part of the aversive state, the observational fear process promotes one’s capability of showing empathic fear when seeing other’s aversive situations. This process may benefit from the neural replay and reactivation of individuals. The process that current state simulation reinforces the existing memory network is called “reactivation” while the neural activity activation is named “neural replay”. The reactivation is based on past experience and in turn, promotes the storage of it, as well as facilitating the planning, inference and reward values updating (Wimmer &amp; Shohamy, 2012; Wise et al., 2021). As mentioned in the previous section, one way to look at future thought simulation is to investigate memory reactivation.</p>\n<p>Recent works have shown that neural replay and reactivation are prior important in avoidance behaviour (Wu et al., 2017), which may provide individuals with a prospective prediction based on the possible consequence simulation (Doll et al., 2015). Since then, it is known “which” correlates to the aversive state, the following step is figuring out to what extent neuronal activity is associated with behaviour. Naturally, it encourages researchers to try predicting one’s avoidance behaviour with the neuroimaging data recording. In recent years, more and more studies start to use neuroimaging classification to look for the inner mechanisms of brain states’ reactivation (Belal et al., 2018; Eichenlaub et al., 2020; Roscow et al., 2021). If we want to look at memory reactivation, what we need is really good decoding methods with neuroimaging data recordings. So, it’s important to optimise existing decoding methods as far as possible, which will set the scene for future related work.</p>\n<h2 id=\"Magnetoencephalography\"><a href=\"#Magnetoencephalography\" class=\"headerlink\" title=\"Magnetoencephalography\"></a>Magnetoencephalography</h2><p>Magnetoencephalography (MEG) is useful for detecting brain states and evaluating the behavioural response. It allows us to map and locate specific brain areas and ongoing functions (Bunge &amp; Kahn, 2009). The principle of MEG is based on magnetic induction. It is widely known that when neurons are activated, electrical signals will be generated synchronously. According to the magnetic induction principle, when the electrical fields change, secondary magnetic fields are generated. The brain-evoked magnetic field strength is usually in the range of femto-tesla to pico-tesla, i.e., 10–15 to 10-12 tesla (Singh, 2014). With the precise MEG device and mathematical preprocessing methods, these tiny signals are able to be separated from the noise and collected. MEG records magnetic fields, from which can be inferred changes in the transmission of postsynaptic current between cortical neurons.</p>\n<p>Compared to other neuroimaging methods, functional magnetic resonance imaging (fMRI) has high spatial resolution but a low temporal resolution (Dash, Sao, et al., 2019); electroencephalography (EEG) records the electrical field that may twist between skin and skull, and EEG is based to reference point location hence it is sensitive to small measurement error. Electrocorticography (ECoG) is an invasive method, so it is not suitable for healthy participants and some patients; MEG stands out for its higher spatial, temporal resolution and dynamic time sequentiality. At the same time, MEG, as a non-invasive method, has its specific advantage: low preparation time, which supports a possibility for most clinical conditions. Furthermore, as novel portable MEG devices come out, it creates opportunity for various ages participants and patients (Boto et al., 2018). MEG data records complex high-dimensional information about the brain network and the responding source locations, which is hard to collect with classic classification methods (Giovannetti et al., 2021). However, in the analysis period, it is a burden for researchers to do classification with MEG data: it is complex to correctly extract required signals during preprocessing, and lots of related experience is required when dealing with complex sensors and waveform patterns. Hence deep learning is expected to lighten the load of researchers, add the universal applicability of classification and increase the prediction accuracy. In this case, it is a challenge to choose the proper neural network.</p>\n<h2 id=\"Convolutional-Neural-Network\"><a href=\"#Convolutional-Neural-Network\" class=\"headerlink\" title=\"Convolutional Neural Network\"></a>Convolutional Neural Network</h2><p>The CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018). The same as the real neural networks in the brain, neurons in CNN process limited input data in a restricted receptive field and cooperate with each other by overlapping to cover the whole visual space (the filter extracting the features is called kernels). It is an automatic feature extraction process. Thus, it is now necessary to manually design feature extraction algorithms, which is required in traditional machine learning algorithms. It is also the main advantage of CNN to learn features from input data: avoiding the impact of artificial artefact in the algorithm design step. The main specialization of CNN is clearly the convolution part, which is a linear mathematic operation allowing extracting the nearby features of input data. The convolutional operation generates a series of machine-recognizable output features. It is suggested that the convolutional layer can be considered as a graphical pattern mining or feature extraction process (Li et al., 2018). What is more, previous research has shown the ability of CNN as a tool for analysing MEG data, which is in detail classifying brain activity and identifying potential neural sources (Zubarev et al., 2019). The process of generating the features map is following the sequential architecture, which is not like a cyclical recurrent neural network. A CNN model is usually composed of the input layer (the first layer where input data is passed in), multiple convolutional layers (feature extraction layers), alternative pooling layers (downsampling layer for feature maps), fully connecting layers (used to map the feature vectors obtained from previous feature extraction layers to the next layer), and output layers (the final layer where predictions are made). Inside each layer, activation functions are optional. A simple CNN network is shown as an example in figure 1. The convolutional layer receives input data, apply the convolution process to the data, and passes data to the following step. In the convolution function shown in equation 1, the f stands for input data; k stands for kernel filter, m, n respectively stands for the result matrix rows and columns index:</p>\n<p>$$\\begin{matrix}<br>G\\lbrack m,\\ n\\rbrack = \\ (f*k)\\lbrack m,\\ n\\rbrack = \\ \\sum_{i = 1}^{m}\\ \\sum_{j = 1}^{n}\\ \\ k\\lbrack i,\\ j\\rbrack f\\lbrack m - i,\\ n - j\\rbrack\\ \\ (1) \\<br>\\end{matrix}$$</p>\n<p>As shown in figure 2 (A), a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure 2 (B)) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well (Y. Huang et al., 2015).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717167.png\" alt=\"image-20220824171734112\"></p>\n<p><strong>Figure 1.</strong> A simple CNN architecture illustration (5 convolutional layers and pooling layers, 3 fully connected layers)</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717946.png\" alt=\"image-20220824171744899\"></p>\n<p><strong>Figure 2</strong>. Convolution illustration (A), a 3*3 kernel filter (blue) is applied to a 6*6 input data (red) and give an output (green) as 4*4 (feature map). Max pooling illustration (B), data transformation is processed from 4*4 input to 2*2 output.</p>\n<p>In previous research, sequence data were usually analysed with the recurrent neural network (RNN) while the convolutional neural network (CNN) was used for image prediction. However, recent works have demonstrated the effectiveness of CNN in time-sequential data (Bai et al., 2018) where CNN even have a longer effective memory. It provides us with the theoretical basis for utilizing various CNN models in behaviour prediction. CNN has also been used for MEG classification in recent years: previous research has successfully predicted different diseases such as brain tumours (Rajasree et al., 2021) and Alzheimer’s disease (Aoe et al., 2019; Giovannetti et al., 2021). In fact, some studies have shown that CNN offers an unreplaceable advantage for patterns modelling those other techniques may not be disposed to reveal (Giovannetti et al., 2021). However, it is still an emergent topic to use deep learning instead of the classic machine learning method. As a special machine learning technique, deep learning benefits from the fast development of high-performance computation (HPC). One example is that deep learning can use the CUDA framework to accelerate training. As the GPU accelerators become more and more performance and energy-consuming effective (Faraji et al., 2016), the cheaper computation source becomes more and more available. Some evidence has shown that deep learning performs better than the classic machine learning methods when doing MEG classification (Aoe et al., 2019; RaviPrakash et al., 2020; Zheng et al., 2020). In addition to these the ability to recognize temporal and spatial data patterns, CNN has the unique character of sharing weight among neurons in a convolutional layer (Anelli et al., 2021). In this case, the parameters quantity reduces sharply which benefits analysing complex structured MEG data.</p>\n<h2 id=\"Band-power-and-Transfer-learning\"><a href=\"#Band-power-and-Transfer-learning\" class=\"headerlink\" title=\"Band power and Transfer learning\"></a>Band power and Transfer learning</h2><p>CNNs are expected to have good performance for extracting features from MEG data, but the performance can be boosted by augmenting the data we feed into them. Here are some ways I did this with MEG data. MEG signals reflect brain activity, in which the brainwave can be deposed into different frequency power bands, such as delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). And these different brainwave frequency bands usually are associated with different brain states, such as the alpha band has been implicated in visual attention (Rohenkohl &amp; Nobre, 2011). and the beta band is usually associated with anxiety (Einöther et al., 2013). That is why I think particular frequency bands might be important in helping classify accurately. In order to understand if it is available to extract critical information from the aversive state, it may be viable to extract different power bands and analyse them as a neural activity representation. One drawback of this method is it may reduce the available temporal information in MEG data, but it can not be denied that it provides an excellent and reliable method to study brain states (Newson &amp; Thiagarajan, 2019).</p>\n<p>However, the trained model may not be suitable for data collected under other conditions. Between the MEG device and its recording source location, there are the skull, skin and even air, which may all affect the signals we get: the deeper source is, the more affected it will be. In addition to these confounds, the geometric shape of the skull which varies a lot between different people, also affects a lot (Hagemann et al., 2008). In order to generalize the model, power spectrum standardization and relative power computation are necessary. Moreover, it is reported that transfer learning can help to improve learning efficiency by reusing or transferring learnt parameters (Karimpanal &amp; Bouffanais, 2018). In this case, transfer learning may reduce the influence of these confound factors and increase the generality of models.</p>\n<p>Transfer learning is the machine learning technique which allows a network to learn in one condition and improve its performance under another relevant condition. It is an optimization method to inform new task learning with relative learnt knowledge (Soria Olivas &amp; IGI Global., 2010). For the transfer learning process, only part of the model parameters is trained and adjusted, which is called “tuning”. If all network parameters are opened for training, it is easy to fall into the state of overfitting the target training set, thereby reducing the generalization performance of the model. The first few layers of the network are generally used for feature extraction. If the difference between the source task and the target task is not quite significant and the model has achieved good performance in the source task, there is no need to perform training from the beginning (Karimpanal &amp; Bouffanais, 2018). In this case, the transfer learning technique solves the small data availability problem: with a small amount of data, it helps eliminate the overfitting problem and reduce the model training time. Some evidence suggests that it can keep at a high accuracy level and saves 90% time (Dash, Ferrari, et al., 2019). It has been widely used to transfer the weight or bias of the current network to a newly trained network with the object of faster convergence and better performance.</p>\n<p>For aversive state reactivation prediction, previous studies have provided an approach with logistic regression methods and get a good accuracy (Wise et al., 2021) With a different approach (CNN) we could probably detect brain state reactivation with much better accuracy and learn a lot more about it. My first aim is to optimize the model with new techniques such as CNN and apply spectrum power. The second aim is to generalize the model by informing one participant model with other participants’ data. I assume that: first, the performance of the CNN model is better than traditional machine learning models; second, adding the power spectrum to augment data will improve the performance as well.</p>\n<h1 id=\"Materials-and-Methods\"><a href=\"#Materials-and-Methods\" class=\"headerlink\" title=\"Materials and Methods\"></a>Materials and Methods</h1><h2 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h2><p>The participants, study design, data collection and preprocessing sections and relevant information are included and published in the paper &quot;Model-based aversive learning in humans is supported by preferential task state reactivation&quot; (Wise et al., 2021). Open access to the original MEG data can be found in the public repository: <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a>. In total 28 participants took the task. The task is designed as follows: participants were required to sit with the MEG device in front of a monitor, where 14 images were shown. The recording duration of each stimulus is 1.29 seconds (from 0.5 before to 0.79 after image is shown). MEG data were collected with CTF 275-channel axial gradiometer system (CTF Omega, VSM MedTech). In the preprocessing session, the Maxwell filter was applied to remove noise firstly. Then a high pass filter above 0.5 Hz and a low pass filter below 45 Hz were applied. Afterwards, signal components were separated with independent component analysis (ICA) to isolate noise-related components in the setting of finding components which explain 95% variance. To reduce information loss, MEG data was upsampled and the window width of data was set as 800 time points (Aoe et al., 2019) when training the model to get better performance.</p>\n<h2 id=\"Power-spectrum-extraction\"><a href=\"#Power-spectrum-extraction\" class=\"headerlink\" title=\"Power spectrum extraction\"></a>Power spectrum extraction</h2><p>In order to compute the relative power (percentage power) of MEG signals, the first step is to extract the power band with the specific frequency. The frequency bands were chosen to be delta (0.5-4 Hz), theta (4-8 Hz), low alpha (8-10 Hz), high alpha (8-12 Hz) beta (12-30 Hz), and gamma (above 30 Hz). Actually, the gamma frequency was below 50 Hz because it is impossible to detect any information above 50 Hz as the data are sampled at 100 Hz.</p>\n<p>Firstly the power spectral densities (PSD) and frequency of each band were derived using Welch’s method with mne.time_frequency.psd_array_welch() function provided by MNE-Python (Percival &amp; Walden, 1993; Slepian, 1978). The reason for choosing this function is this function gives a single value for each trial but other methods that give you power at each timepoint. Then the PSD of each band was integrated with the frequency as spacing point using composite Simpson’s rule. The absolute power in a specific location is the average number of the power from several adjacent electrodes. The relative power is the ratio of the absolute power of a band to the total band power in all frequencies. As shown in equation 2, the r represents the relative power of a frequency band, the a stands for absolute power of the same frequency band, Pi ‘s are the absolute power in all frequency bands:</p>\n<p>$$\\begin{matrix}<br>r = \\frac{a}{P_{t}} = \\ \\frac{a}{\\sum_{\\ }^{\\ }{P_{i}\\ }}\\ \\ (2) \\<br>\\end{matrix}$$</p>\n<p>Eventually, the absolute and relative power bands are transformed from input data in $\\mathbb{R}$C×T (where $\\mathbb{R}$ is a vector space) to $\\mathbb{R}$C×F, where C is the number of channels, T is time points and F is the number of frequency bands, i.e., 6 here.</p>\n<h2 id=\"Neural-Network-architecture\"><a href=\"#Neural-Network-architecture\" class=\"headerlink\" title=\"Neural Network architecture\"></a>Neural Network architecture</h2><p>In order to classify different 14 categories brain states under 14 stimuli based on MEG signals, I proposed a CNN model ASRCNet-v1. The input data are MEG recordings from 24 subjects (4 were removed because of its information missing). In order to augment the data, the input of last fully connected layer was concatenated with relative power bands in all frequencies. The neural network structure of ASRCNet-v1 was developed based on the previously reported model EnvNet-v2 and MNet (Aoe et al., 2019; Tokozume et al., 2017; Tokozume &amp; Harada, 2017), which was used to classify environmental sounds and Alzheimer’s diseases. The detailed configuration of ASRNet-v1 is as demonstrated in figure 3 and the data processing is demonstrated in figure 4. There are three convolutional blocks in total: two feature extracting blocks: spatial and temporal blocks; and a CBAM block after them. In the first convolutional layer, the global features were extracted with a large filter, which has the same kernel width as the channel number of inputs. The kernel length of the first layer is set to be 64. The first layer generates a feature map in $\\mathbb{R}$S×1×T’ from input data in $\\mathbb{R}$C×T, where the T is larger than T’s. The C (number of channels) is larger than S (number of spatial filters) such that the channel dimension is reduced. The second convolutional layer in the spatial block generates a feature map in $\\mathbb{R}$S’×1×T’’ with frequency features then. Afterwards, the data is downsampled with a max pooling layer and swapped along the axis between S and 1, i.e., from $\\mathbb{R}$S’×1×T’’ to $\\mathbb{R}$<code>&lt;!-- --&gt;</code>{=html}1×S’×T’’. This operation allows data being considered as the image changing the convolutional direction (Tokozume et al., 2017). The second block consists of eight convolutional layers and four max pooling layers. The kernel size of convolutional layers is small and decreases every two layers in order to extract local frequency temporal features from the output feature map from the previous layer. Relu is the activation function for all convolutional layers in the spatial block. Max pooling layers are attached after every two convolutional layers.</p>\n<p>The attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images’ edges. The outputs are passed to an MLP (multilayer perceptron) network with the same weight. The MLP layer has a bottleneck. The width and length or the number of neurons in this MLP layer are decided by a reduction ratio of 16. Then the sum of two outputs from the MLP layer is given to the sigmoid activation function in order to project values in features map into $\\mathbb{R \\in}(0,1)$. Finally, the channel attention module returns a feature map as the product of input and calculated scale. Compared with the channel attention module, spatial attention seems to be simpler, which includes one convolutional layer and the sigmoid activation function. The same as the channel attention module, the spatial attention module returns a feature map as the product of input from the previous module and calculated scale in this module.</p>\n<p>Then the first fully connected layer (FC) comes to play the role of classifier, which is projecting the “distributed feature representation” of the feature map to sample labels space $\\mathbb{R}$L, where L is the number of features. In the object of data augmentation, the input is concatenated with relative power bands in all frequencies. The following step is another FC layer, which finally generates 14 features corresponding to the number of categories. At last, data is passed to the softmax activation function to convert the numbers vector into the probabilities vector. To avoid overfitting, 30 % dropout is applied after the last 4 spatial convolutional layers and 50 % dropout is applied after the first fully connected layer (Srivastava et al., 2014); batch normalization is applied to boost the speed of learning (Ioffe &amp; Szegedy, 2015).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718131.png\" alt=\"image-20220824171834060\"></p>\n<p><strong>Figure 3</strong>. Detailed configuration of ASRCNet-v1. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718214.png\" alt=\"image-20220824171849114\"></p>\n<p><strong>Figure 4.</strong> Chart flow of data processing. The original data is shaped as (64,1,272,800) where 64 is the number of batches, 272 is the number of channels and 800 is the number of time points.</p>\n<h2 id=\"Model-training-and-testing\"><a href=\"#Model-training-and-testing\" class=\"headerlink\" title=\"Model training and testing\"></a>Model training and testing</h2><p>The input data is a total of 900 epochs of 800-time-point MEG signals from 272 channels. At the beginning, the data was separately processed directly with the neural network and the Fourier transformation. The latter process provides neural network with relative band power in frequency delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). The input data is shuffled and scaled with variance scaling method, which reasonably preserves the dynamic range of data, before being fed into the model. The first step is to normalize all input data for the reason that normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance. The normalization process is as shown in equation 3, where m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1:</p>\n<p>$$\\begin{matrix}<br>{x_{i}}^{‘} = \\frac{\\left| x_{i} - \\frac{1}{m}\\sum_{1}^{m}\\ x \\right|}{\\sqrt{\\sum_{1}^{m}\\ x^{2}}}\\ \\ (3) \\<br>\\end{matrix}$$</p>\n<p>In every training period, the input is one piece of a small segment of 64 batches of MEG signals segmented with non-overlapped 800-time-point time windows. The cross-entropy loss function was chosen to train the model because of its better performance in computing losses for discrete distributions. I chose SGD to be the optimizer because it is reported to have a better generalization capacity compared with Adam even though it may converge slower (Hardt et al., 2015). For the SGD optimizer, I set the initial learning rate as 0.0005, and momentum to 0.9. Specifically for the parameters in the second FF layer, a weight decay as 0.0005 is set keeping away from overfitting. The initial weight is randomized, which is because it is reported there is no obvious performance promotion with manually weight initialization (Hoshen et al., 2015). In order to improve training efficiency and avoid overfitting, I adapted the update step: I used the dynamic learning rate when the valid loss approaches a plateau (function 4, where $\\lambda$ represents learning decay and L represents valid loss). The patience of the dynamic learning rate is set to 1, the threshold is set to 0.001 and learning rate decay is set to 1e-8. Since there are a large number of features during training, in order to avert overfitting, I introduced L2 regularization (ridge regularization) with the regularization parameter lambda to 0.001. After the trial with model performance in different checkpoints, early stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting.</p>\n<p>$$\\begin{matrix}<br>\\alpha_{t + 1}\\  = \\ \\left{ \\begin{matrix}<br>\\alpha_{t} \\times \\lambda &amp; if\\ L_{t + 1} &gt; \\ \\ L_{t} \\<br>\\alpha_{t} &amp; if\\ L_{t + 1} \\leq \\ \\ L_{t} \\<br>\\end{matrix} \\right.\\ \\ \\ (4) \\<br>\\end{matrix}$$</p>\n<p>Finally, the possibility of each label is generated in the model. It eventually gives only one “most possible” label after comparing the possibility in all labels. In order to prove the validity of this CNN model. ASRCNet-v1’s performance is evaluated with 10-fold cross-validation, where 1 in 10 sets is used as validating set every time.</p>\n<h1 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h1><p>The key results of the article are summarised and given in this section. This section first offers auxiliary findings with the whole dataset and furthermore demonstrates results using a single MEG dataset (i.e., a single subject). The accuracy measure is utilized to compare the performance of various models. All models had previously undergone testing on participant 1 to provide an initial indication of performance. The suggested model solution is validated across all of the participants once all models have been evaluated on participant 1. Additional tests are specifically run on the best model ASRCNet and other two main baseline models (LSTM RNN and simple CNN). For models tested on all subjects, model training was done within each participant, trained and evaluated only using its individual recording MEG data. Additionally, I set the windows of input data to 800 ms enabling an accurate comparison of several test models. Relative power spectrum is introduced to the training improving performance of models. Moreover, average topographical maps are graphed as the representation of the MEG signals intensities in the anatomical brain, illustrating the general topographic maps of brain states from different stimuli in brain states reactivation tasks.</p>\n<h2 id=\"Topographical-map\"><a href=\"#Topographical-map\" class=\"headerlink\" title=\"Topographical map\"></a>Topographical map</h2><p>The global anatomical brain maps are generated with concatenated dataset and were back fitted to MEG recordings. The average MEG signals with different stimuli are calculated and graphed showing commons and differences among various brain states under different stimuli. In the brain states reactivation process, under the different stimuli, the topographical maps all look very similar. There are subtle differences but in general the pattern is the same: similar brain regions are activated while to the different extent (figure 5). This means we need some kind of algorithm that is sensitive to these very small differences between stimuli.</p>\n<p>The result shows the rationality of extracting features of brain states under different stimuli. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, ASRCNet is an effective and reasonable approach to classifying these states.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241719153.png\" alt=\"image-20220824171924099\"></p>\n<p><strong>Figure 5</strong>. brain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.</p>\n<h2 id=\"Power-spectrum\"><a href=\"#Power-spectrum\" class=\"headerlink\" title=\"Power spectrum\"></a>Power spectrum</h2><p>In order to determine the effect of different brain wave frequencies, power spectral density (PSD) at all 272 channels is calculated. The 6 power bands are divided by the sum generating 1632 decoding features (272 channels for each of the 6 frequency bands). I analysed the power spectrum in all frequencies of input 800-time-point MEG signals for different participants. The results show that beta and delta waves are in the large and major proportion (figure 6). It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721133.gif\" alt=\"img\"><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241720900.gif\" alt=\"img\"></p>\n<p><strong>Figure 6.</strong> Relative and absolute power spectrum (average of 24 subjects), beta (12 to 30 Hz) and delta (0.5 to 4 Hz) waves are in the major proportion</p>\n<h2 id=\"Classification-of-multiple-brain-states-reactivations\"><a href=\"#Classification-of-multiple-brain-states-reactivations\" class=\"headerlink\" title=\"Classification of multiple brain states reactivations\"></a>Classification of multiple brain states reactivations</h2><p>In order to classify the brain states reactivation with different given image stimuli (figure 7), ASRCNet-v1, the classifier is developed. It is trained with MEG signals for each of the images. The representative MEG signals for each reactivation states that ASRCNet-v1 accurately identified is displayed in figure 8. A sample of an 800-time-point segment of the preprocessed MEG signals is displayed in the panel, where each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. Therefore, none of these signals are removed because of bad channels. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data. It is suggested that ASRCNet-v1 correctly categorised the MEG signals during aversive state by utilising features that not presents in the typical classification.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721069.png\" alt=\"image-20220824172119017\"></p>\n<p><strong>Figure 7.</strong> image stimuli in different brain states reactivation tasks (Wise et al., 2021), from left to right, above to bottom are labelled as stimulus_i.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721550.png\" alt=\"image-20220824172132497\"></p>\n<p><strong>Figure 8.</strong> representative MEG signal which is classified by the ASRCNet-v1 (from one sample participant)</p>\n<p>Principal component analysis (PCA) (30 to 50 out of 272 channels) was tested to be applied to the input data before feeding data into the model. But the result shows that PCA does not obviously improve the classification performance of ASRCNet-v1. The classification accuracy was not obviously affected when PCA was applied. In the beginning, I didn&#39;t get satisfactory learning convergence results. When the input data values are clipped to be in of standardized bounds, the learning curves became smooth and the valid loss gradually decreased step by step.</p>\n<p>Since there are 14 stimuli and the chances for all stimuli are equal, the random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of ASRCNet-v1 is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. I compared the performance of different models (figure 9) and found it is suggested that ASRCNet-v1 outperformed any other simple approach (LSTM RNN, simple CNN with 2 convolutional layers and 1 pooling layer). Compared with the other classification approach, ASRCNet-v1 exhibits the best classification performance (p = 6.8 × 10 –2 for LSTM RNN, p = 5.9 × 10 –2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of ASRCNet-v1 is able to reach 33.33%. The classification accuracy variety between simple CNN and ASRCNet may suggest that the classification depends on some event-independent signal: the temporal and spatial features. To which extent the performance is a result of the detected differences in the temporal and spatial features of MEG signals, remained to be explored.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721928.png\" alt=\"image-20220824172150882\"></p>\n<p><strong>Figure 9.</strong> performance of different model boxplot. The boxplot shows the classification accuracy of different models. The random chance baseline is 7.14% (1/14 = 7.14%). All models learned from MEG signals (all accuracies are above 7.14% and gives better predictions. ASRCNet gives the best classification accuracy as 23.07%±7.69% (mean ± standard deviation).</p>\n<h1 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h1><p>In this section, I am going to discuss the experimental results, findings, and potential future work. The focus of this paper is to explore the potential of deep learning, especially CNN to classify the aversive brain states associated with visual images. The MEG signals are complex and have low signal-to-noise ratios data structures. What is more, the aversive brain states parameters are continuous variables. Therefore, the aim is to solve a complex classification task. To optimally address this problem, a CNN model ASRCNet (inspired by Mnet and EnvNet, which was used in MEG data) is proposed as the deep learning solution in this research because of its ability to extract complex patterns from raw input data. One focus is to understand whether the CNN model is able to perform the decoding task. The analysis has been evaluated in two distinct steps: First, two well-known architectures (LSTM RNN and CNN: the former model is known as a good fit for sequential data and the second model is usually used in image classification) were selected as baseline models for the purpose of understanding the potential of general-purpose DL models that are not specific to MEG analysis. Second, I test the prediction and classification ability of the CNN-based architecture specially designed for MEG recordings. The results show that ASRCNet provide better performance compared to the other two baseline models. Since the model is specifically designed to extract features from MEG recordings, it can be considered an option in the field of brain state classification.</p>\n<p>I trained a novel deep neural network ASRCNet to classify 14 brain states using data from MEG recordings. It can distinguish brain states under different image stimuli with an accuracy at least as good as, or even higher than the baseline pipeline. ASRCNet allows the extraction of spatial and temporal information from the informative MEG data. It is suggested that classification decisions are unlikely to be associated with activities that are unrelated to the task itself, for example, mind wandering. The trained ASRCNet successfully classifies brain states with relatively high accuracy and specificity. Previous research has been focusing on common symptoms of psychopathology, but less on the domain of aversive states. This is a study using MEG signals to classify different aversive brain states with a classifier. The high specificity for all states suggests that ASRCNet will help improve our understanding of the human cognitive image process. One thing we can do with such a CNN classifier is to look at state reactivation in cognitive tasks. Moreover, this classifier is expected to be applied in clinical studies in order to diagnose nonorganic neurological diseases. As shown in the topological map in the result section, these brain states are hard to classify with the naked eyes. The information from such computer-aided diagnosis may be a novel biomarker for these diseases in clinical practice.</p>\n<p>The advantage of using this neural network is its comprehensive training process, entirely based on gradient descent-based optimization without intermediate steps. As research develops toward explainable artificial intelligence (XAI), the parameters of a model may be going to have a direct and explainable connection to their task. On the separate brain states classification task, ASRCNet also performs on par with state-of-the-art, potentially making it a general method for other neuroimaging data. What is more, as shown in the result section, the classification accuracy varies a lot between simple image classification CNN and ASRCNet. One reason the model is successful in classification is that the first part of the network learns to extract the correct features, while the last layer classifies the extracted features. It may suggest that the classification of such brain states depends on some event-independent temporal and spatial features signal. Some evidence suggests that using features automatically extracted with deep learning models rather than manually selected, is able to help achieve the highest levels of accuracy compared to other machine learning approaches. It is reported that most of the best ImageNet is achieved by using some kind of data augmentation, instead of feature engineering and dimensionality reduction (de Bardeci et al., 2021). However, it was reported that logistic regression may achieve better classification accuracy than ASRCNet (Wise et al., 2021). It may be because of the algorithmic Incompleteness of the current model. Future work on improving the algorithm may improve the performance of CNN models.</p>\n<p>ASRCNet is a relatively robust approach among different subjects. In this research, 14 different stimuli were applied to 24 subjects (data from 4 subjects were removed because of the smaller segment length). ASRCNet successfully classifies states in 24 different subjects with high accuracy, demonstrating the robustness of the CNN model. However, the data itself used in the research has potential for improvement: the 13th stimulus is a face picture, which may be different from other stimuli reflecting brain states (Rapcsak, 2019). What is more, it is concerned that the trained model may have difficulty classifying brain states using data recorded by another MEG scanner. Improvements in current source estimation and alignment techniques may make the method adaptable to different MEG scanners (Pettersen et al., 2006). Apart from the robustness, the size of the data itself may also affect the classification accuracy. A limitation of this experiment is, the same as in most other studies, the cross-validation approach was performed during the validation process, rather than using a separate test dataset. It was reported that using a separate test set in the DL model may help yield the highest level of validity in the results (de Bardeci et al., 2021). Although superficially, it is a relatively advanced practice to use data from the same subject in the training and test sets, there is room for improvement. A possible improvement is to create additional test sets beyond the limited availability of data. Due to the high inter-individual specificity and intra-individual stability of MEG data, it is difficult for the network to learn common features between subjects. The current approach of the model is to recognize different subjects by identifying individual MEG features of different subjects. Therefore, even though the network can achieve high levels of accuracy, classification and prediction will be unpredictable when it is applied to entirely new datasets from different subjects. The application of transfer learning methods with the small tuning of part of model parameters may be a possible solution. However, when performing transfer learning, it is generally assumed that different tasks are related. In this case, how to define the correlation and mathematically describe the strength of the correlation between tasks are subjective decisions that are biased toward researchers. The image classification-related studies usually use ImageNet as a pre-trained model for transfer learning because the large dataset of ImageNet itself ensures that the trained model has high generalization. But when we use a small dataset such as in this experiment, transfer learning may not only fail to achieve the expected result but result in negative transferring which is even worse than training a network from nowhere. For example, AlphaGo Zero learned from zero without any supervision or using chess manual data but achieves higher performance than AlphaGo Lee which is based on chess manual replays (Silver et al., 2017). Therefore, how to perform correct and effective transfer learning is one of the focuses of future work.</p>\n<p>Deep learning from scratch is often difficult with limited amounts of data. However, even with the limited amount of data in this study, I successfully classified 14 types of brain states. One reason for this success is that I enlarged the dataset by dividing each subject&#39;s 1170 seconds of data into 900 segments of 1.3-second time data, allowing me to train 14 classes using approximately 25200 segments. The data amount is slightly less than the amount of MNIST, a database of handwritten digits that is often used to train deep neural networks, but still shows that I have a reasonable amount of data to train a network of such size (Yann LeCun et al., 2012). However, during the training process, the training data generally has a tendency to overfit even though I applied dropout (randomly ignored neurons in network) and batch normalization (normalizes input mini-batches from last layer). The proposed CNN model ASRCNet may benefit from the increase in dataset size. It improves with more training data because deep learning performance is reported to improve significantly with larger datasets (Greenspan et al., 2016). Therefore, it can be taken into account to train this model with more data in hopes of improving model performance. In addition, more research has shown that MEG and EEG provide complementary information, and other modalities such as MRI also provide additional useful information. Using data from multiple method sources at the same time may improve model performance (Dale &amp; Sereno, 1993; Sharon et al., 2007). In future work, combining MEG signal data with EEG to create a multimodal data input may help improve the accuracy of brain states classification.</p>\n<p>In this ASRCNet, the integration of the relative power spectrum improves the CNN model’s performance. Since the beta and delta waves mainly encode perceptual information, the relative power spectrum ensemble adds relevant information to the model so that the different band power values can inform the network. Therefore, the model can adjust the weights accordingly. Additionally, the relative power spectrum may also add valuable information about artefacts or ambient noise (Anelli et al., 2021). All these deep learning models overfit the training dataset more or less, even applied regularization techniques like dropout and batch normalization. The additional information provided by the relative power spectrum ensemble helps the model to generalize. There is still room to improve the model’s performance as the aspect of power spectrum extraction. In the process of relative power spectrum extraction, the wavelet transform can be considered as an optional alternative to Fourier analysis for the reason that the wavelet transform has the multi-scale analysis ability to extract features from the dataset and generate input images for training the model. Compared with the Fourier transform, the wavelet transform is a local transform of temporal and frequency data, so it can more effectively extract information from the signal by performing multi-scale refinement analysis with operations like scaling and translation (Yu &amp; Guowen, 1994), thus has the potential to solve some difficult problems that Fourier transform cannot deal with. Fourier transform can only get a frequency spectrum, but wavelet transform can get a temporal frequency spectrum which not only the frequency can be obtained, but also the time can be located. Some recent studies successfully use the wavelet packet decomposition method to extract time-frequency features and use a dynamic frequency feature selection algorithm to select the most accurate features for each subject (Luo et al., 2016). However, other studies have shown the drawback of wavelet packet decomposition: although this method improves the classification accuracy, it requires a lot of work to select the most suitable features for each subject, and the feature extraction for different target individuals is poorly general (Dai et al., 2020). Only considering the power spectrum is quite limiting at the current moment. The convolutional operation executed by most popular machine learning libraries in deep learning is actually computing the correlation measurement (Graves, 2012). Future work investigating state classification and reactivation should also take steps to measure event-related desynchronization and synchronization in the context of the data generated.</p>\n<p>Another idea to optimize the model is to replace the fully connected layer with global average pooling. The model holds a redundancy of fully connected layer parameters where fully connected layer parameters can account for about 80% of the entire network parameters. Some recent network models with excellent performance, such as ResNet, are trying to use global average pooling (GAP) layer instead of a fully connected layer for fusion. For the learned deep features, loss functions such as SoftMax are still used as the network objective function to guide the learning process (Liu &amp; Zeng, 2022) Some evidence suggests that networks that replace a fully connected layer with a GAP layer may have better classification performance (Wei et al., 2018). However, other studies have pointed out that when applying transfer learning, the fine-tuned results of networks without fully connected layers are worse than those with fully connected layers. Therefore, fully connected can be regarded as a guard for model representation capabilities, especially in the case that there are big differences between the source domain and the target domain, the redundant parameters of FC can maintain a fine model capacity to ensure the migration of model representation capabilities (Zhang et al., 2018). Future work can explore the role of the GAP layer and fully connected layer in detail.</p>\n<p>ASRCNet can extract and analyze features that deep learning neural networks use for classification, which may help researchers understand brain states better. The inherent hidden patterns in brain states and related brain neural activity that deep learning may reveal some fundamental mechanisms behind human behaviour. To the extent these can be explained, researchers are encouraged to apply these sophisticated deep learning modelling techniques to obtain accurate classification and prediction results and to generalize the results more carefully in a wider range of conditions. Moreover, understanding the relevant studies that extract these hidden patterns can increase and deepen our understanding of the brain state electrophysiological characterization.</p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><p>Anelli, M., Lauri, S. P., Advisor, P., &amp; Zubarev, M. I. (2021). <em>Using deep learning to predict continuous hand kinematics from magnetoencephalographic (MEG) measurements of electromagnetic brain activity.</em> <a href=\"http://www.aalto.fi\">www.aalto.fi</a></p>\n<p>Aoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., &amp; Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. <em>Scientific Reports</em>, <em>9</em>(1). <a href=\"https://doi.org/10.1038/S41598-019-41500-X\">https://doi.org/10.1038/S41598-019-41500-X</a></p>\n<p>Bai, S., Kolter, J. Z., &amp; Koltun, V. (2018). <em>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</em>. <a href=\"https://doi.org/10.48550/arxiv.1803.01271\">https://doi.org/10.48550/arxiv.1803.01271</a></p>\n<p>Baumeister, J., Barthel, T., Geiss, K. R., &amp; Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. <em><a href=\"Http://Dx.Doi.Org/10.1179/147683008X301478\">Http://Dx.Doi.Org/10.1179/147683008X301478</a></em>, <em>11</em>(3), 103–110. <a href=\"https://doi.org/10.1179/147683008X301478\">https://doi.org/10.1179/147683008X301478</a></p>\n<p>Belal, S., Cousins, J., El-Deredy, W., Parkes, L., Schneider, J., Tsujimura, H., Zoumpoulaki, A., Perapoch, M., Santamaria, L., &amp; Lewis, P. (2018). Identification of memory reactivation during sleep by EEG classification. <em>NeuroImage</em>, <em>176</em>, 203–214. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2018.04.029\">https://doi.org/10.1016/J.NEUROIMAGE.2018.04.029</a></p>\n<p>Boto, E., Holmes, N., Leggett, J., Roberts, G., Shah, V., Meyer, S. S., Muñoz, L. D., Mullinger, K. J., Tierney, T. M., Bestmann, S., Barnes, G. R., Bowtell, R., &amp; Brookes, M. J. (2018). Moving magnetoencephalography towards real-world applications with a wearable system. <em>Nature 2018 555:7698</em>, <em>555</em>(7698), 657–661. <a href=\"https://doi.org/10.1038/nature26147\">https://doi.org/10.1038/nature26147</a></p>\n<p>Brown, R. E., &amp; Milner, P. M. (2003). The legacy of Donald O. Hebb: More than the Hebb Synapse. <em>Nature Reviews Neuroscience</em>, <em>4</em>(12), 1013–1019. <a href=\"https://doi.org/10.1038/NRN1257\">https://doi.org/10.1038/NRN1257</a></p>\n<p>Bunge, S. A., &amp; Kahn, I. (2009). Cognition: An Overview of Neuroimaging Techniques. <em>Encyclopedia of Neuroscience</em>, 1063–1067. <a href=\"https://doi.org/10.1016/B978-008045046-9.00298-9\">https://doi.org/10.1016/B978-008045046-9.00298-9</a></p>\n<p>Bzdok, D., &amp; Meyer-Lindenberg, A. (2018). Machine Learning for Precision Psychiatry: Opportunities and Challenges. <em>Biological Psychiatry. Cognitive Neuroscience and Neuroimaging</em>, <em>3</em>(3), 223–230. <a href=\"https://doi.org/10.1016/J.BPSC.2017.11.007\">https://doi.org/10.1016/J.BPSC.2017.11.007</a></p>\n<p>Currie, G., Hawk, K. E., Rohren, E., Vial, A., &amp; Klein, R. (2019). Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging. <em>Journal of Medical Imaging and Radiation Sciences</em>, <em>50</em>(4), 477–487. <a href=\"https://doi.org/10.1016/j.jmir.2019.09.005\">https://doi.org/10.1016/j.jmir.2019.09.005</a></p>\n<p>Dai, G., Zhou, J., Huang, J., &amp; Wang, N. (2020). HS-CNN: a CNN with hybrid convolution scale for EEG motor imagery classification. <em>Journal of Neural Engineering</em>, <em>17</em>(1), 016025. <a href=\"https://doi.org/10.1088/1741-2552/AB405F\">https://doi.org/10.1088/1741-2552/AB405F</a></p>\n<p>Dale, A. M., &amp; Sereno, M. I. (1993). Improved Localizadon of Cortical Activity by Combining EEG and MEG with MRI Cortical Surface Reconstruction: A Linear Approach. <em>Journal of Cognitive Neuroscience</em>, <em>5</em>(2), 162–176. <a href=\"https://doi.org/10.1162/JOCN.1993.5.2.162\">https://doi.org/10.1162/JOCN.1993.5.2.162</a></p>\n<p>Dash, D., Ferrari, P., Heitzman, D., &amp; Wang, J. (2019). Decoding Speech from Single Trial MEG Signals Using Convolutional Neural Networks and Transfer Learning. <em>Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS</em>, 5531–5535. <a href=\"https://doi.org/10.1109/EMBC.2019.8857874\">https://doi.org/10.1109/EMBC.2019.8857874</a></p>\n<p>Dash, D., Sao, A. K., Wang, J., &amp; Biswal, B. (2019). How many fmri scans are necessary and sufficient for resting brain connectivity analysis? <em>2018 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2018 - Proceedings</em>, 494–498. <a href=\"https://doi.org/10.1109/GLOBALSIP.2018.8646415\">https://doi.org/10.1109/GLOBALSIP.2018.8646415</a></p>\n<p>de Bardeci, M., Ip, C. T., &amp; Olbrich, S. (2021). Deep learning applied to electroencephalogram data in mental disorders: A systematic review. <em>Biological Psychology</em>, <em>162</em>, 108117. <a href=\"https://doi.org/10.1016/J.BIOPSYCHO.2021.108117\">https://doi.org/10.1016/J.BIOPSYCHO.2021.108117</a></p>\n<p>Doll, B. B., Duncan, K. D., Simon, D. A., Shohamy, D., &amp; Daw, N. D. (2015). Model-based choices involve prospective neural activity. <em>Nature Neuroscience</em>, <em>18</em>(5), 767. <a href=\"https://doi.org/10.1038/NN.3981\">https://doi.org/10.1038/NN.3981</a></p>\n<p>Eichenlaub, J. B., Biswal, S., Peled, N., Rivilis, N., Golby, A. J., Lee, J. W., Westover, M. B., Halgren, E., &amp; Cash, S. S. (2020). Reactivation of Motor-Related Gamma Activity in Human NREM Sleep. <em>Frontiers in Neuroscience</em>, <em>14</em>. <a href=\"https://doi.org/10.3389/FNINS.2020.00449\">https://doi.org/10.3389/FNINS.2020.00449</a></p>\n<p>Einöther, S. J. L., Giesbrecht, T., Walden, C. M., van Buren, L., van der Pijl, P. C., &amp; de Bruin, E. A. (2013). Attention Benefits of Tea and Tea Ingredients: A Review of the Research to Date. <em>Tea in Health and Disease Prevention</em>, 1373–1384. <a href=\"https://doi.org/10.1016/B978-0-12-384937-3.00115-4\">https://doi.org/10.1016/B978-0-12-384937-3.00115-4</a></p>\n<p>Faraji, I., Mirsadeghi, S. H., &amp; Afsahi, A. (2016). Topology-aware GPU selection on multi-GPU nodes. <em>Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016</em>, 712–720. <a href=\"https://doi.org/10.1109/IPDPSW.2016.44\">https://doi.org/10.1109/IPDPSW.2016.44</a></p>\n<p>Giovannetti, A., Susi, G., Casti, P., Mencattini, A., Pusil, S., López, M. E., di Natale, C., &amp; Martinelli, E. (2021). Deep-MEG: spatiotemporal CNN features and multiband ensemble classification for predicting the early signs of Alzheimer’s disease with magnetoencephalography. <em>Neural Computing and Applications</em>, <em>33</em>(21), 14651–14667. <a href=\"https://doi.org/10.1007/S00521-021-06105-4/TABLES/4\">https://doi.org/10.1007/S00521-021-06105-4/TABLES/4</a></p>\n<p>Gramfort, A., Luessi, M., Larson, E., Engemann, D. A., Strohmeier, D., Brodbeck, C., Parkkonen, L., &amp; Hämäläinen, M. S. (2014). MNE software for processing MEG and EEG data. <em>NeuroImage</em>, <em>86</em>, 446–460. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2013.10.027\">https://doi.org/10.1016/J.NEUROIMAGE.2013.10.027</a></p>\n<p>Graves, A. (2012). <em>Supervised Sequence Labelling</em>. 5–13. <a href=\"https://doi.org/10.1007/978-3-642-24797-2_2\">https://doi.org/10.1007/978-3-642-24797-2_2</a></p>\n<p>Greenspan, H., van Ginneken, B., &amp; Summers, R. M. (2016). Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique. <em>IEEE Transactions on Medical Imaging</em>, <em>35</em>(5), 1153–1159. <a href=\"https://doi.org/10.1109/TMI.2016.2553401\">https://doi.org/10.1109/TMI.2016.2553401</a></p>\n<p>Hagemann, D., Hewig, J., Walter, C., &amp; Naumann, E. (2008). Skull thickness and magnitude of EEG alpha activity. <em>Clinical Neurophysiology</em>, <em>119</em>(6), 1271–1280. <a href=\"https://doi.org/10.1016/J.CLINPH.2008.02.010\">https://doi.org/10.1016/J.CLINPH.2008.02.010</a></p>\n<p>Hardt, M., Recht, B., &amp; Singer, Y. (2015). Train faster, generalize better: Stability of stochastic gradient descent. <em>33rd International Conference on Machine Learning, ICML 2016</em>, <em>3</em>, 1868–1877. <a href=\"https://doi.org/10.48550/arxiv.1509.01240\">https://doi.org/10.48550/arxiv.1509.01240</a></p>\n<p>Haynes, J. D. (2012). Brain reading. <em>I Know What You’re Thinking: Brain Imaging and Mental Privacy</em>. <a href=\"https://doi.org/10.1093/ACPROF:OSO/9780199596492.003.0003\">https://doi.org/10.1093/ACPROF:OSO/9780199596492.003.0003</a></p>\n<p>Hedderich, D. M., &amp; Eickhoff, S. B. (2021). Machine learning for psychiatry: getting doctors at the black box? <em>Molecular Psychiatry</em>, <em>26</em>(1), 23. <a href=\"https://doi.org/10.1038/S41380-020-00931-Z\">https://doi.org/10.1038/S41380-020-00931-Z</a></p>\n<p>Hoshen, Y., Weiss, R. J., &amp; Wilson, K. W. (2015). Speech acoustic modeling from raw multichannel waveforms. <em>ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</em>, <em>2015-August</em>, 4624–4628. <a href=\"https://doi.org/10.1109/ICASSP.2015.7178847\">https://doi.org/10.1109/ICASSP.2015.7178847</a></p>\n<p>Huang, W., Yan, H., Wang, C., Li, J., Yang, X., Li, L., Zuo, Z., Zhang, J., &amp; Chen, H. (2020). Long short-term memory-based neural decoding of object categories evoked by natural images. <em>Human Brain Mapping</em>, <em>41</em>(15), 4442–4453. <a href=\"https://doi.org/10.1002/hbm.25136\">https://doi.org/10.1002/hbm.25136</a></p>\n<p>Huang, Y., Sun, X., Lu, M., &amp; Xu, M. (2015). Channel-Max, Channel-Drop and Stochastic Max-pooling. <em>IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops</em>, <em>2015-October</em>, 9–17. <a href=\"https://doi.org/10.1109/CVPRW.2015.7301267\">https://doi.org/10.1109/CVPRW.2015.7301267</a></p>\n<p>IBM Corp. (2021). <em>IBM SPSS Statistics for Windows</em>. <a href=\"https://hadoop.apache.org\">https://hadoop.apache.org</a></p>\n<p>Ioffe, S., &amp; Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. <em>32nd International Conference on Machine Learning, ICML 2015</em>, <em>1</em>, 448–456. <a href=\"https://doi.org/10.48550/arxiv.1502.03167\">https://doi.org/10.48550/arxiv.1502.03167</a></p>\n<p>Karimpanal, T. G., &amp; Bouffanais, R. (2018). Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning. <em>Adaptive Behavior</em>, <em>27</em>(2), 111–126. <a href=\"https://doi.org/10.1177/1059712318818568\">https://doi.org/10.1177/1059712318818568</a></p>\n<p>Khan, S., Rahmani, H., Shah, S. A. A., &amp; Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. <em>A Guide to Convolutional Neural Networks for Computer Vision</em>. <a href=\"https://doi.org/10.1007/978-3-031-01821-3\">https://doi.org/10.1007/978-3-031-01821-3</a></p>\n<p>King’s College London. (2022). <em>King’s Computational Research, Engineering and Technology Environment (CREATE).</em></p>\n<p>Li, H., Ellis, J. G., Zhang, L., &amp; Chang, S. F. (2018). PatternNet: Visual pattern mining with deep neural network. <em>ICMR 2018 - Proceedings of the 2018 ACM International Conference on Multimedia Retrieval</em>, 291–299. <a href=\"https://doi.org/10.1145/3206025.3206039\">https://doi.org/10.1145/3206025.3206039</a></p>\n<p>Liu, W., &amp; Zeng, Y. (2022). Motor Imagery Tasks EEG Signals Classification Using ResNet with Multi-Time-Frequency Representation. <em>2022 7th International Conference on Intelligent Computing and Signal Processing, ICSP 2022</em>, 2026–2029. <a href=\"https://doi.org/10.1109/ICSP54964.2022.9778786\">https://doi.org/10.1109/ICSP54964.2022.9778786</a></p>\n<p>Luo, J., Feng, Z., Zhang, J., &amp; Lu, N. (2016). Dynamic frequency feature selection based approach for classification of motor imageries. <em>Computers in Biology and Medicine</em>, <em>75</em>, 45–53. <a href=\"https://doi.org/10.1016/J.COMPBIOMED.2016.03.004\">https://doi.org/10.1016/J.COMPBIOMED.2016.03.004</a></p>\n<p>Newson, J. J., &amp; Thiagarajan, T. C. (2019). EEG Frequency Bands in Psychiatric Disorders: A Review of Resting State Studies. <em>Frontiers in Human Neuroscience</em>, <em>12</em>, 521. <a href=\"https://doi.org/10.3389/FNHUM.2018.00521/BIBTEX\">https://doi.org/10.3389/FNHUM.2018.00521/BIBTEX</a></p>\n<p>Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., Facebook, Z. D., Research, A. I., Lin, Z., Desmaison, A., Antiga, L., Srl, O., &amp; Lerer, A. (2017). <em>Automatic differentiation in PyTorch</em>.</p>\n<p>Percival, D. B., &amp; Walden, A. T. (1993). Spectral Analysis for Physical Applications. <em>Spectral Analysis for Physical Applications</em>. <a href=\"https://doi.org/10.1017/CBO9780511622762\">https://doi.org/10.1017/CBO9780511622762</a></p>\n<p>Pettersen, K. H., Devor, A., Ulbert, I., Dale, A. M., &amp; Einevoll, G. T. (2006). Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities. <em>Journal of Neuroscience Methods</em>, <em>154</em>(1–2), 116–133. <a href=\"https://doi.org/10.1016/J.JNEUMETH.2005.12.005\">https://doi.org/10.1016/J.JNEUMETH.2005.12.005</a></p>\n<p>Rajasree, R., Columbus, C. C., &amp; Shilaja, C. (2021). Multiscale-based multimodal image classification of brain tumor using deep learning method. <em>Neural Computing and Applications</em>, <em>33</em>(11), 5543–5553. <a href=\"https://doi.org/10.1007/S00521-020-05332-5/FIGURES/9\">https://doi.org/10.1007/S00521-020-05332-5/FIGURES/9</a></p>\n<p>Rapcsak, S. Z. (2019). Face Recognition. <em>Current Neurology and Neuroscience Reports</em>, <em>19</em>(7). <a href=\"https://doi.org/10.1007/S11910-019-0960-9\">https://doi.org/10.1007/S11910-019-0960-9</a></p>\n<p>RaviPrakash, H., Korostenskaja, M., Castillo, E. M., Lee, K. H., Salinas, C. M., Baumgartner, J., Anwar, S. M., Spampinato, C., &amp; Bagci, U. (2020). Deep Learning Provides Exceptional Accuracy to ECoG-Based Functional Language Mapping for Epilepsy Surgery. <em>Frontiers in Neuroscience</em>, <em>14</em>. <a href=\"https://doi.org/10.3389/FNINS.2020.00409/FULL\">https://doi.org/10.3389/FNINS.2020.00409/FULL</a></p>\n<p>Rohenkohl, G., &amp; Nobre, A. C. (2011). Alpha Oscillations Related to Anticipatory Attention Follow Temporal Expectations. <em>The Journal of Neuroscience</em>, <em>31</em>(40), 14076. <a href=\"https://doi.org/10.1523/JNEUROSCI.3387-11.2011\">https://doi.org/10.1523/JNEUROSCI.3387-11.2011</a></p>\n<p>Roscow, E. L., Chua, R., Costa, R. P., Jones, M. W., &amp; Lepora, N. (2021). Learning offline: memory replay in biological and artificial reinforcement learning. <em>Trends in Neurosciences</em>, <em>44</em>(10), 808–821. <a href=\"https://doi.org/10.1016/J.TINS.2021.07.007\">https://doi.org/10.1016/J.TINS.2021.07.007</a></p>\n<p>Schacter, D. L., Benoit, R. G., &amp; Szpunar, K. K. (2017). Episodic Future Thinking: Mechanisms and Functions. <em>Current Opinion in Behavioral Sciences</em>, <em>17</em>, 41. <a href=\"https://doi.org/10.1016/J.COBEHA.2017.06.002\">https://doi.org/10.1016/J.COBEHA.2017.06.002</a></p>\n<p>Sharon, D., Hämäläinen, M. S., Tootell, R. B. H., Halgren, E., &amp; Belliveau, J. W. (2007). The advantage of combining MEG and EEG: Comparison to fMRI in focally stimulated visual cortex. <em>NeuroImage</em>, <em>36</em>(4), 1225–1235. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2007.03.066\">https://doi.org/10.1016/J.NEUROIMAGE.2007.03.066</a></p>\n<p>Shaw, G. L. (1986). Donald Hebb: The Organization of Behavior. <em>Brain Theory</em>, 231–233. <a href=\"https://doi.org/10.1007/978-3-642-70911-1_15\">https://doi.org/10.1007/978-3-642-70911-1_15</a></p>\n<p>Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui, F., Sifre, L., van den Driessche, G., Graepel, T., &amp; Hassabis, D. (2017). Mastering the game of Go without human knowledge. <em>Nature 2017 550:7676</em>, <em>550</em>(7676), 354–359. <a href=\"https://doi.org/10.1038/nature24270\">https://doi.org/10.1038/nature24270</a></p>\n<p>Singh, S. P. (2014). Magnetoencephalography: Basic principles. <em>Annals of Indian Academy of Neurology</em>, <em>17</em>(Suppl 1), S107. <a href=\"https://doi.org/10.4103/0972-2327.128676\">https://doi.org/10.4103/0972-2327.128676</a></p>\n<p>Slepian, D. (1978). Prolate Spheroidal Wave Functions, Fourier Analysis, and Uncertainty—V: The Discrete Case. <em>Bell System Technical Journal</em>, <em>57</em>(5), 1371–1430. <a href=\"https://doi.org/10.1002/J.1538-7305.1978.TB02104.X\">https://doi.org/10.1002/J.1538-7305.1978.TB02104.X</a></p>\n<p>Soria Olivas, E., &amp; IGI Global. (2010). <em>Handbook of research on machine learning applications and trends : algorithms, methods, and techniques</em>. 83.</p>\n<p>Srivastava, N., Hinton, G., Krizhevsky, A., &amp; Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. <em>Journal of Machine Learning Research</em>, <em>15</em>, 1929–1958. <a href=\"https://doi.org/10.5555/2627435\">https://doi.org/10.5555/2627435</a></p>\n<p>Szpunar, K. K. (2010). Episodic Future Thought: An Emerging Concept. <em>Perspectives on Psychological Science : A Journal of the Association for Psychological Science</em>, <em>5</em>(2), 142–162. <a href=\"https://doi.org/10.1177/1745691610362350\">https://doi.org/10.1177/1745691610362350</a></p>\n<p>Tappert, C. C. (2019). Who is the father of deep learning? <em>Proceedings - 6th Annual Conference on Computational Science and Computational Intelligence, CSCI 2019</em>, 343–348. <a href=\"https://doi.org/10.1109/CSCI49370.2019.00067\">https://doi.org/10.1109/CSCI49370.2019.00067</a></p>\n<p>Terranova, J. I., Yokose, J., Osanai, H., Marks, W. D., Yamamoto, J., Ogawa, S. K., &amp; Kitamura, T. (2022). Hippocampal-amygdala memory circuits govern experience-dependent observational fear. <em>Neuron</em>, <em>110</em>(8), 1416-1431.e13. <a href=\"https://doi.org/10.1016/J.NEURON.2022.01.019\">https://doi.org/10.1016/J.NEURON.2022.01.019</a></p>\n<p>Tokozume, Y., &amp; Harada, T. (2017). Learning environmental sounds with end-to-end convolutional neural network. <em>ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</em>, 2721–2725. <a href=\"https://doi.org/10.1109/ICASSP.2017.7952651\">https://doi.org/10.1109/ICASSP.2017.7952651</a></p>\n<p>Tokozume, Y., Ushiku, Y., &amp; Harada, T. (2017). Learning from Between-class Examples for Deep Sound Recognition. <em>6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings</em>. <a href=\"https://doi.org/10.48550/arxiv.1711.10282\">https://doi.org/10.48550/arxiv.1711.10282</a></p>\n<p>Valueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., &amp; Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. <em>Mathematics and Computers in Simulation</em>, <em>177</em>, 232–243. <a href=\"https://doi.org/10.1016/J.MATCOM.2020.04.031\">https://doi.org/10.1016/J.MATCOM.2020.04.031</a></p>\n<p>Wei, X. S., Zhang, C. L., Zhang, H., &amp; Wu, J. (2018). Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences. <em>IEEE Transactions on Affective Computing</em>, <em>9</em>(3), 303–315. <a href=\"https://doi.org/10.1109/TAFFC.2017.2762299\">https://doi.org/10.1109/TAFFC.2017.2762299</a></p>\n<p>Wimmer, G. E., &amp; Shohamy, D. (2012). Preference by association: how memory mechanisms in the hippocampus bias decisions. <em>Science (New York, N.Y.)</em>, <em>338</em>(6104), 270–273. <a href=\"https://doi.org/10.1126/SCIENCE.1223252\">https://doi.org/10.1126/SCIENCE.1223252</a></p>\n<p>Wise, T., Liu, Y., Chowdhury, F., &amp; Dolan, R. J. (2021). Model-based aversive learning in humans is supported by preferential task state reactivation. <em>Science Advances</em>, <em>7</em>(31), 9616–9644. <a href=\"https://doi.org/10.1126/SCIADV.ABF9616\">https://doi.org/10.1126/SCIADV.ABF9616</a></p>\n<p>Wu, C. T., Haggerty, D., Kemere, C., &amp; Ji, D. (2017). Hippocampal awake replay in fear memory retrieval. <em>Nature Neuroscience</em>, <em>20</em>(4), 571. <a href=\"https://doi.org/10.1038/NN.4507\">https://doi.org/10.1038/NN.4507</a></p>\n<p>Yann LeCun, Corinna Cortes, &amp; Chris Burges. (2012). <em>MNIST handwritten digit database</em>. <a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a></p>\n<p>Yu, F. T. S., &amp; Guowen, L. (1994). Short-time Fourier transform and wavelet transform with Fourier-domain processing. <em>Applied Optics</em>, <em>33</em>(23), 5262–5270. <a href=\"https://doi.org/10.1364/AO.33.005262\">https://doi.org/10.1364/AO.33.005262</a></p>\n<p>Zhang, C. L., Luo, J. H., Wei, X. S., &amp; Wu, J. (2018). In defense of fully connected layers in visual representation transfer. <em>Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>, <em>10736 LNCS</em>, 807–817. <a href=\"https://doi.org/10.1007/978-3-319-77383-4_79/TABLES/4\">https://doi.org/10.1007/978-3-319-77383-4_79/TABLES/4</a></p>\n<p>Zheng, L., Liao, P., Luo, S., Sheng, J., Teng, P., Luan, G., &amp; Gao, J. H. (2020). EMS-Net: A Deep Learning Method for Autodetecting Epileptic Magnetoencephalography Spikes. <em>IEEE Transactions on Medical Imaging</em>, <em>39</em>(6), 1833–1844. <a href=\"https://doi.org/10.1109/TMI.2019.2958699\">https://doi.org/10.1109/TMI.2019.2958699</a></p>\n<p>Zubarev, I., Zetter, R., Halme, H. L., &amp; Parkkonen, L. (2019). Adaptive neural network classifier for decoding MEG signals. <em>NeuroImage</em>, <em>197</em>, 425–434. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2019.04.068\">https://doi.org/10.1016/J.NEUROIMAGE.2019.04.068</a></p>\n","excerpt":"","more":"<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208251426116.png\" alt=\"LuoLei_Poster2022_Page_2\"></p>\n<p><strong>A novel convolutional neural network approach for classifying brain states under image stimuli</strong></p>\n<p>Lei Luo</p>\n<p>Dr. Toby Wise</p>\n<p>Department of Neuroimaging<br>Institute of Psychiatry, Psychology &amp; Neuroscience<br>King’s College London<br>University of London</p>\n<p><strong>Thesis in partial fulfilment for the degree of MSc in Neuroscience September, 2022.</strong></p>\n<h1 id=\"Personal-Statement\"><a href=\"#Personal-Statement\" class=\"headerlink\" title=\"Personal Statement:\"></a>Personal Statement:</h1><p>The study was designed by Lei Luo under the supervision of Dr. Toby Wise. MEG data was from Wise et al. (2021). The thesis was written entirely by Lei Luo, with language corrections and suggestions from Dr. Toby wise. Any research or work mentioned in the paper has been fully and accurately cited. Computation resource is provided by King&#39;s Computational Research, Engineering and Technology Environment (CREATE) (King’s College London, 2022). The neural network code is using machine learning library Pytorch (Paszke et al., 2017). Statistics are done with IBM Spss. Topographical maps are generated using library MNE-Python. Code availability: MEG data used in this research in available at <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a>; and all analysis code in available at <a href=\"https://github.com/ReveRoyl/MT_ML_Decoding\">https://github.com/ReveRoyl/MT_ML_Decoding</a>.</p>\n<h1 id=\"Abbreviations\"><a href=\"#Abbreviations\" class=\"headerlink\" title=\"Abbreviations\"></a>Abbreviations</h1><p>CBAM Convolutional block attention module</p>\n<p>CNN Convolutional neural network</p>\n<p>ECoG Electrocorticography</p>\n<p>EEG Electroencephalography</p>\n<p>ICA Independent Components Analysis</p>\n<p>MEG Magnetoencephalography</p>\n<p>MLP Multilayer perceptron</p>\n<p>MRI Magnetic resonance imaging</p>\n<p>fMRI Functional magnetic resonance imaging</p>\n<p>FC Fully connected</p>\n<p>LSTM Long short-term memory</p>\n<p>RNN Recurrent Neural Network</p>\n<p>RPS Relative power spectrum</p>\n<p>PCA principal component analysis</p>\n<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Background: The mechanism of human neural responses to different stimuli has always been of interest to neuroscientists. In the clinical situation, tools to distinguish different diseases or states are required. However, classic classification methods have obvious shortcomings: traditional clinical categorical methods may not be competent for behaviour prediction or brain state classification and traditional machine learning models are improvable in classification accuracy. With the increasing use of convolutional neural networks (CNN) in neuroimaging computer-assisted classification, an ensemble classifier of CNNs might be able to mine hidden patterns from MEG signals. However, developing an effective brain state classifier is a difficult task owing to the non-Euclidean graphical nature of magnetoencephalography (MEG) signals.</p>\n<p>Objective: This project had two aims: 1) to develop a CNN-based model with better performance in classification than traditional machine learning models; 2) to test if the model can be improved with extra information adding relative power spectrum.</p>\n<p>Methods: To address this brain state classification modelling issue, I used MEG signals from 28 participants viewing 14 image stimuli to train the CNN. The CNN subsequently underwent 10-fold cross-validation to ensure proper classification of MEG. I also extracted the relative power spectrum and provided this to the network. The following main techniques were applied in this research, principal component analysis (PCA), convolutional block spatial and temporal features extracting modules, convolutional block attention module (CBAM) techniques, relative power spectrum (RPS) techniques, fully connected (FC) techniques.</p>\n<p>Results: In this research, my method was applied to the MEG dataset, the average classification accuracy is 23.07%±7.69%, which is much better than the baseline models: LSTM RNN model 15.38% (p = 6.8 × 10 ^–2^) and simple image classification CNN model 11.53% (p = 5.9 × 10 ^–2^). Relative power spectrum information (mainly beta and delta during this task) successfully informed the model improving its performance.</p>\n<p>Conclusion: These results demonstrate that my method is feasible for the analysis and classification of brain states. It may help researchers diagnose people in the clinical situations and inform future neurological classification approaches in regard to higher specificity in identifying brain states.</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><h2 id=\"Machine-learning-in-medical-utilisation\"><a href=\"#Machine-learning-in-medical-utilisation\" class=\"headerlink\" title=\"Machine learning in medical utilisation\"></a>Machine learning in medical utilisation</h2><p>Since Donald Hebb first composed the cell assembly theory stating the consistency between neuronal activity and cognitive processes (Brown &amp; Milner, 2003; Shaw, 1986), the idea of neural networks started to stand out in public visibility. Until Frank Rosenblatt first developed and explored the basic ingredients of deep learning (DL) (Tappert, 2019), the only constraint that can slow our steps are applications of math methods. The last past decades have seen the quick and great revolution of artificial intelligence as the development of computer science. What the big breakthrough takes us close to the scientific field are the powerful tools that teach machines to learn about the physical world. Even though machine learning techniques have gradually built their presence in recent decades, the application in medical utilisation lags.</p>\n<p>In the past centuries, neuroscientists have always been attempting to classify and predict the brain’s response to the visual world. Recently, with the rapid emergence of novel non-invasive techniques such as magnetoencephalography (MEG), electroencephalography (EEG) and magnetic resonance imaging (MRI), neuroscientists start to use these tools to solve the historical conundrum; and have made huge progress in the visual perceptual decoding or so-called “brain-reading” field (W. Huang et al., 2020). Each individual conscious experience is associated with a unique brain activity pattern so that it can be regarded as a fingerprint of specific brain activity. It is theoretically viable to read out one’s current idea with a specifically designed computer vision and neuroimaging pattern (Haynes, 2012). In this case, it might be possible that these “brain-reading” techniques can tell us that could be helpful with regard to clinical applications. Nowadays, many neural mechanisms have been elucidated. Although the current studies are mostly on a reflective proof of concept track (Hedderich &amp; Eickhoff, 2021), it is promising that these approaches will pave the way and build a solid foundation in regard to clinical applications. In contrast to the classic understanding of some mental mechanisms, more and more researchers believe that traditional categories systems may twist the real cause of diseases or behaviours (Bzdok &amp; Meyer-Lindenberg, 2018). To fill this gap, deep learning techniques have been introduced into disease diagnosis and classification. It can avoid being affected by people’s opinion bias but conversely get feedback from people so as to improve its learning ability from existing experience (Currie et al., 2019). Apart from disease classification, it is more profound to study human brain states under different conditions. Further studying of future state simulation has properly gained attention, especially on episodic future thought: the ability to rehearse events in mind, which may be going to happen in one’s life trajectory (Schacter et al., 2017; Szpunar, 2010).</p>\n<h2 id=\"Aversive-state-reactivation-and-replay\"><a href=\"#Aversive-state-reactivation-and-replay\" class=\"headerlink\" title=\"Aversive state reactivation and replay\"></a>Aversive state reactivation and replay</h2><p>The aversive state is critical for harm avoidance, playing a vital role in wilderness survival and social life (Terranova et al., 2022). As part of the aversive state, the observational fear process promotes one’s capability of showing empathic fear when seeing other’s aversive situations. This process may benefit from the neural replay and reactivation of individuals. The process that current state simulation reinforces the existing memory network is called “reactivation” while the neural activity activation is named “neural replay”. The reactivation is based on past experience and in turn, promotes the storage of it, as well as facilitating the planning, inference and reward values updating (Wimmer &amp; Shohamy, 2012; Wise et al., 2021). As mentioned in the previous section, one way to look at future thought simulation is to investigate memory reactivation.</p>\n<p>Recent works have shown that neural replay and reactivation are prior important in avoidance behaviour (Wu et al., 2017), which may provide individuals with a prospective prediction based on the possible consequence simulation (Doll et al., 2015). Since then, it is known “which” correlates to the aversive state, the following step is figuring out to what extent neuronal activity is associated with behaviour. Naturally, it encourages researchers to try predicting one’s avoidance behaviour with the neuroimaging data recording. In recent years, more and more studies start to use neuroimaging classification to look for the inner mechanisms of brain states’ reactivation (Belal et al., 2018; Eichenlaub et al., 2020; Roscow et al., 2021). If we want to look at memory reactivation, what we need is really good decoding methods with neuroimaging data recordings. So, it’s important to optimise existing decoding methods as far as possible, which will set the scene for future related work.</p>\n<h2 id=\"Magnetoencephalography\"><a href=\"#Magnetoencephalography\" class=\"headerlink\" title=\"Magnetoencephalography\"></a>Magnetoencephalography</h2><p>Magnetoencephalography (MEG) is useful for detecting brain states and evaluating the behavioural response. It allows us to map and locate specific brain areas and ongoing functions (Bunge &amp; Kahn, 2009). The principle of MEG is based on magnetic induction. It is widely known that when neurons are activated, electrical signals will be generated synchronously. According to the magnetic induction principle, when the electrical fields change, secondary magnetic fields are generated. The brain-evoked magnetic field strength is usually in the range of femto-tesla to pico-tesla, i.e., 10–15 to 10-12 tesla (Singh, 2014). With the precise MEG device and mathematical preprocessing methods, these tiny signals are able to be separated from the noise and collected. MEG records magnetic fields, from which can be inferred changes in the transmission of postsynaptic current between cortical neurons.</p>\n<p>Compared to other neuroimaging methods, functional magnetic resonance imaging (fMRI) has high spatial resolution but a low temporal resolution (Dash, Sao, et al., 2019); electroencephalography (EEG) records the electrical field that may twist between skin and skull, and EEG is based to reference point location hence it is sensitive to small measurement error. Electrocorticography (ECoG) is an invasive method, so it is not suitable for healthy participants and some patients; MEG stands out for its higher spatial, temporal resolution and dynamic time sequentiality. At the same time, MEG, as a non-invasive method, has its specific advantage: low preparation time, which supports a possibility for most clinical conditions. Furthermore, as novel portable MEG devices come out, it creates opportunity for various ages participants and patients (Boto et al., 2018). MEG data records complex high-dimensional information about the brain network and the responding source locations, which is hard to collect with classic classification methods (Giovannetti et al., 2021). However, in the analysis period, it is a burden for researchers to do classification with MEG data: it is complex to correctly extract required signals during preprocessing, and lots of related experience is required when dealing with complex sensors and waveform patterns. Hence deep learning is expected to lighten the load of researchers, add the universal applicability of classification and increase the prediction accuracy. In this case, it is a challenge to choose the proper neural network.</p>\n<h2 id=\"Convolutional-Neural-Network\"><a href=\"#Convolutional-Neural-Network\" class=\"headerlink\" title=\"Convolutional Neural Network\"></a>Convolutional Neural Network</h2><p>The CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018). The same as the real neural networks in the brain, neurons in CNN process limited input data in a restricted receptive field and cooperate with each other by overlapping to cover the whole visual space (the filter extracting the features is called kernels). It is an automatic feature extraction process. Thus, it is now necessary to manually design feature extraction algorithms, which is required in traditional machine learning algorithms. It is also the main advantage of CNN to learn features from input data: avoiding the impact of artificial artefact in the algorithm design step. The main specialization of CNN is clearly the convolution part, which is a linear mathematic operation allowing extracting the nearby features of input data. The convolutional operation generates a series of machine-recognizable output features. It is suggested that the convolutional layer can be considered as a graphical pattern mining or feature extraction process (Li et al., 2018). What is more, previous research has shown the ability of CNN as a tool for analysing MEG data, which is in detail classifying brain activity and identifying potential neural sources (Zubarev et al., 2019). The process of generating the features map is following the sequential architecture, which is not like a cyclical recurrent neural network. A CNN model is usually composed of the input layer (the first layer where input data is passed in), multiple convolutional layers (feature extraction layers), alternative pooling layers (downsampling layer for feature maps), fully connecting layers (used to map the feature vectors obtained from previous feature extraction layers to the next layer), and output layers (the final layer where predictions are made). Inside each layer, activation functions are optional. A simple CNN network is shown as an example in figure 1. The convolutional layer receives input data, apply the convolution process to the data, and passes data to the following step. In the convolution function shown in equation 1, the f stands for input data; k stands for kernel filter, m, n respectively stands for the result matrix rows and columns index:</p>\n<p>$$\\begin{matrix}<br>G\\lbrack m,\\ n\\rbrack = \\ (f*k)\\lbrack m,\\ n\\rbrack = \\ \\sum_{i = 1}^{m}\\ \\sum_{j = 1}^{n}\\ \\ k\\lbrack i,\\ j\\rbrack f\\lbrack m - i,\\ n - j\\rbrack\\ \\ (1) \\<br>\\end{matrix}$$</p>\n<p>As shown in figure 2 (A), a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure 2 (B)) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well (Y. Huang et al., 2015).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717167.png\" alt=\"image-20220824171734112\"></p>\n<p><strong>Figure 1.</strong> A simple CNN architecture illustration (5 convolutional layers and pooling layers, 3 fully connected layers)</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241717946.png\" alt=\"image-20220824171744899\"></p>\n<p><strong>Figure 2</strong>. Convolution illustration (A), a 3*3 kernel filter (blue) is applied to a 6*6 input data (red) and give an output (green) as 4*4 (feature map). Max pooling illustration (B), data transformation is processed from 4*4 input to 2*2 output.</p>\n<p>In previous research, sequence data were usually analysed with the recurrent neural network (RNN) while the convolutional neural network (CNN) was used for image prediction. However, recent works have demonstrated the effectiveness of CNN in time-sequential data (Bai et al., 2018) where CNN even have a longer effective memory. It provides us with the theoretical basis for utilizing various CNN models in behaviour prediction. CNN has also been used for MEG classification in recent years: previous research has successfully predicted different diseases such as brain tumours (Rajasree et al., 2021) and Alzheimer’s disease (Aoe et al., 2019; Giovannetti et al., 2021). In fact, some studies have shown that CNN offers an unreplaceable advantage for patterns modelling those other techniques may not be disposed to reveal (Giovannetti et al., 2021). However, it is still an emergent topic to use deep learning instead of the classic machine learning method. As a special machine learning technique, deep learning benefits from the fast development of high-performance computation (HPC). One example is that deep learning can use the CUDA framework to accelerate training. As the GPU accelerators become more and more performance and energy-consuming effective (Faraji et al., 2016), the cheaper computation source becomes more and more available. Some evidence has shown that deep learning performs better than the classic machine learning methods when doing MEG classification (Aoe et al., 2019; RaviPrakash et al., 2020; Zheng et al., 2020). In addition to these the ability to recognize temporal and spatial data patterns, CNN has the unique character of sharing weight among neurons in a convolutional layer (Anelli et al., 2021). In this case, the parameters quantity reduces sharply which benefits analysing complex structured MEG data.</p>\n<h2 id=\"Band-power-and-Transfer-learning\"><a href=\"#Band-power-and-Transfer-learning\" class=\"headerlink\" title=\"Band power and Transfer learning\"></a>Band power and Transfer learning</h2><p>CNNs are expected to have good performance for extracting features from MEG data, but the performance can be boosted by augmenting the data we feed into them. Here are some ways I did this with MEG data. MEG signals reflect brain activity, in which the brainwave can be deposed into different frequency power bands, such as delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). And these different brainwave frequency bands usually are associated with different brain states, such as the alpha band has been implicated in visual attention (Rohenkohl &amp; Nobre, 2011). and the beta band is usually associated with anxiety (Einöther et al., 2013). That is why I think particular frequency bands might be important in helping classify accurately. In order to understand if it is available to extract critical information from the aversive state, it may be viable to extract different power bands and analyse them as a neural activity representation. One drawback of this method is it may reduce the available temporal information in MEG data, but it can not be denied that it provides an excellent and reliable method to study brain states (Newson &amp; Thiagarajan, 2019).</p>\n<p>However, the trained model may not be suitable for data collected under other conditions. Between the MEG device and its recording source location, there are the skull, skin and even air, which may all affect the signals we get: the deeper source is, the more affected it will be. In addition to these confounds, the geometric shape of the skull which varies a lot between different people, also affects a lot (Hagemann et al., 2008). In order to generalize the model, power spectrum standardization and relative power computation are necessary. Moreover, it is reported that transfer learning can help to improve learning efficiency by reusing or transferring learnt parameters (Karimpanal &amp; Bouffanais, 2018). In this case, transfer learning may reduce the influence of these confound factors and increase the generality of models.</p>\n<p>Transfer learning is the machine learning technique which allows a network to learn in one condition and improve its performance under another relevant condition. It is an optimization method to inform new task learning with relative learnt knowledge (Soria Olivas &amp; IGI Global., 2010). For the transfer learning process, only part of the model parameters is trained and adjusted, which is called “tuning”. If all network parameters are opened for training, it is easy to fall into the state of overfitting the target training set, thereby reducing the generalization performance of the model. The first few layers of the network are generally used for feature extraction. If the difference between the source task and the target task is not quite significant and the model has achieved good performance in the source task, there is no need to perform training from the beginning (Karimpanal &amp; Bouffanais, 2018). In this case, the transfer learning technique solves the small data availability problem: with a small amount of data, it helps eliminate the overfitting problem and reduce the model training time. Some evidence suggests that it can keep at a high accuracy level and saves 90% time (Dash, Ferrari, et al., 2019). It has been widely used to transfer the weight or bias of the current network to a newly trained network with the object of faster convergence and better performance.</p>\n<p>For aversive state reactivation prediction, previous studies have provided an approach with logistic regression methods and get a good accuracy (Wise et al., 2021) With a different approach (CNN) we could probably detect brain state reactivation with much better accuracy and learn a lot more about it. My first aim is to optimize the model with new techniques such as CNN and apply spectrum power. The second aim is to generalize the model by informing one participant model with other participants’ data. I assume that: first, the performance of the CNN model is better than traditional machine learning models; second, adding the power spectrum to augment data will improve the performance as well.</p>\n<h1 id=\"Materials-and-Methods\"><a href=\"#Materials-and-Methods\" class=\"headerlink\" title=\"Materials and Methods\"></a>Materials and Methods</h1><h2 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h2><p>The participants, study design, data collection and preprocessing sections and relevant information are included and published in the paper &quot;Model-based aversive learning in humans is supported by preferential task state reactivation&quot; (Wise et al., 2021). Open access to the original MEG data can be found in the public repository: <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a>. In total 28 participants took the task. The task is designed as follows: participants were required to sit with the MEG device in front of a monitor, where 14 images were shown. The recording duration of each stimulus is 1.29 seconds (from 0.5 before to 0.79 after image is shown). MEG data were collected with CTF 275-channel axial gradiometer system (CTF Omega, VSM MedTech). In the preprocessing session, the Maxwell filter was applied to remove noise firstly. Then a high pass filter above 0.5 Hz and a low pass filter below 45 Hz were applied. Afterwards, signal components were separated with independent component analysis (ICA) to isolate noise-related components in the setting of finding components which explain 95% variance. To reduce information loss, MEG data was upsampled and the window width of data was set as 800 time points (Aoe et al., 2019) when training the model to get better performance.</p>\n<h2 id=\"Power-spectrum-extraction\"><a href=\"#Power-spectrum-extraction\" class=\"headerlink\" title=\"Power spectrum extraction\"></a>Power spectrum extraction</h2><p>In order to compute the relative power (percentage power) of MEG signals, the first step is to extract the power band with the specific frequency. The frequency bands were chosen to be delta (0.5-4 Hz), theta (4-8 Hz), low alpha (8-10 Hz), high alpha (8-12 Hz) beta (12-30 Hz), and gamma (above 30 Hz). Actually, the gamma frequency was below 50 Hz because it is impossible to detect any information above 50 Hz as the data are sampled at 100 Hz.</p>\n<p>Firstly the power spectral densities (PSD) and frequency of each band were derived using Welch’s method with mne.time_frequency.psd_array_welch() function provided by MNE-Python (Percival &amp; Walden, 1993; Slepian, 1978). The reason for choosing this function is this function gives a single value for each trial but other methods that give you power at each timepoint. Then the PSD of each band was integrated with the frequency as spacing point using composite Simpson’s rule. The absolute power in a specific location is the average number of the power from several adjacent electrodes. The relative power is the ratio of the absolute power of a band to the total band power in all frequencies. As shown in equation 2, the r represents the relative power of a frequency band, the a stands for absolute power of the same frequency band, Pi ‘s are the absolute power in all frequency bands:</p>\n<p>$$\\begin{matrix}<br>r = \\frac{a}{P_{t}} = \\ \\frac{a}{\\sum_{\\ }^{\\ }{P_{i}\\ }}\\ \\ (2) \\<br>\\end{matrix}$$</p>\n<p>Eventually, the absolute and relative power bands are transformed from input data in $\\mathbb{R}$C×T (where $\\mathbb{R}$ is a vector space) to $\\mathbb{R}$C×F, where C is the number of channels, T is time points and F is the number of frequency bands, i.e., 6 here.</p>\n<h2 id=\"Neural-Network-architecture\"><a href=\"#Neural-Network-architecture\" class=\"headerlink\" title=\"Neural Network architecture\"></a>Neural Network architecture</h2><p>In order to classify different 14 categories brain states under 14 stimuli based on MEG signals, I proposed a CNN model ASRCNet-v1. The input data are MEG recordings from 24 subjects (4 were removed because of its information missing). In order to augment the data, the input of last fully connected layer was concatenated with relative power bands in all frequencies. The neural network structure of ASRCNet-v1 was developed based on the previously reported model EnvNet-v2 and MNet (Aoe et al., 2019; Tokozume et al., 2017; Tokozume &amp; Harada, 2017), which was used to classify environmental sounds and Alzheimer’s diseases. The detailed configuration of ASRNet-v1 is as demonstrated in figure 3 and the data processing is demonstrated in figure 4. There are three convolutional blocks in total: two feature extracting blocks: spatial and temporal blocks; and a CBAM block after them. In the first convolutional layer, the global features were extracted with a large filter, which has the same kernel width as the channel number of inputs. The kernel length of the first layer is set to be 64. The first layer generates a feature map in $\\mathbb{R}$S×1×T’ from input data in $\\mathbb{R}$C×T, where the T is larger than T’s. The C (number of channels) is larger than S (number of spatial filters) such that the channel dimension is reduced. The second convolutional layer in the spatial block generates a feature map in $\\mathbb{R}$S’×1×T’’ with frequency features then. Afterwards, the data is downsampled with a max pooling layer and swapped along the axis between S and 1, i.e., from $\\mathbb{R}$S’×1×T’’ to $\\mathbb{R}$<code>&lt;!-- --&gt;</code>{=html}1×S’×T’’. This operation allows data being considered as the image changing the convolutional direction (Tokozume et al., 2017). The second block consists of eight convolutional layers and four max pooling layers. The kernel size of convolutional layers is small and decreases every two layers in order to extract local frequency temporal features from the output feature map from the previous layer. Relu is the activation function for all convolutional layers in the spatial block. Max pooling layers are attached after every two convolutional layers.</p>\n<p>The attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images’ edges. The outputs are passed to an MLP (multilayer perceptron) network with the same weight. The MLP layer has a bottleneck. The width and length or the number of neurons in this MLP layer are decided by a reduction ratio of 16. Then the sum of two outputs from the MLP layer is given to the sigmoid activation function in order to project values in features map into $\\mathbb{R \\in}(0,1)$. Finally, the channel attention module returns a feature map as the product of input and calculated scale. Compared with the channel attention module, spatial attention seems to be simpler, which includes one convolutional layer and the sigmoid activation function. The same as the channel attention module, the spatial attention module returns a feature map as the product of input from the previous module and calculated scale in this module.</p>\n<p>Then the first fully connected layer (FC) comes to play the role of classifier, which is projecting the “distributed feature representation” of the feature map to sample labels space $\\mathbb{R}$L, where L is the number of features. In the object of data augmentation, the input is concatenated with relative power bands in all frequencies. The following step is another FC layer, which finally generates 14 features corresponding to the number of categories. At last, data is passed to the softmax activation function to convert the numbers vector into the probabilities vector. To avoid overfitting, 30 % dropout is applied after the last 4 spatial convolutional layers and 50 % dropout is applied after the first fully connected layer (Srivastava et al., 2014); batch normalization is applied to boost the speed of learning (Ioffe &amp; Szegedy, 2015).</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718131.png\" alt=\"image-20220824171834060\"></p>\n<p><strong>Figure 3</strong>. Detailed configuration of ASRCNet-v1. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241718214.png\" alt=\"image-20220824171849114\"></p>\n<p><strong>Figure 4.</strong> Chart flow of data processing. The original data is shaped as (64,1,272,800) where 64 is the number of batches, 272 is the number of channels and 800 is the number of time points.</p>\n<h2 id=\"Model-training-and-testing\"><a href=\"#Model-training-and-testing\" class=\"headerlink\" title=\"Model training and testing\"></a>Model training and testing</h2><p>The input data is a total of 900 epochs of 800-time-point MEG signals from 272 channels. At the beginning, the data was separately processed directly with the neural network and the Fourier transformation. The latter process provides neural network with relative band power in frequency delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz). The input data is shuffled and scaled with variance scaling method, which reasonably preserves the dynamic range of data, before being fed into the model. The first step is to normalize all input data for the reason that normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance. The normalization process is as shown in equation 3, where m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1:</p>\n<p>$$\\begin{matrix}<br>{x_{i}}^{‘} = \\frac{\\left| x_{i} - \\frac{1}{m}\\sum_{1}^{m}\\ x \\right|}{\\sqrt{\\sum_{1}^{m}\\ x^{2}}}\\ \\ (3) \\<br>\\end{matrix}$$</p>\n<p>In every training period, the input is one piece of a small segment of 64 batches of MEG signals segmented with non-overlapped 800-time-point time windows. The cross-entropy loss function was chosen to train the model because of its better performance in computing losses for discrete distributions. I chose SGD to be the optimizer because it is reported to have a better generalization capacity compared with Adam even though it may converge slower (Hardt et al., 2015). For the SGD optimizer, I set the initial learning rate as 0.0005, and momentum to 0.9. Specifically for the parameters in the second FF layer, a weight decay as 0.0005 is set keeping away from overfitting. The initial weight is randomized, which is because it is reported there is no obvious performance promotion with manually weight initialization (Hoshen et al., 2015). In order to improve training efficiency and avoid overfitting, I adapted the update step: I used the dynamic learning rate when the valid loss approaches a plateau (function 4, where $\\lambda$ represents learning decay and L represents valid loss). The patience of the dynamic learning rate is set to 1, the threshold is set to 0.001 and learning rate decay is set to 1e-8. Since there are a large number of features during training, in order to avert overfitting, I introduced L2 regularization (ridge regularization) with the regularization parameter lambda to 0.001. After the trial with model performance in different checkpoints, early stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting.</p>\n<p>$$\\begin{matrix}<br>\\alpha_{t + 1}\\  = \\ \\left{ \\begin{matrix}<br>\\alpha_{t} \\times \\lambda &amp; if\\ L_{t + 1} &gt; \\ \\ L_{t} \\<br>\\alpha_{t} &amp; if\\ L_{t + 1} \\leq \\ \\ L_{t} \\<br>\\end{matrix} \\right.\\ \\ \\ (4) \\<br>\\end{matrix}$$</p>\n<p>Finally, the possibility of each label is generated in the model. It eventually gives only one “most possible” label after comparing the possibility in all labels. In order to prove the validity of this CNN model. ASRCNet-v1’s performance is evaluated with 10-fold cross-validation, where 1 in 10 sets is used as validating set every time.</p>\n<h1 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h1><p>The key results of the article are summarised and given in this section. This section first offers auxiliary findings with the whole dataset and furthermore demonstrates results using a single MEG dataset (i.e., a single subject). The accuracy measure is utilized to compare the performance of various models. All models had previously undergone testing on participant 1 to provide an initial indication of performance. The suggested model solution is validated across all of the participants once all models have been evaluated on participant 1. Additional tests are specifically run on the best model ASRCNet and other two main baseline models (LSTM RNN and simple CNN). For models tested on all subjects, model training was done within each participant, trained and evaluated only using its individual recording MEG data. Additionally, I set the windows of input data to 800 ms enabling an accurate comparison of several test models. Relative power spectrum is introduced to the training improving performance of models. Moreover, average topographical maps are graphed as the representation of the MEG signals intensities in the anatomical brain, illustrating the general topographic maps of brain states from different stimuli in brain states reactivation tasks.</p>\n<h2 id=\"Topographical-map\"><a href=\"#Topographical-map\" class=\"headerlink\" title=\"Topographical map\"></a>Topographical map</h2><p>The global anatomical brain maps are generated with concatenated dataset and were back fitted to MEG recordings. The average MEG signals with different stimuli are calculated and graphed showing commons and differences among various brain states under different stimuli. In the brain states reactivation process, under the different stimuli, the topographical maps all look very similar. There are subtle differences but in general the pattern is the same: similar brain regions are activated while to the different extent (figure 5). This means we need some kind of algorithm that is sensitive to these very small differences between stimuli.</p>\n<p>The result shows the rationality of extracting features of brain states under different stimuli. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, ASRCNet is an effective and reasonable approach to classifying these states.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241719153.png\" alt=\"image-20220824171924099\"></p>\n<p><strong>Figure 5</strong>. brain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.</p>\n<h2 id=\"Power-spectrum\"><a href=\"#Power-spectrum\" class=\"headerlink\" title=\"Power spectrum\"></a>Power spectrum</h2><p>In order to determine the effect of different brain wave frequencies, power spectral density (PSD) at all 272 channels is calculated. The 6 power bands are divided by the sum generating 1632 decoding features (272 channels for each of the 6 frequency bands). I analysed the power spectrum in all frequencies of input 800-time-point MEG signals for different participants. The results show that beta and delta waves are in the large and major proportion (figure 6). It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721133.gif\" alt=\"img\"><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241720900.gif\" alt=\"img\"></p>\n<p><strong>Figure 6.</strong> Relative and absolute power spectrum (average of 24 subjects), beta (12 to 30 Hz) and delta (0.5 to 4 Hz) waves are in the major proportion</p>\n<h2 id=\"Classification-of-multiple-brain-states-reactivations\"><a href=\"#Classification-of-multiple-brain-states-reactivations\" class=\"headerlink\" title=\"Classification of multiple brain states reactivations\"></a>Classification of multiple brain states reactivations</h2><p>In order to classify the brain states reactivation with different given image stimuli (figure 7), ASRCNet-v1, the classifier is developed. It is trained with MEG signals for each of the images. The representative MEG signals for each reactivation states that ASRCNet-v1 accurately identified is displayed in figure 8. A sample of an 800-time-point segment of the preprocessed MEG signals is displayed in the panel, where each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. Therefore, none of these signals are removed because of bad channels. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data. It is suggested that ASRCNet-v1 correctly categorised the MEG signals during aversive state by utilising features that not presents in the typical classification.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721069.png\" alt=\"image-20220824172119017\"></p>\n<p><strong>Figure 7.</strong> image stimuli in different brain states reactivation tasks (Wise et al., 2021), from left to right, above to bottom are labelled as stimulus_i.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721550.png\" alt=\"image-20220824172132497\"></p>\n<p><strong>Figure 8.</strong> representative MEG signal which is classified by the ASRCNet-v1 (from one sample participant)</p>\n<p>Principal component analysis (PCA) (30 to 50 out of 272 channels) was tested to be applied to the input data before feeding data into the model. But the result shows that PCA does not obviously improve the classification performance of ASRCNet-v1. The classification accuracy was not obviously affected when PCA was applied. In the beginning, I didn&#39;t get satisfactory learning convergence results. When the input data values are clipped to be in of standardized bounds, the learning curves became smooth and the valid loss gradually decreased step by step.</p>\n<p>Since there are 14 stimuli and the chances for all stimuli are equal, the random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of ASRCNet-v1 is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. I compared the performance of different models (figure 9) and found it is suggested that ASRCNet-v1 outperformed any other simple approach (LSTM RNN, simple CNN with 2 convolutional layers and 1 pooling layer). Compared with the other classification approach, ASRCNet-v1 exhibits the best classification performance (p = 6.8 × 10 –2 for LSTM RNN, p = 5.9 × 10 –2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of ASRCNet-v1 is able to reach 33.33%. The classification accuracy variety between simple CNN and ASRCNet may suggest that the classification depends on some event-independent signal: the temporal and spatial features. To which extent the performance is a result of the detected differences in the temporal and spatial features of MEG signals, remained to be explored.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208241721928.png\" alt=\"image-20220824172150882\"></p>\n<p><strong>Figure 9.</strong> performance of different model boxplot. The boxplot shows the classification accuracy of different models. The random chance baseline is 7.14% (1/14 = 7.14%). All models learned from MEG signals (all accuracies are above 7.14% and gives better predictions. ASRCNet gives the best classification accuracy as 23.07%±7.69% (mean ± standard deviation).</p>\n<h1 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h1><p>In this section, I am going to discuss the experimental results, findings, and potential future work. The focus of this paper is to explore the potential of deep learning, especially CNN to classify the aversive brain states associated with visual images. The MEG signals are complex and have low signal-to-noise ratios data structures. What is more, the aversive brain states parameters are continuous variables. Therefore, the aim is to solve a complex classification task. To optimally address this problem, a CNN model ASRCNet (inspired by Mnet and EnvNet, which was used in MEG data) is proposed as the deep learning solution in this research because of its ability to extract complex patterns from raw input data. One focus is to understand whether the CNN model is able to perform the decoding task. The analysis has been evaluated in two distinct steps: First, two well-known architectures (LSTM RNN and CNN: the former model is known as a good fit for sequential data and the second model is usually used in image classification) were selected as baseline models for the purpose of understanding the potential of general-purpose DL models that are not specific to MEG analysis. Second, I test the prediction and classification ability of the CNN-based architecture specially designed for MEG recordings. The results show that ASRCNet provide better performance compared to the other two baseline models. Since the model is specifically designed to extract features from MEG recordings, it can be considered an option in the field of brain state classification.</p>\n<p>I trained a novel deep neural network ASRCNet to classify 14 brain states using data from MEG recordings. It can distinguish brain states under different image stimuli with an accuracy at least as good as, or even higher than the baseline pipeline. ASRCNet allows the extraction of spatial and temporal information from the informative MEG data. It is suggested that classification decisions are unlikely to be associated with activities that are unrelated to the task itself, for example, mind wandering. The trained ASRCNet successfully classifies brain states with relatively high accuracy and specificity. Previous research has been focusing on common symptoms of psychopathology, but less on the domain of aversive states. This is a study using MEG signals to classify different aversive brain states with a classifier. The high specificity for all states suggests that ASRCNet will help improve our understanding of the human cognitive image process. One thing we can do with such a CNN classifier is to look at state reactivation in cognitive tasks. Moreover, this classifier is expected to be applied in clinical studies in order to diagnose nonorganic neurological diseases. As shown in the topological map in the result section, these brain states are hard to classify with the naked eyes. The information from such computer-aided diagnosis may be a novel biomarker for these diseases in clinical practice.</p>\n<p>The advantage of using this neural network is its comprehensive training process, entirely based on gradient descent-based optimization without intermediate steps. As research develops toward explainable artificial intelligence (XAI), the parameters of a model may be going to have a direct and explainable connection to their task. On the separate brain states classification task, ASRCNet also performs on par with state-of-the-art, potentially making it a general method for other neuroimaging data. What is more, as shown in the result section, the classification accuracy varies a lot between simple image classification CNN and ASRCNet. One reason the model is successful in classification is that the first part of the network learns to extract the correct features, while the last layer classifies the extracted features. It may suggest that the classification of such brain states depends on some event-independent temporal and spatial features signal. Some evidence suggests that using features automatically extracted with deep learning models rather than manually selected, is able to help achieve the highest levels of accuracy compared to other machine learning approaches. It is reported that most of the best ImageNet is achieved by using some kind of data augmentation, instead of feature engineering and dimensionality reduction (de Bardeci et al., 2021). However, it was reported that logistic regression may achieve better classification accuracy than ASRCNet (Wise et al., 2021). It may be because of the algorithmic Incompleteness of the current model. Future work on improving the algorithm may improve the performance of CNN models.</p>\n<p>ASRCNet is a relatively robust approach among different subjects. In this research, 14 different stimuli were applied to 24 subjects (data from 4 subjects were removed because of the smaller segment length). ASRCNet successfully classifies states in 24 different subjects with high accuracy, demonstrating the robustness of the CNN model. However, the data itself used in the research has potential for improvement: the 13th stimulus is a face picture, which may be different from other stimuli reflecting brain states (Rapcsak, 2019). What is more, it is concerned that the trained model may have difficulty classifying brain states using data recorded by another MEG scanner. Improvements in current source estimation and alignment techniques may make the method adaptable to different MEG scanners (Pettersen et al., 2006). Apart from the robustness, the size of the data itself may also affect the classification accuracy. A limitation of this experiment is, the same as in most other studies, the cross-validation approach was performed during the validation process, rather than using a separate test dataset. It was reported that using a separate test set in the DL model may help yield the highest level of validity in the results (de Bardeci et al., 2021). Although superficially, it is a relatively advanced practice to use data from the same subject in the training and test sets, there is room for improvement. A possible improvement is to create additional test sets beyond the limited availability of data. Due to the high inter-individual specificity and intra-individual stability of MEG data, it is difficult for the network to learn common features between subjects. The current approach of the model is to recognize different subjects by identifying individual MEG features of different subjects. Therefore, even though the network can achieve high levels of accuracy, classification and prediction will be unpredictable when it is applied to entirely new datasets from different subjects. The application of transfer learning methods with the small tuning of part of model parameters may be a possible solution. However, when performing transfer learning, it is generally assumed that different tasks are related. In this case, how to define the correlation and mathematically describe the strength of the correlation between tasks are subjective decisions that are biased toward researchers. The image classification-related studies usually use ImageNet as a pre-trained model for transfer learning because the large dataset of ImageNet itself ensures that the trained model has high generalization. But when we use a small dataset such as in this experiment, transfer learning may not only fail to achieve the expected result but result in negative transferring which is even worse than training a network from nowhere. For example, AlphaGo Zero learned from zero without any supervision or using chess manual data but achieves higher performance than AlphaGo Lee which is based on chess manual replays (Silver et al., 2017). Therefore, how to perform correct and effective transfer learning is one of the focuses of future work.</p>\n<p>Deep learning from scratch is often difficult with limited amounts of data. However, even with the limited amount of data in this study, I successfully classified 14 types of brain states. One reason for this success is that I enlarged the dataset by dividing each subject&#39;s 1170 seconds of data into 900 segments of 1.3-second time data, allowing me to train 14 classes using approximately 25200 segments. The data amount is slightly less than the amount of MNIST, a database of handwritten digits that is often used to train deep neural networks, but still shows that I have a reasonable amount of data to train a network of such size (Yann LeCun et al., 2012). However, during the training process, the training data generally has a tendency to overfit even though I applied dropout (randomly ignored neurons in network) and batch normalization (normalizes input mini-batches from last layer). The proposed CNN model ASRCNet may benefit from the increase in dataset size. It improves with more training data because deep learning performance is reported to improve significantly with larger datasets (Greenspan et al., 2016). Therefore, it can be taken into account to train this model with more data in hopes of improving model performance. In addition, more research has shown that MEG and EEG provide complementary information, and other modalities such as MRI also provide additional useful information. Using data from multiple method sources at the same time may improve model performance (Dale &amp; Sereno, 1993; Sharon et al., 2007). In future work, combining MEG signal data with EEG to create a multimodal data input may help improve the accuracy of brain states classification.</p>\n<p>In this ASRCNet, the integration of the relative power spectrum improves the CNN model’s performance. Since the beta and delta waves mainly encode perceptual information, the relative power spectrum ensemble adds relevant information to the model so that the different band power values can inform the network. Therefore, the model can adjust the weights accordingly. Additionally, the relative power spectrum may also add valuable information about artefacts or ambient noise (Anelli et al., 2021). All these deep learning models overfit the training dataset more or less, even applied regularization techniques like dropout and batch normalization. The additional information provided by the relative power spectrum ensemble helps the model to generalize. There is still room to improve the model’s performance as the aspect of power spectrum extraction. In the process of relative power spectrum extraction, the wavelet transform can be considered as an optional alternative to Fourier analysis for the reason that the wavelet transform has the multi-scale analysis ability to extract features from the dataset and generate input images for training the model. Compared with the Fourier transform, the wavelet transform is a local transform of temporal and frequency data, so it can more effectively extract information from the signal by performing multi-scale refinement analysis with operations like scaling and translation (Yu &amp; Guowen, 1994), thus has the potential to solve some difficult problems that Fourier transform cannot deal with. Fourier transform can only get a frequency spectrum, but wavelet transform can get a temporal frequency spectrum which not only the frequency can be obtained, but also the time can be located. Some recent studies successfully use the wavelet packet decomposition method to extract time-frequency features and use a dynamic frequency feature selection algorithm to select the most accurate features for each subject (Luo et al., 2016). However, other studies have shown the drawback of wavelet packet decomposition: although this method improves the classification accuracy, it requires a lot of work to select the most suitable features for each subject, and the feature extraction for different target individuals is poorly general (Dai et al., 2020). Only considering the power spectrum is quite limiting at the current moment. The convolutional operation executed by most popular machine learning libraries in deep learning is actually computing the correlation measurement (Graves, 2012). Future work investigating state classification and reactivation should also take steps to measure event-related desynchronization and synchronization in the context of the data generated.</p>\n<p>Another idea to optimize the model is to replace the fully connected layer with global average pooling. The model holds a redundancy of fully connected layer parameters where fully connected layer parameters can account for about 80% of the entire network parameters. Some recent network models with excellent performance, such as ResNet, are trying to use global average pooling (GAP) layer instead of a fully connected layer for fusion. For the learned deep features, loss functions such as SoftMax are still used as the network objective function to guide the learning process (Liu &amp; Zeng, 2022) Some evidence suggests that networks that replace a fully connected layer with a GAP layer may have better classification performance (Wei et al., 2018). However, other studies have pointed out that when applying transfer learning, the fine-tuned results of networks without fully connected layers are worse than those with fully connected layers. Therefore, fully connected can be regarded as a guard for model representation capabilities, especially in the case that there are big differences between the source domain and the target domain, the redundant parameters of FC can maintain a fine model capacity to ensure the migration of model representation capabilities (Zhang et al., 2018). Future work can explore the role of the GAP layer and fully connected layer in detail.</p>\n<p>ASRCNet can extract and analyze features that deep learning neural networks use for classification, which may help researchers understand brain states better. The inherent hidden patterns in brain states and related brain neural activity that deep learning may reveal some fundamental mechanisms behind human behaviour. To the extent these can be explained, researchers are encouraged to apply these sophisticated deep learning modelling techniques to obtain accurate classification and prediction results and to generalize the results more carefully in a wider range of conditions. Moreover, understanding the relevant studies that extract these hidden patterns can increase and deepen our understanding of the brain state electrophysiological characterization.</p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><p>Anelli, M., Lauri, S. P., Advisor, P., &amp; Zubarev, M. I. (2021). <em>Using deep learning to predict continuous hand kinematics from magnetoencephalographic (MEG) measurements of electromagnetic brain activity.</em> <a href=\"http://www.aalto.fi\">www.aalto.fi</a></p>\n<p>Aoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., &amp; Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. <em>Scientific Reports</em>, <em>9</em>(1). <a href=\"https://doi.org/10.1038/S41598-019-41500-X\">https://doi.org/10.1038/S41598-019-41500-X</a></p>\n<p>Bai, S., Kolter, J. Z., &amp; Koltun, V. (2018). <em>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</em>. <a href=\"https://doi.org/10.48550/arxiv.1803.01271\">https://doi.org/10.48550/arxiv.1803.01271</a></p>\n<p>Baumeister, J., Barthel, T., Geiss, K. R., &amp; Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. <em><a href=\"Http://Dx.Doi.Org/10.1179/147683008X301478\">Http://Dx.Doi.Org/10.1179/147683008X301478</a></em>, <em>11</em>(3), 103–110. <a href=\"https://doi.org/10.1179/147683008X301478\">https://doi.org/10.1179/147683008X301478</a></p>\n<p>Belal, S., Cousins, J., El-Deredy, W., Parkes, L., Schneider, J., Tsujimura, H., Zoumpoulaki, A., Perapoch, M., Santamaria, L., &amp; Lewis, P. (2018). Identification of memory reactivation during sleep by EEG classification. <em>NeuroImage</em>, <em>176</em>, 203–214. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2018.04.029\">https://doi.org/10.1016/J.NEUROIMAGE.2018.04.029</a></p>\n<p>Boto, E., Holmes, N., Leggett, J., Roberts, G., Shah, V., Meyer, S. S., Muñoz, L. D., Mullinger, K. J., Tierney, T. M., Bestmann, S., Barnes, G. R., Bowtell, R., &amp; Brookes, M. J. (2018). Moving magnetoencephalography towards real-world applications with a wearable system. <em>Nature 2018 555:7698</em>, <em>555</em>(7698), 657–661. <a href=\"https://doi.org/10.1038/nature26147\">https://doi.org/10.1038/nature26147</a></p>\n<p>Brown, R. E., &amp; Milner, P. M. (2003). The legacy of Donald O. Hebb: More than the Hebb Synapse. <em>Nature Reviews Neuroscience</em>, <em>4</em>(12), 1013–1019. <a href=\"https://doi.org/10.1038/NRN1257\">https://doi.org/10.1038/NRN1257</a></p>\n<p>Bunge, S. A., &amp; Kahn, I. (2009). Cognition: An Overview of Neuroimaging Techniques. <em>Encyclopedia of Neuroscience</em>, 1063–1067. <a href=\"https://doi.org/10.1016/B978-008045046-9.00298-9\">https://doi.org/10.1016/B978-008045046-9.00298-9</a></p>\n<p>Bzdok, D., &amp; Meyer-Lindenberg, A. (2018). Machine Learning for Precision Psychiatry: Opportunities and Challenges. <em>Biological Psychiatry. Cognitive Neuroscience and Neuroimaging</em>, <em>3</em>(3), 223–230. <a href=\"https://doi.org/10.1016/J.BPSC.2017.11.007\">https://doi.org/10.1016/J.BPSC.2017.11.007</a></p>\n<p>Currie, G., Hawk, K. E., Rohren, E., Vial, A., &amp; Klein, R. (2019). Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging. <em>Journal of Medical Imaging and Radiation Sciences</em>, <em>50</em>(4), 477–487. <a href=\"https://doi.org/10.1016/j.jmir.2019.09.005\">https://doi.org/10.1016/j.jmir.2019.09.005</a></p>\n<p>Dai, G., Zhou, J., Huang, J., &amp; Wang, N. (2020). HS-CNN: a CNN with hybrid convolution scale for EEG motor imagery classification. <em>Journal of Neural Engineering</em>, <em>17</em>(1), 016025. <a href=\"https://doi.org/10.1088/1741-2552/AB405F\">https://doi.org/10.1088/1741-2552/AB405F</a></p>\n<p>Dale, A. M., &amp; Sereno, M. I. (1993). Improved Localizadon of Cortical Activity by Combining EEG and MEG with MRI Cortical Surface Reconstruction: A Linear Approach. <em>Journal of Cognitive Neuroscience</em>, <em>5</em>(2), 162–176. <a href=\"https://doi.org/10.1162/JOCN.1993.5.2.162\">https://doi.org/10.1162/JOCN.1993.5.2.162</a></p>\n<p>Dash, D., Ferrari, P., Heitzman, D., &amp; Wang, J. (2019). Decoding Speech from Single Trial MEG Signals Using Convolutional Neural Networks and Transfer Learning. <em>Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS</em>, 5531–5535. <a href=\"https://doi.org/10.1109/EMBC.2019.8857874\">https://doi.org/10.1109/EMBC.2019.8857874</a></p>\n<p>Dash, D., Sao, A. K., Wang, J., &amp; Biswal, B. (2019). How many fmri scans are necessary and sufficient for resting brain connectivity analysis? <em>2018 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2018 - Proceedings</em>, 494–498. <a href=\"https://doi.org/10.1109/GLOBALSIP.2018.8646415\">https://doi.org/10.1109/GLOBALSIP.2018.8646415</a></p>\n<p>de Bardeci, M., Ip, C. T., &amp; Olbrich, S. (2021). Deep learning applied to electroencephalogram data in mental disorders: A systematic review. <em>Biological Psychology</em>, <em>162</em>, 108117. <a href=\"https://doi.org/10.1016/J.BIOPSYCHO.2021.108117\">https://doi.org/10.1016/J.BIOPSYCHO.2021.108117</a></p>\n<p>Doll, B. B., Duncan, K. D., Simon, D. A., Shohamy, D., &amp; Daw, N. D. (2015). Model-based choices involve prospective neural activity. <em>Nature Neuroscience</em>, <em>18</em>(5), 767. <a href=\"https://doi.org/10.1038/NN.3981\">https://doi.org/10.1038/NN.3981</a></p>\n<p>Eichenlaub, J. B., Biswal, S., Peled, N., Rivilis, N., Golby, A. J., Lee, J. W., Westover, M. B., Halgren, E., &amp; Cash, S. S. (2020). Reactivation of Motor-Related Gamma Activity in Human NREM Sleep. <em>Frontiers in Neuroscience</em>, <em>14</em>. <a href=\"https://doi.org/10.3389/FNINS.2020.00449\">https://doi.org/10.3389/FNINS.2020.00449</a></p>\n<p>Einöther, S. J. L., Giesbrecht, T., Walden, C. M., van Buren, L., van der Pijl, P. C., &amp; de Bruin, E. A. (2013). Attention Benefits of Tea and Tea Ingredients: A Review of the Research to Date. <em>Tea in Health and Disease Prevention</em>, 1373–1384. <a href=\"https://doi.org/10.1016/B978-0-12-384937-3.00115-4\">https://doi.org/10.1016/B978-0-12-384937-3.00115-4</a></p>\n<p>Faraji, I., Mirsadeghi, S. H., &amp; Afsahi, A. (2016). Topology-aware GPU selection on multi-GPU nodes. <em>Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016</em>, 712–720. <a href=\"https://doi.org/10.1109/IPDPSW.2016.44\">https://doi.org/10.1109/IPDPSW.2016.44</a></p>\n<p>Giovannetti, A., Susi, G., Casti, P., Mencattini, A., Pusil, S., López, M. E., di Natale, C., &amp; Martinelli, E. (2021). Deep-MEG: spatiotemporal CNN features and multiband ensemble classification for predicting the early signs of Alzheimer’s disease with magnetoencephalography. <em>Neural Computing and Applications</em>, <em>33</em>(21), 14651–14667. <a href=\"https://doi.org/10.1007/S00521-021-06105-4/TABLES/4\">https://doi.org/10.1007/S00521-021-06105-4/TABLES/4</a></p>\n<p>Gramfort, A., Luessi, M., Larson, E., Engemann, D. A., Strohmeier, D., Brodbeck, C., Parkkonen, L., &amp; Hämäläinen, M. S. (2014). MNE software for processing MEG and EEG data. <em>NeuroImage</em>, <em>86</em>, 446–460. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2013.10.027\">https://doi.org/10.1016/J.NEUROIMAGE.2013.10.027</a></p>\n<p>Graves, A. (2012). <em>Supervised Sequence Labelling</em>. 5–13. <a href=\"https://doi.org/10.1007/978-3-642-24797-2_2\">https://doi.org/10.1007/978-3-642-24797-2_2</a></p>\n<p>Greenspan, H., van Ginneken, B., &amp; Summers, R. M. (2016). Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique. <em>IEEE Transactions on Medical Imaging</em>, <em>35</em>(5), 1153–1159. <a href=\"https://doi.org/10.1109/TMI.2016.2553401\">https://doi.org/10.1109/TMI.2016.2553401</a></p>\n<p>Hagemann, D., Hewig, J., Walter, C., &amp; Naumann, E. (2008). Skull thickness and magnitude of EEG alpha activity. <em>Clinical Neurophysiology</em>, <em>119</em>(6), 1271–1280. <a href=\"https://doi.org/10.1016/J.CLINPH.2008.02.010\">https://doi.org/10.1016/J.CLINPH.2008.02.010</a></p>\n<p>Hardt, M., Recht, B., &amp; Singer, Y. (2015). Train faster, generalize better: Stability of stochastic gradient descent. <em>33rd International Conference on Machine Learning, ICML 2016</em>, <em>3</em>, 1868–1877. <a href=\"https://doi.org/10.48550/arxiv.1509.01240\">https://doi.org/10.48550/arxiv.1509.01240</a></p>\n<p>Haynes, J. D. (2012). Brain reading. <em>I Know What You’re Thinking: Brain Imaging and Mental Privacy</em>. <a href=\"https://doi.org/10.1093/ACPROF:OSO/9780199596492.003.0003\">https://doi.org/10.1093/ACPROF:OSO/9780199596492.003.0003</a></p>\n<p>Hedderich, D. M., &amp; Eickhoff, S. B. (2021). Machine learning for psychiatry: getting doctors at the black box? <em>Molecular Psychiatry</em>, <em>26</em>(1), 23. <a href=\"https://doi.org/10.1038/S41380-020-00931-Z\">https://doi.org/10.1038/S41380-020-00931-Z</a></p>\n<p>Hoshen, Y., Weiss, R. J., &amp; Wilson, K. W. (2015). Speech acoustic modeling from raw multichannel waveforms. <em>ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</em>, <em>2015-August</em>, 4624–4628. <a href=\"https://doi.org/10.1109/ICASSP.2015.7178847\">https://doi.org/10.1109/ICASSP.2015.7178847</a></p>\n<p>Huang, W., Yan, H., Wang, C., Li, J., Yang, X., Li, L., Zuo, Z., Zhang, J., &amp; Chen, H. (2020). Long short-term memory-based neural decoding of object categories evoked by natural images. <em>Human Brain Mapping</em>, <em>41</em>(15), 4442–4453. <a href=\"https://doi.org/10.1002/hbm.25136\">https://doi.org/10.1002/hbm.25136</a></p>\n<p>Huang, Y., Sun, X., Lu, M., &amp; Xu, M. (2015). Channel-Max, Channel-Drop and Stochastic Max-pooling. <em>IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops</em>, <em>2015-October</em>, 9–17. <a href=\"https://doi.org/10.1109/CVPRW.2015.7301267\">https://doi.org/10.1109/CVPRW.2015.7301267</a></p>\n<p>IBM Corp. (2021). <em>IBM SPSS Statistics for Windows</em>. <a href=\"https://hadoop.apache.org\">https://hadoop.apache.org</a></p>\n<p>Ioffe, S., &amp; Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. <em>32nd International Conference on Machine Learning, ICML 2015</em>, <em>1</em>, 448–456. <a href=\"https://doi.org/10.48550/arxiv.1502.03167\">https://doi.org/10.48550/arxiv.1502.03167</a></p>\n<p>Karimpanal, T. G., &amp; Bouffanais, R. (2018). Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning. <em>Adaptive Behavior</em>, <em>27</em>(2), 111–126. <a href=\"https://doi.org/10.1177/1059712318818568\">https://doi.org/10.1177/1059712318818568</a></p>\n<p>Khan, S., Rahmani, H., Shah, S. A. A., &amp; Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. <em>A Guide to Convolutional Neural Networks for Computer Vision</em>. <a href=\"https://doi.org/10.1007/978-3-031-01821-3\">https://doi.org/10.1007/978-3-031-01821-3</a></p>\n<p>King’s College London. (2022). <em>King’s Computational Research, Engineering and Technology Environment (CREATE).</em></p>\n<p>Li, H., Ellis, J. G., Zhang, L., &amp; Chang, S. F. (2018). PatternNet: Visual pattern mining with deep neural network. <em>ICMR 2018 - Proceedings of the 2018 ACM International Conference on Multimedia Retrieval</em>, 291–299. <a href=\"https://doi.org/10.1145/3206025.3206039\">https://doi.org/10.1145/3206025.3206039</a></p>\n<p>Liu, W., &amp; Zeng, Y. (2022). Motor Imagery Tasks EEG Signals Classification Using ResNet with Multi-Time-Frequency Representation. <em>2022 7th International Conference on Intelligent Computing and Signal Processing, ICSP 2022</em>, 2026–2029. <a href=\"https://doi.org/10.1109/ICSP54964.2022.9778786\">https://doi.org/10.1109/ICSP54964.2022.9778786</a></p>\n<p>Luo, J., Feng, Z., Zhang, J., &amp; Lu, N. (2016). Dynamic frequency feature selection based approach for classification of motor imageries. <em>Computers in Biology and Medicine</em>, <em>75</em>, 45–53. <a href=\"https://doi.org/10.1016/J.COMPBIOMED.2016.03.004\">https://doi.org/10.1016/J.COMPBIOMED.2016.03.004</a></p>\n<p>Newson, J. J., &amp; Thiagarajan, T. C. (2019). EEG Frequency Bands in Psychiatric Disorders: A Review of Resting State Studies. <em>Frontiers in Human Neuroscience</em>, <em>12</em>, 521. <a href=\"https://doi.org/10.3389/FNHUM.2018.00521/BIBTEX\">https://doi.org/10.3389/FNHUM.2018.00521/BIBTEX</a></p>\n<p>Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., Facebook, Z. D., Research, A. I., Lin, Z., Desmaison, A., Antiga, L., Srl, O., &amp; Lerer, A. (2017). <em>Automatic differentiation in PyTorch</em>.</p>\n<p>Percival, D. B., &amp; Walden, A. T. (1993). Spectral Analysis for Physical Applications. <em>Spectral Analysis for Physical Applications</em>. <a href=\"https://doi.org/10.1017/CBO9780511622762\">https://doi.org/10.1017/CBO9780511622762</a></p>\n<p>Pettersen, K. H., Devor, A., Ulbert, I., Dale, A. M., &amp; Einevoll, G. T. (2006). Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities. <em>Journal of Neuroscience Methods</em>, <em>154</em>(1–2), 116–133. <a href=\"https://doi.org/10.1016/J.JNEUMETH.2005.12.005\">https://doi.org/10.1016/J.JNEUMETH.2005.12.005</a></p>\n<p>Rajasree, R., Columbus, C. C., &amp; Shilaja, C. (2021). Multiscale-based multimodal image classification of brain tumor using deep learning method. <em>Neural Computing and Applications</em>, <em>33</em>(11), 5543–5553. <a href=\"https://doi.org/10.1007/S00521-020-05332-5/FIGURES/9\">https://doi.org/10.1007/S00521-020-05332-5/FIGURES/9</a></p>\n<p>Rapcsak, S. Z. (2019). Face Recognition. <em>Current Neurology and Neuroscience Reports</em>, <em>19</em>(7). <a href=\"https://doi.org/10.1007/S11910-019-0960-9\">https://doi.org/10.1007/S11910-019-0960-9</a></p>\n<p>RaviPrakash, H., Korostenskaja, M., Castillo, E. M., Lee, K. H., Salinas, C. M., Baumgartner, J., Anwar, S. M., Spampinato, C., &amp; Bagci, U. (2020). Deep Learning Provides Exceptional Accuracy to ECoG-Based Functional Language Mapping for Epilepsy Surgery. <em>Frontiers in Neuroscience</em>, <em>14</em>. <a href=\"https://doi.org/10.3389/FNINS.2020.00409/FULL\">https://doi.org/10.3389/FNINS.2020.00409/FULL</a></p>\n<p>Rohenkohl, G., &amp; Nobre, A. C. (2011). Alpha Oscillations Related to Anticipatory Attention Follow Temporal Expectations. <em>The Journal of Neuroscience</em>, <em>31</em>(40), 14076. <a href=\"https://doi.org/10.1523/JNEUROSCI.3387-11.2011\">https://doi.org/10.1523/JNEUROSCI.3387-11.2011</a></p>\n<p>Roscow, E. L., Chua, R., Costa, R. P., Jones, M. W., &amp; Lepora, N. (2021). Learning offline: memory replay in biological and artificial reinforcement learning. <em>Trends in Neurosciences</em>, <em>44</em>(10), 808–821. <a href=\"https://doi.org/10.1016/J.TINS.2021.07.007\">https://doi.org/10.1016/J.TINS.2021.07.007</a></p>\n<p>Schacter, D. L., Benoit, R. G., &amp; Szpunar, K. K. (2017). Episodic Future Thinking: Mechanisms and Functions. <em>Current Opinion in Behavioral Sciences</em>, <em>17</em>, 41. <a href=\"https://doi.org/10.1016/J.COBEHA.2017.06.002\">https://doi.org/10.1016/J.COBEHA.2017.06.002</a></p>\n<p>Sharon, D., Hämäläinen, M. S., Tootell, R. B. H., Halgren, E., &amp; Belliveau, J. W. (2007). The advantage of combining MEG and EEG: Comparison to fMRI in focally stimulated visual cortex. <em>NeuroImage</em>, <em>36</em>(4), 1225–1235. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2007.03.066\">https://doi.org/10.1016/J.NEUROIMAGE.2007.03.066</a></p>\n<p>Shaw, G. L. (1986). Donald Hebb: The Organization of Behavior. <em>Brain Theory</em>, 231–233. <a href=\"https://doi.org/10.1007/978-3-642-70911-1_15\">https://doi.org/10.1007/978-3-642-70911-1_15</a></p>\n<p>Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui, F., Sifre, L., van den Driessche, G., Graepel, T., &amp; Hassabis, D. (2017). Mastering the game of Go without human knowledge. <em>Nature 2017 550:7676</em>, <em>550</em>(7676), 354–359. <a href=\"https://doi.org/10.1038/nature24270\">https://doi.org/10.1038/nature24270</a></p>\n<p>Singh, S. P. (2014). Magnetoencephalography: Basic principles. <em>Annals of Indian Academy of Neurology</em>, <em>17</em>(Suppl 1), S107. <a href=\"https://doi.org/10.4103/0972-2327.128676\">https://doi.org/10.4103/0972-2327.128676</a></p>\n<p>Slepian, D. (1978). Prolate Spheroidal Wave Functions, Fourier Analysis, and Uncertainty—V: The Discrete Case. <em>Bell System Technical Journal</em>, <em>57</em>(5), 1371–1430. <a href=\"https://doi.org/10.1002/J.1538-7305.1978.TB02104.X\">https://doi.org/10.1002/J.1538-7305.1978.TB02104.X</a></p>\n<p>Soria Olivas, E., &amp; IGI Global. (2010). <em>Handbook of research on machine learning applications and trends : algorithms, methods, and techniques</em>. 83.</p>\n<p>Srivastava, N., Hinton, G., Krizhevsky, A., &amp; Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. <em>Journal of Machine Learning Research</em>, <em>15</em>, 1929–1958. <a href=\"https://doi.org/10.5555/2627435\">https://doi.org/10.5555/2627435</a></p>\n<p>Szpunar, K. K. (2010). Episodic Future Thought: An Emerging Concept. <em>Perspectives on Psychological Science : A Journal of the Association for Psychological Science</em>, <em>5</em>(2), 142–162. <a href=\"https://doi.org/10.1177/1745691610362350\">https://doi.org/10.1177/1745691610362350</a></p>\n<p>Tappert, C. C. (2019). Who is the father of deep learning? <em>Proceedings - 6th Annual Conference on Computational Science and Computational Intelligence, CSCI 2019</em>, 343–348. <a href=\"https://doi.org/10.1109/CSCI49370.2019.00067\">https://doi.org/10.1109/CSCI49370.2019.00067</a></p>\n<p>Terranova, J. I., Yokose, J., Osanai, H., Marks, W. D., Yamamoto, J., Ogawa, S. K., &amp; Kitamura, T. (2022). Hippocampal-amygdala memory circuits govern experience-dependent observational fear. <em>Neuron</em>, <em>110</em>(8), 1416-1431.e13. <a href=\"https://doi.org/10.1016/J.NEURON.2022.01.019\">https://doi.org/10.1016/J.NEURON.2022.01.019</a></p>\n<p>Tokozume, Y., &amp; Harada, T. (2017). Learning environmental sounds with end-to-end convolutional neural network. <em>ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</em>, 2721–2725. <a href=\"https://doi.org/10.1109/ICASSP.2017.7952651\">https://doi.org/10.1109/ICASSP.2017.7952651</a></p>\n<p>Tokozume, Y., Ushiku, Y., &amp; Harada, T. (2017). Learning from Between-class Examples for Deep Sound Recognition. <em>6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings</em>. <a href=\"https://doi.org/10.48550/arxiv.1711.10282\">https://doi.org/10.48550/arxiv.1711.10282</a></p>\n<p>Valueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., &amp; Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. <em>Mathematics and Computers in Simulation</em>, <em>177</em>, 232–243. <a href=\"https://doi.org/10.1016/J.MATCOM.2020.04.031\">https://doi.org/10.1016/J.MATCOM.2020.04.031</a></p>\n<p>Wei, X. S., Zhang, C. L., Zhang, H., &amp; Wu, J. (2018). Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences. <em>IEEE Transactions on Affective Computing</em>, <em>9</em>(3), 303–315. <a href=\"https://doi.org/10.1109/TAFFC.2017.2762299\">https://doi.org/10.1109/TAFFC.2017.2762299</a></p>\n<p>Wimmer, G. E., &amp; Shohamy, D. (2012). Preference by association: how memory mechanisms in the hippocampus bias decisions. <em>Science (New York, N.Y.)</em>, <em>338</em>(6104), 270–273. <a href=\"https://doi.org/10.1126/SCIENCE.1223252\">https://doi.org/10.1126/SCIENCE.1223252</a></p>\n<p>Wise, T., Liu, Y., Chowdhury, F., &amp; Dolan, R. J. (2021). Model-based aversive learning in humans is supported by preferential task state reactivation. <em>Science Advances</em>, <em>7</em>(31), 9616–9644. <a href=\"https://doi.org/10.1126/SCIADV.ABF9616\">https://doi.org/10.1126/SCIADV.ABF9616</a></p>\n<p>Wu, C. T., Haggerty, D., Kemere, C., &amp; Ji, D. (2017). Hippocampal awake replay in fear memory retrieval. <em>Nature Neuroscience</em>, <em>20</em>(4), 571. <a href=\"https://doi.org/10.1038/NN.4507\">https://doi.org/10.1038/NN.4507</a></p>\n<p>Yann LeCun, Corinna Cortes, &amp; Chris Burges. (2012). <em>MNIST handwritten digit database</em>. <a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a></p>\n<p>Yu, F. T. S., &amp; Guowen, L. (1994). Short-time Fourier transform and wavelet transform with Fourier-domain processing. <em>Applied Optics</em>, <em>33</em>(23), 5262–5270. <a href=\"https://doi.org/10.1364/AO.33.005262\">https://doi.org/10.1364/AO.33.005262</a></p>\n<p>Zhang, C. L., Luo, J. H., Wei, X. S., &amp; Wu, J. (2018). In defense of fully connected layers in visual representation transfer. <em>Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>, <em>10736 LNCS</em>, 807–817. <a href=\"https://doi.org/10.1007/978-3-319-77383-4_79/TABLES/4\">https://doi.org/10.1007/978-3-319-77383-4_79/TABLES/4</a></p>\n<p>Zheng, L., Liao, P., Luo, S., Sheng, J., Teng, P., Luan, G., &amp; Gao, J. H. (2020). EMS-Net: A Deep Learning Method for Autodetecting Epileptic Magnetoencephalography Spikes. <em>IEEE Transactions on Medical Imaging</em>, <em>39</em>(6), 1833–1844. <a href=\"https://doi.org/10.1109/TMI.2019.2958699\">https://doi.org/10.1109/TMI.2019.2958699</a></p>\n<p>Zubarev, I., Zetter, R., Halme, H. L., &amp; Parkkonen, L. (2019). Adaptive neural network classifier for decoding MEG signals. <em>NeuroImage</em>, <em>197</em>, 425–434. <a href=\"https://doi.org/10.1016/J.NEUROIMAGE.2019.04.068\">https://doi.org/10.1016/J.NEUROIMAGE.2019.04.068</a></p>\n"},{"title":"master project","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-05-16T13:00:00.000Z","password":null,"summary":null,"_content":"\n# Table of content \n\n[Toc]\n\n# April 12th\n\n## First meeting \n\n### Objective: \n\nto find out which data we are going to use and which method to analyse it because good understanding of the data can help researching simpler and more accurate. It can also inform me important information about features engineering or neural network designing.\n\n### Results:\n\ndata: https://openneuro.org/datasets/ds003682\n\n28 participants viewing 14 image stimuli \n\nThe file we cares:\n\n![image-20220411140935965](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204111409061.png)\n\nI can use MNE-Python to analyse it because MNE-Python package is highly integrated allowing an easy access to analysing.\n\nWhat these files do can be achieved with:\n\nhttps://mne.tools/stable/generated/mne.read_epochs.html\n\nMore templates can be found in:\n\nhttps://github.com/tobywise/aversive_state_reactivation/blob/master/notebooks/templates/sequenceness_classifier_template.ipynb\n\n# April 13th\n\n## First session meeting \n\n### Objective:\n\nlearn how to write a lab notebook\n\n### Results\n\nGeneral understanding:\n\nTitle: the utility of multi-task machine learning for decoding brain states\n\nTable of Contents:\n\npage numbers; date; title/subject/experiment\n\nGantt charts is good to help organise time.\n\n# April 18th\n\n## Install MNE-Python via pip:\n\n### Objective:\n\nto upgrade environment manager and compiler to the latest stable version because I always tend to use the latest version of packages which is supposed to be more compatible\n\n### Results:\n\nUpdate Anaconda via ` conda upgrade --all` and  `conda install anaconda=2021.10`\n\nThe Python version I am using is:\n\n```\nPython 3.9.12\t\n```\n\nget the data:\n\n`git clone https://github.com/OpenNeuroDatasets/ds003682`\n\nInstall MNE:\n\n`conda install --channel=conda-forge mne-base`\n\n# April 19th\n\n## Second meeting \n\n### Objective: \n\nto have a general understanding of the data and figure out details about methods because these are what I am going to feed into the network so that I should have a clear recognition for each part.\n\n`x_raw`\n\n`x_raw.shape`\n\n`y_raw`\n\n`time = localiser epchoes`\n\n### Results:\n\n#### what I have known:\n\n**scikit-learn** (machine learning library) is an available package I am going to use\n\nuse **PCA** to reduce dimensions \n\n![image-20220419104136746](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204191041843.png)\n\n#### what need to be learned: \n\n##### 1. normalization, regularization\n\nlasso L1 = sets unpredictive features to 0\n\nridge L2 = minimises the weights on unpredictive features\n\nelastic net L1/L2\n\n##### 2. search\n\n`random_search randomizedsearchCV` to test the performance\n\n##### 3. Neural network\n\nneural network can be the best way for logistic leaning \n\n##### 4. validation\t\n\n# April 24th\n\n### Objective:\n\nto play with existing code https://github.com/tobywise/aversive_state_reactivation because it can inform me code grammars analysing MEG data and it will make a foundation for my following coding \n\n### Results:\n\n#### Epochs\n\nExtract signals from continuous EEG signals for specific time windows, which can be called epochs.\n\nBecause EEGs are collected continuously, to analyse EEG event-related potentials requires \"slicing\" the signal into time segments that are locked to time segments within an event (e.g., a stimulus).\n\n#### Data corruption\n\nThe MEG data in the repository https://openneuro.org/datasets/ds003682 is invalid, possibly because of data corruption\n\n**incomplete copying led to corrupted files**\n\nThe following events are an example present in the data: 1, 2, 3, 4, 5, 32\n\n```\nevent_id = {'Auditory/Left': 1, 'Auditory/Right': 2,\n'Visual/Left': 3, 'Visual/Right': 4,\n'smiley': 5, 'button': 32}\n```\n\n`sklearn.cross_validation` has been deprecated since version 1.9, and `sklearn.model_selection` can be used after version 1.9.\n\n# April 25th\n\n## Install scikit-learn (sklearn)\n\nuse the command line \n\n`conda install -c anaconda scikit-learn`\n\nStart the base environment in Anaconda Prompt: `activate base`\n\nAnd install jupyter notebook, numpy and other modules in the environment\n\n```bash\nconda insatll tensorflow\n\nconda install jupyter notebook\n\nconda install scikit-learn\n\nconda install scipy\n```\n\nLearn how to choose the right algorithm \n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n\n![flow chart of scikit](https://scikit-learn.org/stable/_static/ml_map.png)\n\n## Learning sklearn\n\n1. import modules\n\n```python\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n```\n\n2. create data\n\nload `iris` data，store the **attributes** in  `X`，store the **labels** in `y`：\n\n```python\niris = datasets.load_iris()\niris_X = iris.data\niris_y = iris.target\n```\n\nLooking at the dataset, `X` has four attributes, and `y` has three categories: 0, 1, and 2:\n\n```python\nprint(iris_X[:2, :])\nprint(iris_y)\n\n\"\"\"\nOutput:\n[[ 5.1  3.5  1.4  0.2]\n [ 4.9  3.   1.4  0.2]]\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n \"\"\"\n```\n\nDivide the data set into training set and test set, where `test_size=0.3`, that is, the test set accounts for 30% of the total data:\n\n```python\nX_train, X_test, y_train, y_test = train_test_split(\n    iris_X, iris_y, test_size=0.3)\n```\n\nIt can be seen that the separated data sets are also disrupted in order, which is better to train the model:\n\n```python\nprint(y_train)\n\n\"\"\"\nOutputs:\n[2 1 0 1 0 0 1 1 1 1 0 0 1 2 1 1 1 0 2 2 1 1 1 1 0 2 2 0 2 2 2 2 2 0 1 2 2\n 2 2 2 2 0 1 2 2 1 1 1 0 0 1 2 0 1 0 1 0 1 2 2 0 1 2 2 2 1 1 1 1 2 2 2 1 0\n 1 1 0 0 0 2 0 1 0 0 1 2 0 2 2 0 0 2 2 2 1 2 0 0 2 1 2 0 0 1 2]\n \"\"\"\n```\n\n3. Build a model - train - predict\n\nDefine the module method `KNeighborsClassifier()`, use `fit` to train `training data`, this step completes all the steps of training, the latter `knn` is already a trained model, which can be used directly `predict` For the data of the test set, comparing the value predicted by the model with the real value, we can see that the data is roughly simulated, but there is an error, and the prediction will not be completely correct.\n\n```python\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(knn.predict(X_test))\nprint(y_test)\n\n\"\"\"\n[2 0 0 1 2 2 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1\n 0 0 1 0 1 2 0 1]\n[2 0 0 1 2 1 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1\n 0 0 1 0 1 2 0 1]\n \"\"\"\n```\n\nDirectly download the data and store in my computer. However, it is unprofessional to run code in personal computer. I should looking for a way to solve this problem: rent a server or find a HPC cluster in King’s College.\n\n![image-20220425150724894](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204251507965.png)\n\n## Succeed at drawing plot\n\n```python\nimport mne\nimport os\nfrom mne.datasets import sample\nimport matplotlib.pyplot as plt\n\n# The storage path of sample\ndata_path = sample.data_path()\n# The storage path of the fif file\nfname = 'E:\\Proj\\Previous data\\sample\\MEG\\sample\\sub-001_localiser_sub-001_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz'\n\nepochs = mne.read_epochs(fname)\n\nprint(epochs.event_id)\n\npicks = mne.pick_types(epochs.info, meg=True, ref_meg=False, exclude='bads')\n\nepochs.plot(block=True)\n\nepochs.plot_drop_log()\n\nplt.show()\n```\n\n```python\nepochs = mne.read_epochs(fname)\n\nevoked = epochs.average()\nevoked.plot_topomap()\n\nplt.show()\n```\n```python\navailabe_event = [1, 2, 3, 4, 5, 32]\n\nfor i in availabe_event:\n    evoked_i = epochs[i].average(picks=picks)\n    epochs_i = epochs[i]\n    evoked_i.plot(time_unit='s')\n    plt.show()\n\n```\n\nThe panel each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data\n\n![image-20220817193732989](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171937606.png)\n\nTopological map from -500.00 to 790.00 ms. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.\n\n![image-20220817194146606](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171941694.png)\n\n## A few questions at last: \n\n1. why do we split the data as 70%, does it work as other ration?\n\n   Because we have got enough data to train and need more data to test and valid the training performance.\n\n# April 26th\n\n## MRI safety training for 2.5 hrs\n\n## update Anaconda (start to use a new platform)\n\nAnaconda is a good environment manager tool which allows me to manage and deploy packages\n\n`conda update conda`\n\n`conda update anaconda`\n\n`conda update --all`\n\ndone\n\nPython version: 3.8.13-h6244533_0\n\n## change the directory path of Jupyter notebook (in order to save files in preferred path)\n\n1. `jupyter notebook --generate-config` get the config file. change the line `c.NotebookApp.notebook_dir = ''` to the directory I want\n\n2. find jupyter notebook file, change the attributes. ![change the attributes](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204261614733.png)\n\n## Link the local directory and Github\n\nfor the convenience of collaboration \n\nSSH connect public key (id_rsa.pub) was created before.\n\nafter create the directory, run the command in git:\n\n```bash\ngit init\ngit add .\ngit git commit -m  \"Comment\"\ngit remote add origin \"the url of directory\"\ngit push -u origin main\n```\n\n## Journal club preparation for the next session\n\n# April 27th\n\n## Pycharm (use IDE)\n\nGet Pycharm educational version via King’s email\n\ninstall python 3.8 environment for running the code from https://github.com/tobywise/aversive_state_reactivation (because it was coding with python 3.8 compiler)\n\nrun below code in pycharm\n\n```bash\n!conda create -n py38 python=3.8\n!pip install mne\n!pip install scikit-learn\n!pip install plotly\n!pip install cufflinks\n!pip install networkx\n!conda install numba\n!pip install pyyaml\n!pip install papermill\n```\n\n## Fixation for some expired code\n\nThe function `joblib` does not exist in `sklearn.external` anymore.\n\nError occurs when run the function plot_confusion_matrix:\n\nDeprecated since version 1.0: `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the following class methods: `from_predictions` or `from_estimator`.\n\nuse\n\n```python\nConfusionMatrixDisplay.from_predictions(y, y_pred)\n```\n\ninstead of \n\n```python\nplot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title='Normalised confusion matrix, accuracy = {0}'.format(np.round(mean_accuracy, 2)))\n```\n\n## Second session meeting\n\nEvery people gives a general introduction of their projects\n\n# April 28th\n\n## Logistic regression cost function\n\nThe function is using the principle of maximum likelihood estimation to find the parameters $\\theta$ for different models. At the meantime, a nice property is it is convex. So, this cost function is generally everyone use for fitting parameters in logistic regression.![image-20220429010526272](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290105356.png)\n\nThe way we are going to minimize the cost function is using gradient descent:\n\n![image-20220429011210521](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290112574.png)\n\nOther alternative optimization algorithms (no need to manually pick $\\alpha$ studying rate):\n\n1. Conjugate gradient\n2. BFGS\n3. L-BFGS\n\n## Methods to storage trained model\n\nset and train a simple SVC model\n\n```python\nfrom sklearn import svm\nfrom sklearn import datasets\n\nclf = svm.SVC()\niris = datasets.load_iris()\nX, y = iris.data, iris.target\nclf.fit(X,y)\n```\nStorage:\n\n1. pickle\n\n```python\nimport pickle #pickle module\n\n#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)\nwith open('save/clf.pickle', 'wb') as f:\n    pickle.dump(clf, f)\n\n#load Model\nwith open('save/clf.pickle', 'rb') as f:\n    clf2 = pickle.load(f)\n    #test loaded Model\n    print(clf2.predict(X[0:1]))\n```\n\n2. joblib (supposed to be faster when dealing with a large data, because the use of multiprocessing)\n\n```python\nfrom sklearn.externals import joblib #jbolib模块\n\n#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)\njoblib.dump(clf, 'save/clf.pkl')\n\n##load Model\nclf3 = joblib.load('save/clf.pkl')\n\n#test loaded Model\nprint(clf3.predict(X[0:1]))\n\n```\n\n# April 29th\n\n## Google Colab\n\nGet the subscription of Google Colab and Google drive\n\nclone data to google drive\n\nToken: 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\n\nconnect Google Colab with VS code\n\n## Regularization\n\nWe can use **regularization** to rescue the overfitting\n\nThere are two types of regularization:\n\n- **L1 Regularization** (or Lasso Regularization)\n\n  $Min$($$\\sum_{i=1}^{n}{|y_i-w_ix_i|+p\\sum_{i=1}^{n}|w_i|}$$)\n\n- **L2 Regularization** (or Ridge Regularization)\n\n  $Min$($$\\sum_{i=1}^{n}{(y_i-w_ix_i)^2+p\\sum_{i=1}^{n}w_i^2}$$)\n\nwhere `p` is the tuning parameter which decides in what extent we want to penalize the model.\n\nHowever, there is another method for combination\n\n- **Elastic Net:** When L1 and L2 regularization combine together, it becomes the elastic net method, it adds a hyperparameter.\n\nhow to select:\n\n| **No** | **L1 Regularization**                                   | **L2 Regularization**                                        |\n| ------ | ------------------------------------------------------- | ------------------------------------------------------------ |\n| **1**  | Panelises the sum of absolute value of weights.         | Penalises the sum of square weights.                         |\n| **2**  | It has a sparse solution.                               | It has a non-sparse solution.                                |\n| **3**  | It gives multiple solutions.                            | It has only one solution.                                    |\n| **4**  | Constructed in feature selection.                       | No feature selection.                                        |\n| **5**  | Robust to outliers.                                     | Not robust to outliers.                                      |\n| **6**  | It generates simple and interpretable models.           | It gives more accurate predictions when the output variable is the function of whole input variables. |\n| **7**  | Unable to learn complex data patterns.                  | Able to learn complex data patterns.                         |\n| **8**  | Computationally inefficient over non-sparse conditions. | Computationally efficient because of having analytical solutions. |\n\n## Normalization\n\nThe reason for applying normalization is the normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance.\n\n ![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171958842.gif)\n\nwhere m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1\n\n### Question:\n\nwhich layer should I apply the regularization?\n\nFrom the model's summary, I can determine which layers have the most parameters. It is better to apply regularization to the layers with the highest parameters.\n\nIn the above case, how to get each layer’s parameters?\n\n```python\nfrom prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad: continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params+=params\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params\n    \ncount_parameters(model)\n```\n\n# May 2nd\n\n## Question ahead:\n\nget a question: how to determine the classifier centre (windows width)? \n\nfor this case, it is around 20 to be at the middle/ top\n\nGPU accelerations\n\nIt could be a little bit tricky to accelerate the calculation in sklearn with GPU. Here is a possible solution: https://developer.nvidia.com/blog/scikit-learn-tutorial-beginners-guide-to-gpu-accelerating-ml-pipelines/.  \n\n## Third meeting:\n\nDeep learning might be the solution for MEG signals classification. \n\nThe CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018)\n\n> Khan, S., Rahmani, H., Shah, S. A. A., & Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. *A Guide to Convolutional Neural Networks for Computer Vision*. https://doi.org/10.1007/978-3-031-01821-3\n>\n> Valueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., & Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. *Mathematics and Computers in Simulation*, *177*, 232–243. https://doi.org/10.1016/J.MATCOM.2020.04.031\n>\n> Bai, S., Kolter, J. Z., & Koltun, V. (2018). *An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling*. https://doi.org/10.48550/arxiv.1803.01271\n\npossible deep learning packages:\n\nJAX, HAIKU\n\nMy aim is to inform bad-performance data with the training model of good-performance data in aims to increase the performance. One hallmark is to increase the mean accuracy of each cases as high as possible.\n\n# May 3rd\n\nSuccessfully run the code for confusion matrix.\n\n```python\nclf.set_params(**random_search.best_params_)\n\n# Get predictions with 5 fold CV\ny_pred = cross_val_predict(clf, X, y, cv=confusion_matrix_cv)\nmean_conf_mat = confusion_matrix(y, y_pred)\nmean_accuracy = accuracy_score(y[y != 99], y_pred[y != 99])\nmean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n\nprint(\"Mean accuracy = {0}\".format(mean_accuracy))\n    \n# Plot mean confusion matrix\n#plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title='Normalised confusion matrix, accuracy = {0}'.format(np.round(mean_accuracy, 2)))\n#plt.imshow(mean_conf_mat[:n_stim, :n_stim])\n\nConfusionMatrixDisplay.from_predictions(y, y_pred)\nplt.savefig('./save_folder/fig-{}.png'.format(session_id), dpi=600)\nplt.show()\n```\n\npictures of each case are stored in the Github depository: \n\nhttps://github.com/ReveRoyl/MT_ML_Decoding/tree/main/Aversive_state_reactivation/notebooks/templates/save_folder\n\nIt takes around 36 minutes to run 28 cases. \n\nMean accuracy with existing code:\n\n```python\n[0.4288888888888889, 0.33666666666666667, 0.2777777777777778, 0.5022222222222222, 0.5066666666666667, 0.4245810055865922, 0.5577777777777778, 0.43222222222222223, 0.65, 0.47888888888888886, 0.3377777777777778, 0.4800469483568075, 0.27111111111111114, 0.37193763919821826, 0.4288888888888889, 0.40555555555555556, 0.46444444444444444, 0.7077777777777777, 0.5811111111111111, 0.4711111111111111, 0.4255555555555556, 0.5022222222222222, 0.45394006659267483, 0.38555555555555554, 0.6222222222222222, 0.4622222222222222, 0.35444444444444445, 0.47444444444444445]\n```\n# May 10th\n\nGet rid of the effect of null data\n\ntransform X into the same size as clf\n\n# May 11th\n\n## Grid Search CV\n\nTo test Grid Search CV instead of Randomized Search CV\n\nHowever, the result of grid search CV is worse than the randomized search CV. I think the reason is that random search CV uses a random combination of hyperparameters to find the best solution for a built model. However, the random search CV is not 100% better than grid search CV: the disadvantage of random search is that it produces high variance during computation.\n\n## Concatenation\n\n### Objective\n\nSince my aim is to transfer the model prediction of one case to anther, I try to concatenate multiple cases data together to train the model and see what will happen.\n\n```python\nlocaliser_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{}', 'localiser', 'sub-{}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format('001','001')) \n\nfor session_id_int in range(2, 3):\n    session_id = '{:03d}'.format(session_id_int)\n    print(session_id)\n    \n    localiser_epochs_unconcatenate = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{}', 'localiser', 'sub-{}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id,session_id))  \n    localiser_epochs_unconcatenate.info = localiser_epochs.info\n    localiser_epochs = mne.concatenate_epochs([localiser_epochs, localiser_epochs_unconcatenate]) \n\n```\n\n### Result\n\nConcatenate X np arrays and test, the mean accuracy increases. I test 5 cases.\n\nMean accuracy = 0.5111111111111111, while for each cases, previous mean accuracy = 0.43777777777777777; 0.34; 0.2788888888888889; 0.5055555555555555.\n\n![img](data:image/png;base64,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)\n\n![img](data:image/png;base64,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)\n\n![img](data:image/png;base64,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)\n\n![img](data:image/png;base64,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)\n\nThe concatenated data gives a better fit:\n\n![output](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205121731546.png)\n\nHowever, the generalization ability of this method has not been decided yet till now.\n\n# May 12th\n\nadd ‘participant number’ dimension to X\n\n```python\nX_4D = []\nfor session_id_int in range(1, 2):\n    session_id = '{:03d}'.format(session_id_int)\n    print(session_id)\n    # Get data\n    localiser_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{}', 'localiser', 'sub-{}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id,session_id))  \n    \n    X_raw = localiser_epochs.get_data()\n    \n    picks_meg = mne.pick_types(localiser_epochs.info, meg=True, ref_meg=False)\n    event_selector = (y_raw < n_stim * 2 + 1)\n    X_raw = X_raw[event_selector, ...]\n    X_raw = X_raw[:, picks_meg, :]\n    X = X_raw.copy()\n    X = X[..., classifier_center_idx + classifier_window[0]:classifier_center_idx + classifier_window[1]] \n\n    X_4D.append(X)\n# for epoch in localiser_epochs_concatenate:\n#     print(epoch.shape)\n# localiser_epochs = mne.concatenate_epochs(localiser_epochs_concatenate)\nX = np.stack(X_4D)\n```\n\nIt takes me 1 hour to make the code logical elegant.\n\n# May 13th\n\n## Forth meeting\n\n### Objective:\n\nWe have tested existing code, the following step is to try different models to predict.\n\nMy supervisor’s suggestion is to use haiku trying CNN.\n\n```\npip install -upgrade jax optax dm-haiku \n```\n\nto be learnt: \n\nactive function: rectifier RELU\n\n### Result:\n\nNew model selection: CNN with Haiku\n\n# May 14th\n\nFind a  bug: concatenated data was not giving a correct result. The better performance was because of the randomness of every time training. The concatenated data won’t give a better prediction. \n\npossible solution: transfer learning instead of directly concatenation.\n\n# May 16th\n\n### Objective\n\nto learning deep learning courses (Andrew Ng) in coursera because as said in ‘Knife don't miss your job’, to solid the foundation of deep learning will help me build the CNN and understand others’ work\n\n### Result:\n\nIn the context of artificial neural networks, the rectifier or ReLU (Rectified Linear Unit) activation function is an activation function defined as the positive part of its argument.\n\n#### Convolution\n\nTypes of layer in a CNN:\n\n- Covolution\n- Pooling\n- Fully connected \n\nCases:\n\nClassic networks: \n\n- LeNet-5\n- AlexNet\n- VGG\n\nResNet\n\nInception\n\nLeNet -5 \n\n# May 17th\n\n## Learning JAX\n\n**Question: why jax has its own numpy type: jax.numpy? what is the difference between it and numpy?**\n\nJax.numpy is a little bit different from numpy: the former is immutable\n\n**Question: why do we need jax.numpy?** \n\nbecause numpy only works on CPU while jax.numpy works on GPU\n\n**another advantage of JAX**\n\n`jit()` can be used to compile the data input thus makes the program run faster\n\n## First group meeting\n\nYiqi introduced his recent work which is based on U-net, VAE\n\n# May 18th\n\n## Learning JAX\n\n```python\ngrad() # for differentation\nfrom jax import jacfwd, jacrev # for Jacobian matrix\nvmap() # for vectorization; it can makes you write your functions as if you were dealing wiht a single datapoint\n```\n\nJAX API structure\n\n- NumPy <-> lax <-> XLA\n- lax API is stricter and more powerful\n- It's a Python wrapper around XLA\n\n![nn](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221751704.svg)\n\n```python\nclass CNN(hk.Module):\n    def __init__(self):\n        super().__init__(name=\"CNN\")\n        # self.conv1 = hk.Conv2D(output_channels=32, kernel_shape=(3,3), padding=\"SAME\")\n        # self.conv2 = hk.Conv2D(output_channels=16, kernel_shape=(3,3), padding=\"SAME\")\n        self.conv1 = hk.Conv2D(output_channels=64, kernel_shape=(11,11), stride=4, padding=\"SAME\")\n        self.conv2 = hk.Conv2D(output_channels=192, kernel_shape=(5,5), padding=\"SAME\")\n        self.conv3 = hk.Conv2D(output_channels=384, kernel_shape=(3,3), padding=\"SAME\")\n        self.conv4 = hk.Conv2D(output_channels=256, kernel_shape=(3,3), padding=\"SAME\")\n        self.conv5 = hk.Conv2D(output_channels=256, kernel_shape=(3,3), padding=\"SAME\")\n        self.flatten = hk.Flatten()\n        self.linear = hk.Linear(len(classes))\n\n    def __call__(self, x_batch):\n        x = self.conv1(x_batch)\n        x = jax.nn.relu(x)\n        x = hk.MaxPool(window_shape=(3, 3), strides=(2, 2), padding='VALID')(x)\n        x = self.conv2(x)\n        x = jax.nn.relu(x)\n        x = hk.MaxPool(window_shape=(3, 3), strides=(2, 2), padding='VALID')(x)        \n        x = self.conv3(x_batch)\n        x = jax.nn.relu(x)\n        x = self.conv4(x_batch)\n        x = jax.nn.relu(x)\n        x = self.conv5(x_batch)\n        x = jax.nn.relu(x)\n        x = hk.MaxPool(window_shape=(3, 3), strides=2, padding='VALID')(x)\n        # x = hk.AvgPool(window_shape=(6, 6), strides=(2, 2), padding='SAME')(x)\n        \n        x = self.flatten(x)\n        x = self.linear(x)\n        x = jax.nn.softmax(x)\n        return x\n```\n\n# May 19th\n\n## Test CNN\n\nCNN test was run but the prediction result is not as good as expected: \n\nthe performance of it is about 0.4 for training dataset and 0.15 for test dataset. \n\nI think we should try to tune the parameters of model or test a different model since the current model is suitable for image recognition. Before that, literature reviews should be done. \n\nLater after I read Aoe’s work, I start to under stand it is because my image classification CNN model fails to extract the temporal and spatial information. \n\n> Aoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., & Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. *Scientific Reports*, *9*(1). https://doi.org/10.1038/S41598-019-41500-X\n\n## Fifth meeting\n\nI have the requirement of visualization during training: \n\nTo use Tensor Board to show the training process\n\n```python\n!rm -rf /logs/ # clear logs\n# if 'google.colab' in str(get_ipython()): # tensor board\n%load_ext tensorboard  \n# %tensorboard --logdir logs\n%tensorboard --logdir=./models/test\n```\n\n# May 20th\n\n## Tried AlexNet (can be easily get from Pytorch hub)\n\nAlexNet\n\n```python\nAlexNet  = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True).cuda()\n```\n\nResnet 18\n\n```python\nResnet   = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).cuda()\n```\n\nThese 2 models fail as well. The same reason: these models fail to extract the temporal and spatial information in the first convolutional layers.\n\n![image-20220722175851266](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221758352.png)\n\n\n\n## Sixth meeting\n\n### Objective:\n\nto discuss about that if we should use concatenate data and pre-processing for standardization because the conditions of recording may varies a lot among different subjects: the device position or potential individual reasons.\n\n### Results:\n\nDr. Toby and I had a discussion together with Dr. Rossalin \n\nRossalin advices me to try transfer learning or LSTM.\n\nAfter trying the model is usually used in image classification, it is a good idea to try the model LSTM RNN, which is known as a good fit for sequential data.\n\n# May 24th\n\n## Second group meeting\n\nZarc gives a presentation about his NLP project.\n\n# May 27th\n\n## Learning Tensorflow\n\nTensorflow is a more popular packages which allows me to get access to many templates. Some research is also using Tensorflow as their machine learning library. But I found Pytorch is a more popular packages which allows me to get access to more well-known templates. Most related research is using Pytorch as their machine learning library.\n\nHowever, I found the variable and  placeholder operations are more commonly used in Tensorflow-v1 rather than the latest  Tensorflow-v1\n\n### Session control\n\nIn Tensorflow, a string is defined as a variable, and it is a variable, which is different from Python. (later on I found it was correct in Tensorflow v1 but changes in Tensorflow v2)\n\n `state = tf.Variable()`\n\n```python\nimport tensorflow as tf\n\nstate = tf.Variable(0, name='counter')\n\n# define variable one\none = tf.constant(1)\n\n# define plus step (hint: no computation here)\nnew_value = tf.add(state, one)\n\n# update State to new_value\nupdate = tf.assign(state, new_value)\n```\n\nIf I set variables in Tensorflow, initializing the variables is the most important thing! ! So after defining the variable, be sure to define `init = tf.initialize_all_variables()`.\n\nAt this point, the variable is still not activated, and it needs to be added in `sess` , `sess.run(init)` , to activate`init`. (again, it changes in v2, we do not need to initialize the session in Tensorflow v2)\n\n```Python\n# Variable, initialize\n# init = tf.initialize_all_variables() # expired\ninit = tf.global_variables_initializer()  \n \n# Session\nwith tf.Session() as sess:\n    sess.run(init)\n    for _ in range(3):\n        sess.run(update)\n        print(sess.run(state))\n\n```\n\nNote: directly `print(state)` does not work! !\n\nBe sure to point the `sess` pointer to `state` and then `print` to get the desired result!\n\n### placeholder\n\n`placeholder` is a placeholder in Tensorflow that temporarily stores variables.\n\nIf Tensorflow wants to pass in data from the outside, it needs to use `tf.placeholder()`, and then transfer the data in this form `sess.run(***, feed_dict={input: **})`.\n\nExamoles：\n\n```\nimport tensorflow as tf\n\n# Tensorflow requires defining placeholder's type, usually float32\ninput1 = tf.placeholder(tf.float32)\ninput2 = tf.placeholder(tf.float32)\n\n# multiply input1 and input2\nouput = tf.multiply(input1, input2)\n```\n\nNext, the work of passing the value is handed over to `sess.run()`, the value that needs to be passed in is placed in `feed_dict={}` and corresponds to each `input` one by one. `placeholder` and `feed_dict={ }` are bound together.\n\n```\nwith tf.Session() as sess:\n    print(sess.run(ouput, feed_dict={input1: [7.], input2: [2.]}))\n# [ 14.]\n```\n\n### Activation function\n\nwhen there are many layers, be careful to use activation function in case of the **gradient exploding or gradient disappearance**.\n\n# May 28th\n\n> Although in the computer vision field convolutional layer often followed by a pooling layer to reduce the data dimension at the expense of information loss, in the scenes of MEG decoding, the size of MEG data is much smaller than the computer vision field. So in order to keep all the information, we don’t use the pooling layer. After the spatial convolutional layer, we use two layers of temporal convolutional layers to extract temporal features, a fully connected layer with dropout operation for feature fusion, and a softmax layer for final classification. (Huang2019)\n\nIt is important to select if we should use pooling layers and how many to use.\n\n# May 30th\n\n## ML optimizer\n\n### Objective:\n\nto learn how to use and select different optimizer, because it modifies model’s parameters like weights and learning rate, which helps to increase accuracy and reduce overall loss.\n\n### Results:\n\n- Stochastic Gradient Descent (SGD)\n- Momentum\n- AdaGrad\n- RMSProp\n- Adam\n\n![speedup3](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205302233928.png)\n\nX.shape gives (n_epochs, n_channels, n_times) corresponding to (batches, pixels,channels)  of images\n\nApart for optimizer, scheduler may help a lot with providing a dynamic learning rate.\n\n### impression\n\nAs I tried to apply regularization at the same time. It is important to bear in mind, if we give a momentum in SGD (about 0.9), we can easily apply L2 regularization when the weight_decay is larger than 0.\n\n# May 31st\n\n### Objective:\n\nto learn data augmentation and learn a important rule: “No free lunch theorem”\n\n### Results:\n\nD. H. Wolpert et. al. (1995) come up with “No free lunch theorem”: all optimization algorithms perform equally well when their performance is averaged across all possible problems.\n\nFor any prediction function, if it performs well on some training samples, it must perform poorly on other training samples. If there are certain assumptions about the prior distribution of the data in the feature space, there are as many good and bad performances.\n\nLater I found relative power spectrum including delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz), provide important information to augmenting the MEG data.\n\n```python\nX_train_numpy = X_train_tensors.cpu().numpy()\nX_test_numpy = X_test_tensors.cpu().numpy()\n\nX = np.swapaxes(X_train_numpy, 2, -1).squeeze()\ndata = X[X.shape[0]-1, 70, :]\npsd_mne, freqs_mne = psd_array_welch(data, 100, 1., 70., n_per_seg=None,\n                          n_overlap=0, n_jobs=1)\nfor low, high in [(0.5, 4), (4, 8), (8, 10), (10, 12), (12, 30),\n                  (30, 70)]:\n    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n    # Find intersecting values in frequency vector\n    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n      # Frequency resolution\n    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n\n    # Compute the absolute power by approximating the area under the curve\n    power = simps(psd_mne[idx_delta], dx=freq_res)\n    print('Absolute power: {:.4f} uV^2'.format(power))\n    \n    total_power = simps(psd_mne, dx=freq_res)\n    rel_power = power / total_power\n    \n    print('Relative power: {:.4f}'.format(rel_power))\n```\n\n# Jun 1st\n\n## Seventh meeting\n\nDr Toby provide me the code to load data with dataloader\n\nit defines load_MEG_dataset function with following parameters: \n\n```python\ndef load_MEG_dataset(\n        subject_ids: List[str],\n        mode: str = \"individual\",\n        output_format: str = \"numpy\",\n        trial_data_format: str = \"2D\",\n        data_location: str = \"./data/\",\n        center_timepoint: int = 20,\n        window_width: List[int] = [-400, 400],\n        shuffle: bool = False,\n        pca_n_components: int = None,\n        training: bool = True,\n        train_test_split: float = 0.75,\n        batch_size: int = 32,\n        scale: bool = True,\n        seed: int = 0,\n    )\n```\n\n# Jun 6th\n\n### Objective:\n\nto try different loss function, because different evaluating methods may affect the learning process, and lead to a different approach to training results.\n\n### Results:\n\nwhen apply other loss function instead of CrossEntropy, there are some format error occurs:\n\nsolution: transform inputs from multi hot coding into one hot coding. \n\n```Python\ndef onehot(batches, n_classes, y):\n  yn = torch.zeros(batches, n_classes)\n  for i in range(batches):\n    x = [0 for j in range(batches)]\n    x[i] = y[i]/2-1                     #ex. [12]-> [5]\n    yn[i][int(x[i])]+= 1                  #[000010000]\n  return yn\n```\n\nLater I found that we can use the function in Pytorch: F.onehot\n\n# Jun 7th\n\ntry different models, reshape the data from [batches, channels, times point ]to be [batches, times point, channels] in corresponding to images format [batches, picture channels (layers), pixels] (not the same channels, the same names but different meanings, former one is electrode channels. latter one is picture layers)\n\n# Jun 8th\n\n## Third session meeting\n\n### Objective:\n\nto learn the key points of writing a good introduction\n\n### Results:\n\nfrom the history of ML to the current meaning \n\n- [x] The **history** of **ML**, (black box...)\n- [x] the **history** of disease classification or **behaviour prediction**\n- [x] how people use the ML techniques to **predict  behaviours** these days\n- [x] what is aversive state reactivation (one sentence); why people want to learn aversive state reactivation\n- [x] how people tried to connect ML with aversive state reactivation\n- [x] the problem (gap) is previous model only gives a low prediction accuracy\n- [x] Introduction of CNN, LSTM, RNN or transfer learning\n- [x] My aims is to optimize the model with new techniques: CNN, LSTM RNN or transfer learning\n\nNote: state what in each paragraph is not enough and leads to the next paragraph.\n\n## LSTM RNN\n\n### Objective: \n\ntry LSTM RNN\n\n### Results:\n\nThe problems when I try to use one hot data `  labels = F.one_hot(labels)`, it is not applicable because in that case the dimensions could be 28 instead of 14 as we only have even numbers,\n\nSome packages automatically figure out where there missing labels during one hot operation but this one (pytorch) doesn't\n\n## Eighth meeting\n\n### questions: \n\n- [x] loss functions give similar values?\n- [x] ~~is it correct to use enumerate to loop each data?~~\n\nIn my case, CrossEntropy is the better for MEG data. It is the experience gained from Dr Toby. Even though I found the others’ research about hands behaviour prediction used MSE loss. It is not suitable for our results because theirs is about the movements while ours is not.\n\n# Jun 9th\n\n## Label noise.\n\n### Objectives:\n\nto figure out if labels format it self may affect the model performance. Because some models only accept data in one kind of format. \n\n**question**: how to determine numbers of hidden layers in LSTM RNN.\n\n### Results:\n\nWe cannot correctly compare each label when we are using **one-hot format**. If the labels you predict are apples, bananas, and strawberries, obviously they do not directly have a comparison relationship. If we use 1, 2, 3 as labels, there will be a comparison relationship between the labels. Distances are different. With the comparison relationship, the distance between the first label and the last label is too far, which affects the learning of the model.\n\nOne promotion:\n\n> Knowledge distillation (KD) improves performance precisely by suppressing this label nosie. Based on this understanding, we introduce a particularly simple improvement method of knowledge disillation, which can significantly improve the performance of ordinary KD by setting different temperatures for each image. \n>\n> Xu, K., Rui, L., Li, Y., Gu, L. (2020). *Feature Normalized Knowledge Distillation for Image Classification.* In: Vedaldi, A., Bischof, H., Brox, T., Frahm, JM. (eds) Computer Vision – ECCV 2020. ECCV 2020. Lecture Notes in Computer Science(), vol 12370. Springer, Cham. https://doi.org/10.1007/978-3-030-58595-2_40\n\n**Hidden layers in LSTM RNN**\n\nThe effect of the number of hidden layers for neural networks\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202206120108575.jpeg)\n\n# Jun 10th\n\ntry `CrossEntropyLoss()` with onehot format data\n\nconvert the labels from “every 2 in 0 to 28” to “every 1 in 1 to 14”\n\n```python\ny_train = (y_train / 2) - 1\ny_test = (y_test / 2) - 1\n```\n\nuse `  with torch.autocast('cuda')` to solve “cuda error” of `CrossEntropyLoss()`\n\n```python\nwith torch.autocast('cuda'):\n        # loss = criterion(outputs, torch.tensor(labels).cuda())\n            loss = criterion(outputs, labels)\n```\n\n# Jun 12th\n\neven though the accuracy of prediction for train data increases quickly as training, the accuracy for test data is still very low. It seems the validation loss does not converge. I decide the next step is going to do more literature research and adjust the parameters.\n\n# Jun 13th\n\n### Problems:\n\nthe problem is overfitting. There could be 2 alternative options: 1, get more data; 2, try different learning rate or dynamic learning rate.\n\nthe way the train-test split worked wasn't ideal in the data loading function - because the data wasn't shuffled prior to splitting, the train and test set would often consist of different subjects if we load multiple subjects. The data can be shuffled before splitting (by setting shuffle=True), which means that there will be a mix of subjects in both the training and testing data. This seems to boost accuracy in the test set a little bit.\n\n# Jun 14th\n\n### Objective:\n\nto try `CosineEmbeddingLoss()` because it is reported that cosine loss may improve the performance for small dataset\n\n> Cosine loss could have better performance for small dataset (around 30%). \n>\n> Barz, B., & Denzler, J. (2019). Deep Learning on Small Datasets without Pre-Training using Cosine Loss. *Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020*, 1360–1369. https://doi.org/10.48550/arxiv.1901.09054\n\n### Results:\n\nhowever, the performance is not promoted\n\n# Jun 15th\n\n## Fourth session meeting\n\nI read others work, practice to extract the key words and main ideas:\n\n> *Affective modulation of the startle response in depression: Influence of the severity of depression, anhedonia and anxiety*\n\nstartle reflex (SR)\n\n1. affective rating\n\n​\tget affective rating after participants watched every clips \n\n​\tand analysis the difference between depressed patients and control.\n\n2. Startle amplitude\n\n3. EMG\n\n   higher baseline EMG activity during pleasant and unpleasant clips, relative to the neutral clips\n\n**Conclusion**\n\na reduced degree of self-reported mood modulation \n\n**Gap**\n\nThe findings differ from those of Allen et al. (1999): they think it does not matter for depression or anhedonia for affective and emotional modulation.\n\n**key wards**\n\nDepression\n\nAnxiety\n\nAnhedonia\n\nAffective modulation\n\nMood regulation\n\nStartle response\n\nEMG\n\naffective rating\n\n## Ninth meeting\n\n### Problems:\n\nSince the past work does not give a good result and it has been nearly halfway of the project. My following work is suggested to be focused on:\n\n1. Multilayer Perceptron\n\n2. transfer learning\n\n# Jun 16th\n\n>  **Convolutional Layer** : Consider a convolutional layer which takes “l” feature maps as the input and has “k” feature maps as output. The filter size is “**n\\*m**”.\n> Here the input has ***l=32\\*** feature maps as inputs, ***k=64\\*** feature maps as outputs and filter size is ***n=3 and m=3\\***. It is important to understand, that we don’t simply have a 3*3 filter, but actually, we have **3\\*3\\*32** filter, as our input has 32 dimensions. And as an output from first conv layer, we learn 64 different **3\\*3\\*32** filters which total weights is “**n\\*m\\*k\\*l**”. Then there is a term called bias for each feature map. So, the total number of parameters are “**(n\\*m\\*l+1)\\*k**”.\n>\n> https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\n\nbicubic interpolation: torch.nn.functional.interpolate() with mode='bicubic' \n\n> https://stackoverflow.com/questions/54083474/bicubic-interpolation-in-pytorch\n\nMeeting these data and fitting problems, I realize the insufficiency of understanding data itself, so I look back to the Machine Learning courses materials from 2 years ago, trying to get some new approaches.\n\nWhen reading the Chapter 1 of *Computational Modelling of Cognition and Behaviour*, I get the following points: \n\n> 1. Data never speak for themselves but require a model to be understood and to be explained.\n> 2. Verbal theorizing alone ultimately cannot replace for quantitative analysis.\n> 3. There are always several alternative models that vie for explanation of data and we must select among them.\n> 4. Model selection rests on both quantitative evaluation and intellectual and scholarly judgment.\n\n# June 21th\n\nHave a meeting with Eammon, we talked about my recent work:\n\nEammon gives me a suggestion: in behaviour level, picture of faces are different. Try and see what if we get rid of the picture of faces in labels.\n\nHere are the pictures shown to participants: \n\n![image-20220722184848108](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221848253.png)\n\n# June 25th\n\nto try Mnet (was used to predict the Alzheimer's disease by Aoe .etc)\n\n> Aoe, J., Fukuma, R., Yanagisawa, T. *et al.* Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. *Sci Rep* **9,** 5057 (2019). https://doi.org/10.1038/s41598-019-41500-xz\n\nScore method:\n\nAs an alternative option, the accuracy can be expressed as root mean square error. \n\n# Jun 27th\n\n### Objective:\n\nto apply data augmentation because it was reported that relative power spectrum provide extra information which may improve model’s performance on MEG data.\n\n### Result:\n\none possible solution is to extract band power to augment the data\n\n> “This model was implemented to check the proprieties of the RPS to extract meaningful features from the input data. The RPS was combined with an MLP to add nonlinearity and increase the capability of approximate the target variable.”\n>\n> The RPS was implemented in 4 steps: \n>\n> 1. Compute the modified periodogram using Welch methods (Welch 1967) to get the power spectral density. \n> 2. Calculate the average band power approximating using the composite Simpson’s rule to get it for a specific target band. \n> 3. Divide the average band power of the specific target band by the total power of the signal to get the relative power spectrum.\n\n> Anelli, M. (2020). *Using Deep learning to predict continuous hand kinematics from Magnetoencephalographic (MEG) measurements of electromagnetic brain activity* (Doctoral dissertation, ETSI_Informatica).\n\n```python\nX_train_bp = np.squeeze(X_train_numpy, axis=1)\n# X_train_bp = X_train_bp[: :, :, :]\nX_train_bp = standard_scaling_sklearn(X_train_bp)\nX_test_bp = np.squeeze(X_test_numpy, axis=1)\n# X_train_bp = X_train_bp[: :, :, :]\nX_test_bp = standard_scaling_sklearn(X_test_bp)\nbands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\nbp_train = bandpower_multi_bands(X_train_bp, fs=800.0, bands=bands, relative=True)\nbp_test = bandpower_multi_bands(X_test_bp, fs=800.0, bands=bands, relative=True)\nbp_train_tensor = torch.Tensor(bp_train).cuda()\nbp_test_tensor = torch.Tensor(bp_test).cuda()\n```\n\n# June 28th\n\n### Problem:\n\nMy Google Colab subscriptions is expired but luckily I have got the access of HPC in KCL (create)\n\n### Solution:\n\nset up cluster as the tutorial: https://docs.er.kcl.ac.uk/CREATE/access/\n\n1. Start an interactive session:\n\n```\nsrun -p gpu --pty -t 6:00:00 --mem=30GB --gres=gpu /bin/bash\n```\n\n**Make a note of the node I am connected to, e.g. erc-hpc-comp001**\n\n`sinfo avail` to check the available cores\n\n2. start Jupyter lab without the display on a specific port (here this is port 9998)\n\n```\njupyter lab --no-browser --port=9998 --ip=\"*\"\n```\n\n3. **Open a separate connection** to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)\n\n```\nssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk\" -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk\n```\n\n- Note:\n  - k12345678 should be replaced with your username.\n  - erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running\n  - 9998 should be replaced with the port you specified when running Jupyter lab (using e.g. `--port=9998`)\n  - authorize via https://portal.er.kcl.ac.uk/mfa/\n\n4. Start notebook in http://localhost:9998/lab\n\n5. VS code part: set the Jupyter server as remote :\n\n   ```\n   http://localhost:9998/lab?token=XXX\n   # replace the localhost as erc-hpc-comp031\n   ```\n\n   Note: However, After the latest weekly update, existing problem has been found is the connection via VS code is not stable. Reason could be the dynamic allocated node and port confuses the VS code connection server.\n\n# June 29th\n\n### Objective:\n\nto try different normalization method: **Z-Score Normalization**\n\n### Results:\n\nwhich maps the raw data to a distribution with mean 0 and standard deviation \n\n1. Assuming that the mean of the original feature is μ and the variance is σ , the formula is as follows:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221914685.png)\n\n# July 1th\n\n### Objective:\n\nto try Mnet with band power (RPS Ment); the reason for splitting alpha into low and high is that kinematic show that alpha band significant after movement and beta before movement. It is also reported that gamma band is associated with it is related to synergistic muscle activation (Kolasinski et. al, 2019)\n\n> Kolasinski, J., Dima, D. C., Mehler, D. M. A., Stephenson, A., Valadan, S., Kusmia, S., & Rossiter, H. E. (2019). Spatially and temporally distinct encoding of muscle and kinematic information in rostral and caudal primary motor cortex. *BioRxiv*, 613323. https://doi.org/10.1101/613323\n\n### Results:\n\nextract band powers to get a 6 RPS (relative power spectrum) for each frequency period:\n\n```python\ndef bandpower_1d(data, sf, band, nperseg=800, relative=False):\n\n    # band = np.asarray(band)\n    low, high = band\n\n    # Compute the modified periodogram (Welch)\n    # TODO: generalize freq values\n    psd, freqs = psd_array_welch(data, sf, 1., 70., n_per_seg=int(800 / 2),\n                                 n_overlap=0, n_jobs=1)\n\n    # Frequency resolution\n    freq_res = freqs[1] - freqs[0]\n\n    # Find closest indices of band in frequency vector\n    idx_band = np.logical_and(freqs >= low, freqs <= high)\n\n    # Integral approximation of the spectrum using Simpson's rule.\n    bp = simps(psd[idx_band], dx=freq_res)\n\n    if relative:\n        bp /= simps(psd, dx=freq_res)\n    return bp\n\ndef bandpower(x, fs, bands, nperseg=800, relative=True):\n\n    psd, freqs = psd_array_welch(x, fs, 1., 70., n_per_seg=int(fs/2),\n                                 n_overlap=0, n_jobs=1)\n    # Frequency resolution\n    freq_res = freqs[1] - freqs[0]\n    n_channel, _ = x.shape\n    bp = np.zeros((n_channel, len(bands)))\n    for idx, band in enumerate(bands):\n        low, high = band\n        # Find closest indices of band in frequency vector\n        idx_band = np.logical_and(freqs >= low, freqs <= high)\n\n        # Integral approximation of the spectrum using Simpson's rule.\n        _bp = simps(psd[..., idx_band], dx=freq_res, axis=-1)\n\n        if relative:\n            _bp /= simps(psd, dx=freq_res, axis=-1)\n        \n        # print(bp.shape, _bp.shape) #272,6  80,272\n        bp[:, idx] = _bp\n\n    return bp\n\ndef bandpower_multi_bands(x, fs, bands,  nperseg=800, relative=True):\n    \n    n_epoch, n_channel, _ = x.shape\n    bp = np.zeros((n_epoch, n_channel, len(bands)))\n    for e in range(n_epoch):\n        bp[e] = bandpower(x[e], fs, bands, nperseg=nperseg, relative=relative)\n\n    return bp\n\ndef standard_scaling_sklearn(data):\n    \n    n_epoch = data.shape[0]\n    for e in range(n_epoch):\n        scaler = skScaler()\n        data[e, ...] = scaler.fit_transform(data[e, ...])\n\n    return data\n```\n\nIn main code:\n\n````python\nX = np.swapaxes(X_train, 2, -1).squeeze()\ndata = X[X.shape[0]-1, 70, :]\npsd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n                          n_overlap=0, n_jobs=1)\nfor low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n                  (30, 70)]:\n    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n    # Find intersecting values in frequency vector\n    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n      # Frequency resolution\n    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n\n    # Compute the absolute power by approximating the area under the curve\n    power = simps(psd_mne[idx_delta], dx=freq_res)\n    print('Absolute power: {:.4f} uV^2'.format(power))\n    \n    total_power = simps(psd_mne, dx=freq_res)\n    rel_power = power / total_power\n    \n    print('Relative power: {:.4f}'.format(rel_power))\n    \n```\nOutputs:\nEffective window size : 1.024 (s)\nprocessing bands (low, high) : (1,4)\nAbsolute power: 0.0610 uV^2\nRelative power: 0.1251\nprocessing bands (low, high) : (4,8)\nAbsolute power: 0.0315 uV^2\nRelative power: 0.0647\nprocessing bands (low, high) : (8,10)\nAbsolute power: 0.0220 uV^2\nRelative power: 0.0452\nprocessing bands (low, high) : (10,13)\nAbsolute power: 0.0031 uV^2\nRelative power: 0.0064\nprocessing bands (low, high) : (13,30)\nAbsolute power: 0.0577 uV^2\nRelative power: 0.1184\nprocessing bands (low, high) : (30,70)\nAbsolute power: 0.2356 uV^2\nRelative power: 0.4837\n```\n````\n\nThe average power spectrum for all subjects:\n\n![image-20220817205940319](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172059472.png)\n\nThe results show that beta and delta waves are in the large and major proportion. It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.\n\n> Baumeister, J., Barthel, T., Geiss, K. R., & Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. *Http://Dx.Doi.Org/10.1179/147683008X301478*, *11*(3), 103–110. https://doi.org/10.1179/147683008X301478\n\n### Problems:\n\nfind the initial loss is too huge and does not change afterwards. Guess it is because of too large initial loss or wrongly `loss.backward()`\n\n### solution:\n\nparameters of optimizer was set wrongly, fix it with `model.parameters()`\n\n# July 2th\n\n### Problems:\n\nlooking for solution to merge the function\n\nguess I am meeting “dying ReLU” problem\n\n# July 5th\n\n### Objectives:\n\nto try dynamic learning rate and interpolate 130 time points to be 800 time points without losing too much information.\n\n### Solution:\n\n```python\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')\n\nscheduler.step(acc[-1]) #at last of each epoch training \n```\n\nthe update step: I use the dynamic learning rate when the valid loss approaches a plateau (function 4, where ![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102154.gif) represents learning decay and L represents valid loss). \n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102153.gif)\n\nMultilayer perceptron\n\ninterpolate https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html\n\nLearning rate scheduling https://pytorch.org/docs/stable/optim.html\n\n# July 9th\n\nIn order to make the input data the same shape as required, I use resample function `localiser_epochs.copy().resample(800, npad='auto')` to upsamle the data\n\nCBAM modules are added because the attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images’ edges. \n\n> Attention in Deep Learning, Alex Smola and Aston Zhang, Amazon Web Services (AWS), ICML 2019\n\n```python\nclass SpatialAttention(nn.Module):\n    def __init__(self):\n        super(SpatialAttention, self).__init__()\n        self.compress = ChannelPool()\n        self.spatialAttention = nn.Sequential(\n            nn.Conv2d(2, 1, 7, 7, padding=3), #padding = (7-1)/2\n            )\n\n    def forward(self, x):\n        # print('x',x.shape)\n        x = self.compress(x)\n        x = self.spatialAttention(x)\n        # scale = F.sigmoid(x)\n        scale = torch.sigmoid(x)\n        \n        return x * scale\n    \nclass Flatten_MEG(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n    \nclass ChannelAttention(nn.Module):\n    \"\"\"\n            Implementation of a channel attention module.\n        \"\"\"\n    class Showsize(nn.Module):\n        def __init__(self):\n            super(ChannelAttention.Showsize, self).__init__()\n        def forward(self, x):\n            # print(x.shape)\n            return x\n\n    def __init__(self, shape, reduction_factor=16):\n\n        super(ChannelAttention, self).__init__()\n\n        _, in_channel, h, w = shape\n        self.mlp = nn.Sequential(\n            # self.Showsize(),\n            Flatten_MEG(),\n            # self.Showsize(),\n            nn.Linear(in_channel, in_channel // reduction_factor),\n            nn.ReLU(),\n            nn.Linear(in_channel // reduction_factor, in_channel),\n        )\n\n    def forward(self, x):\n        avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n        max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n        sum = self.mlp(avg_pool) + self.mlp(max_pool)\n        scale = (\n            torch.sigmoid(sum)\n            .unsqueeze(2)\n            .unsqueeze(3)\n            .expand_as(x)\n        )\n\n        return x * scale\n```\n\n# July 10th\n\nIn order to find the rationality of extracting features of brain states under different stimuli. I draw the topographical maps of all stimuli at different time. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, my model is an effective and reasonable approach to classifying these states.\n\n```python\nsti=[1,2,3,4,5,6,7,8,9,10,11,12,13,14]                     \nfor stimuli in range (1,15):\n    epochs_standard = fname.get_epochs(sub=1)\n    for sub in [sub for sub in range (2,29) if sub not in [6, 12, 14 ,23]]:\n        if sub == 1:\n            epochs_standard = fname.get_epochs(sub=1)\n        else:\n            epochs = fname.get_epochs(sub)['stimulus_{}'.format(2*stimuli)]\n            epochs.info['dev_head_t'] = epochs_standard.info['dev_head_t']\n            epochs_standard = mne.concatenate_epochs([epochs_standard['stimulus_{}'.format(2*stimuli)], epochs['stimulus_{}'.format(2*stimuli)]])\n    exec('evoked_{} = epochs_standard.average()'.format(stimuli))\n        # evoked_standard = mne.concatenate_epochs([evoked_standard, evoked])\n\n```\n\n![image-20220817205119443](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172051592.png)\n\nbrain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity.\n\n# July 12th\n\nThe random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of my model is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. Compared with the other classification approach, my model exhibits the best classification performance (p = 6.8 × 10 –2 for LSTM RNN, p = 5.9 × 10 –2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of my model is able to reach 33.33%. \n\n![image-20220817205549898](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172055038.png)\n\nearly stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting:\n\n```python\nclass EarlyStopping:\n\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score <= self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n            \n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.4f} --> {val_loss:.4f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n```\n\nHowever, would early stopping necessarily prevent overfitting? There’s some interesting work showing that if you over-train the model it actually suddenly gets a lot better at some point (an approach referred to as “grokking” for some reason). It may be possible that more training doesn’t necessarily mean worse performance.\n\n# July 13th\n\nI want to visualize my model and data process steps.\n\nFirst save the model as .onnx file:\n\n```python\nx = torch.randn(64, 1, 272, 800).requires_grad_(True).cuda() \ntorch_out = rpsmnet(x)\n\n# Export the model\ntorch.onnx.export(rpsmnet,               # model being run\n                  x,                         # model input (or a tuple for multiple inputs)\n                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n                  export_params=True,        # store the trained parameter weights inside the model file\n                  opset_version=10,          # the ONNX version to export the model to\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\n                  input_names = ['input'],   # the model's input names\n                  output_names = ['output'], # the model's output names\n)\n```\n\nAnd I generate the flow chat of this model with Netron:\n\n![image-20220817210610588](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172106759.png)\n\nDetailed configuration of my model. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply\n\nThe steps data are processed is generated with following code: \n\n```python\nimport hiddenlayer as hl\n\ntransforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n\ngraph = hl.build_graph(rpsmnet, torch.zeros(64,1,272,800).cuda())\ngraph.theme = hl.graph.THEMES['blue'].copy()\ngraph.save('ASRCnet_hiddenlayer', format='png')\n\nfrom torchviz import make_dot\nx = torch.randn(64, 1, 272, 800).requires_grad_(True).cuda() # 定义一个网络的输入值\ny = rpsmnet(x)    # 获取网络的预测值\n# y = y.cuda()\nMyConvNetVis = make_dot(y)#, params=dict(list(rpsmnet.named_parameters()) + [('x', x)]))\nMyConvNetVis.format = \"png\"\n# 指定文件生成的文件夹\nMyConvNetVis.directory = \"data\"\n# 生成文件\nMyConvNetVis.view()\n```\n\n![image-20220817210806647](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172108920.png)\n\n\n\n# July 15th\n\nI want to visualize the pooling and convolution operations, so I use CAD to draw the illustrations:\n\nAs shown in figure A, a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure B) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well \n\n![image-20220817211402695](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172114867.png)\n","source":"_posts/master project.md","raw":"---\ntitle: master project\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-05-16 14:00\npassword:\nsummary:\ntags:\n- project\ncategories:\n- Neuroscience programming\n---\n\n# Table of content \n\n[Toc]\n\n# April 12th\n\n## First meeting \n\n### Objective: \n\nto find out which data we are going to use and which method to analyse it because good understanding of the data can help researching simpler and more accurate. It can also inform me important information about features engineering or neural network designing.\n\n### Results:\n\ndata: https://openneuro.org/datasets/ds003682\n\n28 participants viewing 14 image stimuli \n\nThe file we cares:\n\n![image-20220411140935965](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204111409061.png)\n\nI can use MNE-Python to analyse it because MNE-Python package is highly integrated allowing an easy access to analysing.\n\nWhat these files do can be achieved with:\n\nhttps://mne.tools/stable/generated/mne.read_epochs.html\n\nMore templates can be found in:\n\nhttps://github.com/tobywise/aversive_state_reactivation/blob/master/notebooks/templates/sequenceness_classifier_template.ipynb\n\n# April 13th\n\n## First session meeting \n\n### Objective:\n\nlearn how to write a lab notebook\n\n### Results\n\nGeneral understanding:\n\nTitle: the utility of multi-task machine learning for decoding brain states\n\nTable of Contents:\n\npage numbers; date; title/subject/experiment\n\nGantt charts is good to help organise time.\n\n# April 18th\n\n## Install MNE-Python via pip:\n\n### Objective:\n\nto upgrade environment manager and compiler to the latest stable version because I always tend to use the latest version of packages which is supposed to be more compatible\n\n### Results:\n\nUpdate Anaconda via ` conda upgrade --all` and  `conda install anaconda=2021.10`\n\nThe Python version I am using is:\n\n```\nPython 3.9.12\t\n```\n\nget the data:\n\n`git clone https://github.com/OpenNeuroDatasets/ds003682`\n\nInstall MNE:\n\n`conda install --channel=conda-forge mne-base`\n\n# April 19th\n\n## Second meeting \n\n### Objective: \n\nto have a general understanding of the data and figure out details about methods because these are what I am going to feed into the network so that I should have a clear recognition for each part.\n\n`x_raw`\n\n`x_raw.shape`\n\n`y_raw`\n\n`time = localiser epchoes`\n\n### Results:\n\n#### what I have known:\n\n**scikit-learn** (machine learning library) is an available package I am going to use\n\nuse **PCA** to reduce dimensions \n\n![image-20220419104136746](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204191041843.png)\n\n#### what need to be learned: \n\n##### 1. normalization, regularization\n\nlasso L1 = sets unpredictive features to 0\n\nridge L2 = minimises the weights on unpredictive features\n\nelastic net L1/L2\n\n##### 2. search\n\n`random_search randomizedsearchCV` to test the performance\n\n##### 3. Neural network\n\nneural network can be the best way for logistic leaning \n\n##### 4. validation\t\n\n# April 24th\n\n### Objective:\n\nto play with existing code https://github.com/tobywise/aversive_state_reactivation because it can inform me code grammars analysing MEG data and it will make a foundation for my following coding \n\n### Results:\n\n#### Epochs\n\nExtract signals from continuous EEG signals for specific time windows, which can be called epochs.\n\nBecause EEGs are collected continuously, to analyse EEG event-related potentials requires \"slicing\" the signal into time segments that are locked to time segments within an event (e.g., a stimulus).\n\n#### Data corruption\n\nThe MEG data in the repository https://openneuro.org/datasets/ds003682 is invalid, possibly because of data corruption\n\n**incomplete copying led to corrupted files**\n\nThe following events are an example present in the data: 1, 2, 3, 4, 5, 32\n\n```\nevent_id = {'Auditory/Left': 1, 'Auditory/Right': 2,\n'Visual/Left': 3, 'Visual/Right': 4,\n'smiley': 5, 'button': 32}\n```\n\n`sklearn.cross_validation` has been deprecated since version 1.9, and `sklearn.model_selection` can be used after version 1.9.\n\n# April 25th\n\n## Install scikit-learn (sklearn)\n\nuse the command line \n\n`conda install -c anaconda scikit-learn`\n\nStart the base environment in Anaconda Prompt: `activate base`\n\nAnd install jupyter notebook, numpy and other modules in the environment\n\n```bash\nconda insatll tensorflow\n\nconda install jupyter notebook\n\nconda install scikit-learn\n\nconda install scipy\n```\n\nLearn how to choose the right algorithm \n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n\n![flow chart of scikit](https://scikit-learn.org/stable/_static/ml_map.png)\n\n## Learning sklearn\n\n1. import modules\n\n```python\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n```\n\n2. create data\n\nload `iris` data，store the **attributes** in  `X`，store the **labels** in `y`：\n\n```python\niris = datasets.load_iris()\niris_X = iris.data\niris_y = iris.target\n```\n\nLooking at the dataset, `X` has four attributes, and `y` has three categories: 0, 1, and 2:\n\n```python\nprint(iris_X[:2, :])\nprint(iris_y)\n\n\"\"\"\nOutput:\n[[ 5.1  3.5  1.4  0.2]\n [ 4.9  3.   1.4  0.2]]\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n \"\"\"\n```\n\nDivide the data set into training set and test set, where `test_size=0.3`, that is, the test set accounts for 30% of the total data:\n\n```python\nX_train, X_test, y_train, y_test = train_test_split(\n    iris_X, iris_y, test_size=0.3)\n```\n\nIt can be seen that the separated data sets are also disrupted in order, which is better to train the model:\n\n```python\nprint(y_train)\n\n\"\"\"\nOutputs:\n[2 1 0 1 0 0 1 1 1 1 0 0 1 2 1 1 1 0 2 2 1 1 1 1 0 2 2 0 2 2 2 2 2 0 1 2 2\n 2 2 2 2 0 1 2 2 1 1 1 0 0 1 2 0 1 0 1 0 1 2 2 0 1 2 2 2 1 1 1 1 2 2 2 1 0\n 1 1 0 0 0 2 0 1 0 0 1 2 0 2 2 0 0 2 2 2 1 2 0 0 2 1 2 0 0 1 2]\n \"\"\"\n```\n\n3. Build a model - train - predict\n\nDefine the module method `KNeighborsClassifier()`, use `fit` to train `training data`, this step completes all the steps of training, the latter `knn` is already a trained model, which can be used directly `predict` For the data of the test set, comparing the value predicted by the model with the real value, we can see that the data is roughly simulated, but there is an error, and the prediction will not be completely correct.\n\n```python\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(knn.predict(X_test))\nprint(y_test)\n\n\"\"\"\n[2 0 0 1 2 2 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1\n 0 0 1 0 1 2 0 1]\n[2 0 0 1 2 1 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1\n 0 0 1 0 1 2 0 1]\n \"\"\"\n```\n\nDirectly download the data and store in my computer. However, it is unprofessional to run code in personal computer. I should looking for a way to solve this problem: rent a server or find a HPC cluster in King’s College.\n\n![image-20220425150724894](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204251507965.png)\n\n## Succeed at drawing plot\n\n```python\nimport mne\nimport os\nfrom mne.datasets import sample\nimport matplotlib.pyplot as plt\n\n# The storage path of sample\ndata_path = sample.data_path()\n# The storage path of the fif file\nfname = 'E:\\Proj\\Previous data\\sample\\MEG\\sample\\sub-001_localiser_sub-001_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz'\n\nepochs = mne.read_epochs(fname)\n\nprint(epochs.event_id)\n\npicks = mne.pick_types(epochs.info, meg=True, ref_meg=False, exclude='bads')\n\nepochs.plot(block=True)\n\nepochs.plot_drop_log()\n\nplt.show()\n```\n\n```python\nepochs = mne.read_epochs(fname)\n\nevoked = epochs.average()\nevoked.plot_topomap()\n\nplt.show()\n```\n```python\navailabe_event = [1, 2, 3, 4, 5, 32]\n\nfor i in availabe_event:\n    evoked_i = epochs[i].average(picks=picks)\n    epochs_i = epochs[i]\n    evoked_i.plot(time_unit='s')\n    plt.show()\n\n```\n\nThe panel each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data\n\n![image-20220817193732989](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171937606.png)\n\nTopological map from -500.00 to 790.00 ms. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.\n\n![image-20220817194146606](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171941694.png)\n\n## A few questions at last: \n\n1. why do we split the data as 70%, does it work as other ration?\n\n   Because we have got enough data to train and need more data to test and valid the training performance.\n\n# April 26th\n\n## MRI safety training for 2.5 hrs\n\n## update Anaconda (start to use a new platform)\n\nAnaconda is a good environment manager tool which allows me to manage and deploy packages\n\n`conda update conda`\n\n`conda update anaconda`\n\n`conda update --all`\n\ndone\n\nPython version: 3.8.13-h6244533_0\n\n## change the directory path of Jupyter notebook (in order to save files in preferred path)\n\n1. `jupyter notebook --generate-config` get the config file. change the line `c.NotebookApp.notebook_dir = ''` to the directory I want\n\n2. find jupyter notebook file, change the attributes. ![change the attributes](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204261614733.png)\n\n## Link the local directory and Github\n\nfor the convenience of collaboration \n\nSSH connect public key (id_rsa.pub) was created before.\n\nafter create the directory, run the command in git:\n\n```bash\ngit init\ngit add .\ngit git commit -m  \"Comment\"\ngit remote add origin \"the url of directory\"\ngit push -u origin main\n```\n\n## Journal club preparation for the next session\n\n# April 27th\n\n## Pycharm (use IDE)\n\nGet Pycharm educational version via King’s email\n\ninstall python 3.8 environment for running the code from https://github.com/tobywise/aversive_state_reactivation (because it was coding with python 3.8 compiler)\n\nrun below code in pycharm\n\n```bash\n!conda create -n py38 python=3.8\n!pip install mne\n!pip install scikit-learn\n!pip install plotly\n!pip install cufflinks\n!pip install networkx\n!conda install numba\n!pip install pyyaml\n!pip install papermill\n```\n\n## Fixation for some expired code\n\nThe function `joblib` does not exist in `sklearn.external` anymore.\n\nError occurs when run the function plot_confusion_matrix:\n\nDeprecated since version 1.0: `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the following class methods: `from_predictions` or `from_estimator`.\n\nuse\n\n```python\nConfusionMatrixDisplay.from_predictions(y, y_pred)\n```\n\ninstead of \n\n```python\nplot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title='Normalised confusion matrix, accuracy = {0}'.format(np.round(mean_accuracy, 2)))\n```\n\n## Second session meeting\n\nEvery people gives a general introduction of their projects\n\n# April 28th\n\n## Logistic regression cost function\n\nThe function is using the principle of maximum likelihood estimation to find the parameters $\\theta$ for different models. At the meantime, a nice property is it is convex. So, this cost function is generally everyone use for fitting parameters in logistic regression.![image-20220429010526272](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290105356.png)\n\nThe way we are going to minimize the cost function is using gradient descent:\n\n![image-20220429011210521](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290112574.png)\n\nOther alternative optimization algorithms (no need to manually pick $\\alpha$ studying rate):\n\n1. Conjugate gradient\n2. BFGS\n3. L-BFGS\n\n## Methods to storage trained model\n\nset and train a simple SVC model\n\n```python\nfrom sklearn import svm\nfrom sklearn import datasets\n\nclf = svm.SVC()\niris = datasets.load_iris()\nX, y = iris.data, iris.target\nclf.fit(X,y)\n```\nStorage:\n\n1. pickle\n\n```python\nimport pickle #pickle module\n\n#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)\nwith open('save/clf.pickle', 'wb') as f:\n    pickle.dump(clf, f)\n\n#load Model\nwith open('save/clf.pickle', 'rb') as f:\n    clf2 = pickle.load(f)\n    #test loaded Model\n    print(clf2.predict(X[0:1]))\n```\n\n2. joblib (supposed to be faster when dealing with a large data, because the use of multiprocessing)\n\n```python\nfrom sklearn.externals import joblib #jbolib模块\n\n#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)\njoblib.dump(clf, 'save/clf.pkl')\n\n##load Model\nclf3 = joblib.load('save/clf.pkl')\n\n#test loaded Model\nprint(clf3.predict(X[0:1]))\n\n```\n\n# April 29th\n\n## Google Colab\n\nGet the subscription of Google Colab and Google drive\n\nclone data to google drive\n\nToken: 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\n\nconnect Google Colab with VS code\n\n## Regularization\n\nWe can use **regularization** to rescue the overfitting\n\nThere are two types of regularization:\n\n- **L1 Regularization** (or Lasso Regularization)\n\n  $Min$($$\\sum_{i=1}^{n}{|y_i-w_ix_i|+p\\sum_{i=1}^{n}|w_i|}$$)\n\n- **L2 Regularization** (or Ridge Regularization)\n\n  $Min$($$\\sum_{i=1}^{n}{(y_i-w_ix_i)^2+p\\sum_{i=1}^{n}w_i^2}$$)\n\nwhere `p` is the tuning parameter which decides in what extent we want to penalize the model.\n\nHowever, there is another method for combination\n\n- **Elastic Net:** When L1 and L2 regularization combine together, it becomes the elastic net method, it adds a hyperparameter.\n\nhow to select:\n\n| **No** | **L1 Regularization**                                   | **L2 Regularization**                                        |\n| ------ | ------------------------------------------------------- | ------------------------------------------------------------ |\n| **1**  | Panelises the sum of absolute value of weights.         | Penalises the sum of square weights.                         |\n| **2**  | It has a sparse solution.                               | It has a non-sparse solution.                                |\n| **3**  | It gives multiple solutions.                            | It has only one solution.                                    |\n| **4**  | Constructed in feature selection.                       | No feature selection.                                        |\n| **5**  | Robust to outliers.                                     | Not robust to outliers.                                      |\n| **6**  | It generates simple and interpretable models.           | It gives more accurate predictions when the output variable is the function of whole input variables. |\n| **7**  | Unable to learn complex data patterns.                  | Able to learn complex data patterns.                         |\n| **8**  | Computationally inefficient over non-sparse conditions. | Computationally efficient because of having analytical solutions. |\n\n## Normalization\n\nThe reason for applying normalization is the normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance.\n\n ![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171958842.gif)\n\nwhere m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1\n\n### Question:\n\nwhich layer should I apply the regularization?\n\nFrom the model's summary, I can determine which layers have the most parameters. It is better to apply regularization to the layers with the highest parameters.\n\nIn the above case, how to get each layer’s parameters?\n\n```python\nfrom prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad: continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params+=params\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params\n    \ncount_parameters(model)\n```\n\n# May 2nd\n\n## Question ahead:\n\nget a question: how to determine the classifier centre (windows width)? \n\nfor this case, it is around 20 to be at the middle/ top\n\nGPU accelerations\n\nIt could be a little bit tricky to accelerate the calculation in sklearn with GPU. Here is a possible solution: https://developer.nvidia.com/blog/scikit-learn-tutorial-beginners-guide-to-gpu-accelerating-ml-pipelines/.  \n\n## Third meeting:\n\nDeep learning might be the solution for MEG signals classification. \n\nThe CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018)\n\n> Khan, S., Rahmani, H., Shah, S. A. A., & Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. *A Guide to Convolutional Neural Networks for Computer Vision*. https://doi.org/10.1007/978-3-031-01821-3\n>\n> Valueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., & Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. *Mathematics and Computers in Simulation*, *177*, 232–243. https://doi.org/10.1016/J.MATCOM.2020.04.031\n>\n> Bai, S., Kolter, J. Z., & Koltun, V. (2018). *An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling*. https://doi.org/10.48550/arxiv.1803.01271\n\npossible deep learning packages:\n\nJAX, HAIKU\n\nMy aim is to inform bad-performance data with the training model of good-performance data in aims to increase the performance. One hallmark is to increase the mean accuracy of each cases as high as possible.\n\n# May 3rd\n\nSuccessfully run the code for confusion matrix.\n\n```python\nclf.set_params(**random_search.best_params_)\n\n# Get predictions with 5 fold CV\ny_pred = cross_val_predict(clf, X, y, cv=confusion_matrix_cv)\nmean_conf_mat = confusion_matrix(y, y_pred)\nmean_accuracy = accuracy_score(y[y != 99], y_pred[y != 99])\nmean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n\nprint(\"Mean accuracy = {0}\".format(mean_accuracy))\n    \n# Plot mean confusion matrix\n#plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title='Normalised confusion matrix, accuracy = {0}'.format(np.round(mean_accuracy, 2)))\n#plt.imshow(mean_conf_mat[:n_stim, :n_stim])\n\nConfusionMatrixDisplay.from_predictions(y, y_pred)\nplt.savefig('./save_folder/fig-{}.png'.format(session_id), dpi=600)\nplt.show()\n```\n\npictures of each case are stored in the Github depository: \n\nhttps://github.com/ReveRoyl/MT_ML_Decoding/tree/main/Aversive_state_reactivation/notebooks/templates/save_folder\n\nIt takes around 36 minutes to run 28 cases. \n\nMean accuracy with existing code:\n\n```python\n[0.4288888888888889, 0.33666666666666667, 0.2777777777777778, 0.5022222222222222, 0.5066666666666667, 0.4245810055865922, 0.5577777777777778, 0.43222222222222223, 0.65, 0.47888888888888886, 0.3377777777777778, 0.4800469483568075, 0.27111111111111114, 0.37193763919821826, 0.4288888888888889, 0.40555555555555556, 0.46444444444444444, 0.7077777777777777, 0.5811111111111111, 0.4711111111111111, 0.4255555555555556, 0.5022222222222222, 0.45394006659267483, 0.38555555555555554, 0.6222222222222222, 0.4622222222222222, 0.35444444444444445, 0.47444444444444445]\n```\n# May 10th\n\nGet rid of the effect of null data\n\ntransform X into the same size as clf\n\n# May 11th\n\n## Grid Search CV\n\nTo test Grid Search CV instead of Randomized Search CV\n\nHowever, the result of grid search CV is worse than the randomized search CV. I think the reason is that random search CV uses a random combination of hyperparameters to find the best solution for a built model. However, the random search CV is not 100% better than grid search CV: the disadvantage of random search is that it produces high variance during computation.\n\n## Concatenation\n\n### Objective\n\nSince my aim is to transfer the model prediction of one case to anther, I try to concatenate multiple cases data together to train the model and see what will happen.\n\n```python\nlocaliser_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{}', 'localiser', 'sub-{}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format('001','001')) \n\nfor session_id_int in range(2, 3):\n    session_id = '{:03d}'.format(session_id_int)\n    print(session_id)\n    \n    localiser_epochs_unconcatenate = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{}', 'localiser', 'sub-{}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id,session_id))  \n    localiser_epochs_unconcatenate.info = localiser_epochs.info\n    localiser_epochs = mne.concatenate_epochs([localiser_epochs, localiser_epochs_unconcatenate]) \n\n```\n\n### Result\n\nConcatenate X np arrays and test, the mean accuracy increases. I test 5 cases.\n\nMean accuracy = 0.5111111111111111, while for each cases, previous mean accuracy = 0.43777777777777777; 0.34; 0.2788888888888889; 0.5055555555555555.\n\n![img](data:image/png;base64,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)\n\n![img](data:image/png;base64,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)\n\n![img](data:image/png;base64,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)\n\n![img](data:image/png;base64,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)\n\nThe concatenated data gives a better fit:\n\n![output](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205121731546.png)\n\nHowever, the generalization ability of this method has not been decided yet till now.\n\n# May 12th\n\nadd ‘participant number’ dimension to X\n\n```python\nX_4D = []\nfor session_id_int in range(1, 2):\n    session_id = '{:03d}'.format(session_id_int)\n    print(session_id)\n    # Get data\n    localiser_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{}', 'localiser', 'sub-{}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id,session_id))  \n    \n    X_raw = localiser_epochs.get_data()\n    \n    picks_meg = mne.pick_types(localiser_epochs.info, meg=True, ref_meg=False)\n    event_selector = (y_raw < n_stim * 2 + 1)\n    X_raw = X_raw[event_selector, ...]\n    X_raw = X_raw[:, picks_meg, :]\n    X = X_raw.copy()\n    X = X[..., classifier_center_idx + classifier_window[0]:classifier_center_idx + classifier_window[1]] \n\n    X_4D.append(X)\n# for epoch in localiser_epochs_concatenate:\n#     print(epoch.shape)\n# localiser_epochs = mne.concatenate_epochs(localiser_epochs_concatenate)\nX = np.stack(X_4D)\n```\n\nIt takes me 1 hour to make the code logical elegant.\n\n# May 13th\n\n## Forth meeting\n\n### Objective:\n\nWe have tested existing code, the following step is to try different models to predict.\n\nMy supervisor’s suggestion is to use haiku trying CNN.\n\n```\npip install -upgrade jax optax dm-haiku \n```\n\nto be learnt: \n\nactive function: rectifier RELU\n\n### Result:\n\nNew model selection: CNN with Haiku\n\n# May 14th\n\nFind a  bug: concatenated data was not giving a correct result. The better performance was because of the randomness of every time training. The concatenated data won’t give a better prediction. \n\npossible solution: transfer learning instead of directly concatenation.\n\n# May 16th\n\n### Objective\n\nto learning deep learning courses (Andrew Ng) in coursera because as said in ‘Knife don't miss your job’, to solid the foundation of deep learning will help me build the CNN and understand others’ work\n\n### Result:\n\nIn the context of artificial neural networks, the rectifier or ReLU (Rectified Linear Unit) activation function is an activation function defined as the positive part of its argument.\n\n#### Convolution\n\nTypes of layer in a CNN:\n\n- Covolution\n- Pooling\n- Fully connected \n\nCases:\n\nClassic networks: \n\n- LeNet-5\n- AlexNet\n- VGG\n\nResNet\n\nInception\n\nLeNet -5 \n\n# May 17th\n\n## Learning JAX\n\n**Question: why jax has its own numpy type: jax.numpy? what is the difference between it and numpy?**\n\nJax.numpy is a little bit different from numpy: the former is immutable\n\n**Question: why do we need jax.numpy?** \n\nbecause numpy only works on CPU while jax.numpy works on GPU\n\n**another advantage of JAX**\n\n`jit()` can be used to compile the data input thus makes the program run faster\n\n## First group meeting\n\nYiqi introduced his recent work which is based on U-net, VAE\n\n# May 18th\n\n## Learning JAX\n\n```python\ngrad() # for differentation\nfrom jax import jacfwd, jacrev # for Jacobian matrix\nvmap() # for vectorization; it can makes you write your functions as if you were dealing wiht a single datapoint\n```\n\nJAX API structure\n\n- NumPy <-> lax <-> XLA\n- lax API is stricter and more powerful\n- It's a Python wrapper around XLA\n\n![nn](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221751704.svg)\n\n```python\nclass CNN(hk.Module):\n    def __init__(self):\n        super().__init__(name=\"CNN\")\n        # self.conv1 = hk.Conv2D(output_channels=32, kernel_shape=(3,3), padding=\"SAME\")\n        # self.conv2 = hk.Conv2D(output_channels=16, kernel_shape=(3,3), padding=\"SAME\")\n        self.conv1 = hk.Conv2D(output_channels=64, kernel_shape=(11,11), stride=4, padding=\"SAME\")\n        self.conv2 = hk.Conv2D(output_channels=192, kernel_shape=(5,5), padding=\"SAME\")\n        self.conv3 = hk.Conv2D(output_channels=384, kernel_shape=(3,3), padding=\"SAME\")\n        self.conv4 = hk.Conv2D(output_channels=256, kernel_shape=(3,3), padding=\"SAME\")\n        self.conv5 = hk.Conv2D(output_channels=256, kernel_shape=(3,3), padding=\"SAME\")\n        self.flatten = hk.Flatten()\n        self.linear = hk.Linear(len(classes))\n\n    def __call__(self, x_batch):\n        x = self.conv1(x_batch)\n        x = jax.nn.relu(x)\n        x = hk.MaxPool(window_shape=(3, 3), strides=(2, 2), padding='VALID')(x)\n        x = self.conv2(x)\n        x = jax.nn.relu(x)\n        x = hk.MaxPool(window_shape=(3, 3), strides=(2, 2), padding='VALID')(x)        \n        x = self.conv3(x_batch)\n        x = jax.nn.relu(x)\n        x = self.conv4(x_batch)\n        x = jax.nn.relu(x)\n        x = self.conv5(x_batch)\n        x = jax.nn.relu(x)\n        x = hk.MaxPool(window_shape=(3, 3), strides=2, padding='VALID')(x)\n        # x = hk.AvgPool(window_shape=(6, 6), strides=(2, 2), padding='SAME')(x)\n        \n        x = self.flatten(x)\n        x = self.linear(x)\n        x = jax.nn.softmax(x)\n        return x\n```\n\n# May 19th\n\n## Test CNN\n\nCNN test was run but the prediction result is not as good as expected: \n\nthe performance of it is about 0.4 for training dataset and 0.15 for test dataset. \n\nI think we should try to tune the parameters of model or test a different model since the current model is suitable for image recognition. Before that, literature reviews should be done. \n\nLater after I read Aoe’s work, I start to under stand it is because my image classification CNN model fails to extract the temporal and spatial information. \n\n> Aoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., & Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. *Scientific Reports*, *9*(1). https://doi.org/10.1038/S41598-019-41500-X\n\n## Fifth meeting\n\nI have the requirement of visualization during training: \n\nTo use Tensor Board to show the training process\n\n```python\n!rm -rf /logs/ # clear logs\n# if 'google.colab' in str(get_ipython()): # tensor board\n%load_ext tensorboard  \n# %tensorboard --logdir logs\n%tensorboard --logdir=./models/test\n```\n\n# May 20th\n\n## Tried AlexNet (can be easily get from Pytorch hub)\n\nAlexNet\n\n```python\nAlexNet  = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True).cuda()\n```\n\nResnet 18\n\n```python\nResnet   = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).cuda()\n```\n\nThese 2 models fail as well. The same reason: these models fail to extract the temporal and spatial information in the first convolutional layers.\n\n![image-20220722175851266](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221758352.png)\n\n\n\n## Sixth meeting\n\n### Objective:\n\nto discuss about that if we should use concatenate data and pre-processing for standardization because the conditions of recording may varies a lot among different subjects: the device position or potential individual reasons.\n\n### Results:\n\nDr. Toby and I had a discussion together with Dr. Rossalin \n\nRossalin advices me to try transfer learning or LSTM.\n\nAfter trying the model is usually used in image classification, it is a good idea to try the model LSTM RNN, which is known as a good fit for sequential data.\n\n# May 24th\n\n## Second group meeting\n\nZarc gives a presentation about his NLP project.\n\n# May 27th\n\n## Learning Tensorflow\n\nTensorflow is a more popular packages which allows me to get access to many templates. Some research is also using Tensorflow as their machine learning library. But I found Pytorch is a more popular packages which allows me to get access to more well-known templates. Most related research is using Pytorch as their machine learning library.\n\nHowever, I found the variable and  placeholder operations are more commonly used in Tensorflow-v1 rather than the latest  Tensorflow-v1\n\n### Session control\n\nIn Tensorflow, a string is defined as a variable, and it is a variable, which is different from Python. (later on I found it was correct in Tensorflow v1 but changes in Tensorflow v2)\n\n `state = tf.Variable()`\n\n```python\nimport tensorflow as tf\n\nstate = tf.Variable(0, name='counter')\n\n# define variable one\none = tf.constant(1)\n\n# define plus step (hint: no computation here)\nnew_value = tf.add(state, one)\n\n# update State to new_value\nupdate = tf.assign(state, new_value)\n```\n\nIf I set variables in Tensorflow, initializing the variables is the most important thing! ! So after defining the variable, be sure to define `init = tf.initialize_all_variables()`.\n\nAt this point, the variable is still not activated, and it needs to be added in `sess` , `sess.run(init)` , to activate`init`. (again, it changes in v2, we do not need to initialize the session in Tensorflow v2)\n\n```Python\n# Variable, initialize\n# init = tf.initialize_all_variables() # expired\ninit = tf.global_variables_initializer()  \n \n# Session\nwith tf.Session() as sess:\n    sess.run(init)\n    for _ in range(3):\n        sess.run(update)\n        print(sess.run(state))\n\n```\n\nNote: directly `print(state)` does not work! !\n\nBe sure to point the `sess` pointer to `state` and then `print` to get the desired result!\n\n### placeholder\n\n`placeholder` is a placeholder in Tensorflow that temporarily stores variables.\n\nIf Tensorflow wants to pass in data from the outside, it needs to use `tf.placeholder()`, and then transfer the data in this form `sess.run(***, feed_dict={input: **})`.\n\nExamoles：\n\n```\nimport tensorflow as tf\n\n# Tensorflow requires defining placeholder's type, usually float32\ninput1 = tf.placeholder(tf.float32)\ninput2 = tf.placeholder(tf.float32)\n\n# multiply input1 and input2\nouput = tf.multiply(input1, input2)\n```\n\nNext, the work of passing the value is handed over to `sess.run()`, the value that needs to be passed in is placed in `feed_dict={}` and corresponds to each `input` one by one. `placeholder` and `feed_dict={ }` are bound together.\n\n```\nwith tf.Session() as sess:\n    print(sess.run(ouput, feed_dict={input1: [7.], input2: [2.]}))\n# [ 14.]\n```\n\n### Activation function\n\nwhen there are many layers, be careful to use activation function in case of the **gradient exploding or gradient disappearance**.\n\n# May 28th\n\n> Although in the computer vision field convolutional layer often followed by a pooling layer to reduce the data dimension at the expense of information loss, in the scenes of MEG decoding, the size of MEG data is much smaller than the computer vision field. So in order to keep all the information, we don’t use the pooling layer. After the spatial convolutional layer, we use two layers of temporal convolutional layers to extract temporal features, a fully connected layer with dropout operation for feature fusion, and a softmax layer for final classification. (Huang2019)\n\nIt is important to select if we should use pooling layers and how many to use.\n\n# May 30th\n\n## ML optimizer\n\n### Objective:\n\nto learn how to use and select different optimizer, because it modifies model’s parameters like weights and learning rate, which helps to increase accuracy and reduce overall loss.\n\n### Results:\n\n- Stochastic Gradient Descent (SGD)\n- Momentum\n- AdaGrad\n- RMSProp\n- Adam\n\n![speedup3](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205302233928.png)\n\nX.shape gives (n_epochs, n_channels, n_times) corresponding to (batches, pixels,channels)  of images\n\nApart for optimizer, scheduler may help a lot with providing a dynamic learning rate.\n\n### impression\n\nAs I tried to apply regularization at the same time. It is important to bear in mind, if we give a momentum in SGD (about 0.9), we can easily apply L2 regularization when the weight_decay is larger than 0.\n\n# May 31st\n\n### Objective:\n\nto learn data augmentation and learn a important rule: “No free lunch theorem”\n\n### Results:\n\nD. H. Wolpert et. al. (1995) come up with “No free lunch theorem”: all optimization algorithms perform equally well when their performance is averaged across all possible problems.\n\nFor any prediction function, if it performs well on some training samples, it must perform poorly on other training samples. If there are certain assumptions about the prior distribution of the data in the feature space, there are as many good and bad performances.\n\nLater I found relative power spectrum including delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz), provide important information to augmenting the MEG data.\n\n```python\nX_train_numpy = X_train_tensors.cpu().numpy()\nX_test_numpy = X_test_tensors.cpu().numpy()\n\nX = np.swapaxes(X_train_numpy, 2, -1).squeeze()\ndata = X[X.shape[0]-1, 70, :]\npsd_mne, freqs_mne = psd_array_welch(data, 100, 1., 70., n_per_seg=None,\n                          n_overlap=0, n_jobs=1)\nfor low, high in [(0.5, 4), (4, 8), (8, 10), (10, 12), (12, 30),\n                  (30, 70)]:\n    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n    # Find intersecting values in frequency vector\n    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n      # Frequency resolution\n    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n\n    # Compute the absolute power by approximating the area under the curve\n    power = simps(psd_mne[idx_delta], dx=freq_res)\n    print('Absolute power: {:.4f} uV^2'.format(power))\n    \n    total_power = simps(psd_mne, dx=freq_res)\n    rel_power = power / total_power\n    \n    print('Relative power: {:.4f}'.format(rel_power))\n```\n\n# Jun 1st\n\n## Seventh meeting\n\nDr Toby provide me the code to load data with dataloader\n\nit defines load_MEG_dataset function with following parameters: \n\n```python\ndef load_MEG_dataset(\n        subject_ids: List[str],\n        mode: str = \"individual\",\n        output_format: str = \"numpy\",\n        trial_data_format: str = \"2D\",\n        data_location: str = \"./data/\",\n        center_timepoint: int = 20,\n        window_width: List[int] = [-400, 400],\n        shuffle: bool = False,\n        pca_n_components: int = None,\n        training: bool = True,\n        train_test_split: float = 0.75,\n        batch_size: int = 32,\n        scale: bool = True,\n        seed: int = 0,\n    )\n```\n\n# Jun 6th\n\n### Objective:\n\nto try different loss function, because different evaluating methods may affect the learning process, and lead to a different approach to training results.\n\n### Results:\n\nwhen apply other loss function instead of CrossEntropy, there are some format error occurs:\n\nsolution: transform inputs from multi hot coding into one hot coding. \n\n```Python\ndef onehot(batches, n_classes, y):\n  yn = torch.zeros(batches, n_classes)\n  for i in range(batches):\n    x = [0 for j in range(batches)]\n    x[i] = y[i]/2-1                     #ex. [12]-> [5]\n    yn[i][int(x[i])]+= 1                  #[000010000]\n  return yn\n```\n\nLater I found that we can use the function in Pytorch: F.onehot\n\n# Jun 7th\n\ntry different models, reshape the data from [batches, channels, times point ]to be [batches, times point, channels] in corresponding to images format [batches, picture channels (layers), pixels] (not the same channels, the same names but different meanings, former one is electrode channels. latter one is picture layers)\n\n# Jun 8th\n\n## Third session meeting\n\n### Objective:\n\nto learn the key points of writing a good introduction\n\n### Results:\n\nfrom the history of ML to the current meaning \n\n- [x] The **history** of **ML**, (black box...)\n- [x] the **history** of disease classification or **behaviour prediction**\n- [x] how people use the ML techniques to **predict  behaviours** these days\n- [x] what is aversive state reactivation (one sentence); why people want to learn aversive state reactivation\n- [x] how people tried to connect ML with aversive state reactivation\n- [x] the problem (gap) is previous model only gives a low prediction accuracy\n- [x] Introduction of CNN, LSTM, RNN or transfer learning\n- [x] My aims is to optimize the model with new techniques: CNN, LSTM RNN or transfer learning\n\nNote: state what in each paragraph is not enough and leads to the next paragraph.\n\n## LSTM RNN\n\n### Objective: \n\ntry LSTM RNN\n\n### Results:\n\nThe problems when I try to use one hot data `  labels = F.one_hot(labels)`, it is not applicable because in that case the dimensions could be 28 instead of 14 as we only have even numbers,\n\nSome packages automatically figure out where there missing labels during one hot operation but this one (pytorch) doesn't\n\n## Eighth meeting\n\n### questions: \n\n- [x] loss functions give similar values?\n- [x] ~~is it correct to use enumerate to loop each data?~~\n\nIn my case, CrossEntropy is the better for MEG data. It is the experience gained from Dr Toby. Even though I found the others’ research about hands behaviour prediction used MSE loss. It is not suitable for our results because theirs is about the movements while ours is not.\n\n# Jun 9th\n\n## Label noise.\n\n### Objectives:\n\nto figure out if labels format it self may affect the model performance. Because some models only accept data in one kind of format. \n\n**question**: how to determine numbers of hidden layers in LSTM RNN.\n\n### Results:\n\nWe cannot correctly compare each label when we are using **one-hot format**. If the labels you predict are apples, bananas, and strawberries, obviously they do not directly have a comparison relationship. If we use 1, 2, 3 as labels, there will be a comparison relationship between the labels. Distances are different. With the comparison relationship, the distance between the first label and the last label is too far, which affects the learning of the model.\n\nOne promotion:\n\n> Knowledge distillation (KD) improves performance precisely by suppressing this label nosie. Based on this understanding, we introduce a particularly simple improvement method of knowledge disillation, which can significantly improve the performance of ordinary KD by setting different temperatures for each image. \n>\n> Xu, K., Rui, L., Li, Y., Gu, L. (2020). *Feature Normalized Knowledge Distillation for Image Classification.* In: Vedaldi, A., Bischof, H., Brox, T., Frahm, JM. (eds) Computer Vision – ECCV 2020. ECCV 2020. Lecture Notes in Computer Science(), vol 12370. Springer, Cham. https://doi.org/10.1007/978-3-030-58595-2_40\n\n**Hidden layers in LSTM RNN**\n\nThe effect of the number of hidden layers for neural networks\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202206120108575.jpeg)\n\n# Jun 10th\n\ntry `CrossEntropyLoss()` with onehot format data\n\nconvert the labels from “every 2 in 0 to 28” to “every 1 in 1 to 14”\n\n```python\ny_train = (y_train / 2) - 1\ny_test = (y_test / 2) - 1\n```\n\nuse `  with torch.autocast('cuda')` to solve “cuda error” of `CrossEntropyLoss()`\n\n```python\nwith torch.autocast('cuda'):\n        # loss = criterion(outputs, torch.tensor(labels).cuda())\n            loss = criterion(outputs, labels)\n```\n\n# Jun 12th\n\neven though the accuracy of prediction for train data increases quickly as training, the accuracy for test data is still very low. It seems the validation loss does not converge. I decide the next step is going to do more literature research and adjust the parameters.\n\n# Jun 13th\n\n### Problems:\n\nthe problem is overfitting. There could be 2 alternative options: 1, get more data; 2, try different learning rate or dynamic learning rate.\n\nthe way the train-test split worked wasn't ideal in the data loading function - because the data wasn't shuffled prior to splitting, the train and test set would often consist of different subjects if we load multiple subjects. The data can be shuffled before splitting (by setting shuffle=True), which means that there will be a mix of subjects in both the training and testing data. This seems to boost accuracy in the test set a little bit.\n\n# Jun 14th\n\n### Objective:\n\nto try `CosineEmbeddingLoss()` because it is reported that cosine loss may improve the performance for small dataset\n\n> Cosine loss could have better performance for small dataset (around 30%). \n>\n> Barz, B., & Denzler, J. (2019). Deep Learning on Small Datasets without Pre-Training using Cosine Loss. *Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020*, 1360–1369. https://doi.org/10.48550/arxiv.1901.09054\n\n### Results:\n\nhowever, the performance is not promoted\n\n# Jun 15th\n\n## Fourth session meeting\n\nI read others work, practice to extract the key words and main ideas:\n\n> *Affective modulation of the startle response in depression: Influence of the severity of depression, anhedonia and anxiety*\n\nstartle reflex (SR)\n\n1. affective rating\n\n​\tget affective rating after participants watched every clips \n\n​\tand analysis the difference between depressed patients and control.\n\n2. Startle amplitude\n\n3. EMG\n\n   higher baseline EMG activity during pleasant and unpleasant clips, relative to the neutral clips\n\n**Conclusion**\n\na reduced degree of self-reported mood modulation \n\n**Gap**\n\nThe findings differ from those of Allen et al. (1999): they think it does not matter for depression or anhedonia for affective and emotional modulation.\n\n**key wards**\n\nDepression\n\nAnxiety\n\nAnhedonia\n\nAffective modulation\n\nMood regulation\n\nStartle response\n\nEMG\n\naffective rating\n\n## Ninth meeting\n\n### Problems:\n\nSince the past work does not give a good result and it has been nearly halfway of the project. My following work is suggested to be focused on:\n\n1. Multilayer Perceptron\n\n2. transfer learning\n\n# Jun 16th\n\n>  **Convolutional Layer** : Consider a convolutional layer which takes “l” feature maps as the input and has “k” feature maps as output. The filter size is “**n\\*m**”.\n> Here the input has ***l=32\\*** feature maps as inputs, ***k=64\\*** feature maps as outputs and filter size is ***n=3 and m=3\\***. It is important to understand, that we don’t simply have a 3*3 filter, but actually, we have **3\\*3\\*32** filter, as our input has 32 dimensions. And as an output from first conv layer, we learn 64 different **3\\*3\\*32** filters which total weights is “**n\\*m\\*k\\*l**”. Then there is a term called bias for each feature map. So, the total number of parameters are “**(n\\*m\\*l+1)\\*k**”.\n>\n> https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\n\nbicubic interpolation: torch.nn.functional.interpolate() with mode='bicubic' \n\n> https://stackoverflow.com/questions/54083474/bicubic-interpolation-in-pytorch\n\nMeeting these data and fitting problems, I realize the insufficiency of understanding data itself, so I look back to the Machine Learning courses materials from 2 years ago, trying to get some new approaches.\n\nWhen reading the Chapter 1 of *Computational Modelling of Cognition and Behaviour*, I get the following points: \n\n> 1. Data never speak for themselves but require a model to be understood and to be explained.\n> 2. Verbal theorizing alone ultimately cannot replace for quantitative analysis.\n> 3. There are always several alternative models that vie for explanation of data and we must select among them.\n> 4. Model selection rests on both quantitative evaluation and intellectual and scholarly judgment.\n\n# June 21th\n\nHave a meeting with Eammon, we talked about my recent work:\n\nEammon gives me a suggestion: in behaviour level, picture of faces are different. Try and see what if we get rid of the picture of faces in labels.\n\nHere are the pictures shown to participants: \n\n![image-20220722184848108](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221848253.png)\n\n# June 25th\n\nto try Mnet (was used to predict the Alzheimer's disease by Aoe .etc)\n\n> Aoe, J., Fukuma, R., Yanagisawa, T. *et al.* Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. *Sci Rep* **9,** 5057 (2019). https://doi.org/10.1038/s41598-019-41500-xz\n\nScore method:\n\nAs an alternative option, the accuracy can be expressed as root mean square error. \n\n# Jun 27th\n\n### Objective:\n\nto apply data augmentation because it was reported that relative power spectrum provide extra information which may improve model’s performance on MEG data.\n\n### Result:\n\none possible solution is to extract band power to augment the data\n\n> “This model was implemented to check the proprieties of the RPS to extract meaningful features from the input data. The RPS was combined with an MLP to add nonlinearity and increase the capability of approximate the target variable.”\n>\n> The RPS was implemented in 4 steps: \n>\n> 1. Compute the modified periodogram using Welch methods (Welch 1967) to get the power spectral density. \n> 2. Calculate the average band power approximating using the composite Simpson’s rule to get it for a specific target band. \n> 3. Divide the average band power of the specific target band by the total power of the signal to get the relative power spectrum.\n\n> Anelli, M. (2020). *Using Deep learning to predict continuous hand kinematics from Magnetoencephalographic (MEG) measurements of electromagnetic brain activity* (Doctoral dissertation, ETSI_Informatica).\n\n```python\nX_train_bp = np.squeeze(X_train_numpy, axis=1)\n# X_train_bp = X_train_bp[: :, :, :]\nX_train_bp = standard_scaling_sklearn(X_train_bp)\nX_test_bp = np.squeeze(X_test_numpy, axis=1)\n# X_train_bp = X_train_bp[: :, :, :]\nX_test_bp = standard_scaling_sklearn(X_test_bp)\nbands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\nbp_train = bandpower_multi_bands(X_train_bp, fs=800.0, bands=bands, relative=True)\nbp_test = bandpower_multi_bands(X_test_bp, fs=800.0, bands=bands, relative=True)\nbp_train_tensor = torch.Tensor(bp_train).cuda()\nbp_test_tensor = torch.Tensor(bp_test).cuda()\n```\n\n# June 28th\n\n### Problem:\n\nMy Google Colab subscriptions is expired but luckily I have got the access of HPC in KCL (create)\n\n### Solution:\n\nset up cluster as the tutorial: https://docs.er.kcl.ac.uk/CREATE/access/\n\n1. Start an interactive session:\n\n```\nsrun -p gpu --pty -t 6:00:00 --mem=30GB --gres=gpu /bin/bash\n```\n\n**Make a note of the node I am connected to, e.g. erc-hpc-comp001**\n\n`sinfo avail` to check the available cores\n\n2. start Jupyter lab without the display on a specific port (here this is port 9998)\n\n```\njupyter lab --no-browser --port=9998 --ip=\"*\"\n```\n\n3. **Open a separate connection** to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)\n\n```\nssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk\" -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk\n```\n\n- Note:\n  - k12345678 should be replaced with your username.\n  - erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running\n  - 9998 should be replaced with the port you specified when running Jupyter lab (using e.g. `--port=9998`)\n  - authorize via https://portal.er.kcl.ac.uk/mfa/\n\n4. Start notebook in http://localhost:9998/lab\n\n5. VS code part: set the Jupyter server as remote :\n\n   ```\n   http://localhost:9998/lab?token=XXX\n   # replace the localhost as erc-hpc-comp031\n   ```\n\n   Note: However, After the latest weekly update, existing problem has been found is the connection via VS code is not stable. Reason could be the dynamic allocated node and port confuses the VS code connection server.\n\n# June 29th\n\n### Objective:\n\nto try different normalization method: **Z-Score Normalization**\n\n### Results:\n\nwhich maps the raw data to a distribution with mean 0 and standard deviation \n\n1. Assuming that the mean of the original feature is μ and the variance is σ , the formula is as follows:\n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221914685.png)\n\n# July 1th\n\n### Objective:\n\nto try Mnet with band power (RPS Ment); the reason for splitting alpha into low and high is that kinematic show that alpha band significant after movement and beta before movement. It is also reported that gamma band is associated with it is related to synergistic muscle activation (Kolasinski et. al, 2019)\n\n> Kolasinski, J., Dima, D. C., Mehler, D. M. A., Stephenson, A., Valadan, S., Kusmia, S., & Rossiter, H. E. (2019). Spatially and temporally distinct encoding of muscle and kinematic information in rostral and caudal primary motor cortex. *BioRxiv*, 613323. https://doi.org/10.1101/613323\n\n### Results:\n\nextract band powers to get a 6 RPS (relative power spectrum) for each frequency period:\n\n```python\ndef bandpower_1d(data, sf, band, nperseg=800, relative=False):\n\n    # band = np.asarray(band)\n    low, high = band\n\n    # Compute the modified periodogram (Welch)\n    # TODO: generalize freq values\n    psd, freqs = psd_array_welch(data, sf, 1., 70., n_per_seg=int(800 / 2),\n                                 n_overlap=0, n_jobs=1)\n\n    # Frequency resolution\n    freq_res = freqs[1] - freqs[0]\n\n    # Find closest indices of band in frequency vector\n    idx_band = np.logical_and(freqs >= low, freqs <= high)\n\n    # Integral approximation of the spectrum using Simpson's rule.\n    bp = simps(psd[idx_band], dx=freq_res)\n\n    if relative:\n        bp /= simps(psd, dx=freq_res)\n    return bp\n\ndef bandpower(x, fs, bands, nperseg=800, relative=True):\n\n    psd, freqs = psd_array_welch(x, fs, 1., 70., n_per_seg=int(fs/2),\n                                 n_overlap=0, n_jobs=1)\n    # Frequency resolution\n    freq_res = freqs[1] - freqs[0]\n    n_channel, _ = x.shape\n    bp = np.zeros((n_channel, len(bands)))\n    for idx, band in enumerate(bands):\n        low, high = band\n        # Find closest indices of band in frequency vector\n        idx_band = np.logical_and(freqs >= low, freqs <= high)\n\n        # Integral approximation of the spectrum using Simpson's rule.\n        _bp = simps(psd[..., idx_band], dx=freq_res, axis=-1)\n\n        if relative:\n            _bp /= simps(psd, dx=freq_res, axis=-1)\n        \n        # print(bp.shape, _bp.shape) #272,6  80,272\n        bp[:, idx] = _bp\n\n    return bp\n\ndef bandpower_multi_bands(x, fs, bands,  nperseg=800, relative=True):\n    \n    n_epoch, n_channel, _ = x.shape\n    bp = np.zeros((n_epoch, n_channel, len(bands)))\n    for e in range(n_epoch):\n        bp[e] = bandpower(x[e], fs, bands, nperseg=nperseg, relative=relative)\n\n    return bp\n\ndef standard_scaling_sklearn(data):\n    \n    n_epoch = data.shape[0]\n    for e in range(n_epoch):\n        scaler = skScaler()\n        data[e, ...] = scaler.fit_transform(data[e, ...])\n\n    return data\n```\n\nIn main code:\n\n````python\nX = np.swapaxes(X_train, 2, -1).squeeze()\ndata = X[X.shape[0]-1, 70, :]\npsd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n                          n_overlap=0, n_jobs=1)\nfor low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n                  (30, 70)]:\n    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n    # Find intersecting values in frequency vector\n    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n      # Frequency resolution\n    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n\n    # Compute the absolute power by approximating the area under the curve\n    power = simps(psd_mne[idx_delta], dx=freq_res)\n    print('Absolute power: {:.4f} uV^2'.format(power))\n    \n    total_power = simps(psd_mne, dx=freq_res)\n    rel_power = power / total_power\n    \n    print('Relative power: {:.4f}'.format(rel_power))\n    \n```\nOutputs:\nEffective window size : 1.024 (s)\nprocessing bands (low, high) : (1,4)\nAbsolute power: 0.0610 uV^2\nRelative power: 0.1251\nprocessing bands (low, high) : (4,8)\nAbsolute power: 0.0315 uV^2\nRelative power: 0.0647\nprocessing bands (low, high) : (8,10)\nAbsolute power: 0.0220 uV^2\nRelative power: 0.0452\nprocessing bands (low, high) : (10,13)\nAbsolute power: 0.0031 uV^2\nRelative power: 0.0064\nprocessing bands (low, high) : (13,30)\nAbsolute power: 0.0577 uV^2\nRelative power: 0.1184\nprocessing bands (low, high) : (30,70)\nAbsolute power: 0.2356 uV^2\nRelative power: 0.4837\n```\n````\n\nThe average power spectrum for all subjects:\n\n![image-20220817205940319](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172059472.png)\n\nThe results show that beta and delta waves are in the large and major proportion. It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.\n\n> Baumeister, J., Barthel, T., Geiss, K. R., & Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. *Http://Dx.Doi.Org/10.1179/147683008X301478*, *11*(3), 103–110. https://doi.org/10.1179/147683008X301478\n\n### Problems:\n\nfind the initial loss is too huge and does not change afterwards. Guess it is because of too large initial loss or wrongly `loss.backward()`\n\n### solution:\n\nparameters of optimizer was set wrongly, fix it with `model.parameters()`\n\n# July 2th\n\n### Problems:\n\nlooking for solution to merge the function\n\nguess I am meeting “dying ReLU” problem\n\n# July 5th\n\n### Objectives:\n\nto try dynamic learning rate and interpolate 130 time points to be 800 time points without losing too much information.\n\n### Solution:\n\n```python\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')\n\nscheduler.step(acc[-1]) #at last of each epoch training \n```\n\nthe update step: I use the dynamic learning rate when the valid loss approaches a plateau (function 4, where ![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102154.gif) represents learning decay and L represents valid loss). \n\n![img](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102153.gif)\n\nMultilayer perceptron\n\ninterpolate https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html\n\nLearning rate scheduling https://pytorch.org/docs/stable/optim.html\n\n# July 9th\n\nIn order to make the input data the same shape as required, I use resample function `localiser_epochs.copy().resample(800, npad='auto')` to upsamle the data\n\nCBAM modules are added because the attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images’ edges. \n\n> Attention in Deep Learning, Alex Smola and Aston Zhang, Amazon Web Services (AWS), ICML 2019\n\n```python\nclass SpatialAttention(nn.Module):\n    def __init__(self):\n        super(SpatialAttention, self).__init__()\n        self.compress = ChannelPool()\n        self.spatialAttention = nn.Sequential(\n            nn.Conv2d(2, 1, 7, 7, padding=3), #padding = (7-1)/2\n            )\n\n    def forward(self, x):\n        # print('x',x.shape)\n        x = self.compress(x)\n        x = self.spatialAttention(x)\n        # scale = F.sigmoid(x)\n        scale = torch.sigmoid(x)\n        \n        return x * scale\n    \nclass Flatten_MEG(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n    \nclass ChannelAttention(nn.Module):\n    \"\"\"\n            Implementation of a channel attention module.\n        \"\"\"\n    class Showsize(nn.Module):\n        def __init__(self):\n            super(ChannelAttention.Showsize, self).__init__()\n        def forward(self, x):\n            # print(x.shape)\n            return x\n\n    def __init__(self, shape, reduction_factor=16):\n\n        super(ChannelAttention, self).__init__()\n\n        _, in_channel, h, w = shape\n        self.mlp = nn.Sequential(\n            # self.Showsize(),\n            Flatten_MEG(),\n            # self.Showsize(),\n            nn.Linear(in_channel, in_channel // reduction_factor),\n            nn.ReLU(),\n            nn.Linear(in_channel // reduction_factor, in_channel),\n        )\n\n    def forward(self, x):\n        avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n        max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n        sum = self.mlp(avg_pool) + self.mlp(max_pool)\n        scale = (\n            torch.sigmoid(sum)\n            .unsqueeze(2)\n            .unsqueeze(3)\n            .expand_as(x)\n        )\n\n        return x * scale\n```\n\n# July 10th\n\nIn order to find the rationality of extracting features of brain states under different stimuli. I draw the topographical maps of all stimuli at different time. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, my model is an effective and reasonable approach to classifying these states.\n\n```python\nsti=[1,2,3,4,5,6,7,8,9,10,11,12,13,14]                     \nfor stimuli in range (1,15):\n    epochs_standard = fname.get_epochs(sub=1)\n    for sub in [sub for sub in range (2,29) if sub not in [6, 12, 14 ,23]]:\n        if sub == 1:\n            epochs_standard = fname.get_epochs(sub=1)\n        else:\n            epochs = fname.get_epochs(sub)['stimulus_{}'.format(2*stimuli)]\n            epochs.info['dev_head_t'] = epochs_standard.info['dev_head_t']\n            epochs_standard = mne.concatenate_epochs([epochs_standard['stimulus_{}'.format(2*stimuli)], epochs['stimulus_{}'.format(2*stimuli)]])\n    exec('evoked_{} = epochs_standard.average()'.format(stimuli))\n        # evoked_standard = mne.concatenate_epochs([evoked_standard, evoked])\n\n```\n\n![image-20220817205119443](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172051592.png)\n\nbrain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity.\n\n# July 12th\n\nThe random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of my model is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. Compared with the other classification approach, my model exhibits the best classification performance (p = 6.8 × 10 –2 for LSTM RNN, p = 5.9 × 10 –2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of my model is able to reach 33.33%. \n\n![image-20220817205549898](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172055038.png)\n\nearly stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting:\n\n```python\nclass EarlyStopping:\n\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score <= self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n            \n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.4f} --> {val_loss:.4f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n```\n\nHowever, would early stopping necessarily prevent overfitting? There’s some interesting work showing that if you over-train the model it actually suddenly gets a lot better at some point (an approach referred to as “grokking” for some reason). It may be possible that more training doesn’t necessarily mean worse performance.\n\n# July 13th\n\nI want to visualize my model and data process steps.\n\nFirst save the model as .onnx file:\n\n```python\nx = torch.randn(64, 1, 272, 800).requires_grad_(True).cuda() \ntorch_out = rpsmnet(x)\n\n# Export the model\ntorch.onnx.export(rpsmnet,               # model being run\n                  x,                         # model input (or a tuple for multiple inputs)\n                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n                  export_params=True,        # store the trained parameter weights inside the model file\n                  opset_version=10,          # the ONNX version to export the model to\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\n                  input_names = ['input'],   # the model's input names\n                  output_names = ['output'], # the model's output names\n)\n```\n\nAnd I generate the flow chat of this model with Netron:\n\n![image-20220817210610588](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172106759.png)\n\nDetailed configuration of my model. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply\n\nThe steps data are processed is generated with following code: \n\n```python\nimport hiddenlayer as hl\n\ntransforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n\ngraph = hl.build_graph(rpsmnet, torch.zeros(64,1,272,800).cuda())\ngraph.theme = hl.graph.THEMES['blue'].copy()\ngraph.save('ASRCnet_hiddenlayer', format='png')\n\nfrom torchviz import make_dot\nx = torch.randn(64, 1, 272, 800).requires_grad_(True).cuda() # 定义一个网络的输入值\ny = rpsmnet(x)    # 获取网络的预测值\n# y = y.cuda()\nMyConvNetVis = make_dot(y)#, params=dict(list(rpsmnet.named_parameters()) + [('x', x)]))\nMyConvNetVis.format = \"png\"\n# 指定文件生成的文件夹\nMyConvNetVis.directory = \"data\"\n# 生成文件\nMyConvNetVis.view()\n```\n\n![image-20220817210806647](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172108920.png)\n\n\n\n# July 15th\n\nI want to visualize the pooling and convolution operations, so I use CAD to draw the illustrations:\n\nAs shown in figure A, a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure B) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well \n\n![image-20220817211402695](https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172114867.png)\n","slug":"master project","published":1,"updated":"2023-10-21T05:49:03.036Z","comments":1,"layout":"post","photos":[],"_id":"cuidmXoTyS2k4NzlyH_PI_-3q","content":"<h1 id=\"Table-of-content\"><a href=\"#Table-of-content\" class=\"headerlink\" title=\"Table of content\"></a>Table of content</h1><p>[Toc]</p>\n<h1 id=\"April-12th\"><a href=\"#April-12th\" class=\"headerlink\" title=\"April 12th\"></a>April 12th</h1><h2 id=\"First-meeting\"><a href=\"#First-meeting\" class=\"headerlink\" title=\"First meeting\"></a>First meeting</h2><h3 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to find out which data we are going to use and which method to analyse it because good understanding of the data can help researching simpler and more accurate. It can also inform me important information about features engineering or neural network designing.</p>\n<h3 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>data: <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a></p>\n<p>28 participants viewing 14 image stimuli </p>\n<p>The file we cares:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204111409061.png\" alt=\"image-20220411140935965\"></p>\n<p>I can use MNE-Python to analyse it because MNE-Python package is highly integrated allowing an easy access to analysing.</p>\n<p>What these files do can be achieved with:</p>\n<p><a href=\"https://mne.tools/stable/generated/mne.read_epochs.html\">https://mne.tools/stable/generated/mne.read_epochs.html</a></p>\n<p>More templates can be found in:</p>\n<p><a href=\"https://github.com/tobywise/aversive_state_reactivation/blob/master/notebooks/templates/sequenceness_classifier_template.ipynb\">https://github.com/tobywise/aversive_state_reactivation/blob/master/notebooks/templates/sequenceness_classifier_template.ipynb</a></p>\n<h1 id=\"April-13th\"><a href=\"#April-13th\" class=\"headerlink\" title=\"April 13th\"></a>April 13th</h1><h2 id=\"First-session-meeting\"><a href=\"#First-session-meeting\" class=\"headerlink\" title=\"First session meeting\"></a>First session meeting</h2><h3 id=\"Objective-1\"><a href=\"#Objective-1\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>learn how to write a lab notebook</p>\n<h3 id=\"Results-1\"><a href=\"#Results-1\" class=\"headerlink\" title=\"Results\"></a>Results</h3><p>General understanding:</p>\n<p>Title: the utility of multi-task machine learning for decoding brain states</p>\n<p>Table of Contents:</p>\n<p>page numbers; date; title/subject/experiment</p>\n<p>Gantt charts is good to help organise time.</p>\n<h1 id=\"April-18th\"><a href=\"#April-18th\" class=\"headerlink\" title=\"April 18th\"></a>April 18th</h1><h2 id=\"Install-MNE-Python-via-pip\"><a href=\"#Install-MNE-Python-via-pip\" class=\"headerlink\" title=\"Install MNE-Python via pip:\"></a>Install MNE-Python via pip:</h2><h3 id=\"Objective-2\"><a href=\"#Objective-2\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to upgrade environment manager and compiler to the latest stable version because I always tend to use the latest version of packages which is supposed to be more compatible</p>\n<h3 id=\"Results-2\"><a href=\"#Results-2\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>Update Anaconda via <code>conda upgrade --all</code> and  <code>conda install anaconda=2021.10</code></p>\n<p>The Python version I am using is:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Python 3.9.12\t</span><br></pre></td></tr></table></figure>\n\n<p>get the data:</p>\n<p><code>git clone https://github.com/OpenNeuroDatasets/ds003682</code></p>\n<p>Install MNE:</p>\n<p><code>conda install --channel=conda-forge mne-base</code></p>\n<h1 id=\"April-19th\"><a href=\"#April-19th\" class=\"headerlink\" title=\"April 19th\"></a>April 19th</h1><h2 id=\"Second-meeting\"><a href=\"#Second-meeting\" class=\"headerlink\" title=\"Second meeting\"></a>Second meeting</h2><h3 id=\"Objective-3\"><a href=\"#Objective-3\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to have a general understanding of the data and figure out details about methods because these are what I am going to feed into the network so that I should have a clear recognition for each part.</p>\n<p><code>x_raw</code></p>\n<p><code>x_raw.shape</code></p>\n<p><code>y_raw</code></p>\n<p><code>time = localiser epchoes</code></p>\n<h3 id=\"Results-3\"><a href=\"#Results-3\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><h4 id=\"what-I-have-known\"><a href=\"#what-I-have-known\" class=\"headerlink\" title=\"what I have known:\"></a>what I have known:</h4><p><strong>scikit-learn</strong> (machine learning library) is an available package I am going to use</p>\n<p>use <strong>PCA</strong> to reduce dimensions </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204191041843.png\" alt=\"image-20220419104136746\"></p>\n<h4 id=\"what-need-to-be-learned\"><a href=\"#what-need-to-be-learned\" class=\"headerlink\" title=\"what need to be learned:\"></a>what need to be learned:</h4><h5 id=\"1-normalization-regularization\"><a href=\"#1-normalization-regularization\" class=\"headerlink\" title=\"1. normalization, regularization\"></a>1. normalization, regularization</h5><p>lasso L1 = sets unpredictive features to 0</p>\n<p>ridge L2 = minimises the weights on unpredictive features</p>\n<p>elastic net L1/L2</p>\n<h5 id=\"2-search\"><a href=\"#2-search\" class=\"headerlink\" title=\"2. search\"></a>2. search</h5><p><code>random_search randomizedsearchCV</code> to test the performance</p>\n<h5 id=\"3-Neural-network\"><a href=\"#3-Neural-network\" class=\"headerlink\" title=\"3. Neural network\"></a>3. Neural network</h5><p>neural network can be the best way for logistic leaning </p>\n<h5 id=\"4-validation\"><a href=\"#4-validation\" class=\"headerlink\" title=\"4. validation\"></a>4. validation</h5><h1 id=\"April-24th\"><a href=\"#April-24th\" class=\"headerlink\" title=\"April 24th\"></a>April 24th</h1><h3 id=\"Objective-4\"><a href=\"#Objective-4\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to play with existing code <a href=\"https://github.com/tobywise/aversive_state_reactivation\">https://github.com/tobywise/aversive_state_reactivation</a> because it can inform me code grammars analysing MEG data and it will make a foundation for my following coding </p>\n<h3 id=\"Results-4\"><a href=\"#Results-4\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><h4 id=\"Epochs\"><a href=\"#Epochs\" class=\"headerlink\" title=\"Epochs\"></a>Epochs</h4><p>Extract signals from continuous EEG signals for specific time windows, which can be called epochs.</p>\n<p>Because EEGs are collected continuously, to analyse EEG event-related potentials requires “slicing” the signal into time segments that are locked to time segments within an event (e.g., a stimulus).</p>\n<h4 id=\"Data-corruption\"><a href=\"#Data-corruption\" class=\"headerlink\" title=\"Data corruption\"></a>Data corruption</h4><p>The MEG data in the repository <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a> is invalid, possibly because of data corruption</p>\n<p><strong>incomplete copying led to corrupted files</strong></p>\n<p>The following events are an example present in the data: 1, 2, 3, 4, 5, 32</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">event_id = &#123;&#x27;Auditory/Left&#x27;: 1, &#x27;Auditory/Right&#x27;: 2,</span><br><span class=\"line\">&#x27;Visual/Left&#x27;: 3, &#x27;Visual/Right&#x27;: 4,</span><br><span class=\"line\">&#x27;smiley&#x27;: 5, &#x27;button&#x27;: 32&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>sklearn.cross_validation</code> has been deprecated since version 1.9, and <code>sklearn.model_selection</code> can be used after version 1.9.</p>\n<h1 id=\"April-25th\"><a href=\"#April-25th\" class=\"headerlink\" title=\"April 25th\"></a>April 25th</h1><h2 id=\"Install-scikit-learn-sklearn\"><a href=\"#Install-scikit-learn-sklearn\" class=\"headerlink\" title=\"Install scikit-learn (sklearn)\"></a>Install scikit-learn (sklearn)</h2><p>use the command line </p>\n<p><code>conda install -c anaconda scikit-learn</code></p>\n<p>Start the base environment in Anaconda Prompt: <code>activate base</code></p>\n<p>And install jupyter notebook, numpy and other modules in the environment</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda insatll tensorflow</span><br><span class=\"line\"></span><br><span class=\"line\">conda install jupyter notebook</span><br><span class=\"line\"></span><br><span class=\"line\">conda install scikit-learn</span><br><span class=\"line\"></span><br><span class=\"line\">conda install scipy</span><br></pre></td></tr></table></figure>\n\n<p>Learn how to choose the right algorithm </p>\n<p><a href=\"https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\">https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html</a></p>\n<p><img src=\"https://scikit-learn.org/stable/_static/ml_map.png\" alt=\"flow chart of scikit\"></p>\n<h2 id=\"Learning-sklearn\"><a href=\"#Learning-sklearn\" class=\"headerlink\" title=\"Learning sklearn\"></a>Learning sklearn</h2><ol>\n<li>import modules</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>create data</li>\n</ol>\n<p>load <code>iris</code> data，store the <strong>attributes</strong> in  <code>X</code>，store the <strong>labels</strong> in <code>y</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">iris_X = iris.data</span><br><span class=\"line\">iris_y = iris.target</span><br></pre></td></tr></table></figure>\n\n<p>Looking at the dataset, <code>X</code> has four attributes, and <code>y</code> has three categories: 0, 1, and 2:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(iris_X[:<span class=\"number\">2</span>, :])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(iris_y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">Output:</span></span><br><span class=\"line\"><span class=\"string\">[[ 5.1  3.5  1.4  0.2]</span></span><br><span class=\"line\"><span class=\"string\"> [ 4.9  3.   1.4  0.2]]</span></span><br><span class=\"line\"><span class=\"string\">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span></span><br><span class=\"line\"><span class=\"string\"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2]</span></span><br><span class=\"line\"><span class=\"string\"> &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>Divide the data set into training set and test set, where <code>test_size=0.3</code>, that is, the test set accounts for 30% of the total data:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class=\"line\">    iris_X, iris_y, test_size=<span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n\n<p>It can be seen that the separated data sets are also disrupted in order, which is better to train the model:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">Outputs:</span></span><br><span class=\"line\"><span class=\"string\">[2 1 0 1 0 0 1 1 1 1 0 0 1 2 1 1 1 0 2 2 1 1 1 1 0 2 2 0 2 2 2 2 2 0 1 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2 2 2 0 1 2 2 1 1 1 0 0 1 2 0 1 0 1 0 1 2 2 0 1 2 2 2 1 1 1 1 2 2 2 1 0</span></span><br><span class=\"line\"><span class=\"string\"> 1 1 0 0 0 2 0 1 0 0 1 2 0 2 2 0 0 2 2 2 1 2 0 0 2 1 2 0 0 1 2]</span></span><br><span class=\"line\"><span class=\"string\"> &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>Build a model - train - predict</li>\n</ol>\n<p>Define the module method <code>KNeighborsClassifier()</code>, use <code>fit</code> to train <code>training data</code>, this step completes all the steps of training, the latter <code>knn</code> is already a trained model, which can be used directly <code>predict</code> For the data of the test set, comparing the value predicted by the model with the real value, we can see that the data is roughly simulated, but there is an error, and the prediction will not be completely correct.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">knn = KNeighborsClassifier()</span><br><span class=\"line\">knn.fit(X_train, y_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(knn.predict(X_test))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">[2 0 0 1 2 2 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 1 0 1 2 0 1]</span></span><br><span class=\"line\"><span class=\"string\">[2 0 0 1 2 1 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 1 0 1 2 0 1]</span></span><br><span class=\"line\"><span class=\"string\"> &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>Directly download the data and store in my computer. However, it is unprofessional to run code in personal computer. I should looking for a way to solve this problem: rent a server or find a HPC cluster in King’s College.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204251507965.png\" alt=\"image-20220425150724894\"></p>\n<h2 id=\"Succeed-at-drawing-plot\"><a href=\"#Succeed-at-drawing-plot\" class=\"headerlink\" title=\"Succeed at drawing plot\"></a>Succeed at drawing plot</h2><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> mne</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> mne.datasets <span class=\"keyword\">import</span> sample</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The storage path of sample</span></span><br><span class=\"line\">data_path = sample.data_path()</span><br><span class=\"line\"><span class=\"comment\"># The storage path of the fif file</span></span><br><span class=\"line\">fname = <span class=\"string\">&#x27;E:\\Proj\\Previous data\\sample\\MEG\\sample\\sub-001_localiser_sub-001_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">epochs = mne.read_epochs(fname)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(epochs.event_id)</span><br><span class=\"line\"></span><br><span class=\"line\">picks = mne.pick_types(epochs.info, meg=<span class=\"literal\">True</span>, ref_meg=<span class=\"literal\">False</span>, exclude=<span class=\"string\">&#x27;bads&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">epochs.plot(block=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">epochs.plot_drop_log()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">epochs = mne.read_epochs(fname)</span><br><span class=\"line\"></span><br><span class=\"line\">evoked = epochs.average()</span><br><span class=\"line\">evoked.plot_topomap()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">availabe_event = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">32</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> availabe_event:</span><br><span class=\"line\">    evoked_i = epochs[i].average(picks=picks)</span><br><span class=\"line\">    epochs_i = epochs[i]</span><br><span class=\"line\">    evoked_i.plot(time_unit=<span class=\"string\">&#x27;s&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>The panel each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171937606.png\" alt=\"image-20220817193732989\"></p>\n<p>Topological map from -500.00 to 790.00 ms. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171941694.png\" alt=\"image-20220817194146606\"></p>\n<h2 id=\"A-few-questions-at-last\"><a href=\"#A-few-questions-at-last\" class=\"headerlink\" title=\"A few questions at last:\"></a>A few questions at last:</h2><ol>\n<li><p>why do we split the data as 70%, does it work as other ration?</p>\n<p>Because we have got enough data to train and need more data to test and valid the training performance.</p>\n</li>\n</ol>\n<h1 id=\"April-26th\"><a href=\"#April-26th\" class=\"headerlink\" title=\"April 26th\"></a>April 26th</h1><h2 id=\"MRI-safety-training-for-2-5-hrs\"><a href=\"#MRI-safety-training-for-2-5-hrs\" class=\"headerlink\" title=\"MRI safety training for 2.5 hrs\"></a>MRI safety training for 2.5 hrs</h2><h2 id=\"update-Anaconda-start-to-use-a-new-platform\"><a href=\"#update-Anaconda-start-to-use-a-new-platform\" class=\"headerlink\" title=\"update Anaconda (start to use a new platform)\"></a>update Anaconda (start to use a new platform)</h2><p>Anaconda is a good environment manager tool which allows me to manage and deploy packages</p>\n<p><code>conda update conda</code></p>\n<p><code>conda update anaconda</code></p>\n<p><code>conda update --all</code></p>\n<p>done</p>\n<p>Python version: 3.8.13-h6244533_0</p>\n<h2 id=\"change-the-directory-path-of-Jupyter-notebook-in-order-to-save-files-in-preferred-path\"><a href=\"#change-the-directory-path-of-Jupyter-notebook-in-order-to-save-files-in-preferred-path\" class=\"headerlink\" title=\"change the directory path of Jupyter notebook (in order to save files in preferred path)\"></a>change the directory path of Jupyter notebook (in order to save files in preferred path)</h2><ol>\n<li><p><code>jupyter notebook --generate-config</code> get the config file. change the line <code>c.NotebookApp.notebook_dir = &#39;&#39;</code> to the directory I want</p>\n</li>\n<li><p>find jupyter notebook file, change the attributes. <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204261614733.png\" alt=\"change the attributes\"></p>\n</li>\n</ol>\n<h2 id=\"Link-the-local-directory-and-Github\"><a href=\"#Link-the-local-directory-and-Github\" class=\"headerlink\" title=\"Link the local directory and Github\"></a>Link the local directory and Github</h2><p>for the convenience of collaboration </p>\n<p>SSH connect public key (id_rsa.pub) was created before.</p>\n<p>after create the directory, run the command in git:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">git init</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git git commit -m  <span class=\"string\">&quot;Comment&quot;</span></span><br><span class=\"line\">git remote add origin <span class=\"string\">&quot;the url of directory&quot;</span></span><br><span class=\"line\">git push -u origin main</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Journal-club-preparation-for-the-next-session\"><a href=\"#Journal-club-preparation-for-the-next-session\" class=\"headerlink\" title=\"Journal club preparation for the next session\"></a>Journal club preparation for the next session</h2><h1 id=\"April-27th\"><a href=\"#April-27th\" class=\"headerlink\" title=\"April 27th\"></a>April 27th</h1><h2 id=\"Pycharm-use-IDE\"><a href=\"#Pycharm-use-IDE\" class=\"headerlink\" title=\"Pycharm (use IDE)\"></a>Pycharm (use IDE)</h2><p>Get Pycharm educational version via King’s email</p>\n<p>install python 3.8 environment for running the code from <a href=\"https://github.com/tobywise/aversive_state_reactivation\">https://github.com/tobywise/aversive_state_reactivation</a> (because it was coding with python 3.8 compiler)</p>\n<p>run below code in pycharm</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">!conda create -n py38 python=3.8</span><br><span class=\"line\">!pip install mne</span><br><span class=\"line\">!pip install scikit-learn</span><br><span class=\"line\">!pip install plotly</span><br><span class=\"line\">!pip install cufflinks</span><br><span class=\"line\">!pip install networkx</span><br><span class=\"line\">!conda install numba</span><br><span class=\"line\">!pip install pyyaml</span><br><span class=\"line\">!pip install papermill</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Fixation-for-some-expired-code\"><a href=\"#Fixation-for-some-expired-code\" class=\"headerlink\" title=\"Fixation for some expired code\"></a>Fixation for some expired code</h2><p>The function <code>joblib</code> does not exist in <code>sklearn.external</code> anymore.</p>\n<p>Error occurs when run the function plot_confusion_matrix:</p>\n<p>Deprecated since version 1.0: <code>plot_confusion_matrix</code> is deprecated in 1.0 and will be removed in 1.2. Use one of the following class methods: <code>from_predictions</code> or <code>from_estimator</code>.</p>\n<p>use</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">ConfusionMatrixDisplay.from_predictions(y, y_pred)</span><br></pre></td></tr></table></figure>\n\n<p>instead of </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title=<span class=\"string\">&#x27;Normalised confusion matrix, accuracy = &#123;0&#125;&#x27;</span>.<span class=\"built_in\">format</span>(np.<span class=\"built_in\">round</span>(mean_accuracy, <span class=\"number\">2</span>)))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Second-session-meeting\"><a href=\"#Second-session-meeting\" class=\"headerlink\" title=\"Second session meeting\"></a>Second session meeting</h2><p>Every people gives a general introduction of their projects</p>\n<h1 id=\"April-28th\"><a href=\"#April-28th\" class=\"headerlink\" title=\"April 28th\"></a>April 28th</h1><h2 id=\"Logistic-regression-cost-function\"><a href=\"#Logistic-regression-cost-function\" class=\"headerlink\" title=\"Logistic regression cost function\"></a>Logistic regression cost function</h2><p>The function is using the principle of maximum likelihood estimation to find the parameters $\\theta$ for different models. At the meantime, a nice property is it is convex. So, this cost function is generally everyone use for fitting parameters in logistic regression.<img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290105356.png\" alt=\"image-20220429010526272\"></p>\n<p>The way we are going to minimize the cost function is using gradient descent:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290112574.png\" alt=\"image-20220429011210521\"></p>\n<p>Other alternative optimization algorithms (no need to manually pick $\\alpha$ studying rate):</p>\n<ol>\n<li>Conjugate gradient</li>\n<li>BFGS</li>\n<li>L-BFGS</li>\n</ol>\n<h2 id=\"Methods-to-storage-trained-model\"><a href=\"#Methods-to-storage-trained-model\" class=\"headerlink\" title=\"Methods to storage trained model\"></a>Methods to storage trained model</h2><p>set and train a simple SVC model</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"></span><br><span class=\"line\">clf = svm.SVC()</span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">X, y = iris.data, iris.target</span><br><span class=\"line\">clf.fit(X,y)</span><br></pre></td></tr></table></figure>\n<p>Storage:</p>\n<ol>\n<li>pickle</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pickle <span class=\"comment\">#pickle module</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;save/clf.pickle&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(clf, f)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#load Model</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;save/clf.pickle&#x27;</span>, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    clf2 = pickle.load(f)</span><br><span class=\"line\">    <span class=\"comment\">#test loaded Model</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(clf2.predict(X[<span class=\"number\">0</span>:<span class=\"number\">1</span>]))</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>joblib (supposed to be faster when dealing with a large data, because the use of multiprocessing)</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib <span class=\"comment\">#jbolib模块</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)</span></span><br><span class=\"line\">joblib.dump(clf, <span class=\"string\">&#x27;save/clf.pkl&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##load Model</span></span><br><span class=\"line\">clf3 = joblib.load(<span class=\"string\">&#x27;save/clf.pkl&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test loaded Model</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf3.predict(X[<span class=\"number\">0</span>:<span class=\"number\">1</span>]))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"April-29th\"><a href=\"#April-29th\" class=\"headerlink\" title=\"April 29th\"></a>April 29th</h1><h2 id=\"Google-Colab\"><a href=\"#Google-Colab\" class=\"headerlink\" title=\"Google Colab\"></a>Google Colab</h2><p>Get the subscription of Google Colab and Google drive</p>\n<p>clone data to google drive</p>\n<p>Token: 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</p>\n<p>connect Google Colab with VS code</p>\n<h2 id=\"Regularization\"><a href=\"#Regularization\" class=\"headerlink\" title=\"Regularization\"></a>Regularization</h2><p>We can use <strong>regularization</strong> to rescue the overfitting</p>\n<p>There are two types of regularization:</p>\n<ul>\n<li><p><strong>L1 Regularization</strong> (or Lasso Regularization)</p>\n<p>$Min$($$\\sum_{i=1}^{n}{|y_i-w_ix_i|+p\\sum_{i=1}^{n}|w_i|}$$)</p>\n</li>\n<li><p><strong>L2 Regularization</strong> (or Ridge Regularization)</p>\n<p>$Min$($$\\sum_{i=1}^{n}{(y_i-w_ix_i)^2+p\\sum_{i=1}^{n}w_i^2}$$)</p>\n</li>\n</ul>\n<p>where <code>p</code> is the tuning parameter which decides in what extent we want to penalize the model.</p>\n<p>However, there is another method for combination</p>\n<ul>\n<li><strong>Elastic Net:</strong> When L1 and L2 regularization combine together, it becomes the elastic net method, it adds a hyperparameter.</li>\n</ul>\n<p>how to select:</p>\n<table>\n<thead>\n<tr>\n<th><strong>No</strong></th>\n<th><strong>L1 Regularization</strong></th>\n<th><strong>L2 Regularization</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1</strong></td>\n<td>Panelises the sum of absolute value of weights.</td>\n<td>Penalises the sum of square weights.</td>\n</tr>\n<tr>\n<td><strong>2</strong></td>\n<td>It has a sparse solution.</td>\n<td>It has a non-sparse solution.</td>\n</tr>\n<tr>\n<td><strong>3</strong></td>\n<td>It gives multiple solutions.</td>\n<td>It has only one solution.</td>\n</tr>\n<tr>\n<td><strong>4</strong></td>\n<td>Constructed in feature selection.</td>\n<td>No feature selection.</td>\n</tr>\n<tr>\n<td><strong>5</strong></td>\n<td>Robust to outliers.</td>\n<td>Not robust to outliers.</td>\n</tr>\n<tr>\n<td><strong>6</strong></td>\n<td>It generates simple and interpretable models.</td>\n<td>It gives more accurate predictions when the output variable is the function of whole input variables.</td>\n</tr>\n<tr>\n<td><strong>7</strong></td>\n<td>Unable to learn complex data patterns.</td>\n<td>Able to learn complex data patterns.</td>\n</tr>\n<tr>\n<td><strong>8</strong></td>\n<td>Computationally inefficient over non-sparse conditions.</td>\n<td>Computationally efficient because of having analytical solutions.</td>\n</tr>\n</tbody></table>\n<h2 id=\"Normalization\"><a href=\"#Normalization\" class=\"headerlink\" title=\"Normalization\"></a>Normalization</h2><p>The reason for applying normalization is the normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance.</p>\n<p> <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171958842.gif\" alt=\"img\"></p>\n<p>where m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1</p>\n<h3 id=\"Question\"><a href=\"#Question\" class=\"headerlink\" title=\"Question:\"></a>Question:</h3><p>which layer should I apply the regularization?</p>\n<p>From the model’s summary, I can determine which layers have the most parameters. It is better to apply regularization to the layers with the highest parameters.</p>\n<p>In the above case, how to get each layer’s parameters?</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> prettytable <span class=\"keyword\">import</span> PrettyTable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">count_parameters</span>(<span class=\"params\">model</span>):</span><br><span class=\"line\">    table = PrettyTable([<span class=\"string\">&quot;Modules&quot;</span>, <span class=\"string\">&quot;Parameters&quot;</span>])</span><br><span class=\"line\">    total_params = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name, parameter <span class=\"keyword\">in</span> model.named_parameters():</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> parameter.requires_grad: <span class=\"keyword\">continue</span></span><br><span class=\"line\">        params = parameter.numel()</span><br><span class=\"line\">        table.add_row([name, params])</span><br><span class=\"line\">        total_params+=params</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(table)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Total Trainable Params: <span class=\"subst\">&#123;total_params&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> total_params</span><br><span class=\"line\">    </span><br><span class=\"line\">count_parameters(model)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"May-2nd\"><a href=\"#May-2nd\" class=\"headerlink\" title=\"May 2nd\"></a>May 2nd</h1><h2 id=\"Question-ahead\"><a href=\"#Question-ahead\" class=\"headerlink\" title=\"Question ahead:\"></a>Question ahead:</h2><p>get a question: how to determine the classifier centre (windows width)? </p>\n<p>for this case, it is around 20 to be at the middle/ top</p>\n<p>GPU accelerations</p>\n<p>It could be a little bit tricky to accelerate the calculation in sklearn with GPU. Here is a possible solution: <a href=\"https://developer.nvidia.com/blog/scikit-learn-tutorial-beginners-guide-to-gpu-accelerating-ml-pipelines/\">https://developer.nvidia.com/blog/scikit-learn-tutorial-beginners-guide-to-gpu-accelerating-ml-pipelines/</a>.  </p>\n<h2 id=\"Third-meeting\"><a href=\"#Third-meeting\" class=\"headerlink\" title=\"Third meeting:\"></a>Third meeting:</h2><p>Deep learning might be the solution for MEG signals classification. </p>\n<p>The CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018)</p>\n<blockquote>\n<p>Khan, S., Rahmani, H., Shah, S. A. A., &amp; Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. <em>A Guide to Convolutional Neural Networks for Computer Vision</em>. <a href=\"https://doi.org/10.1007/978-3-031-01821-3\">https://doi.org/10.1007/978-3-031-01821-3</a></p>\n<p>Valueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., &amp; Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. <em>Mathematics and Computers in Simulation</em>, <em>177</em>, 232–243. <a href=\"https://doi.org/10.1016/J.MATCOM.2020.04.031\">https://doi.org/10.1016/J.MATCOM.2020.04.031</a></p>\n<p>Bai, S., Kolter, J. Z., &amp; Koltun, V. (2018). <em>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</em>. <a href=\"https://doi.org/10.48550/arxiv.1803.01271\">https://doi.org/10.48550/arxiv.1803.01271</a></p>\n</blockquote>\n<p>possible deep learning packages:</p>\n<p>JAX, HAIKU</p>\n<p>My aim is to inform bad-performance data with the training model of good-performance data in aims to increase the performance. One hallmark is to increase the mean accuracy of each cases as high as possible.</p>\n<h1 id=\"May-3rd\"><a href=\"#May-3rd\" class=\"headerlink\" title=\"May 3rd\"></a>May 3rd</h1><p>Successfully run the code for confusion matrix.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">clf.set_params(**random_search.best_params_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get predictions with 5 fold CV</span></span><br><span class=\"line\">y_pred = cross_val_predict(clf, X, y, cv=confusion_matrix_cv)</span><br><span class=\"line\">mean_conf_mat = confusion_matrix(y, y_pred)</span><br><span class=\"line\">mean_accuracy = accuracy_score(y[y != <span class=\"number\">99</span>], y_pred[y != <span class=\"number\">99</span>])</span><br><span class=\"line\">mean_conf_mat = mean_conf_mat.astype(<span class=\"string\">&#x27;float&#x27;</span>) / mean_conf_mat.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">1</span>)  <span class=\"comment\"># normalise</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Mean accuracy = &#123;0&#125;&quot;</span>.<span class=\"built_in\">format</span>(mean_accuracy))</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># Plot mean confusion matrix</span></span><br><span class=\"line\"><span class=\"comment\">#plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title=&#x27;Normalised confusion matrix, accuracy = &#123;0&#125;&#x27;.format(np.round(mean_accuracy, 2)))</span></span><br><span class=\"line\"><span class=\"comment\">#plt.imshow(mean_conf_mat[:n_stim, :n_stim])</span></span><br><span class=\"line\"></span><br><span class=\"line\">ConfusionMatrixDisplay.from_predictions(y, y_pred)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">&#x27;./save_folder/fig-&#123;&#125;.png&#x27;</span>.<span class=\"built_in\">format</span>(session_id), dpi=<span class=\"number\">600</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<p>pictures of each case are stored in the Github depository: </p>\n<p><a href=\"https://github.com/ReveRoyl/MT_ML_Decoding/tree/main/Aversive_state_reactivation/notebooks/templates/save_folder\">https://github.com/ReveRoyl/MT_ML_Decoding/tree/main/Aversive_state_reactivation/notebooks/templates/save_folder</a></p>\n<p>It takes around 36 minutes to run 28 cases. </p>\n<p>Mean accuracy with existing code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[<span class=\"number\">0.4288888888888889</span>, <span class=\"number\">0.33666666666666667</span>, <span class=\"number\">0.2777777777777778</span>, <span class=\"number\">0.5022222222222222</span>, <span class=\"number\">0.5066666666666667</span>, <span class=\"number\">0.4245810055865922</span>, <span class=\"number\">0.5577777777777778</span>, <span class=\"number\">0.43222222222222223</span>, <span class=\"number\">0.65</span>, <span class=\"number\">0.47888888888888886</span>, <span class=\"number\">0.3377777777777778</span>, <span class=\"number\">0.4800469483568075</span>, <span class=\"number\">0.27111111111111114</span>, <span class=\"number\">0.37193763919821826</span>, <span class=\"number\">0.4288888888888889</span>, <span class=\"number\">0.40555555555555556</span>, <span class=\"number\">0.46444444444444444</span>, <span class=\"number\">0.7077777777777777</span>, <span class=\"number\">0.5811111111111111</span>, <span class=\"number\">0.4711111111111111</span>, <span class=\"number\">0.4255555555555556</span>, <span class=\"number\">0.5022222222222222</span>, <span class=\"number\">0.45394006659267483</span>, <span class=\"number\">0.38555555555555554</span>, <span class=\"number\">0.6222222222222222</span>, <span class=\"number\">0.4622222222222222</span>, <span class=\"number\">0.35444444444444445</span>, <span class=\"number\">0.47444444444444445</span>]</span><br></pre></td></tr></table></figure>\n<h1 id=\"May-10th\"><a href=\"#May-10th\" class=\"headerlink\" title=\"May 10th\"></a>May 10th</h1><p>Get rid of the effect of null data</p>\n<p>transform X into the same size as clf</p>\n<h1 id=\"May-11th\"><a href=\"#May-11th\" class=\"headerlink\" title=\"May 11th\"></a>May 11th</h1><h2 id=\"Grid-Search-CV\"><a href=\"#Grid-Search-CV\" class=\"headerlink\" title=\"Grid Search CV\"></a>Grid Search CV</h2><p>To test Grid Search CV instead of Randomized Search CV</p>\n<p>However, the result of grid search CV is worse than the randomized search CV. I think the reason is that random search CV uses a random combination of hyperparameters to find the best solution for a built model. However, the random search CV is not 100% better than grid search CV: the disadvantage of random search is that it produces high variance during computation.</p>\n<h2 id=\"Concatenation\"><a href=\"#Concatenation\" class=\"headerlink\" title=\"Concatenation\"></a>Concatenation</h2><h3 id=\"Objective-5\"><a href=\"#Objective-5\" class=\"headerlink\" title=\"Objective\"></a>Objective</h3><p>Since my aim is to transfer the model prediction of one case to anther, I try to concatenate multiple cases data together to train the model and see what will happen.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">localiser_epochs = mne.read_epochs(os.path.join(output_dir, <span class=\"string\">&#x27;preprocessing&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;&#x27;</span>, <span class=\"string\">&#x27;localiser&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span>).<span class=\"built_in\">format</span>(<span class=\"string\">&#x27;001&#x27;</span>,<span class=\"string\">&#x27;001&#x27;</span>)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> session_id_int <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">2</span>, <span class=\"number\">3</span>):</span><br><span class=\"line\">    session_id = <span class=\"string\">&#x27;&#123;:03d&#125;&#x27;</span>.<span class=\"built_in\">format</span>(session_id_int)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(session_id)</span><br><span class=\"line\">    </span><br><span class=\"line\">    localiser_epochs_unconcatenate = mne.read_epochs(os.path.join(output_dir, <span class=\"string\">&#x27;preprocessing&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;&#x27;</span>, <span class=\"string\">&#x27;localiser&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span>).<span class=\"built_in\">format</span>(session_id,session_id))  </span><br><span class=\"line\">    localiser_epochs_unconcatenate.info = localiser_epochs.info</span><br><span class=\"line\">    localiser_epochs = mne.concatenate_epochs([localiser_epochs, localiser_epochs_unconcatenate]) </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p>Concatenate X np arrays and test, the mean accuracy increases. I test 5 cases.</p>\n<p>Mean accuracy = 0.5111111111111111, while for each cases, previous mean accuracy = 0.43777777777777777; 0.34; 0.2788888888888889; 0.5055555555555555.</p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p>The concatenated data gives a better fit:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205121731546.png\" alt=\"output\"></p>\n<p>However, the generalization ability of this method has not been decided yet till now.</p>\n<h1 id=\"May-12th\"><a href=\"#May-12th\" class=\"headerlink\" title=\"May 12th\"></a>May 12th</h1><p>add ‘participant number’ dimension to X</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_4D = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> session_id_int <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>):</span><br><span class=\"line\">    session_id = <span class=\"string\">&#x27;&#123;:03d&#125;&#x27;</span>.<span class=\"built_in\">format</span>(session_id_int)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(session_id)</span><br><span class=\"line\">    <span class=\"comment\"># Get data</span></span><br><span class=\"line\">    localiser_epochs = mne.read_epochs(os.path.join(output_dir, <span class=\"string\">&#x27;preprocessing&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;&#x27;</span>, <span class=\"string\">&#x27;localiser&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span>).<span class=\"built_in\">format</span>(session_id,session_id))  </span><br><span class=\"line\">    </span><br><span class=\"line\">    X_raw = localiser_epochs.get_data()</span><br><span class=\"line\">    </span><br><span class=\"line\">    picks_meg = mne.pick_types(localiser_epochs.info, meg=<span class=\"literal\">True</span>, ref_meg=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    event_selector = (y_raw &lt; n_stim * <span class=\"number\">2</span> + <span class=\"number\">1</span>)</span><br><span class=\"line\">    X_raw = X_raw[event_selector, ...]</span><br><span class=\"line\">    X_raw = X_raw[:, picks_meg, :]</span><br><span class=\"line\">    X = X_raw.copy()</span><br><span class=\"line\">    X = X[..., classifier_center_idx + classifier_window[<span class=\"number\">0</span>]:classifier_center_idx + classifier_window[<span class=\"number\">1</span>]] </span><br><span class=\"line\"></span><br><span class=\"line\">    X_4D.append(X)</span><br><span class=\"line\"><span class=\"comment\"># for epoch in localiser_epochs_concatenate:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(epoch.shape)</span></span><br><span class=\"line\"><span class=\"comment\"># localiser_epochs = mne.concatenate_epochs(localiser_epochs_concatenate)</span></span><br><span class=\"line\">X = np.stack(X_4D)</span><br></pre></td></tr></table></figure>\n\n<p>It takes me 1 hour to make the code logical elegant.</p>\n<h1 id=\"May-13th\"><a href=\"#May-13th\" class=\"headerlink\" title=\"May 13th\"></a>May 13th</h1><h2 id=\"Forth-meeting\"><a href=\"#Forth-meeting\" class=\"headerlink\" title=\"Forth meeting\"></a>Forth meeting</h2><h3 id=\"Objective-6\"><a href=\"#Objective-6\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>We have tested existing code, the following step is to try different models to predict.</p>\n<p>My supervisor’s suggestion is to use haiku trying CNN.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install -upgrade jax optax dm-haiku </span><br></pre></td></tr></table></figure>\n\n<p>to be learnt: </p>\n<p>active function: rectifier RELU</p>\n<h3 id=\"Result-1\"><a href=\"#Result-1\" class=\"headerlink\" title=\"Result:\"></a>Result:</h3><p>New model selection: CNN with Haiku</p>\n<h1 id=\"May-14th\"><a href=\"#May-14th\" class=\"headerlink\" title=\"May 14th\"></a>May 14th</h1><p>Find a  bug: concatenated data was not giving a correct result. The better performance was because of the randomness of every time training. The concatenated data won’t give a better prediction. </p>\n<p>possible solution: transfer learning instead of directly concatenation.</p>\n<h1 id=\"May-16th\"><a href=\"#May-16th\" class=\"headerlink\" title=\"May 16th\"></a>May 16th</h1><h3 id=\"Objective-7\"><a href=\"#Objective-7\" class=\"headerlink\" title=\"Objective\"></a>Objective</h3><p>to learning deep learning courses (Andrew Ng) in coursera because as said in ‘Knife don’t miss your job’, to solid the foundation of deep learning will help me build the CNN and understand others’ work</p>\n<h3 id=\"Result-2\"><a href=\"#Result-2\" class=\"headerlink\" title=\"Result:\"></a>Result:</h3><p>In the context of artificial neural networks, the rectifier or ReLU (Rectified Linear Unit) activation function is an activation function defined as the positive part of its argument.</p>\n<h4 id=\"Convolution\"><a href=\"#Convolution\" class=\"headerlink\" title=\"Convolution\"></a>Convolution</h4><p>Types of layer in a CNN:</p>\n<ul>\n<li>Covolution</li>\n<li>Pooling</li>\n<li>Fully connected </li>\n</ul>\n<p>Cases:</p>\n<p>Classic networks: </p>\n<ul>\n<li>LeNet-5</li>\n<li>AlexNet</li>\n<li>VGG</li>\n</ul>\n<p>ResNet</p>\n<p>Inception</p>\n<p>LeNet -5 </p>\n<h1 id=\"May-17th\"><a href=\"#May-17th\" class=\"headerlink\" title=\"May 17th\"></a>May 17th</h1><h2 id=\"Learning-JAX\"><a href=\"#Learning-JAX\" class=\"headerlink\" title=\"Learning JAX\"></a>Learning JAX</h2><p><strong>Question: why jax has its own numpy type: jax.numpy? what is the difference between it and numpy?</strong></p>\n<p>Jax.numpy is a little bit different from numpy: the former is immutable</p>\n<p><strong>Question: why do we need jax.numpy?</strong> </p>\n<p>because numpy only works on CPU while jax.numpy works on GPU</p>\n<p><strong>another advantage of JAX</strong></p>\n<p><code>jit()</code> can be used to compile the data input thus makes the program run faster</p>\n<h2 id=\"First-group-meeting\"><a href=\"#First-group-meeting\" class=\"headerlink\" title=\"First group meeting\"></a>First group meeting</h2><p>Yiqi introduced his recent work which is based on U-net, VAE</p>\n<h1 id=\"May-18th\"><a href=\"#May-18th\" class=\"headerlink\" title=\"May 18th\"></a>May 18th</h1><h2 id=\"Learning-JAX-1\"><a href=\"#Learning-JAX-1\" class=\"headerlink\" title=\"Learning JAX\"></a>Learning JAX</h2><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">grad() <span class=\"comment\"># for differentation</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> jax <span class=\"keyword\">import</span> jacfwd, jacrev <span class=\"comment\"># for Jacobian matrix</span></span><br><span class=\"line\">vmap() <span class=\"comment\"># for vectorization; it can makes you write your functions as if you were dealing wiht a single datapoint</span></span><br></pre></td></tr></table></figure>\n\n<p>JAX API structure</p>\n<ul>\n<li>NumPy &lt;-&gt; lax &lt;-&gt; XLA</li>\n<li>lax API is stricter and more powerful</li>\n<li>It’s a Python wrapper around XLA</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221751704.svg\" alt=\"nn\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CNN</span>(hk.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__(name=<span class=\"string\">&quot;CNN&quot;</span>)</span><br><span class=\"line\">        <span class=\"comment\"># self.conv1 = hk.Conv2D(output_channels=32, kernel_shape=(3,3), padding=&quot;SAME&quot;)</span></span><br><span class=\"line\">        <span class=\"comment\"># self.conv2 = hk.Conv2D(output_channels=16, kernel_shape=(3,3), padding=&quot;SAME&quot;)</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv1 = hk.Conv2D(output_channels=<span class=\"number\">64</span>, kernel_shape=(<span class=\"number\">11</span>,<span class=\"number\">11</span>), stride=<span class=\"number\">4</span>, padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv2 = hk.Conv2D(output_channels=<span class=\"number\">192</span>, kernel_shape=(<span class=\"number\">5</span>,<span class=\"number\">5</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv3 = hk.Conv2D(output_channels=<span class=\"number\">384</span>, kernel_shape=(<span class=\"number\">3</span>,<span class=\"number\">3</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv4 = hk.Conv2D(output_channels=<span class=\"number\">256</span>, kernel_shape=(<span class=\"number\">3</span>,<span class=\"number\">3</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv5 = hk.Conv2D(output_channels=<span class=\"number\">256</span>, kernel_shape=(<span class=\"number\">3</span>,<span class=\"number\">3</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.flatten = hk.Flatten()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.linear = hk.Linear(<span class=\"built_in\">len</span>(classes))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__call__</span>(<span class=\"params\">self, x_batch</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv1(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = hk.MaxPool(window_shape=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), strides=(<span class=\"number\">2</span>, <span class=\"number\">2</span>), padding=<span class=\"string\">&#x27;VALID&#x27;</span>)(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv2(x)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = hk.MaxPool(window_shape=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), strides=(<span class=\"number\">2</span>, <span class=\"number\">2</span>), padding=<span class=\"string\">&#x27;VALID&#x27;</span>)(x)        </span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv3(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv4(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv5(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = hk.MaxPool(window_shape=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), strides=<span class=\"number\">2</span>, padding=<span class=\"string\">&#x27;VALID&#x27;</span>)(x)</span><br><span class=\"line\">        <span class=\"comment\"># x = hk.AvgPool(window_shape=(6, 6), strides=(2, 2), padding=&#x27;SAME&#x27;)(x)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.flatten(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.linear(x)</span><br><span class=\"line\">        x = jax.nn.softmax(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"May-19th\"><a href=\"#May-19th\" class=\"headerlink\" title=\"May 19th\"></a>May 19th</h1><h2 id=\"Test-CNN\"><a href=\"#Test-CNN\" class=\"headerlink\" title=\"Test CNN\"></a>Test CNN</h2><p>CNN test was run but the prediction result is not as good as expected: </p>\n<p>the performance of it is about 0.4 for training dataset and 0.15 for test dataset. </p>\n<p>I think we should try to tune the parameters of model or test a different model since the current model is suitable for image recognition. Before that, literature reviews should be done. </p>\n<p>Later after I read Aoe’s work, I start to under stand it is because my image classification CNN model fails to extract the temporal and spatial information. </p>\n<blockquote>\n<p>Aoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., &amp; Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. <em>Scientific Reports</em>, <em>9</em>(1). <a href=\"https://doi.org/10.1038/S41598-019-41500-X\">https://doi.org/10.1038/S41598-019-41500-X</a></p>\n</blockquote>\n<h2 id=\"Fifth-meeting\"><a href=\"#Fifth-meeting\" class=\"headerlink\" title=\"Fifth meeting\"></a>Fifth meeting</h2><p>I have the requirement of visualization during training: </p>\n<p>To use Tensor Board to show the training process</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">!rm -rf /logs/ <span class=\"comment\"># clear logs</span></span><br><span class=\"line\"><span class=\"comment\"># if &#x27;google.colab&#x27; in str(get_ipython()): # tensor board</span></span><br><span class=\"line\">%load_ext tensorboard  </span><br><span class=\"line\"><span class=\"comment\"># %tensorboard --logdir logs</span></span><br><span class=\"line\">%tensorboard --logdir=./models/test</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"May-20th\"><a href=\"#May-20th\" class=\"headerlink\" title=\"May 20th\"></a>May 20th</h1><h2 id=\"Tried-AlexNet-can-be-easily-get-from-Pytorch-hub\"><a href=\"#Tried-AlexNet-can-be-easily-get-from-Pytorch-hub\" class=\"headerlink\" title=\"Tried AlexNet (can be easily get from Pytorch hub)\"></a>Tried AlexNet (can be easily get from Pytorch hub)</h2><p>AlexNet</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">AlexNet  = torch.hub.load(<span class=\"string\">&#x27;pytorch/vision:v0.10.0&#x27;</span>, <span class=\"string\">&#x27;alexnet&#x27;</span>, pretrained=<span class=\"literal\">True</span>).cuda()</span><br></pre></td></tr></table></figure>\n\n<p>Resnet 18</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Resnet   = torch.hub.load(<span class=\"string\">&#x27;pytorch/vision:v0.10.0&#x27;</span>, <span class=\"string\">&#x27;resnet18&#x27;</span>, pretrained=<span class=\"literal\">True</span>).cuda()</span><br></pre></td></tr></table></figure>\n\n<p>These 2 models fail as well. The same reason: these models fail to extract the temporal and spatial information in the first convolutional layers.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221758352.png\" alt=\"image-20220722175851266\"></p>\n<h2 id=\"Sixth-meeting\"><a href=\"#Sixth-meeting\" class=\"headerlink\" title=\"Sixth meeting\"></a>Sixth meeting</h2><h3 id=\"Objective-8\"><a href=\"#Objective-8\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to discuss about that if we should use concatenate data and pre-processing for standardization because the conditions of recording may varies a lot among different subjects: the device position or potential individual reasons.</p>\n<h3 id=\"Results-5\"><a href=\"#Results-5\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>Dr. Toby and I had a discussion together with Dr. Rossalin </p>\n<p>Rossalin advices me to try transfer learning or LSTM.</p>\n<p>After trying the model is usually used in image classification, it is a good idea to try the model LSTM RNN, which is known as a good fit for sequential data.</p>\n<h1 id=\"May-24th\"><a href=\"#May-24th\" class=\"headerlink\" title=\"May 24th\"></a>May 24th</h1><h2 id=\"Second-group-meeting\"><a href=\"#Second-group-meeting\" class=\"headerlink\" title=\"Second group meeting\"></a>Second group meeting</h2><p>Zarc gives a presentation about his NLP project.</p>\n<h1 id=\"May-27th\"><a href=\"#May-27th\" class=\"headerlink\" title=\"May 27th\"></a>May 27th</h1><h2 id=\"Learning-Tensorflow\"><a href=\"#Learning-Tensorflow\" class=\"headerlink\" title=\"Learning Tensorflow\"></a>Learning Tensorflow</h2><p>Tensorflow is a more popular packages which allows me to get access to many templates. Some research is also using Tensorflow as their machine learning library. But I found Pytorch is a more popular packages which allows me to get access to more well-known templates. Most related research is using Pytorch as their machine learning library.</p>\n<p>However, I found the variable and  placeholder operations are more commonly used in Tensorflow-v1 rather than the latest  Tensorflow-v1</p>\n<h3 id=\"Session-control\"><a href=\"#Session-control\" class=\"headerlink\" title=\"Session control\"></a>Session control</h3><p>In Tensorflow, a string is defined as a variable, and it is a variable, which is different from Python. (later on I found it was correct in Tensorflow v1 but changes in Tensorflow v2)</p>\n<p> <code>state = tf.Variable()</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">state = tf.Variable(<span class=\"number\">0</span>, name=<span class=\"string\">&#x27;counter&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define variable one</span></span><br><span class=\"line\">one = tf.constant(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define plus step (hint: no computation here)</span></span><br><span class=\"line\">new_value = tf.add(state, one)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># update State to new_value</span></span><br><span class=\"line\">update = tf.assign(state, new_value)</span><br></pre></td></tr></table></figure>\n\n<p>If I set variables in Tensorflow, initializing the variables is the most important thing! ! So after defining the variable, be sure to define <code>init = tf.initialize_all_variables()</code>.</p>\n<p>At this point, the variable is still not activated, and it needs to be added in <code>sess</code> , <code>sess.run(init)</code> , to activate<code>init</code>. (again, it changes in v2, we do not need to initialize the session in Tensorflow v2)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Variable, initialize</span></span><br><span class=\"line\"><span class=\"comment\"># init = tf.initialize_all_variables() # expired</span></span><br><span class=\"line\">init = tf.global_variables_initializer()  </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># Session</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">        sess.run(update)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(sess.run(state))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>Note: directly <code>print(state)</code> does not work! !</p>\n<p>Be sure to point the <code>sess</code> pointer to <code>state</code> and then <code>print</code> to get the desired result!</p>\n<h3 id=\"placeholder\"><a href=\"#placeholder\" class=\"headerlink\" title=\"placeholder\"></a>placeholder</h3><p><code>placeholder</code> is a placeholder in Tensorflow that temporarily stores variables.</p>\n<p>If Tensorflow wants to pass in data from the outside, it needs to use <code>tf.placeholder()</code>, and then transfer the data in this form <code>sess.run(***, feed_dict={input: **})</code>.</p>\n<p>Examoles：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\"></span><br><span class=\"line\"># Tensorflow requires defining placeholder&#x27;s type, usually float32</span><br><span class=\"line\">input1 = tf.placeholder(tf.float32)</span><br><span class=\"line\">input2 = tf.placeholder(tf.float32)</span><br><span class=\"line\"></span><br><span class=\"line\"># multiply input1 and input2</span><br><span class=\"line\">ouput = tf.multiply(input1, input2)</span><br></pre></td></tr></table></figure>\n\n<p>Next, the work of passing the value is handed over to <code>sess.run()</code>, the value that needs to be passed in is placed in <code>feed_dict={}</code> and corresponds to each <code>input</code> one by one. <code>placeholder</code> and <code>feed_dict={ }</code> are bound together.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with tf.Session() as sess:</span><br><span class=\"line\">    print(sess.run(ouput, feed_dict=&#123;input1: [7.], input2: [2.]&#125;))</span><br><span class=\"line\"># [ 14.]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Activation-function\"><a href=\"#Activation-function\" class=\"headerlink\" title=\"Activation function\"></a>Activation function</h3><p>when there are many layers, be careful to use activation function in case of the <strong>gradient exploding or gradient disappearance</strong>.</p>\n<h1 id=\"May-28th\"><a href=\"#May-28th\" class=\"headerlink\" title=\"May 28th\"></a>May 28th</h1><blockquote>\n<p>Although in the computer vision field convolutional layer often followed by a pooling layer to reduce the data dimension at the expense of information loss, in the scenes of MEG decoding, the size of MEG data is much smaller than the computer vision field. So in order to keep all the information, we don’t use the pooling layer. After the spatial convolutional layer, we use two layers of temporal convolutional layers to extract temporal features, a fully connected layer with dropout operation for feature fusion, and a softmax layer for final classification. (Huang2019)</p>\n</blockquote>\n<p>It is important to select if we should use pooling layers and how many to use.</p>\n<h1 id=\"May-30th\"><a href=\"#May-30th\" class=\"headerlink\" title=\"May 30th\"></a>May 30th</h1><h2 id=\"ML-optimizer\"><a href=\"#ML-optimizer\" class=\"headerlink\" title=\"ML optimizer\"></a>ML optimizer</h2><h3 id=\"Objective-9\"><a href=\"#Objective-9\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to learn how to use and select different optimizer, because it modifies model’s parameters like weights and learning rate, which helps to increase accuracy and reduce overall loss.</p>\n<h3 id=\"Results-6\"><a href=\"#Results-6\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><ul>\n<li>Stochastic Gradient Descent (SGD)</li>\n<li>Momentum</li>\n<li>AdaGrad</li>\n<li>RMSProp</li>\n<li>Adam</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205302233928.png\" alt=\"speedup3\"></p>\n<p>X.shape gives (n_epochs, n_channels, n_times) corresponding to (batches, pixels,channels)  of images</p>\n<p>Apart for optimizer, scheduler may help a lot with providing a dynamic learning rate.</p>\n<h3 id=\"impression\"><a href=\"#impression\" class=\"headerlink\" title=\"impression\"></a>impression</h3><p>As I tried to apply regularization at the same time. It is important to bear in mind, if we give a momentum in SGD (about 0.9), we can easily apply L2 regularization when the weight_decay is larger than 0.</p>\n<h1 id=\"May-31st\"><a href=\"#May-31st\" class=\"headerlink\" title=\"May 31st\"></a>May 31st</h1><h3 id=\"Objective-10\"><a href=\"#Objective-10\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to learn data augmentation and learn a important rule: “No free lunch theorem”</p>\n<h3 id=\"Results-7\"><a href=\"#Results-7\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>D. H. Wolpert et. al. (1995) come up with “No free lunch theorem”: all optimization algorithms perform equally well when their performance is averaged across all possible problems.</p>\n<p>For any prediction function, if it performs well on some training samples, it must perform poorly on other training samples. If there are certain assumptions about the prior distribution of the data in the feature space, there are as many good and bad performances.</p>\n<p>Later I found relative power spectrum including delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz), provide important information to augmenting the MEG data.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train_numpy = X_train_tensors.cpu().numpy()</span><br><span class=\"line\">X_test_numpy = X_test_tensors.cpu().numpy()</span><br><span class=\"line\"></span><br><span class=\"line\">X = np.swapaxes(X_train_numpy, <span class=\"number\">2</span>, -<span class=\"number\">1</span>).squeeze()</span><br><span class=\"line\">data = X[X.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>, <span class=\"number\">70</span>, :]</span><br><span class=\"line\">psd_mne, freqs_mne = psd_array_welch(data, <span class=\"number\">100</span>, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                          n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> low, high <span class=\"keyword\">in</span> [(<span class=\"number\">0.5</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">12</span>), (<span class=\"number\">12</span>, <span class=\"number\">30</span>),</span><br><span class=\"line\">                  (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;processing bands (low, high) : (&#123;&#125;,&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(low, high))</span><br><span class=\"line\">    <span class=\"comment\"># Find intersecting values in frequency vector</span></span><br><span class=\"line\">    idx_delta = np.logical_and(freqs_mne &gt;= low, freqs_mne &lt;= high)</span><br><span class=\"line\">      <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs_mne[<span class=\"number\">1</span>] - freqs_mne[<span class=\"number\">0</span>]  <span class=\"comment\"># = 1 / 4 = 0.25</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute the absolute power by approximating the area under the curve</span></span><br><span class=\"line\">    power = simps(psd_mne[idx_delta], dx=freq_res)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Absolute power: &#123;:.4f&#125; uV^2&#x27;</span>.<span class=\"built_in\">format</span>(power))</span><br><span class=\"line\">    </span><br><span class=\"line\">    total_power = simps(psd_mne, dx=freq_res)</span><br><span class=\"line\">    rel_power = power / total_power</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Relative power: &#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(rel_power))</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Jun-1st\"><a href=\"#Jun-1st\" class=\"headerlink\" title=\"Jun 1st\"></a>Jun 1st</h1><h2 id=\"Seventh-meeting\"><a href=\"#Seventh-meeting\" class=\"headerlink\" title=\"Seventh meeting\"></a>Seventh meeting</h2><p>Dr Toby provide me the code to load data with dataloader</p>\n<p>it defines load_MEG_dataset function with following parameters: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_MEG_dataset</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">        subject_ids: <span class=\"type\">List</span>[<span class=\"built_in\">str</span>],</span></span><br><span class=\"line\"><span class=\"params\">        mode: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;individual&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        output_format: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;numpy&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        trial_data_format: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;2D&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        data_location: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;./data/&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        center_timepoint: <span class=\"built_in\">int</span> = <span class=\"number\">20</span>,</span></span><br><span class=\"line\"><span class=\"params\">        window_width: <span class=\"type\">List</span>[<span class=\"built_in\">int</span>] = [-<span class=\"number\">400</span>, <span class=\"number\">400</span>],</span></span><br><span class=\"line\"><span class=\"params\">        shuffle: <span class=\"built_in\">bool</span> = <span class=\"literal\">False</span>,</span></span><br><span class=\"line\"><span class=\"params\">        pca_n_components: <span class=\"built_in\">int</span> = <span class=\"literal\">None</span>,</span></span><br><span class=\"line\"><span class=\"params\">        training: <span class=\"built_in\">bool</span> = <span class=\"literal\">True</span>,</span></span><br><span class=\"line\"><span class=\"params\">        train_test_split: <span class=\"built_in\">float</span> = <span class=\"number\">0.75</span>,</span></span><br><span class=\"line\"><span class=\"params\">        batch_size: <span class=\"built_in\">int</span> = <span class=\"number\">32</span>,</span></span><br><span class=\"line\"><span class=\"params\">        scale: <span class=\"built_in\">bool</span> = <span class=\"literal\">True</span>,</span></span><br><span class=\"line\"><span class=\"params\">        seed: <span class=\"built_in\">int</span> = <span class=\"number\">0</span>,</span></span><br><span class=\"line\"><span class=\"params\">    </span>)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Jun-6th\"><a href=\"#Jun-6th\" class=\"headerlink\" title=\"Jun 6th\"></a>Jun 6th</h1><h3 id=\"Objective-11\"><a href=\"#Objective-11\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try different loss function, because different evaluating methods may affect the learning process, and lead to a different approach to training results.</p>\n<h3 id=\"Results-8\"><a href=\"#Results-8\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>when apply other loss function instead of CrossEntropy, there are some format error occurs:</p>\n<p>solution: transform inputs from multi hot coding into one hot coding. </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">onehot</span>(<span class=\"params\">batches, n_classes, y</span>):</span><br><span class=\"line\">  yn = torch.zeros(batches, n_classes)</span><br><span class=\"line\">  <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(batches):</span><br><span class=\"line\">    x = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(batches)]</span><br><span class=\"line\">    x[i] = y[i]/<span class=\"number\">2</span>-<span class=\"number\">1</span>                     <span class=\"comment\">#ex. [12]-&gt; [5]</span></span><br><span class=\"line\">    yn[i][<span class=\"built_in\">int</span>(x[i])]+= <span class=\"number\">1</span>                  <span class=\"comment\">#[000010000]</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> yn</span><br></pre></td></tr></table></figure>\n\n<p>Later I found that we can use the function in Pytorch: F.onehot</p>\n<h1 id=\"Jun-7th\"><a href=\"#Jun-7th\" class=\"headerlink\" title=\"Jun 7th\"></a>Jun 7th</h1><p>try different models, reshape the data from [batches, channels, times point ]to be [batches, times point, channels] in corresponding to images format [batches, picture channels (layers), pixels] (not the same channels, the same names but different meanings, former one is electrode channels. latter one is picture layers)</p>\n<h1 id=\"Jun-8th\"><a href=\"#Jun-8th\" class=\"headerlink\" title=\"Jun 8th\"></a>Jun 8th</h1><h2 id=\"Third-session-meeting\"><a href=\"#Third-session-meeting\" class=\"headerlink\" title=\"Third session meeting\"></a>Third session meeting</h2><h3 id=\"Objective-12\"><a href=\"#Objective-12\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to learn the key points of writing a good introduction</p>\n<h3 id=\"Results-9\"><a href=\"#Results-9\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>from the history of ML to the current meaning </p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> The <strong>history</strong> of <strong>ML</strong>, (black box…)</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> the <strong>history</strong> of disease classification or <strong>behaviour prediction</strong></li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> how people use the ML techniques to <strong>predict  behaviours</strong> these days</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> what is aversive state reactivation (one sentence); why people want to learn aversive state reactivation</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> how people tried to connect ML with aversive state reactivation</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> the problem (gap) is previous model only gives a low prediction accuracy</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Introduction of CNN, LSTM, RNN or transfer learning</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> My aims is to optimize the model with new techniques: CNN, LSTM RNN or transfer learning</li>\n</ul>\n<p>Note: state what in each paragraph is not enough and leads to the next paragraph.</p>\n<h2 id=\"LSTM-RNN\"><a href=\"#LSTM-RNN\" class=\"headerlink\" title=\"LSTM RNN\"></a>LSTM RNN</h2><h3 id=\"Objective-13\"><a href=\"#Objective-13\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>try LSTM RNN</p>\n<h3 id=\"Results-10\"><a href=\"#Results-10\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>The problems when I try to use one hot data <code>labels = F.one_hot(labels)</code>, it is not applicable because in that case the dimensions could be 28 instead of 14 as we only have even numbers,</p>\n<p>Some packages automatically figure out where there missing labels during one hot operation but this one (pytorch) doesn’t</p>\n<h2 id=\"Eighth-meeting\"><a href=\"#Eighth-meeting\" class=\"headerlink\" title=\"Eighth meeting\"></a>Eighth meeting</h2><h3 id=\"questions\"><a href=\"#questions\" class=\"headerlink\" title=\"questions:\"></a>questions:</h3><ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> loss functions give similar values?</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> <del>is it correct to use enumerate to loop each data?</del></li>\n</ul>\n<p>In my case, CrossEntropy is the better for MEG data. It is the experience gained from Dr Toby. Even though I found the others’ research about hands behaviour prediction used MSE loss. It is not suitable for our results because theirs is about the movements while ours is not.</p>\n<h1 id=\"Jun-9th\"><a href=\"#Jun-9th\" class=\"headerlink\" title=\"Jun 9th\"></a>Jun 9th</h1><h2 id=\"Label-noise\"><a href=\"#Label-noise\" class=\"headerlink\" title=\"Label noise.\"></a>Label noise.</h2><h3 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives:\"></a>Objectives:</h3><p>to figure out if labels format it self may affect the model performance. Because some models only accept data in one kind of format. </p>\n<p><strong>question</strong>: how to determine numbers of hidden layers in LSTM RNN.</p>\n<h3 id=\"Results-11\"><a href=\"#Results-11\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>We cannot correctly compare each label when we are using <strong>one-hot format</strong>. If the labels you predict are apples, bananas, and strawberries, obviously they do not directly have a comparison relationship. If we use 1, 2, 3 as labels, there will be a comparison relationship between the labels. Distances are different. With the comparison relationship, the distance between the first label and the last label is too far, which affects the learning of the model.</p>\n<p>One promotion:</p>\n<blockquote>\n<p>Knowledge distillation (KD) improves performance precisely by suppressing this label nosie. Based on this understanding, we introduce a particularly simple improvement method of knowledge disillation, which can significantly improve the performance of ordinary KD by setting different temperatures for each image. </p>\n<p>Xu, K., Rui, L., Li, Y., Gu, L. (2020). <em>Feature Normalized Knowledge Distillation for Image Classification.</em> In: Vedaldi, A., Bischof, H., Brox, T., Frahm, JM. (eds) Computer Vision – ECCV 2020. ECCV 2020. Lecture Notes in Computer Science(), vol 12370. Springer, Cham. <a href=\"https://doi.org/10.1007/978-3-030-58595-2_40\">https://doi.org/10.1007/978-3-030-58595-2_40</a></p>\n</blockquote>\n<p><strong>Hidden layers in LSTM RNN</strong></p>\n<p>The effect of the number of hidden layers for neural networks</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202206120108575.jpeg\" alt=\"img\"></p>\n<h1 id=\"Jun-10th\"><a href=\"#Jun-10th\" class=\"headerlink\" title=\"Jun 10th\"></a>Jun 10th</h1><p>try <code>CrossEntropyLoss()</code> with onehot format data</p>\n<p>convert the labels from “every 2 in 0 to 28” to “every 1 in 1 to 14”</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">y_train = (y_train / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br><span class=\"line\">y_test = (y_test / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n<p>use <code>with torch.autocast(&#39;cuda&#39;)</code> to solve “cuda error” of <code>CrossEntropyLoss()</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> torch.autocast(<span class=\"string\">&#x27;cuda&#x27;</span>):</span><br><span class=\"line\">        <span class=\"comment\"># loss = criterion(outputs, torch.tensor(labels).cuda())</span></span><br><span class=\"line\">            loss = criterion(outputs, labels)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Jun-12th\"><a href=\"#Jun-12th\" class=\"headerlink\" title=\"Jun 12th\"></a>Jun 12th</h1><p>even though the accuracy of prediction for train data increases quickly as training, the accuracy for test data is still very low. It seems the validation loss does not converge. I decide the next step is going to do more literature research and adjust the parameters.</p>\n<h1 id=\"Jun-13th\"><a href=\"#Jun-13th\" class=\"headerlink\" title=\"Jun 13th\"></a>Jun 13th</h1><h3 id=\"Problems\"><a href=\"#Problems\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>the problem is overfitting. There could be 2 alternative options: 1, get more data; 2, try different learning rate or dynamic learning rate.</p>\n<p>the way the train-test split worked wasn’t ideal in the data loading function - because the data wasn’t shuffled prior to splitting, the train and test set would often consist of different subjects if we load multiple subjects. The data can be shuffled before splitting (by setting shuffle=True), which means that there will be a mix of subjects in both the training and testing data. This seems to boost accuracy in the test set a little bit.</p>\n<h1 id=\"Jun-14th\"><a href=\"#Jun-14th\" class=\"headerlink\" title=\"Jun 14th\"></a>Jun 14th</h1><h3 id=\"Objective-14\"><a href=\"#Objective-14\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try <code>CosineEmbeddingLoss()</code> because it is reported that cosine loss may improve the performance for small dataset</p>\n<blockquote>\n<p>Cosine loss could have better performance for small dataset (around 30%). </p>\n<p>Barz, B., &amp; Denzler, J. (2019). Deep Learning on Small Datasets without Pre-Training using Cosine Loss. <em>Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020</em>, 1360–1369. <a href=\"https://doi.org/10.48550/arxiv.1901.09054\">https://doi.org/10.48550/arxiv.1901.09054</a></p>\n</blockquote>\n<h3 id=\"Results-12\"><a href=\"#Results-12\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>however, the performance is not promoted</p>\n<h1 id=\"Jun-15th\"><a href=\"#Jun-15th\" class=\"headerlink\" title=\"Jun 15th\"></a>Jun 15th</h1><h2 id=\"Fourth-session-meeting\"><a href=\"#Fourth-session-meeting\" class=\"headerlink\" title=\"Fourth session meeting\"></a>Fourth session meeting</h2><p>I read others work, practice to extract the key words and main ideas:</p>\n<blockquote>\n<p><em>Affective modulation of the startle response in depression: Influence of the severity of depression, anhedonia and anxiety</em></p>\n</blockquote>\n<p>startle reflex (SR)</p>\n<ol>\n<li>affective rating</li>\n</ol>\n<p>​    get affective rating after participants watched every clips </p>\n<p>​    and analysis the difference between depressed patients and control.</p>\n<ol start=\"2\">\n<li><p>Startle amplitude</p>\n</li>\n<li><p>EMG</p>\n<p>higher baseline EMG activity during pleasant and unpleasant clips, relative to the neutral clips</p>\n</li>\n</ol>\n<p><strong>Conclusion</strong></p>\n<p>a reduced degree of self-reported mood modulation </p>\n<p><strong>Gap</strong></p>\n<p>The findings differ from those of Allen et al. (1999): they think it does not matter for depression or anhedonia for affective and emotional modulation.</p>\n<p><strong>key wards</strong></p>\n<p>Depression</p>\n<p>Anxiety</p>\n<p>Anhedonia</p>\n<p>Affective modulation</p>\n<p>Mood regulation</p>\n<p>Startle response</p>\n<p>EMG</p>\n<p>affective rating</p>\n<h2 id=\"Ninth-meeting\"><a href=\"#Ninth-meeting\" class=\"headerlink\" title=\"Ninth meeting\"></a>Ninth meeting</h2><h3 id=\"Problems-1\"><a href=\"#Problems-1\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>Since the past work does not give a good result and it has been nearly halfway of the project. My following work is suggested to be focused on:</p>\n<ol>\n<li><p>Multilayer Perceptron</p>\n</li>\n<li><p>transfer learning</p>\n</li>\n</ol>\n<h1 id=\"Jun-16th\"><a href=\"#Jun-16th\" class=\"headerlink\" title=\"Jun 16th\"></a>Jun 16th</h1><blockquote>\n<p> <strong>Convolutional Layer</strong> : Consider a convolutional layer which takes “l” feature maps as the input and has “k” feature maps as output. The filter size is “<strong>n*m</strong>”.<br>Here the input has <strong><em>l=32\\</em></strong> feature maps as inputs, <strong><em>k=64\\</em></strong> feature maps as outputs and filter size is <strong><em>n=3 and m=3\\</em></strong>. It is important to understand, that we don’t simply have a 3<em>3 filter, but actually, we have *</em>3*3*32** filter, as our input has 32 dimensions. And as an output from first conv layer, we learn 64 different <strong>3*3*32</strong> filters which total weights is “<strong>n*m*k*l</strong>”. Then there is a term called bias for each feature map. So, the total number of parameters are “<strong>(n*m*l+1)*k</strong>”.</p>\n<p><a href=\"https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\">https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca</a></p>\n</blockquote>\n<p>bicubic interpolation: torch.nn.functional.interpolate() with mode=’bicubic’ </p>\n<blockquote>\n<p><a href=\"https://stackoverflow.com/questions/54083474/bicubic-interpolation-in-pytorch\">https://stackoverflow.com/questions/54083474/bicubic-interpolation-in-pytorch</a></p>\n</blockquote>\n<p>Meeting these data and fitting problems, I realize the insufficiency of understanding data itself, so I look back to the Machine Learning courses materials from 2 years ago, trying to get some new approaches.</p>\n<p>When reading the Chapter 1 of <em>Computational Modelling of Cognition and Behaviour</em>, I get the following points: </p>\n<blockquote>\n<ol>\n<li>Data never speak for themselves but require a model to be understood and to be explained.</li>\n<li>Verbal theorizing alone ultimately cannot replace for quantitative analysis.</li>\n<li>There are always several alternative models that vie for explanation of data and we must select among them.</li>\n<li>Model selection rests on both quantitative evaluation and intellectual and scholarly judgment.</li>\n</ol>\n</blockquote>\n<h1 id=\"June-21th\"><a href=\"#June-21th\" class=\"headerlink\" title=\"June 21th\"></a>June 21th</h1><p>Have a meeting with Eammon, we talked about my recent work:</p>\n<p>Eammon gives me a suggestion: in behaviour level, picture of faces are different. Try and see what if we get rid of the picture of faces in labels.</p>\n<p>Here are the pictures shown to participants: </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221848253.png\" alt=\"image-20220722184848108\"></p>\n<h1 id=\"June-25th\"><a href=\"#June-25th\" class=\"headerlink\" title=\"June 25th\"></a>June 25th</h1><p>to try Mnet (was used to predict the Alzheimer’s disease by Aoe .etc)</p>\n<blockquote>\n<p>Aoe, J., Fukuma, R., Yanagisawa, T. <em>et al.</em> Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. <em>Sci Rep</em> <strong>9,</strong> 5057 (2019). <a href=\"https://doi.org/10.1038/s41598-019-41500-xz\">https://doi.org/10.1038/s41598-019-41500-xz</a></p>\n</blockquote>\n<p>Score method:</p>\n<p>As an alternative option, the accuracy can be expressed as root mean square error. </p>\n<h1 id=\"Jun-27th\"><a href=\"#Jun-27th\" class=\"headerlink\" title=\"Jun 27th\"></a>Jun 27th</h1><h3 id=\"Objective-15\"><a href=\"#Objective-15\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to apply data augmentation because it was reported that relative power spectrum provide extra information which may improve model’s performance on MEG data.</p>\n<h3 id=\"Result-3\"><a href=\"#Result-3\" class=\"headerlink\" title=\"Result:\"></a>Result:</h3><p>one possible solution is to extract band power to augment the data</p>\n<blockquote>\n<p>“This model was implemented to check the proprieties of the RPS to extract meaningful features from the input data. The RPS was combined with an MLP to add nonlinearity and increase the capability of approximate the target variable.”</p>\n<p>The RPS was implemented in 4 steps: </p>\n<ol>\n<li>Compute the modified periodogram using Welch methods (Welch 1967) to get the power spectral density. </li>\n<li>Calculate the average band power approximating using the composite Simpson’s rule to get it for a specific target band. </li>\n<li>Divide the average band power of the specific target band by the total power of the signal to get the relative power spectrum.</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>Anelli, M. (2020). <em>Using Deep learning to predict continuous hand kinematics from Magnetoencephalographic (MEG) measurements of electromagnetic brain activity</em> (Doctoral dissertation, ETSI_Informatica).</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train_bp = np.squeeze(X_train_numpy, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># X_train_bp = X_train_bp[: :, :, :]</span></span><br><span class=\"line\">X_train_bp = standard_scaling_sklearn(X_train_bp)</span><br><span class=\"line\">X_test_bp = np.squeeze(X_test_numpy, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># X_train_bp = X_train_bp[: :, :, :]</span></span><br><span class=\"line\">X_test_bp = standard_scaling_sklearn(X_test_bp)</span><br><span class=\"line\">bands = [(<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">13</span>), (<span class=\"number\">13</span>, <span class=\"number\">30</span>), (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]</span><br><span class=\"line\">bp_train = bandpower_multi_bands(X_train_bp, fs=<span class=\"number\">800.0</span>, bands=bands, relative=<span class=\"literal\">True</span>)</span><br><span class=\"line\">bp_test = bandpower_multi_bands(X_test_bp, fs=<span class=\"number\">800.0</span>, bands=bands, relative=<span class=\"literal\">True</span>)</span><br><span class=\"line\">bp_train_tensor = torch.Tensor(bp_train).cuda()</span><br><span class=\"line\">bp_test_tensor = torch.Tensor(bp_test).cuda()</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"June-28th\"><a href=\"#June-28th\" class=\"headerlink\" title=\"June 28th\"></a>June 28th</h1><h3 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem:\"></a>Problem:</h3><p>My Google Colab subscriptions is expired but luckily I have got the access of HPC in KCL (create)</p>\n<h3 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution:\"></a>Solution:</h3><p>set up cluster as the tutorial: <a href=\"https://docs.er.kcl.ac.uk/CREATE/access/\">https://docs.er.kcl.ac.uk/CREATE/access/</a></p>\n<ol>\n<li>Start an interactive session:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">srun -p gpu --pty -t 6:00:00 --mem=30GB --gres=gpu /bin/bash</span><br></pre></td></tr></table></figure>\n\n<p><strong>Make a note of the node I am connected to, e.g. erc-hpc-comp001</strong></p>\n<p><code>sinfo avail</code> to check the available cores</p>\n<ol start=\"2\">\n<li>start Jupyter lab without the display on a specific port (here this is port 9998)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">jupyter lab --no-browser --port=9998 --ip=&quot;*&quot;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><strong>Open a separate connection</strong> to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 -o ProxyCommand=&quot;ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk&quot; -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Note:<ul>\n<li>k12345678 should be replaced with your username.</li>\n<li>erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running</li>\n<li>9998 should be replaced with the port you specified when running Jupyter lab (using e.g. <code>--port=9998</code>)</li>\n<li>authorize via <a href=\"https://portal.er.kcl.ac.uk/mfa/\">https://portal.er.kcl.ac.uk/mfa/</a></li>\n</ul>\n</li>\n</ul>\n<ol start=\"4\">\n<li><p>Start notebook in <a href=\"http://localhost:9998/lab\">http://localhost:9998/lab</a></p>\n</li>\n<li><p>VS code part: set the Jupyter server as remote :</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">http://localhost:9998/lab?token=XXX</span><br><span class=\"line\"># replace the localhost as erc-hpc-comp031</span><br></pre></td></tr></table></figure>\n\n<p>Note: However, After the latest weekly update, existing problem has been found is the connection via VS code is not stable. Reason could be the dynamic allocated node and port confuses the VS code connection server.</p>\n</li>\n</ol>\n<h1 id=\"June-29th\"><a href=\"#June-29th\" class=\"headerlink\" title=\"June 29th\"></a>June 29th</h1><h3 id=\"Objective-16\"><a href=\"#Objective-16\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try different normalization method: <strong>Z-Score Normalization</strong></p>\n<h3 id=\"Results-13\"><a href=\"#Results-13\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>which maps the raw data to a distribution with mean 0 and standard deviation </p>\n<ol>\n<li>Assuming that the mean of the original feature is μ and the variance is σ , the formula is as follows:</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221914685.png\" alt=\"img\"></p>\n<h1 id=\"July-1th\"><a href=\"#July-1th\" class=\"headerlink\" title=\"July 1th\"></a>July 1th</h1><h3 id=\"Objective-17\"><a href=\"#Objective-17\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try Mnet with band power (RPS Ment); the reason for splitting alpha into low and high is that kinematic show that alpha band significant after movement and beta before movement. It is also reported that gamma band is associated with it is related to synergistic muscle activation (Kolasinski et. al, 2019)</p>\n<blockquote>\n<p>Kolasinski, J., Dima, D. C., Mehler, D. M. A., Stephenson, A., Valadan, S., Kusmia, S., &amp; Rossiter, H. E. (2019). Spatially and temporally distinct encoding of muscle and kinematic information in rostral and caudal primary motor cortex. <em>BioRxiv</em>, 613323. <a href=\"https://doi.org/10.1101/613323\">https://doi.org/10.1101/613323</a></p>\n</blockquote>\n<h3 id=\"Results-14\"><a href=\"#Results-14\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>extract band powers to get a 6 RPS (relative power spectrum) for each frequency period:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bandpower_1d</span>(<span class=\"params\">data, sf, band, nperseg=<span class=\"number\">800</span>, relative=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># band = np.asarray(band)</span></span><br><span class=\"line\">    low, high = band</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute the modified periodogram (Welch)</span></span><br><span class=\"line\">    <span class=\"comment\"># <span class=\"doctag\">TODO:</span> generalize freq values</span></span><br><span class=\"line\">    psd, freqs = psd_array_welch(data, sf, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"built_in\">int</span>(<span class=\"number\">800</span> / <span class=\"number\">2</span>),</span><br><span class=\"line\">                                 n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs[<span class=\"number\">1</span>] - freqs[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Find closest indices of band in frequency vector</span></span><br><span class=\"line\">    idx_band = np.logical_and(freqs &gt;= low, freqs &lt;= high)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Integral approximation of the spectrum using Simpson&#x27;s rule.</span></span><br><span class=\"line\">    bp = simps(psd[idx_band], dx=freq_res)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> relative:</span><br><span class=\"line\">        bp /= simps(psd, dx=freq_res)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> bp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bandpower</span>(<span class=\"params\">x, fs, bands, nperseg=<span class=\"number\">800</span>, relative=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    psd, freqs = psd_array_welch(x, fs, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"built_in\">int</span>(fs/<span class=\"number\">2</span>),</span><br><span class=\"line\">                                 n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs[<span class=\"number\">1</span>] - freqs[<span class=\"number\">0</span>]</span><br><span class=\"line\">    n_channel, _ = x.shape</span><br><span class=\"line\">    bp = np.zeros((n_channel, <span class=\"built_in\">len</span>(bands)))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, band <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(bands):</span><br><span class=\"line\">        low, high = band</span><br><span class=\"line\">        <span class=\"comment\"># Find closest indices of band in frequency vector</span></span><br><span class=\"line\">        idx_band = np.logical_and(freqs &gt;= low, freqs &lt;= high)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Integral approximation of the spectrum using Simpson&#x27;s rule.</span></span><br><span class=\"line\">        _bp = simps(psd[..., idx_band], dx=freq_res, axis=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> relative:</span><br><span class=\"line\">            _bp /= simps(psd, dx=freq_res, axis=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># print(bp.shape, _bp.shape) #272,6  80,272</span></span><br><span class=\"line\">        bp[:, idx] = _bp</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bandpower_multi_bands</span>(<span class=\"params\">x, fs, bands,  nperseg=<span class=\"number\">800</span>, relative=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    </span><br><span class=\"line\">    n_epoch, n_channel, _ = x.shape</span><br><span class=\"line\">    bp = np.zeros((n_epoch, n_channel, <span class=\"built_in\">len</span>(bands)))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n_epoch):</span><br><span class=\"line\">        bp[e] = bandpower(x[e], fs, bands, nperseg=nperseg, relative=relative)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">standard_scaling_sklearn</span>(<span class=\"params\">data</span>):</span><br><span class=\"line\">    </span><br><span class=\"line\">    n_epoch = data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n_epoch):</span><br><span class=\"line\">        scaler = skScaler()</span><br><span class=\"line\">        data[e, ...] = scaler.fit_transform(data[e, ...])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br></pre></td></tr></table></figure>\n\n<p>In main code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X = np.swapaxes(X_train, <span class=\"number\">2</span>, -<span class=\"number\">1</span>).squeeze()</span><br><span class=\"line\">data = X[X.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>, <span class=\"number\">70</span>, :]</span><br><span class=\"line\">psd_mne, freqs_mne = psd_array_welch(data, <span class=\"number\">250</span>, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                          n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> low, high <span class=\"keyword\">in</span> [(<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">13</span>), (<span class=\"number\">13</span>, <span class=\"number\">30</span>),</span><br><span class=\"line\">                  (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;processing bands (low, high) : (&#123;&#125;,&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(low, high))</span><br><span class=\"line\">    <span class=\"comment\"># Find intersecting values in frequency vector</span></span><br><span class=\"line\">    idx_delta = np.logical_and(freqs_mne &gt;= low, freqs_mne &lt;= high)</span><br><span class=\"line\">      <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs_mne[<span class=\"number\">1</span>] - freqs_mne[<span class=\"number\">0</span>]  <span class=\"comment\"># = 1 / 4 = 0.25</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute the absolute power by approximating the area under the curve</span></span><br><span class=\"line\">    power = simps(psd_mne[idx_delta], dx=freq_res)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Absolute power: &#123;:.4f&#125; uV^2&#x27;</span>.<span class=\"built_in\">format</span>(power))</span><br><span class=\"line\">    </span><br><span class=\"line\">    total_power = simps(psd_mne, dx=freq_res)</span><br><span class=\"line\">    rel_power = power / total_power</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Relative power: &#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(rel_power))</span><br><span class=\"line\">    </span><br><span class=\"line\">```</span><br><span class=\"line\">Outputs:</span><br><span class=\"line\">Effective window size : <span class=\"number\">1.024</span> (s)</span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">1</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0610</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.1251</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">4</span>,<span class=\"number\">8</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0315</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.0647</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">8</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0220</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.0452</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">10</span>,<span class=\"number\">13</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0031</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.0064</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">13</span>,<span class=\"number\">30</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0577</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.1184</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">30</span>,<span class=\"number\">70</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.2356</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.4837</span></span><br><span class=\"line\">```</span><br></pre></td></tr></table></figure>\n\n<p>The average power spectrum for all subjects:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172059472.png\" alt=\"image-20220817205940319\"></p>\n<p>The results show that beta and delta waves are in the large and major proportion. It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.</p>\n<blockquote>\n<p>Baumeister, J., Barthel, T., Geiss, K. R., &amp; Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. <em><a href=\"Http://Dx.Doi.Org/10.1179/147683008X301478\">Http://Dx.Doi.Org/10.1179/147683008X301478</a></em>, <em>11</em>(3), 103–110. <a href=\"https://doi.org/10.1179/147683008X301478\">https://doi.org/10.1179/147683008X301478</a></p>\n</blockquote>\n<h3 id=\"Problems-2\"><a href=\"#Problems-2\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>find the initial loss is too huge and does not change afterwards. Guess it is because of too large initial loss or wrongly <code>loss.backward()</code></p>\n<h3 id=\"solution\"><a href=\"#solution\" class=\"headerlink\" title=\"solution:\"></a>solution:</h3><p>parameters of optimizer was set wrongly, fix it with <code>model.parameters()</code></p>\n<h1 id=\"July-2th\"><a href=\"#July-2th\" class=\"headerlink\" title=\"July 2th\"></a>July 2th</h1><h3 id=\"Problems-3\"><a href=\"#Problems-3\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>looking for solution to merge the function</p>\n<p>guess I am meeting “dying ReLU” problem</p>\n<h1 id=\"July-5th\"><a href=\"#July-5th\" class=\"headerlink\" title=\"July 5th\"></a>July 5th</h1><h3 id=\"Objectives-1\"><a href=\"#Objectives-1\" class=\"headerlink\" title=\"Objectives:\"></a>Objectives:</h3><p>to try dynamic learning rate and interpolate 130 time points to be 800 time points without losing too much information.</p>\n<h3 id=\"Solution-1\"><a href=\"#Solution-1\" class=\"headerlink\" title=\"Solution:\"></a>Solution:</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, <span class=\"string\">&#x27;max&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">scheduler.step(acc[-<span class=\"number\">1</span>]) <span class=\"comment\">#at last of each epoch training </span></span><br></pre></td></tr></table></figure>\n\n<p>the update step: I use the dynamic learning rate when the valid loss approaches a plateau (function 4, where <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102154.gif\" alt=\"img\"> represents learning decay and L represents valid loss). </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102153.gif\" alt=\"img\"></p>\n<p>Multilayer perceptron</p>\n<p>interpolate <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html\">https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html</a></p>\n<p>Learning rate scheduling <a href=\"https://pytorch.org/docs/stable/optim.html\">https://pytorch.org/docs/stable/optim.html</a></p>\n<h1 id=\"July-9th\"><a href=\"#July-9th\" class=\"headerlink\" title=\"July 9th\"></a>July 9th</h1><p>In order to make the input data the same shape as required, I use resample function <code>localiser_epochs.copy().resample(800, npad=&#39;auto&#39;)</code> to upsamle the data</p>\n<p>CBAM modules are added because the attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images’ edges. </p>\n<blockquote>\n<p>Attention in Deep Learning, Alex Smola and Aston Zhang, Amazon Web Services (AWS), ICML 2019</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SpatialAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(SpatialAttention, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.compress = ChannelPool()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.spatialAttention = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">7</span>, <span class=\"number\">7</span>, padding=<span class=\"number\">3</span>), <span class=\"comment\">#padding = (7-1)/2</span></span><br><span class=\"line\">            )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;x&#x27;,x.shape)</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.compress(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.spatialAttention(x)</span><br><span class=\"line\">        <span class=\"comment\"># scale = F.sigmoid(x)</span></span><br><span class=\"line\">        scale = torch.sigmoid(x)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> x * scale</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Flatten_MEG</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x.view(x.size(<span class=\"number\">0</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ChannelAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            Implementation of a channel attention module.</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">class</span> <span class=\"title class_\">Showsize</span>(nn.Module):</span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">            <span class=\"built_in\">super</span>(ChannelAttention.Showsize, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">            <span class=\"comment\"># print(x.shape)</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, shape, reduction_factor=<span class=\"number\">16</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">super</span>(ChannelAttention, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">        _, in_channel, h, w = shape</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.mlp = nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># self.Showsize(),</span></span><br><span class=\"line\">            Flatten_MEG(),</span><br><span class=\"line\">            <span class=\"comment\"># self.Showsize(),</span></span><br><span class=\"line\">            nn.Linear(in_channel, in_channel // reduction_factor),</span><br><span class=\"line\">            nn.ReLU(),</span><br><span class=\"line\">            nn.Linear(in_channel // reduction_factor, in_channel),</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        avg_pool = F.avg_pool2d( x, (x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)), stride=(x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)))</span><br><span class=\"line\">        max_pool = F.max_pool2d( x, (x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)), stride=(x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)))</span><br><span class=\"line\">        <span class=\"built_in\">sum</span> = <span class=\"variable language_\">self</span>.mlp(avg_pool) + <span class=\"variable language_\">self</span>.mlp(max_pool)</span><br><span class=\"line\">        scale = (</span><br><span class=\"line\">            torch.sigmoid(<span class=\"built_in\">sum</span>)</span><br><span class=\"line\">            .unsqueeze(<span class=\"number\">2</span>)</span><br><span class=\"line\">            .unsqueeze(<span class=\"number\">3</span>)</span><br><span class=\"line\">            .expand_as(x)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x * scale</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"July-10th\"><a href=\"#July-10th\" class=\"headerlink\" title=\"July 10th\"></a>July 10th</h1><p>In order to find the rationality of extracting features of brain states under different stimuli. I draw the topographical maps of all stimuli at different time. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, my model is an effective and reasonable approach to classifying these states.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">sti=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>,<span class=\"number\">7</span>,<span class=\"number\">8</span>,<span class=\"number\">9</span>,<span class=\"number\">10</span>,<span class=\"number\">11</span>,<span class=\"number\">12</span>,<span class=\"number\">13</span>,<span class=\"number\">14</span>]                     </span><br><span class=\"line\"><span class=\"keyword\">for</span> stimuli <span class=\"keyword\">in</span> <span class=\"built_in\">range</span> (<span class=\"number\">1</span>,<span class=\"number\">15</span>):</span><br><span class=\"line\">    epochs_standard = fname.get_epochs(sub=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> sub <span class=\"keyword\">in</span> [sub <span class=\"keyword\">for</span> sub <span class=\"keyword\">in</span> <span class=\"built_in\">range</span> (<span class=\"number\">2</span>,<span class=\"number\">29</span>) <span class=\"keyword\">if</span> sub <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"number\">6</span>, <span class=\"number\">12</span>, <span class=\"number\">14</span> ,<span class=\"number\">23</span>]]:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sub == <span class=\"number\">1</span>:</span><br><span class=\"line\">            epochs_standard = fname.get_epochs(sub=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            epochs = fname.get_epochs(sub)[<span class=\"string\">&#x27;stimulus_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"number\">2</span>*stimuli)]</span><br><span class=\"line\">            epochs.info[<span class=\"string\">&#x27;dev_head_t&#x27;</span>] = epochs_standard.info[<span class=\"string\">&#x27;dev_head_t&#x27;</span>]</span><br><span class=\"line\">            epochs_standard = mne.concatenate_epochs([epochs_standard[<span class=\"string\">&#x27;stimulus_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"number\">2</span>*stimuli)], epochs[<span class=\"string\">&#x27;stimulus_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"number\">2</span>*stimuli)]])</span><br><span class=\"line\">    <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;evoked_&#123;&#125; = epochs_standard.average()&#x27;</span>.<span class=\"built_in\">format</span>(stimuli))</span><br><span class=\"line\">        <span class=\"comment\"># evoked_standard = mne.concatenate_epochs([evoked_standard, evoked])</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172051592.png\" alt=\"image-20220817205119443\"></p>\n<p>brain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity.</p>\n<h1 id=\"July-12th\"><a href=\"#July-12th\" class=\"headerlink\" title=\"July 12th\"></a>July 12th</h1><p>The random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of my model is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. Compared with the other classification approach, my model exhibits the best classification performance (p = 6.8 × 10 –2 for LSTM RNN, p = 5.9 × 10 –2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of my model is able to reach 33.33%. </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172055038.png\" alt=\"image-20220817205549898\"></p>\n<p>early stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">EarlyStopping</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, patience=<span class=\"number\">7</span>, verbose=<span class=\"literal\">False</span>, delta=<span class=\"number\">0</span>, path=<span class=\"string\">&#x27;checkpoint.pt&#x27;</span>, trace_func=<span class=\"built_in\">print</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.patience = patience</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.verbose = verbose</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.counter = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.best_score = <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.early_stop = <span class=\"literal\">False</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss_min = np.Inf</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.delta = delta</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.path = path</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.trace_func = trace_func</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__call__</span>(<span class=\"params\">self, val_loss, model</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        score = -val_loss</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.best_score <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.best_score = score</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.save_checkpoint(val_loss, model)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> score &lt;= <span class=\"variable language_\">self</span>.best_score + <span class=\"variable language_\">self</span>.delta:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.counter += <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.trace_func(<span class=\"string\">f&#x27;EarlyStopping counter: <span class=\"subst\">&#123;self.counter&#125;</span> out of <span class=\"subst\">&#123;self.patience&#125;</span>&#x27;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.counter &gt;= <span class=\"variable language_\">self</span>.patience:</span><br><span class=\"line\">                <span class=\"variable language_\">self</span>.early_stop = <span class=\"literal\">True</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.best_score = score</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.save_checkpoint(val_loss, model)</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.counter = <span class=\"number\">0</span></span><br><span class=\"line\">            </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">save_checkpoint</span>(<span class=\"params\">self, val_loss, model</span>):</span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;Saves model when validation loss decrease.&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.verbose:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.trace_func(<span class=\"string\">f&#x27;Validation loss decreased (<span class=\"subst\">&#123;self.val_loss_min:<span class=\"number\">.4</span>f&#125;</span> --&gt; <span class=\"subst\">&#123;val_loss:<span class=\"number\">.4</span>f&#125;</span>).  Saving model ...&#x27;</span>)</span><br><span class=\"line\">        torch.save(model.state_dict(), <span class=\"variable language_\">self</span>.path)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss_min = val_loss</span><br></pre></td></tr></table></figure>\n\n<p>However, would early stopping necessarily prevent overfitting? There’s some interesting work showing that if you over-train the model it actually suddenly gets a lot better at some point (an approach referred to as “grokking” for some reason). It may be possible that more training doesn’t necessarily mean worse performance.</p>\n<h1 id=\"July-13th\"><a href=\"#July-13th\" class=\"headerlink\" title=\"July 13th\"></a>July 13th</h1><p>I want to visualize my model and data process steps.</p>\n<p>First save the model as .onnx file:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">x = torch.randn(<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">272</span>, <span class=\"number\">800</span>).requires_grad_(<span class=\"literal\">True</span>).cuda() </span><br><span class=\"line\">torch_out = rpsmnet(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Export the model</span></span><br><span class=\"line\">torch.onnx.export(rpsmnet,               <span class=\"comment\"># model being run</span></span><br><span class=\"line\">                  x,                         <span class=\"comment\"># model input (or a tuple for multiple inputs)</span></span><br><span class=\"line\">                  <span class=\"string\">&quot;super_resolution.onnx&quot;</span>,   <span class=\"comment\"># where to save the model (can be a file or file-like object)</span></span><br><span class=\"line\">                  export_params=<span class=\"literal\">True</span>,        <span class=\"comment\"># store the trained parameter weights inside the model file</span></span><br><span class=\"line\">                  opset_version=<span class=\"number\">10</span>,          <span class=\"comment\"># the ONNX version to export the model to</span></span><br><span class=\"line\">                  do_constant_folding=<span class=\"literal\">True</span>,  <span class=\"comment\"># whether to execute constant folding for optimization</span></span><br><span class=\"line\">                  input_names = [<span class=\"string\">&#x27;input&#x27;</span>],   <span class=\"comment\"># the model&#x27;s input names</span></span><br><span class=\"line\">                  output_names = [<span class=\"string\">&#x27;output&#x27;</span>], <span class=\"comment\"># the model&#x27;s output names</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>And I generate the flow chat of this model with Netron:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172106759.png\" alt=\"image-20220817210610588\"></p>\n<p>Detailed configuration of my model. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply</p>\n<p>The steps data are processed is generated with following code: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> hiddenlayer <span class=\"keyword\">as</span> hl</span><br><span class=\"line\"></span><br><span class=\"line\">transforms = [ hl.transforms.Prune(<span class=\"string\">&#x27;Constant&#x27;</span>) ] <span class=\"comment\"># Removes Constant nodes from graph.</span></span><br><span class=\"line\"></span><br><span class=\"line\">graph = hl.build_graph(rpsmnet, torch.zeros(<span class=\"number\">64</span>,<span class=\"number\">1</span>,<span class=\"number\">272</span>,<span class=\"number\">800</span>).cuda())</span><br><span class=\"line\">graph.theme = hl.graph.THEMES[<span class=\"string\">&#x27;blue&#x27;</span>].copy()</span><br><span class=\"line\">graph.save(<span class=\"string\">&#x27;ASRCnet_hiddenlayer&#x27;</span>, <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;png&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> torchviz <span class=\"keyword\">import</span> make_dot</span><br><span class=\"line\">x = torch.randn(<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">272</span>, <span class=\"number\">800</span>).requires_grad_(<span class=\"literal\">True</span>).cuda() <span class=\"comment\"># 定义一个网络的输入值</span></span><br><span class=\"line\">y = rpsmnet(x)    <span class=\"comment\"># 获取网络的预测值</span></span><br><span class=\"line\"><span class=\"comment\"># y = y.cuda()</span></span><br><span class=\"line\">MyConvNetVis = make_dot(y)<span class=\"comment\">#, params=dict(list(rpsmnet.named_parameters()) + [(&#x27;x&#x27;, x)]))</span></span><br><span class=\"line\">MyConvNetVis.<span class=\"built_in\">format</span> = <span class=\"string\">&quot;png&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 指定文件生成的文件夹</span></span><br><span class=\"line\">MyConvNetVis.directory = <span class=\"string\">&quot;data&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 生成文件</span></span><br><span class=\"line\">MyConvNetVis.view()</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172108920.png\" alt=\"image-20220817210806647\"></p>\n<h1 id=\"July-15th\"><a href=\"#July-15th\" class=\"headerlink\" title=\"July 15th\"></a>July 15th</h1><p>I want to visualize the pooling and convolution operations, so I use CAD to draw the illustrations:</p>\n<p>As shown in figure A, a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure B) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172114867.png\" alt=\"image-20220817211402695\"></p>\n","excerpt":"","more":"<h1 id=\"Table-of-content\"><a href=\"#Table-of-content\" class=\"headerlink\" title=\"Table of content\"></a>Table of content</h1><p>[Toc]</p>\n<h1 id=\"April-12th\"><a href=\"#April-12th\" class=\"headerlink\" title=\"April 12th\"></a>April 12th</h1><h2 id=\"First-meeting\"><a href=\"#First-meeting\" class=\"headerlink\" title=\"First meeting\"></a>First meeting</h2><h3 id=\"Objective\"><a href=\"#Objective\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to find out which data we are going to use and which method to analyse it because good understanding of the data can help researching simpler and more accurate. It can also inform me important information about features engineering or neural network designing.</p>\n<h3 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>data: <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a></p>\n<p>28 participants viewing 14 image stimuli </p>\n<p>The file we cares:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204111409061.png\" alt=\"image-20220411140935965\"></p>\n<p>I can use MNE-Python to analyse it because MNE-Python package is highly integrated allowing an easy access to analysing.</p>\n<p>What these files do can be achieved with:</p>\n<p><a href=\"https://mne.tools/stable/generated/mne.read_epochs.html\">https://mne.tools/stable/generated/mne.read_epochs.html</a></p>\n<p>More templates can be found in:</p>\n<p><a href=\"https://github.com/tobywise/aversive_state_reactivation/blob/master/notebooks/templates/sequenceness_classifier_template.ipynb\">https://github.com/tobywise/aversive_state_reactivation/blob/master/notebooks/templates/sequenceness_classifier_template.ipynb</a></p>\n<h1 id=\"April-13th\"><a href=\"#April-13th\" class=\"headerlink\" title=\"April 13th\"></a>April 13th</h1><h2 id=\"First-session-meeting\"><a href=\"#First-session-meeting\" class=\"headerlink\" title=\"First session meeting\"></a>First session meeting</h2><h3 id=\"Objective-1\"><a href=\"#Objective-1\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>learn how to write a lab notebook</p>\n<h3 id=\"Results-1\"><a href=\"#Results-1\" class=\"headerlink\" title=\"Results\"></a>Results</h3><p>General understanding:</p>\n<p>Title: the utility of multi-task machine learning for decoding brain states</p>\n<p>Table of Contents:</p>\n<p>page numbers; date; title/subject/experiment</p>\n<p>Gantt charts is good to help organise time.</p>\n<h1 id=\"April-18th\"><a href=\"#April-18th\" class=\"headerlink\" title=\"April 18th\"></a>April 18th</h1><h2 id=\"Install-MNE-Python-via-pip\"><a href=\"#Install-MNE-Python-via-pip\" class=\"headerlink\" title=\"Install MNE-Python via pip:\"></a>Install MNE-Python via pip:</h2><h3 id=\"Objective-2\"><a href=\"#Objective-2\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to upgrade environment manager and compiler to the latest stable version because I always tend to use the latest version of packages which is supposed to be more compatible</p>\n<h3 id=\"Results-2\"><a href=\"#Results-2\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>Update Anaconda via <code>conda upgrade --all</code> and  <code>conda install anaconda=2021.10</code></p>\n<p>The Python version I am using is:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Python 3.9.12\t</span><br></pre></td></tr></table></figure>\n\n<p>get the data:</p>\n<p><code>git clone https://github.com/OpenNeuroDatasets/ds003682</code></p>\n<p>Install MNE:</p>\n<p><code>conda install --channel=conda-forge mne-base</code></p>\n<h1 id=\"April-19th\"><a href=\"#April-19th\" class=\"headerlink\" title=\"April 19th\"></a>April 19th</h1><h2 id=\"Second-meeting\"><a href=\"#Second-meeting\" class=\"headerlink\" title=\"Second meeting\"></a>Second meeting</h2><h3 id=\"Objective-3\"><a href=\"#Objective-3\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to have a general understanding of the data and figure out details about methods because these are what I am going to feed into the network so that I should have a clear recognition for each part.</p>\n<p><code>x_raw</code></p>\n<p><code>x_raw.shape</code></p>\n<p><code>y_raw</code></p>\n<p><code>time = localiser epchoes</code></p>\n<h3 id=\"Results-3\"><a href=\"#Results-3\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><h4 id=\"what-I-have-known\"><a href=\"#what-I-have-known\" class=\"headerlink\" title=\"what I have known:\"></a>what I have known:</h4><p><strong>scikit-learn</strong> (machine learning library) is an available package I am going to use</p>\n<p>use <strong>PCA</strong> to reduce dimensions </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204191041843.png\" alt=\"image-20220419104136746\"></p>\n<h4 id=\"what-need-to-be-learned\"><a href=\"#what-need-to-be-learned\" class=\"headerlink\" title=\"what need to be learned:\"></a>what need to be learned:</h4><h5 id=\"1-normalization-regularization\"><a href=\"#1-normalization-regularization\" class=\"headerlink\" title=\"1. normalization, regularization\"></a>1. normalization, regularization</h5><p>lasso L1 = sets unpredictive features to 0</p>\n<p>ridge L2 = minimises the weights on unpredictive features</p>\n<p>elastic net L1/L2</p>\n<h5 id=\"2-search\"><a href=\"#2-search\" class=\"headerlink\" title=\"2. search\"></a>2. search</h5><p><code>random_search randomizedsearchCV</code> to test the performance</p>\n<h5 id=\"3-Neural-network\"><a href=\"#3-Neural-network\" class=\"headerlink\" title=\"3. Neural network\"></a>3. Neural network</h5><p>neural network can be the best way for logistic leaning </p>\n<h5 id=\"4-validation\"><a href=\"#4-validation\" class=\"headerlink\" title=\"4. validation\"></a>4. validation</h5><h1 id=\"April-24th\"><a href=\"#April-24th\" class=\"headerlink\" title=\"April 24th\"></a>April 24th</h1><h3 id=\"Objective-4\"><a href=\"#Objective-4\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to play with existing code <a href=\"https://github.com/tobywise/aversive_state_reactivation\">https://github.com/tobywise/aversive_state_reactivation</a> because it can inform me code grammars analysing MEG data and it will make a foundation for my following coding </p>\n<h3 id=\"Results-4\"><a href=\"#Results-4\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><h4 id=\"Epochs\"><a href=\"#Epochs\" class=\"headerlink\" title=\"Epochs\"></a>Epochs</h4><p>Extract signals from continuous EEG signals for specific time windows, which can be called epochs.</p>\n<p>Because EEGs are collected continuously, to analyse EEG event-related potentials requires “slicing” the signal into time segments that are locked to time segments within an event (e.g., a stimulus).</p>\n<h4 id=\"Data-corruption\"><a href=\"#Data-corruption\" class=\"headerlink\" title=\"Data corruption\"></a>Data corruption</h4><p>The MEG data in the repository <a href=\"https://openneuro.org/datasets/ds003682\">https://openneuro.org/datasets/ds003682</a> is invalid, possibly because of data corruption</p>\n<p><strong>incomplete copying led to corrupted files</strong></p>\n<p>The following events are an example present in the data: 1, 2, 3, 4, 5, 32</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">event_id = &#123;&#x27;Auditory/Left&#x27;: 1, &#x27;Auditory/Right&#x27;: 2,</span><br><span class=\"line\">&#x27;Visual/Left&#x27;: 3, &#x27;Visual/Right&#x27;: 4,</span><br><span class=\"line\">&#x27;smiley&#x27;: 5, &#x27;button&#x27;: 32&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>sklearn.cross_validation</code> has been deprecated since version 1.9, and <code>sklearn.model_selection</code> can be used after version 1.9.</p>\n<h1 id=\"April-25th\"><a href=\"#April-25th\" class=\"headerlink\" title=\"April 25th\"></a>April 25th</h1><h2 id=\"Install-scikit-learn-sklearn\"><a href=\"#Install-scikit-learn-sklearn\" class=\"headerlink\" title=\"Install scikit-learn (sklearn)\"></a>Install scikit-learn (sklearn)</h2><p>use the command line </p>\n<p><code>conda install -c anaconda scikit-learn</code></p>\n<p>Start the base environment in Anaconda Prompt: <code>activate base</code></p>\n<p>And install jupyter notebook, numpy and other modules in the environment</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">conda insatll tensorflow</span><br><span class=\"line\"></span><br><span class=\"line\">conda install jupyter notebook</span><br><span class=\"line\"></span><br><span class=\"line\">conda install scikit-learn</span><br><span class=\"line\"></span><br><span class=\"line\">conda install scipy</span><br></pre></td></tr></table></figure>\n\n<p>Learn how to choose the right algorithm </p>\n<p><a href=\"https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\">https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html</a></p>\n<p><img src=\"https://scikit-learn.org/stable/_static/ml_map.png\" alt=\"flow chart of scikit\"></p>\n<h2 id=\"Learning-sklearn\"><a href=\"#Learning-sklearn\" class=\"headerlink\" title=\"Learning sklearn\"></a>Learning sklearn</h2><ol>\n<li>import modules</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>create data</li>\n</ol>\n<p>load <code>iris</code> data，store the <strong>attributes</strong> in  <code>X</code>，store the <strong>labels</strong> in <code>y</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">iris_X = iris.data</span><br><span class=\"line\">iris_y = iris.target</span><br></pre></td></tr></table></figure>\n\n<p>Looking at the dataset, <code>X</code> has four attributes, and <code>y</code> has three categories: 0, 1, and 2:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(iris_X[:<span class=\"number\">2</span>, :])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(iris_y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">Output:</span></span><br><span class=\"line\"><span class=\"string\">[[ 5.1  3.5  1.4  0.2]</span></span><br><span class=\"line\"><span class=\"string\"> [ 4.9  3.   1.4  0.2]]</span></span><br><span class=\"line\"><span class=\"string\">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span></span><br><span class=\"line\"><span class=\"string\"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2]</span></span><br><span class=\"line\"><span class=\"string\"> &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>Divide the data set into training set and test set, where <code>test_size=0.3</code>, that is, the test set accounts for 30% of the total data:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class=\"line\">    iris_X, iris_y, test_size=<span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n\n<p>It can be seen that the separated data sets are also disrupted in order, which is better to train the model:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">Outputs:</span></span><br><span class=\"line\"><span class=\"string\">[2 1 0 1 0 0 1 1 1 1 0 0 1 2 1 1 1 0 2 2 1 1 1 1 0 2 2 0 2 2 2 2 2 0 1 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2 2 2 0 1 2 2 1 1 1 0 0 1 2 0 1 0 1 0 1 2 2 0 1 2 2 2 1 1 1 1 2 2 2 1 0</span></span><br><span class=\"line\"><span class=\"string\"> 1 1 0 0 0 2 0 1 0 0 1 2 0 2 2 0 0 2 2 2 1 2 0 0 2 1 2 0 0 1 2]</span></span><br><span class=\"line\"><span class=\"string\"> &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>Build a model - train - predict</li>\n</ol>\n<p>Define the module method <code>KNeighborsClassifier()</code>, use <code>fit</code> to train <code>training data</code>, this step completes all the steps of training, the latter <code>knn</code> is already a trained model, which can be used directly <code>predict</code> For the data of the test set, comparing the value predicted by the model with the real value, we can see that the data is roughly simulated, but there is an error, and the prediction will not be completely correct.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">knn = KNeighborsClassifier()</span><br><span class=\"line\">knn.fit(X_train, y_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(knn.predict(X_test))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">[2 0 0 1 2 2 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 1 0 1 2 0 1]</span></span><br><span class=\"line\"><span class=\"string\">[2 0 0 1 2 1 0 0 0 1 2 2 1 1 2 1 2 1 0 0 0 2 1 2 0 0 0 0 1 0 2 0 0 2 1 0 1</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 1 0 1 2 0 1]</span></span><br><span class=\"line\"><span class=\"string\"> &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>Directly download the data and store in my computer. However, it is unprofessional to run code in personal computer. I should looking for a way to solve this problem: rent a server or find a HPC cluster in King’s College.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204251507965.png\" alt=\"image-20220425150724894\"></p>\n<h2 id=\"Succeed-at-drawing-plot\"><a href=\"#Succeed-at-drawing-plot\" class=\"headerlink\" title=\"Succeed at drawing plot\"></a>Succeed at drawing plot</h2><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> mne</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> mne.datasets <span class=\"keyword\">import</span> sample</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The storage path of sample</span></span><br><span class=\"line\">data_path = sample.data_path()</span><br><span class=\"line\"><span class=\"comment\"># The storage path of the fif file</span></span><br><span class=\"line\">fname = <span class=\"string\">&#x27;E:\\Proj\\Previous data\\sample\\MEG\\sample\\sub-001_localiser_sub-001_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">epochs = mne.read_epochs(fname)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(epochs.event_id)</span><br><span class=\"line\"></span><br><span class=\"line\">picks = mne.pick_types(epochs.info, meg=<span class=\"literal\">True</span>, ref_meg=<span class=\"literal\">False</span>, exclude=<span class=\"string\">&#x27;bads&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">epochs.plot(block=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">epochs.plot_drop_log()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">epochs = mne.read_epochs(fname)</span><br><span class=\"line\"></span><br><span class=\"line\">evoked = epochs.average()</span><br><span class=\"line\">evoked.plot_topomap()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">availabe_event = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">32</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> availabe_event:</span><br><span class=\"line\">    evoked_i = epochs[i].average(picks=picks)</span><br><span class=\"line\">    epochs_i = epochs[i]</span><br><span class=\"line\">    evoked_i.plot(time_unit=<span class=\"string\">&#x27;s&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>The panel each contains 900 epochs. In these samples, there are no spikes or other distinctive abnormal waveforms. For every single training dataset from various participants, 900 of in total 900 events passed the rejection process. It is because the rejection algorithm was purposefully designed to be inclusive. All data were deliberately included because the CNN model should be robust to noise in the data</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171937606.png\" alt=\"image-20220817193732989\"></p>\n<p>Topological map from -500.00 to 790.00 ms. The brain areas that are activated are concentrated in the downstream temporal region or visual cortex.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171941694.png\" alt=\"image-20220817194146606\"></p>\n<h2 id=\"A-few-questions-at-last\"><a href=\"#A-few-questions-at-last\" class=\"headerlink\" title=\"A few questions at last:\"></a>A few questions at last:</h2><ol>\n<li><p>why do we split the data as 70%, does it work as other ration?</p>\n<p>Because we have got enough data to train and need more data to test and valid the training performance.</p>\n</li>\n</ol>\n<h1 id=\"April-26th\"><a href=\"#April-26th\" class=\"headerlink\" title=\"April 26th\"></a>April 26th</h1><h2 id=\"MRI-safety-training-for-2-5-hrs\"><a href=\"#MRI-safety-training-for-2-5-hrs\" class=\"headerlink\" title=\"MRI safety training for 2.5 hrs\"></a>MRI safety training for 2.5 hrs</h2><h2 id=\"update-Anaconda-start-to-use-a-new-platform\"><a href=\"#update-Anaconda-start-to-use-a-new-platform\" class=\"headerlink\" title=\"update Anaconda (start to use a new platform)\"></a>update Anaconda (start to use a new platform)</h2><p>Anaconda is a good environment manager tool which allows me to manage and deploy packages</p>\n<p><code>conda update conda</code></p>\n<p><code>conda update anaconda</code></p>\n<p><code>conda update --all</code></p>\n<p>done</p>\n<p>Python version: 3.8.13-h6244533_0</p>\n<h2 id=\"change-the-directory-path-of-Jupyter-notebook-in-order-to-save-files-in-preferred-path\"><a href=\"#change-the-directory-path-of-Jupyter-notebook-in-order-to-save-files-in-preferred-path\" class=\"headerlink\" title=\"change the directory path of Jupyter notebook (in order to save files in preferred path)\"></a>change the directory path of Jupyter notebook (in order to save files in preferred path)</h2><ol>\n<li><p><code>jupyter notebook --generate-config</code> get the config file. change the line <code>c.NotebookApp.notebook_dir = &#39;&#39;</code> to the directory I want</p>\n</li>\n<li><p>find jupyter notebook file, change the attributes. <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204261614733.png\" alt=\"change the attributes\"></p>\n</li>\n</ol>\n<h2 id=\"Link-the-local-directory-and-Github\"><a href=\"#Link-the-local-directory-and-Github\" class=\"headerlink\" title=\"Link the local directory and Github\"></a>Link the local directory and Github</h2><p>for the convenience of collaboration </p>\n<p>SSH connect public key (id_rsa.pub) was created before.</p>\n<p>after create the directory, run the command in git:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">git init</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git git commit -m  <span class=\"string\">&quot;Comment&quot;</span></span><br><span class=\"line\">git remote add origin <span class=\"string\">&quot;the url of directory&quot;</span></span><br><span class=\"line\">git push -u origin main</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Journal-club-preparation-for-the-next-session\"><a href=\"#Journal-club-preparation-for-the-next-session\" class=\"headerlink\" title=\"Journal club preparation for the next session\"></a>Journal club preparation for the next session</h2><h1 id=\"April-27th\"><a href=\"#April-27th\" class=\"headerlink\" title=\"April 27th\"></a>April 27th</h1><h2 id=\"Pycharm-use-IDE\"><a href=\"#Pycharm-use-IDE\" class=\"headerlink\" title=\"Pycharm (use IDE)\"></a>Pycharm (use IDE)</h2><p>Get Pycharm educational version via King’s email</p>\n<p>install python 3.8 environment for running the code from <a href=\"https://github.com/tobywise/aversive_state_reactivation\">https://github.com/tobywise/aversive_state_reactivation</a> (because it was coding with python 3.8 compiler)</p>\n<p>run below code in pycharm</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">!conda create -n py38 python=3.8</span><br><span class=\"line\">!pip install mne</span><br><span class=\"line\">!pip install scikit-learn</span><br><span class=\"line\">!pip install plotly</span><br><span class=\"line\">!pip install cufflinks</span><br><span class=\"line\">!pip install networkx</span><br><span class=\"line\">!conda install numba</span><br><span class=\"line\">!pip install pyyaml</span><br><span class=\"line\">!pip install papermill</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Fixation-for-some-expired-code\"><a href=\"#Fixation-for-some-expired-code\" class=\"headerlink\" title=\"Fixation for some expired code\"></a>Fixation for some expired code</h2><p>The function <code>joblib</code> does not exist in <code>sklearn.external</code> anymore.</p>\n<p>Error occurs when run the function plot_confusion_matrix:</p>\n<p>Deprecated since version 1.0: <code>plot_confusion_matrix</code> is deprecated in 1.0 and will be removed in 1.2. Use one of the following class methods: <code>from_predictions</code> or <code>from_estimator</code>.</p>\n<p>use</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">ConfusionMatrixDisplay.from_predictions(y, y_pred)</span><br></pre></td></tr></table></figure>\n\n<p>instead of </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title=<span class=\"string\">&#x27;Normalised confusion matrix, accuracy = &#123;0&#125;&#x27;</span>.<span class=\"built_in\">format</span>(np.<span class=\"built_in\">round</span>(mean_accuracy, <span class=\"number\">2</span>)))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Second-session-meeting\"><a href=\"#Second-session-meeting\" class=\"headerlink\" title=\"Second session meeting\"></a>Second session meeting</h2><p>Every people gives a general introduction of their projects</p>\n<h1 id=\"April-28th\"><a href=\"#April-28th\" class=\"headerlink\" title=\"April 28th\"></a>April 28th</h1><h2 id=\"Logistic-regression-cost-function\"><a href=\"#Logistic-regression-cost-function\" class=\"headerlink\" title=\"Logistic regression cost function\"></a>Logistic regression cost function</h2><p>The function is using the principle of maximum likelihood estimation to find the parameters $\\theta$ for different models. At the meantime, a nice property is it is convex. So, this cost function is generally everyone use for fitting parameters in logistic regression.<img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290105356.png\" alt=\"image-20220429010526272\"></p>\n<p>The way we are going to minimize the cost function is using gradient descent:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202204290112574.png\" alt=\"image-20220429011210521\"></p>\n<p>Other alternative optimization algorithms (no need to manually pick $\\alpha$ studying rate):</p>\n<ol>\n<li>Conjugate gradient</li>\n<li>BFGS</li>\n<li>L-BFGS</li>\n</ol>\n<h2 id=\"Methods-to-storage-trained-model\"><a href=\"#Methods-to-storage-trained-model\" class=\"headerlink\" title=\"Methods to storage trained model\"></a>Methods to storage trained model</h2><p>set and train a simple SVC model</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"></span><br><span class=\"line\">clf = svm.SVC()</span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">X, y = iris.data, iris.target</span><br><span class=\"line\">clf.fit(X,y)</span><br></pre></td></tr></table></figure>\n<p>Storage:</p>\n<ol>\n<li>pickle</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pickle <span class=\"comment\">#pickle module</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;save/clf.pickle&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(clf, f)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#load Model</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;save/clf.pickle&#x27;</span>, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    clf2 = pickle.load(f)</span><br><span class=\"line\">    <span class=\"comment\">#test loaded Model</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(clf2.predict(X[<span class=\"number\">0</span>:<span class=\"number\">1</span>]))</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>joblib (supposed to be faster when dealing with a large data, because the use of multiprocessing)</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib <span class=\"comment\">#jbolib模块</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#store Model(Note: The save folder must be created in advance, otherwise an error will be reported)</span></span><br><span class=\"line\">joblib.dump(clf, <span class=\"string\">&#x27;save/clf.pkl&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##load Model</span></span><br><span class=\"line\">clf3 = joblib.load(<span class=\"string\">&#x27;save/clf.pkl&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test loaded Model</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf3.predict(X[<span class=\"number\">0</span>:<span class=\"number\">1</span>]))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"April-29th\"><a href=\"#April-29th\" class=\"headerlink\" title=\"April 29th\"></a>April 29th</h1><h2 id=\"Google-Colab\"><a href=\"#Google-Colab\" class=\"headerlink\" title=\"Google Colab\"></a>Google Colab</h2><p>Get the subscription of Google Colab and Google drive</p>\n<p>clone data to google drive</p>\n<p>Token: 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</p>\n<p>connect Google Colab with VS code</p>\n<h2 id=\"Regularization\"><a href=\"#Regularization\" class=\"headerlink\" title=\"Regularization\"></a>Regularization</h2><p>We can use <strong>regularization</strong> to rescue the overfitting</p>\n<p>There are two types of regularization:</p>\n<ul>\n<li><p><strong>L1 Regularization</strong> (or Lasso Regularization)</p>\n<p>$Min$($$\\sum_{i=1}^{n}{|y_i-w_ix_i|+p\\sum_{i=1}^{n}|w_i|}$$)</p>\n</li>\n<li><p><strong>L2 Regularization</strong> (or Ridge Regularization)</p>\n<p>$Min$($$\\sum_{i=1}^{n}{(y_i-w_ix_i)^2+p\\sum_{i=1}^{n}w_i^2}$$)</p>\n</li>\n</ul>\n<p>where <code>p</code> is the tuning parameter which decides in what extent we want to penalize the model.</p>\n<p>However, there is another method for combination</p>\n<ul>\n<li><strong>Elastic Net:</strong> When L1 and L2 regularization combine together, it becomes the elastic net method, it adds a hyperparameter.</li>\n</ul>\n<p>how to select:</p>\n<table>\n<thead>\n<tr>\n<th><strong>No</strong></th>\n<th><strong>L1 Regularization</strong></th>\n<th><strong>L2 Regularization</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1</strong></td>\n<td>Panelises the sum of absolute value of weights.</td>\n<td>Penalises the sum of square weights.</td>\n</tr>\n<tr>\n<td><strong>2</strong></td>\n<td>It has a sparse solution.</td>\n<td>It has a non-sparse solution.</td>\n</tr>\n<tr>\n<td><strong>3</strong></td>\n<td>It gives multiple solutions.</td>\n<td>It has only one solution.</td>\n</tr>\n<tr>\n<td><strong>4</strong></td>\n<td>Constructed in feature selection.</td>\n<td>No feature selection.</td>\n</tr>\n<tr>\n<td><strong>5</strong></td>\n<td>Robust to outliers.</td>\n<td>Not robust to outliers.</td>\n</tr>\n<tr>\n<td><strong>6</strong></td>\n<td>It generates simple and interpretable models.</td>\n<td>It gives more accurate predictions when the output variable is the function of whole input variables.</td>\n</tr>\n<tr>\n<td><strong>7</strong></td>\n<td>Unable to learn complex data patterns.</td>\n<td>Able to learn complex data patterns.</td>\n</tr>\n<tr>\n<td><strong>8</strong></td>\n<td>Computationally inefficient over non-sparse conditions.</td>\n<td>Computationally efficient because of having analytical solutions.</td>\n</tr>\n</tbody></table>\n<h2 id=\"Normalization\"><a href=\"#Normalization\" class=\"headerlink\" title=\"Normalization\"></a>Normalization</h2><p>The reason for applying normalization is the normalization step can generalize the statistical distribution of uniform samples, which is expected to enhance the training performance.</p>\n<p> <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208171958842.gif\" alt=\"img\"></p>\n<p>where m is the total number of data and x represents data, makes the average value and standard deviation of data in each channel to be located in the range between 0 and 1</p>\n<h3 id=\"Question\"><a href=\"#Question\" class=\"headerlink\" title=\"Question:\"></a>Question:</h3><p>which layer should I apply the regularization?</p>\n<p>From the model’s summary, I can determine which layers have the most parameters. It is better to apply regularization to the layers with the highest parameters.</p>\n<p>In the above case, how to get each layer’s parameters?</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> prettytable <span class=\"keyword\">import</span> PrettyTable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">count_parameters</span>(<span class=\"params\">model</span>):</span><br><span class=\"line\">    table = PrettyTable([<span class=\"string\">&quot;Modules&quot;</span>, <span class=\"string\">&quot;Parameters&quot;</span>])</span><br><span class=\"line\">    total_params = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name, parameter <span class=\"keyword\">in</span> model.named_parameters():</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> parameter.requires_grad: <span class=\"keyword\">continue</span></span><br><span class=\"line\">        params = parameter.numel()</span><br><span class=\"line\">        table.add_row([name, params])</span><br><span class=\"line\">        total_params+=params</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(table)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Total Trainable Params: <span class=\"subst\">&#123;total_params&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> total_params</span><br><span class=\"line\">    </span><br><span class=\"line\">count_parameters(model)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"May-2nd\"><a href=\"#May-2nd\" class=\"headerlink\" title=\"May 2nd\"></a>May 2nd</h1><h2 id=\"Question-ahead\"><a href=\"#Question-ahead\" class=\"headerlink\" title=\"Question ahead:\"></a>Question ahead:</h2><p>get a question: how to determine the classifier centre (windows width)? </p>\n<p>for this case, it is around 20 to be at the middle/ top</p>\n<p>GPU accelerations</p>\n<p>It could be a little bit tricky to accelerate the calculation in sklearn with GPU. Here is a possible solution: <a href=\"https://developer.nvidia.com/blog/scikit-learn-tutorial-beginners-guide-to-gpu-accelerating-ml-pipelines/\">https://developer.nvidia.com/blog/scikit-learn-tutorial-beginners-guide-to-gpu-accelerating-ml-pipelines/</a>.  </p>\n<h2 id=\"Third-meeting\"><a href=\"#Third-meeting\" class=\"headerlink\" title=\"Third meeting:\"></a>Third meeting:</h2><p>Deep learning might be the solution for MEG signals classification. </p>\n<p>The CNN is a particular subtype of the neural network, which is effective in analysing images or other data containing high spatial information (Khan et al., 2018; Valueva et al., 2020) and also works well with temporal information (Bai et al., 2018)</p>\n<blockquote>\n<p>Khan, S., Rahmani, H., Shah, S. A. A., &amp; Bennamoun, M. (2018). A Guide to Convolutional Neural Networks for Computer Vision. <em>A Guide to Convolutional Neural Networks for Computer Vision</em>. <a href=\"https://doi.org/10.1007/978-3-031-01821-3\">https://doi.org/10.1007/978-3-031-01821-3</a></p>\n<p>Valueva, M. v., Nagornov, N. N., Lyakhov, P. A., Valuev, G. v., &amp; Chervyakov, N. I. (2020). Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. <em>Mathematics and Computers in Simulation</em>, <em>177</em>, 232–243. <a href=\"https://doi.org/10.1016/J.MATCOM.2020.04.031\">https://doi.org/10.1016/J.MATCOM.2020.04.031</a></p>\n<p>Bai, S., Kolter, J. Z., &amp; Koltun, V. (2018). <em>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</em>. <a href=\"https://doi.org/10.48550/arxiv.1803.01271\">https://doi.org/10.48550/arxiv.1803.01271</a></p>\n</blockquote>\n<p>possible deep learning packages:</p>\n<p>JAX, HAIKU</p>\n<p>My aim is to inform bad-performance data with the training model of good-performance data in aims to increase the performance. One hallmark is to increase the mean accuracy of each cases as high as possible.</p>\n<h1 id=\"May-3rd\"><a href=\"#May-3rd\" class=\"headerlink\" title=\"May 3rd\"></a>May 3rd</h1><p>Successfully run the code for confusion matrix.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">clf.set_params(**random_search.best_params_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get predictions with 5 fold CV</span></span><br><span class=\"line\">y_pred = cross_val_predict(clf, X, y, cv=confusion_matrix_cv)</span><br><span class=\"line\">mean_conf_mat = confusion_matrix(y, y_pred)</span><br><span class=\"line\">mean_accuracy = accuracy_score(y[y != <span class=\"number\">99</span>], y_pred[y != <span class=\"number\">99</span>])</span><br><span class=\"line\">mean_conf_mat = mean_conf_mat.astype(<span class=\"string\">&#x27;float&#x27;</span>) / mean_conf_mat.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">1</span>)  <span class=\"comment\"># normalise</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Mean accuracy = &#123;0&#125;&quot;</span>.<span class=\"built_in\">format</span>(mean_accuracy))</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># Plot mean confusion matrix</span></span><br><span class=\"line\"><span class=\"comment\">#plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title=&#x27;Normalised confusion matrix, accuracy = &#123;0&#125;&#x27;.format(np.round(mean_accuracy, 2)))</span></span><br><span class=\"line\"><span class=\"comment\">#plt.imshow(mean_conf_mat[:n_stim, :n_stim])</span></span><br><span class=\"line\"></span><br><span class=\"line\">ConfusionMatrixDisplay.from_predictions(y, y_pred)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">&#x27;./save_folder/fig-&#123;&#125;.png&#x27;</span>.<span class=\"built_in\">format</span>(session_id), dpi=<span class=\"number\">600</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<p>pictures of each case are stored in the Github depository: </p>\n<p><a href=\"https://github.com/ReveRoyl/MT_ML_Decoding/tree/main/Aversive_state_reactivation/notebooks/templates/save_folder\">https://github.com/ReveRoyl/MT_ML_Decoding/tree/main/Aversive_state_reactivation/notebooks/templates/save_folder</a></p>\n<p>It takes around 36 minutes to run 28 cases. </p>\n<p>Mean accuracy with existing code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[<span class=\"number\">0.4288888888888889</span>, <span class=\"number\">0.33666666666666667</span>, <span class=\"number\">0.2777777777777778</span>, <span class=\"number\">0.5022222222222222</span>, <span class=\"number\">0.5066666666666667</span>, <span class=\"number\">0.4245810055865922</span>, <span class=\"number\">0.5577777777777778</span>, <span class=\"number\">0.43222222222222223</span>, <span class=\"number\">0.65</span>, <span class=\"number\">0.47888888888888886</span>, <span class=\"number\">0.3377777777777778</span>, <span class=\"number\">0.4800469483568075</span>, <span class=\"number\">0.27111111111111114</span>, <span class=\"number\">0.37193763919821826</span>, <span class=\"number\">0.4288888888888889</span>, <span class=\"number\">0.40555555555555556</span>, <span class=\"number\">0.46444444444444444</span>, <span class=\"number\">0.7077777777777777</span>, <span class=\"number\">0.5811111111111111</span>, <span class=\"number\">0.4711111111111111</span>, <span class=\"number\">0.4255555555555556</span>, <span class=\"number\">0.5022222222222222</span>, <span class=\"number\">0.45394006659267483</span>, <span class=\"number\">0.38555555555555554</span>, <span class=\"number\">0.6222222222222222</span>, <span class=\"number\">0.4622222222222222</span>, <span class=\"number\">0.35444444444444445</span>, <span class=\"number\">0.47444444444444445</span>]</span><br></pre></td></tr></table></figure>\n<h1 id=\"May-10th\"><a href=\"#May-10th\" class=\"headerlink\" title=\"May 10th\"></a>May 10th</h1><p>Get rid of the effect of null data</p>\n<p>transform X into the same size as clf</p>\n<h1 id=\"May-11th\"><a href=\"#May-11th\" class=\"headerlink\" title=\"May 11th\"></a>May 11th</h1><h2 id=\"Grid-Search-CV\"><a href=\"#Grid-Search-CV\" class=\"headerlink\" title=\"Grid Search CV\"></a>Grid Search CV</h2><p>To test Grid Search CV instead of Randomized Search CV</p>\n<p>However, the result of grid search CV is worse than the randomized search CV. I think the reason is that random search CV uses a random combination of hyperparameters to find the best solution for a built model. However, the random search CV is not 100% better than grid search CV: the disadvantage of random search is that it produces high variance during computation.</p>\n<h2 id=\"Concatenation\"><a href=\"#Concatenation\" class=\"headerlink\" title=\"Concatenation\"></a>Concatenation</h2><h3 id=\"Objective-5\"><a href=\"#Objective-5\" class=\"headerlink\" title=\"Objective\"></a>Objective</h3><p>Since my aim is to transfer the model prediction of one case to anther, I try to concatenate multiple cases data together to train the model and see what will happen.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">localiser_epochs = mne.read_epochs(os.path.join(output_dir, <span class=\"string\">&#x27;preprocessing&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;&#x27;</span>, <span class=\"string\">&#x27;localiser&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span>).<span class=\"built_in\">format</span>(<span class=\"string\">&#x27;001&#x27;</span>,<span class=\"string\">&#x27;001&#x27;</span>)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> session_id_int <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">2</span>, <span class=\"number\">3</span>):</span><br><span class=\"line\">    session_id = <span class=\"string\">&#x27;&#123;:03d&#125;&#x27;</span>.<span class=\"built_in\">format</span>(session_id_int)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(session_id)</span><br><span class=\"line\">    </span><br><span class=\"line\">    localiser_epochs_unconcatenate = mne.read_epochs(os.path.join(output_dir, <span class=\"string\">&#x27;preprocessing&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;&#x27;</span>, <span class=\"string\">&#x27;localiser&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span>).<span class=\"built_in\">format</span>(session_id,session_id))  </span><br><span class=\"line\">    localiser_epochs_unconcatenate.info = localiser_epochs.info</span><br><span class=\"line\">    localiser_epochs = mne.concatenate_epochs([localiser_epochs, localiser_epochs_unconcatenate]) </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p>Concatenate X np arrays and test, the mean accuracy increases. I test 5 cases.</p>\n<p>Mean accuracy = 0.5111111111111111, while for each cases, previous mean accuracy = 0.43777777777777777; 0.34; 0.2788888888888889; 0.5055555555555555.</p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAATgAAAEKCAYAAACGzUnMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXwU5f2An+9u7kBCCPcNCqiAHAIiXoharZWq1VZ7erTVVm21Fe9qW696VX/W2lrqgVrvq7YigiLWUkAEL1BOOUMSIIEkQM7d/f7+mA1ESHZn5p3sJDgPn/2QPb7zHjt5M/MezyuqSkBAQMCBSMjvDAQEBAS0FkEDFxAQcMASNHABAQEHLEEDFxAQcMASNHABAQEHLEEDFxAQcMASNHABAQFtDhHJEpFFIvKJiHwmIr+Pvz5dRNaJyMfxx6hEx0lLTXYDAgICHFEHTFbVXSKSDswTkZnx965W1ZfsHCRo4AICAtocaq1A2BV/mh5/OF6VIO1hJUM4N1fTOnd2HZ+1td594rGY+1iA9HT3sYbfTTTL/d+v8K5ao7SNyg1oSFzHSkPEKG3CYdehWmNYbwZIVqbr2JqGSuoj1e4rHTjlhFwt3x619dkln9Z9BjStrGmqOq3pZ0QkDCwBDgYeUtVrRWQ6cBTWFd4c4DpVrWspnXZxBZfWuTO9r/yV6/ihf9rkOlZralzHAmif7q5jpcagYQZ2Dit0HdvxvTVGaZuUGyCa7b6BTC8qN0o7VpjnPvbjz43SNiE84GDXsQvWTzdOv3x7lEWz+tn6bLjn6lpVHZvoM6oaBUaJSCfgVREZDlwPlAIZwDTgWuCWlo4RDDIEBAR4ggIxm/8cHVe1ApgLnKqqJWpRBzwOjE8UGzRwAQEBnqAoDRq19UiGiHSNX7khItnAycAKEekZf02AM4FliY7TLm5RG/nDhLlM7r2B8tpsTptxLgAPHPMWAztWAJCXUUdVfSbfnPntpMdKz4hy18MLSM+IEQ4r/3unJ0//fYitfHTpXstVt39OQWE9qsKbL/fitaf7OirL9Mf/RXVNGrGoEI2FuOKKUxzFh0LKAw/Pobwsm9/dcLSj2HMmLWXKxBWIwL//dwgvvjvCVlxbKHduTj2/vnQ+A/pVoCr88aGJLF/VNWmcyfftRd7HTqriZ7cWEw4pM5/tzAt/dnYLbxpvcr44wenVWQJ6Ak/E++FCwAuq+rqIvCMiXQEBPgZ+luggKW/gRKQv8CTQHeuqdpqqPmAn9pW1Q/nHyuHcM/GdPa9dMe/kPT9fP2Y+O+szbOWjoT7EDZdNoLYmjXA4xj3TFrB4QVdWLitIGhuNCo/8cTBfLO9Idk6EPz33AR8u6Mymtbm20m7kuutOpKrKXcfwGWevZtPGPHJyGhzFDey5nSkTV3DxPWcRiYa499KZzF/Wj81l+Ulj20K5L71oER981Jtb751EWlqUzAx7ndom33dT3OQ9FFIuu2Mz1583iLKSdB58YzULZ+WzcXVWSuLB/fniBEWJejRoqaqfAqObeX2yk+P4cYsaAa5S1cOACcBlInKYncAPtvaior6lk0s5rd8X/HuD3Y5WobbGat/T0pRwWsz2IPSOsky+WN4RgJrqNDauy6VLtxYHcjynsEs14yaUMmvGAMex/XtU8Pn6btQ1pBGNhfh4TU+OH7XOVqzf5c7JqWfEYVt5c471HUciYXZX2/uDZvJ9mzJ0dDXF6zMo3ZhJpCHEu6914qhTKlMWb3K+OCWG2nqkipRfwalqCVAS/3mniCwHegNGw0/jupVQVpvDhp2dbMeEQsoDT8yjZ5/dzHipPys/c/bXHKBbrxoOOmQnK5Y6G3lThdtvm4sqzJx5MDPftD8Cdsnln/LY30aQne18OsS64gIunvIBebm11NWnMWHYRlZuTH6Lty9+lLtHt11UVGUy9fL5DOq/ndVrC/nrY+OorbM34mr6fbvNe2GPBrYV722Iy0rSOWRMte10TeNNzhcnKBBNYeNlB1/74ERkANZl6PvNvHcxcDFAuCD5iXh6/zW8vt7ZMHksJvzih8eS26GB39y9mP6DdrJhbUfb8VnZEW68bxnT7h5MzW5nVTn16pMoL88hP7+WO26fy6aiPJYt65Y0bvyEEioqMlmzqoARI7c5ShNgw5YCnn5rJPdd9gY19WmsKSokGnM2/cmPcgOEwzEGD9rOXx4dz4rVXfn5RYs496xlPPHcfncyzWL6fZvk3S9MzxenpPLqzA6+jaKKSAfgZeBKVa3a931VnaaqY1V1bDg3cR9PWGKc0ncdMzYc5Covu3el8+mSLhxx1FbbMeG0GDfet4x3Z3Rn/hznJ3l5eQ4AlZVZzF/Qh6FD7M3dOmx4ORMmlvD4szO59ub3OXz0NqbesMhR2jMWHMJP7v4Wv/i/b7KzOpNNW5P3vzXiV7kByspz2Vaew4rV1hXnfxf05+BB2x3nwc33De7zXl6aTtdee+c0dunZQFmJ/Xl+JvFenC92UaBB1dYjVfjSwMXXlr0MPK2qr5ge7+geRayt6kRpTQfbMXmd6sjtYHW4ZmRGGTV+G5vW241Xrvz9Cjaty+HVp+xNbGxKZmaE7OyGPT+PGV3K+g32GpnpjwznR985jQu/+3XuuuVIPv2oK/fekXAq0H506mBNXu5WsIvjRq7j7cV2r3z9KzfAjopstpXl0qeX1f80ekQJG4vsxZt932Z5X/lxDr0H1tO9bx1p6TEmnVHBwtn2y20S78X5YhdFidp8pAo/RlEFeBRYrqr3OYm9/+i3ObJ7MQWZtcw76yke+HQsL35xKN/ov8bB4IJF5y51/PrmTwiFFAkp8+b04oP/2Rt6P2x0JSdOKWXdqlwefMH6a/jEnwaxeF4XW/EFBbXc9Jv/AtZt17vvDmDJkl6O8m/CbT95i/zcWiLREPe/cAy7auyNCraFcj/06Hiuu2IeaelRSrd05N4/T7QVZ/J9m+Y9FhUeurE3dzyzllAYZj/XmQ2r7I+AmsanDIVo27pDTf1aVBE5BvgvsBT2TJq5QVXfaCkms29fDZZqOSdYquWOdrtUa6jZUq3KmhKjtagjDk/X196w98fuoL6lS5It1fICP0ZR52FN0gsICDigEKJt7Fe7Xa1kCAgIaLtYgwxBAxcQEHAAYs2DCxo4x2SVRRjyiPs5PJ/f6L4Df8jPzIbUw4XOJw/voXyHUdp5H7h3kzUM7mOUtiz4xCg+nJPjPrjQvTsQoGy0/RHOfela5L7fEwCD80WqDVx0pt7DxsMEV3ABAQEHIsEVXEBAwAGLIkTbmIGt3TdwTjQw3Z9cS+7SCqId09lws6UIyiiqpvvT6wjVxWgozKT0ooOIZSdXVpvqa5zmvRFTZZGpNsitrqgRk3r71R/WMH7yDirK0/n5aQk3U9oPN+W+6VtzOWboBnbszua8P1l6rhOHf8HFkxczoOsOLnj4WyzfnHw1hxeaKbe6Iy80UU4IblHjxD1Pi4HNqnq62+M40cBUHdWFiknd6TF97Z7Xejy1jm1n96VmSB55/9tGwVsllH8zcf+TF/oap3lvxFRZZKoNcqsrAvN6e+uVbvzrHz2Yeo/zOXpuyv36h0N5YeFwfn/OXj3XF1s6c80zp3D9Gf+xnbYXmim3uiOvNFF2UIR6db+fRWvg5/XkFcBykwM41cDUDM4jmvPlNj19Sy01g60F19WH5tHhw+RrG031NW7y3oi5ssi9NshMV2Reb8s+yGNnhdu/yc7L/dH6XlRVf3mVx/ptBWwos2+sAfPvzEx3lDpNlKUsD9l6pApfruBEpA/wDeB24Nduj+OFBqa+Vza5n1Swe1QBHT7cTvqO5KsHTPU14E3e3SqL3GqDTHVFXtSbCV7osUxx852ZniupLHdbG2Tw6wru/4BrwL3fuKkGxoTSHw2k03+20O+OZYRqY2ha639BXuTdRFnUqA06f8qJDBlWQf9BO23FNeqKXp81hEuvnkJtXRrnnpVQid+mcFtur3DznXlxrqSq3KpCVEO2HqnCj8X2pwNbVXWJiExK8Lk9PristP3/2jVqYMYdWUp6RpScnAhTb1jk2JTQ0CObzVccAkD6lho6LK1IGmOqvzHNu6myqJGm2iA7XrTmdEVOGjjTevMKp+X2ArffmVfnOaSm3LE2dgXnxy3q0cA3ReQ0IAvIE5F/qOoPmn4ovgnsNID87J779RpMf2Q40x8ZDsCIkds4+9xVrr70cFUD0bx0iCmFbxRTcVzyk6+pvqa8NJ1JZ1Rw52X9badplnczZVFepzqikRC7d6Xv0Qa99KQ9j15TXVFRcb4jXRGY15sJJuU2x/13Znqep7Lc1iBD25qY4cdi++uxNm8lfgU3dd/GrbXo8cgaclbtJLwrwsDrPqJ8Sh9CtVE6/WcLALtGd6ZqYnIbgp/6GlNlkak2yK2uCMzr7dr7V3H4kVXkFUR4at4SnnqgD7NftJd3N+W+7Ttvc8SgYjrl1PL6NU8xbc5YqmqymHr6PApya7j/RzNZVVLIL6cnngRg+p2ZYPp9O6FxkKEtkXJd0pcS39vAJTxD8rN76lEDLnCdzvJfuV+6Y7xUy0BhY7pUS7KzXcc29DFbcmS6VCtksFQrZLhUa+tJzuaoNaXrv1cZpe3XUq35pc9QWbfF6P7y4BE5evc/h9r67NkHf5wSXZKvza2qvmsyBy4gIKDt0LiSwc4jGSKSJSKLROQTEflMRH4ff32giLwvImtE5HkRSThPqW1dTwYEBLRrYhqy9bBBHTBZVUcCo4BTRWQCcBdwv6oeDOwAfpzoIEEDFxAQ4AnWYntvruDUYlf8aXr8ocBk4KX4608AZyY6Ttsa8miJWMyof+Gw24tdx2641n4nenP0nZV82klLhAz60AA0x/3AR01Ps0GTDqNs7eXdIlK0xXWsqWa+63z3ai5TVbtJuWMmaW8zX2KlCA32l2p1EZHFTZ5Pi8+c2EN8OecS4GDgIeALoEJVG2c8F2Htqdwi7aOBCwgIaPOo4mQSb1myQQZVjQKjRKQT8CpwiNM8BQ1cQECAR0irTPRV1QoRmQscBXQSkbT4VVwfYHOi2KAPLiAgwBMUPFuqJSJd41duiEg2cDKWnGMucE78Y+cDryU6Tru9gjP1XLmJv/WkuRw3cD3bq7M56+nzvvTe+aM/5urjFnDM3y6gojZ539n0x/9FdU0asagQjYW44opTWi3fzeHWL3bOpKVMmbgCEfj3/w7hxXdHOErXbbnBzKvmp5MN/Cu3adpO8VB42RN4It4PFwJeUNXXReRz4DkRuQ34CGuP5RbxyybSCXgEGI7V8F+kqgucHMPUc+Um/p+fD+WZT4Zzx9fmfOn1Hh12MbF/EcVV9ndKB7juuhOpqrK36bJJvpvDjV9sYM/tTJm4govvOYtINMS9l85k/rJ+bC5ztoeBm3KDmVfNTydbI36U2zRtJyjimfBSVT8FRjfz+lrA9lo1v25RHwDeVNVDgJG48sKZeq6cxy8p7kVl7f4nyTXH/Y/75k1AU7LQ2Nzv5dYv1r9HBZ+v70ZdQxrRWIiP1/Tk+FHrnCVugIlXzV8nmxnmDsDUYG0bmGbrkSr8sInkA8cBFwCoaj3gagt3U8+VF56sEwatY+uuXFaWOVtXqAq33zYXVZg582Bmvml/SZdpvt36xdYVF3DxlA/Iy62lrj6NCcM2snKjfV05mJW7KW5deG5jTZ1sfpbbq7STE2z8DDAQ2AY8LiIjsea5XKGqu5t+6Eu6pHDzapdGz1VuhwZ+c/di+g/a6UgDYxqfldbAT8d9yMWvOl9tNvXqkygvzyE/v5Y7bp/LpqI8li2zp9ExyXdTv9iIkc7me23YUsDTb43kvsveoKY+jTVFhURjzk5ok3I3YuLCM3WyOa2zRvwstxdp20HB7iqFlOFHbtKAMcBfVXU0sBu4bt8Pqeo0VR2rqmMzwok77Zt6rtzgNr5vfhW986p4+fsvMuvCf9C9wy5e/N5LFOYkt9SWl1uLySsrs5i/oA9Dh5SnJN+NfrHHn53JtTe/z+GjtzH1BvtCgRkLDuEnd3+LX/zfN9lZncmmrc7630zLbeLCM3Wyua0z8LfcXpxrdonGr+KSPVKFHw1cEVCkqu/Hn7+E1eA5Iq9THbkdrM7eRs/VpvX2O/lN4wFWlxdy/N8v5JTHf8Apj/+ALbs68O1nzqG8OrEJIzMzQnZ2w56fx4wuZf0Gew2Fab6nPzKcH33nNC787te565Yj+fSjro78Yp06WKsEuhXs4riR63h7sf3bHZNyW5i48MycbCZ15me5zdO2j6p4uRbVE/zwwZWKyCYRGaqqK4ETgc+dHsfUc+Um/u5T32Jcn2I6ZdXy9kVP8pf3x/HKZ4c6zToFBbXc9Jv/ApYG/N13B7BkSa9Wy7eX3PaTt8jPrSUSDXH/C8ewq8b+yJxJucHMq+ank83Pcpum7QRrkKFt7arliw9OREZhTRPJANYCF6pqi/Kz/MzuOrHH91KVvS+x4XvOrblNMVqLWl5llLbJWtSdw8x8cB3Wmnn/TdZkGmPgZNNs+7uMNYfRGlyDtagLV/ydyupio3vHXsMK9MfPTbL12dsO/2dKfHC+zINT1Y+BVi9cQEBA6rAGGYJR1ICAgAMUD1cyeELQwAUEBHiClysZvKJ9NHDhMLFC5xM6GzHp1+j+gdmM8S0T3I9Y9XjJrB9Ky7e7js0z8O8B7B7R0yg+Osj9ZNSO760xStvEPejnPhr+7a6yl7a26Uz7aOACAgLaPKrQEAsauICAgAMQ6xY1aOACAgIOUIK1qB7il2OrT89Kbrp87p7nPbvtZPpLY3hl1rAWY347ZS7HDtnA9t3ZfOfhcwG48qQFHDtkA5FoiE078vjdayewqy7xxFlTN9iv/rCG8ZN3UFGezs9PG2U7rhFTH905Jy/lG8esBIS1RQXc9fhx1EfsnYYmLjrTejMpt59pQ+p8cME0kTgi8ivgJ1h1shRroq+rnl0/HFtFJflccqO1mU9IYjz/4PPMW9w/Ycy/PxnK8x8M55Yz39nz2sK1fXhwzpFENcQvT1zIRcd8xJ/mTGi1fAO89Uo3/vWPHky9x11HvImPrkun3Zw9+TPOv/kc6hvS+O0lc5g8fi1vzk/+y2rqojOtN5Ny+5l2I6nwwdEGb1FTnhsR6Q38EhirqsOBMHBe4ijv8cqxNXpYCcVbO7K1PPF60A839qJyn2VNC9f23aNvXlrUnW55u5oL9TTfyz7IY2eFyd81Mx9dOKxkZkQIh2JkZUQoq7C3g72pi878+3Zfbj/TTjWx+L4MyR6pwq9b1DQgW0QagBzA1b5+bcEtdsJRa3lnwSBX6TbljNErmP3ZQY5iTPJtglsfXVlFLs/PGsELdz1HXUMaH3zWm8Wf97EV64WLrhG39eaFP9CPtFPlg7NGUdvWWlQ/FttvFpF7gY1ADTBbVWfv+7kv+eDSm78N8dstlhaOMnHMRh593mzV2Y+PWUIkJryxdLDtGJN8m+LWR9chp46jR23gvOvOZVdNJr//2RxOnrCatxYmL7cXLjowqzdjf6BPaafOB9f2Jvr6cYtaAJyBJb7sBeSKyA/2/dyXfHBpzd/G+OnYAhg/sojV6wvZUeV+cuaUkSs4dshGfvPKiWDz0t00317h1Ed3xKGbKSnrSOWubKLREO99OIBhB9l32Zm66LyqNzcePj/TTqUPrq3dovrRI3gSsE5Vt6lqA/AK4Hj7eH/dYhaTDW9PJx60kfMnfsKVz51KbSTdZpR5vk0w8dFt3d6BwwZtJTMjAihjDi1mQ0kn22mbuOhM683Mw+df2in1wWGNotp5pAo/+uA2AhNEJAfrFvVEYLHTg/jp2ALIymzgiOHF3P+Yve3j7vjW2xzRv5hOObXMvPIpHn53LBcd8xHp4Sh//cHrgDXQcMcbx7Vqvq+9fxWHH1lFXkGEp+Yt4akH+jD7xdb16DWyfF03/rNkIH+/6VWisRCrNxby+nv2Nys3cdGZ1ptJuf1MO5U+OGh7ynK/fHC/B84FIlh7G/5EVVscVsrP6aUTDvmp+/QM1qLWHT7AdSzAjiHu/WA9XlpllLZW17iODRV2NkrbeC1qlvtfFOO1qCbrQWvc17lp2ibrtb3wwRUc0k0nP3ZO8g8Crxz914Q+OBHpCzwJdMe6OJymqg+IyO+An2Lt6wJwg6q+0dJx/PLB/Rb4rR9pBwQEtB4e3n5GgKtU9UMR6QgsEZG34u/dr6r32jlIu17JEBAQ0HbwciWDqpYAJfGfd4rIcqC30+O0jwZOFalxtXWqMZmbK43iuy90NcUPgMs+/dAo7Qd+eK7r2FCR2UhbzqK1RvFGt4kGynEANVAemeQbILKpyHVsqNzepOlmqfPm98tBA9dFRJr2vU9T1WnNfVBEBmDtcv8+cDRwuYj8CKvv/qpE2x20jwYuICCgzeNwHlyZnT0ZRKQD8DJwpapWichfgVuxLhhvBf4IXNRSfNDABQQEeIaXc9xEJB2rcXtaVV8BUNUtTd7/O/B6omMEDVxAQIAnqELEI+GliAjwKLBcVe9r8nrPeP8cwFnAskTHafcNXCikPPDwHMrLsvndDfbmpIG5wsYkbafKokid8PJ3+xGtF2IR4eBTdzLhyjI+ebITH0/vTOXGDH66aDXZnaO20s/NqefXl85nQL8KVIU/PjSR5avsretsz9og8Od88SLfYydV8bNbiwmHlJnPduaFP9ufu2iqyHKCh6OoRwM/BJaKyMfx124AvhvfdlSB9cAliQ7Sag2ciDwGnA5sjVtDEJHOwPPAgHjmvpOog9AOZ5y9mk0b88jJaXAUZ6qwMUnbqbIonKGc9dRGMnKVaAO8dF5/+h+/i55H1DBw8iZe/r6z2fGXXrSIDz7qza33TiItLUpmhr2GEdq/NsiP88U036GQctkdm7n+vEGUlaTz4BurWTgrn42r7e17a6rIsouXa1FVdR7Nr11scc5bc7TmtOPpwKn7vHYdMEdVBwNz4s9dU9ilmnETSpk1Y4DjWFOFjUnaTpVFIpCRa03IjkWEWIMgAt2G1ZHXx9kvak5OPSMO28qbc6xlTpFImN3VTiYjt19tkH/ni1m+h46upnh9BqUbM4k0hHj3tU4cdYr90X1zRZZ9VMXWI1W0WqlV9b348G5TzgAmxX9+AngXuNZtGpdc/imP/W0E2dkRt4cA3ClsvErbLrEoPHfmACo3ZHD4D3bQY5S7nZ96dNtFRVUmUy+fz6D+21m9tpC/PjaO2jq7a2HbrzbIz/PFJN+FPRrYVrz3j1BZSTqHjKl2lOdUkcqF9HZI9cKx7k06CEuxlmE0i4hcLCKLRWRxfWT/L3P8hBIqKjJZs8pszpMbhY1XaTshFIbv/Xs9F81bQ+knWZSvcrcELByOMXjQdl6fNYRLr55CbV0a556VsJ92PxrVPedPOZEhwyroP2ino3gvtEFO0/bzfAHzOmsPqAaL7fegqioiLV6oxyf9TQPIz+653+cOG17OhIkljDuylPSMKDk5EabesIh77xhvOw9uFTZepO2WzLwYfSZUs+G9DhQOcb7vaVl5LtvKc1ix2hpU+O+C/o4buEaaqnvsuslaQxtkJ20/zxeTfAOUl6bTtdfeibhdejZQVmL/ijt1WHs+tCVS3cBtaRzmFZGegH2p1T5Mf2Q40x8ZDsCIkds4+9xVDhsY9wob87SdUV0eJpyuZObFiNQKm/6XyxEXu1tpsKMim21lufTpVUlRcT6jR5Swsci+PievUx3RSIjdu9L3qHteetKuidhcG+Q2bT/PF7M6g5Uf59B7YD3d+9ZRXprOpDMquPOyxHuA+EUq+9fskOoG7l/A+cCd8f9fS3H6ezBV2JjgVFlUvS2N2Vf3RGOgMWHwaVUMnLybj58oYMm0zlSXpfHM6QPof/xuTvpDadL0H3p0PNddMY+09CilWzpy75/t6/jaqzbIFJO8m+Y7FhUeurE3dzyzllAYZj/XmQ2r7I2ggrkiyy5tcVetVtMlicizWAMKXYAtWPaQfwIvAP2ADVjTRJLeZ+Vn99SjBlzgPjMGawsxXde4yf1a1Mt9XIuabrgW1U9tkObY/+Vvlva6FjXH/VrUhTUzqIyWGbVOuYN76mF/utDWZxef9oeEuiSvaM1R1O+28NaJrZVmQECAv7S1UdR2v5IhICCgbaDBIENAQMCBjA+C8IS0iwYulh6mrrf7jTLSVrpfohIy0H4DSF/3/vs/nzPAKO3NN7mf0Nrvh86noDTFVHlu1I9m0ueKv8pyPWqk61jZvtt9wuu9mXbyVR9FDQgIOEBRDRq4gICAA5i2Nk0kaOACAgI8I+iD84g+PSu56fK5e5737LaT6S+N4ZVZw2wfw2/Hlls32fTH/0V1TRqxqDVqdcUVpyT8fLisgYI/FRGutLRIu08uYNfpheQ/UUrW4p1omhDtkcH2y3ujueGExzIpd3v1uZnm3Qv3oInDD9zXmxMUIfZVGUVtwQd3DzAFqAe+AC5U1Qo3xy8qyeeSG88EICQxnn/weeYttr98pS04tty6yQCuu+5EqqrsbXysYai8oAcNg7KRmijdrl5L7chcakd2oPIH3SEs5D9VSt4r26j8YY+ExzIpd3v1uZnm3Qv3oInDD8zONSe0sQu4lPvg3gKGq+rhwCrgei8SGj2shOKtHdla3sF2jN+OLRM3mVNiBek0DLJGBjU7TKRPJuHtEepGdYCw1WdSNySHcHnyUVezcrdXnxv46cEzdfil7FzTr7gPTlVnN3m6ELC3DXYSTjhqLe8sGOQoxm/HlombTBVuv20uqjBz5sHMfPNg27HhrfWkr6ulfvCXp0LkztlBzdHup+LYpb363MA/D56pwy+l7sI2dgnn5w3zRcDMlt5s6oNraGh5fk9aOMrEMRt57/2BrZHHVsHUTTb16pP4xS9P5aabJ3H66asZPtyelEVqohTes4mKC3ugOXv72jq+tA3CQvVxrd/AtVefG/jnwTNx+KXaXdhuruBE5EEStMeq+ku3iYrIjUAEeDrB8ff44Drm9WkxH+NHFrF6fSE7qpxNzvTTsWXqJiuPb/BbWZnF/AV9GDqknGXLkvjJIkrhPZuoPjaf2gl7rx5y3tlB1pKdlP1ugOVGTxHt1efmJu+maZs4/FLpLlSsP4pD4V0AACAASURBVAJtiUR/RhYneM81InIB1uDDieqBymSyi9tT8NexZeImy8yMEAopNTXpZGZGGDO6lGeeTTJyrErBXzbT0CeTXd/cq/fJ/GgnHV8rZ9stA9DM1r+Yb68+N9O8m6Zt4vBLqbtQgfYyD05Vn2j6XERyVNWok0pETgWuAY43PRZAVmYDRwwv5v7HnA97txfH1r4UFNRy02/+C1i3Lu++O4AlSxIvB8tYUU3ufyqp75dJt6u+AKDqe93o9FgpNMTocssGAOqHZFNxSeJjmZS7vfrcwF8PHpg5/FJJW5sHl9QHJyJHYW3A2kFV+4nISOASVb00SVxzPrjrgUygUTa2UFV/liyTHfP66Njxlyf7WIukvbPEdayJYwvM1qJqtrt9FxrZeJP7v6b9frjOKO1gLao7IoP7uI5NM1iLumD9dCprSowuvzIH9dbet11m67Prvn9jQh+ciPQFnsTat0WBaar6gNOtR+30dP4fcAqWjRdV/UREjksW1IIP7lEb6QUEBLRLPB1AiABXqeqHItIRWCIibwEXYG09eqeIXIe19WiLO/PZ6nhR1U37vORslmFAQMBXA7X5SHYY1RJV/TD+805gOdAba+vRxu6zJ4AzEx3HzhXcJhGZCKiIpANXxBNrN5goaEKG6u6YyW3mqvVGafe/xP2tVugNsykj0dPMdEsYVLvp7bGJNtzkXAMIf7LadayYlDsWcx/biFp7hnhNfD7taOB9HGw9Cvau4H4GXIbVehYDo+LPAwICAvZBbD7o0jjPNf64uNmjiXQAXgauVNWqpu/FZ2EkvB5MegWnqmXA95N9LiAgIMDBSoayZJvOxO8YXwaeVtVX4i872no06RWciAwSkX+LyDYR2Soir4mI84lnAQEBBz4e9cGJiGANSi5X1fuavNW49SjY2HrUTh/cM8BDwFnx5+cBzwJH2ohtNbzQJblV0Hih/XGqPGqKibLIqbpHt0aJ3lGB7oiBQOj0HMLn5BJ9fCexGdWQb/2NDP+0I6EJiad2mCqm/FY1mei1THRHfpfbNt5O9D0a+CGwVEQ+jr92A9aeyi+IyI+Jbz2a6CB2GrgcVX2qyfN/iMjVyYKa0yU1ee8q4F6ga/wW2DGmuiRwr6DxQvsDzpRHTTFRFjlW94QhfGkeMiQdrY4RubiM0Fhr4CR0Ti7h8+wbXEwVU36qmkz1Wia6I78VVU7waqKvqs6DFvcgtL31aIu3qCLSOT6pbqaIXCciA0Skv4hcA7xh49jT2V+X1DiB72vARruZTIYbXZKZgsZM+2OKibLIqbpHCsPIEGuNruSEkP5paJm7ETdTxZSfqiYTvZap7sjPcjsmJvYeKSJRrS3BqorG3FzS5D0licutOV1SnPuxlmslvHd2ghtdkqmCxlSdY6I88gqn6h4tiaCrG5BD09Gl9cRerSY2uwYZmm5d5XVsWzbXfTH5zkz0WqbnmileaJ7sIm1sqVaLZ6SqDlTVQfH/9324GmQQkTOAzar6iY3PtqouyURBA+bqHLfKI69wqu7R6hiR3+4gfHkekhsidEYOac90Je2RLkhhiOhfqpIew29MvzO3mJ5rpqSs3HYHGFLYCNr6kysiw0XkOyLyo8aH04REJAerk/BmO59X1WmqOlZVx6ant6x2dqtLak5Bc/Ag55NTm6pznNCc8ihVOFX3aESJ/nYHoZOyCR1n1bN0DiNhQUJC6Bs56PLWVWF7iZvvzESv5dW5Zorbc9U+Yg0y2HmkCDvTRH4LPBh/nADcDXzTRVoHAQOBT0RkPdAH+FBEEm8CkAS3uqSmChrAkYImr1MduR2sX+hGdc6m9fb7/zIzI2RnN+z5eczoUtZvaH3ZpIUzdY+qEr27EumXRvg7e8uo5Xs7yWPzapGBbXv/ItPvrKleKy09xqQzKlg42953ZnKumWJabse0sSs4O2flOcBI4CNVvVBEugP/cJqQqi4F9lwuxBu5sW5HUcFMlwTuFTSm2h83yqOmmCiLnKp7dGkDOrsGHZRG7MfbrDz/tCOxObXomgYQkB5hwlcl/4U1VUz5qWoy1WuZ6I7alaLKgxVfXmJHl7RIVceLyBKsK7idWJPvDkkSt58uSVUfbfL+emw2cKa6pHCNexd9uula1EJn3v8vYbgWVXIM1qK+ZKZqip5mfwMfr/mqrkU1Kff80meorNtipkvq11d7Xnulrc9uuHxqQl2SV9i5glssIp2Av2ONrO4CFiQLakGX1PT9AXYyGBAQ0H5oa6OodtaiNootHxaRN4E8Vf20dbMVEBDQLmkvDZyIjEn0XqOrKSAgIKCtkugK7o8J3lNgssd5aTmxsFDfyf0oXY6BsjxmqCzHoA/OtC/JhIZJ7vuhAJ7bNN8o/vsnOZ6JtAc1VJaHuxS6jo0uSDrFMyEmffQmfa6e+OBoR7eoqnpCKjMSEBDQzlFSugzLDm178lJAQED7or1cwQUEBAQ4pd3corYHzpm0lCkTVyAC//7fIbz47ghH8SZ+L1O3mVsfnKnfyzTeaZ3V1wq/P2c4DfUhYlHhyNPK+fZVe/cwmn7zQOY+340nVr5vK/1QSHng4TmUl2XzuxvsT/B26sHzOt7kXDOJN823Y9pbAxc3a34fGKSqt4hIP6CHqi5KEtesD05EfoG1p0MUmKGq17jJ+MCe25kycQUX33MWkWiIey+dyfxl/dhcZm8JjKnfy9RtBu58cKZ+L5N4N3WWnqnc9PxnZOXGiDQIv/3WcEadsIPBY3bxxSe57KoM2y47wBlnr2bTxjxycpytfXXswfMw3vRcM4k3Lbdj2lgDZ2ex/V+Ao4DGibs7sQy/yZjOPj44ETkBa9uvkao6DEt66Yr+PSr4fH036hrSiMZCfLymJ8ePsr9ZsYnfC8zdZu4x9Xu5j3dTZyKQlWuN0EUjQjQiIBCLwtO3D+D7N2ywnfPCLtWMm1DKrBkDbMc04tSD52W86blmEm9abieI2n+kCju/oUeq6hgR+QhAVXeISNJ1PC344H4O3KmqdfHPuNYarCsu4OIpH5CXW0tdfRoThm1k5UZ7Cmgw83t5gYkPztTv5TbebZ3FonD9aSMpXZ/F184vZfDoXbzxaE+OOHk7Bd3tX4ldcvmnPPa3EWRnu196B849eKbxpueaV+eqablt0Q5HURtEJEz877yIdMX9dJ0hwLEicjtQC0xV1Q+a+2B8G7GLATKyO+33/oYtBTz91kjuu+wNaurTWFNUSLSNVW4ipl59EuXlOeTn13LH7XPZVJTHsmXJ1UWw1++V26GB39y9mP6DdrJhbUfbaZvGOyUUhrtmfcLuyjB//OkhLF+Yx/szCrn5BftOtPETSqioyGTNqgJGjNzmOi9OPXhex/tFqvLdHgcZ/gS8CnSLN0znAL8xSK8zMAEYh7V5xCBtZsW/qk4DpgF0KOjbbLXNWHAIMxZYa/4vnrKIrRX2+xVM/F5e0JwPzm4D10hTv5ebBsppvGmd5eZHGTaxks8W5FG6PosrjrUWy9TXhLjimNE8MO+jFmMPG17OhIkljDuylPSMKDk5EabesIh77xhvO32nHjyv4k3rzTTetNyOaGMNXNI+OFV9Gksx/gegBDhTVV90mV4R8IpaLMK6Emze02ODTh1qAOhWsIvjRq7j7cX2b/NM/F6mmPjgTP1eJvFu6qyqPI3d8YGE+poQn77XiYEjdvO3Dxfz5wUf8ucFH5KRHUvYuAFMf2Q4P/rOaVz43a9z1y1H8ulHXR01bk49eF7Gm55rZvGm5XZAe+yDi4+aVgP/bvqaqrrZNOafWMqluSIyBMgAXPvgbvvJW+Tn1hKJhrj/hWPYVWN/RNLU72Xi6DLxwZn6vUzi3dTZjq0Z/PVXBxOLCrGYcNSUMo44yWwplRucevC8jDc910ziTcvtmDZ2BWfHB7eUvZvPZGFZeVfGR0ETxe3ngwOeAh4DRgH1WH1w7yTLZIeCvjryxCuSfaxFcl6xN8eqOUKma1GHDHCfdrl/+xyYONHA37WoGK5FNSFaljr1/L6YrKFdsONlKhu2GXViZ/Xuq/1/9mtbn111868T+uCam2YmIr8Dfgo0dsLeoKoJd/izo0v60uzZuGXk0hY+3jSuJR/cD5LFBgQEfOWZDvwZeHKf1+9XVdvTyxzv8xbXJPm6q31AQEAbxaM9GVT1PcB4Zx47fXBNrzlDwBig2DThgICAA4zUDCBcHt/VbzFwlaom7I+wM02k6fyBCDADeNl9/pwTrovSYa37vRxDfft4mBtnxEz2VTD0wZnsB5GGWZ0Z9aEBG890P52h36NmfXB1hw9wHZuxsMYo7V2nOltP3ZS8Dza7T7jSo0277TdwXURkcZPn0+JTwxLxV+DWeCq3YjkrL0oUkLCBi0/w7aiqU5PnNyAg4CuP/QauzOmmM6q6pfFnEfk78HqymBabbRFJU9Uo4G5PvoCAgK8UAkjM3sPV8UV6Nnl6FpB0KUyiK7hFWP1tH4vIv4AXgd2Nb6rqK+6y6R1ulUNgpg0yVQ6ZqJZM0wb/6q0RJ8qjW0+ay3ED17O9Opuznj7vS++dP/pjrj5uAcf87QIqahPruk21QX16VnLT5XP3PO/ZbSfTXxrDK7MSzpYCzNVa4F4N5sX3ZRsP++CaTjMTkSKsaWaTRGSUlRLrgUuSHcdOH1wWUI61B0PjfDgFEjZwLcxjGQU8HD9mBLg0mXYpGW6UQ2CmDTJVFpmolkzTbsSPemvEifLon58P5ZlPhnPH1+Z86fUeHXYxsX8RxVX2VmGYaoOKSvK55MYzAQhJjOcffJ55i/vbijVVa5mowbw6X2zjUQPXwjSzR5t5LSGJeha7xUdQlwFL4/9/Fv/fzirp6eyjSwLuBn6vqqOAm+PPfcJEO2SmLDJTLZnqkkwxS9+p8mhJcS8qa/dviK857n/cN28Cir25qV5qg0YPK6F4a0e2lttrXE3VWmZqsBSfLx5NE/GKRLUeBjpAs2dQ0iy2oEtSoHFoLx/D6SYmyiEw0w6ZKotMME3bz3rzQnl0wqB1bN2Vy8oyd8uNTLVBJxy1lncWDHIV6wZTNVgqz9X2ZBMpUdVbPE7vSmCWiNyLdfU4saUPNtUlZaU3fyluohwCM21QqpVDXqbtV715oTzKSmvgp+M+5OJXT3cXb6gNSgtHmThmI48+72gA0AhTNVhKz9U21sAlukVtDbnaz4FfqWpf4FckuKdW1WmqOlZVx2akNb8etDnlkBuaaoNSGWuK27T9qrdG5dHjz87k2pvf5/DR25h6g7Mu2L75VfTOq+Ll77/IrAv/QfcOu3jxey9RmJNcAOmFNmj8yCJWry9kR5XBHqQumLHgEH5y97f4xf99k53VmWza6tx80+rnqrbuKKobEjVwJ7ZCeuezd3DiRcCJ7+ZLmCiHwEwbZKosMsE0bT/rzVx5BKvLCzn+7xdyyuM/4JTHf8CWXR349jPnUF6dTIrgjTZocopvTxtxqwZL+bnaXvrgVNV4HVgzFAPHA+9ijcqudnsgE+UQmGmDTJVFJqol07T9rDc33H3qW4zrU0ynrFrevuhJ/vL+OF757FDHx/FCG5SV2cARw4u5/zFnU0NNvu9G3KrBUv19tbU+uKS6JNcHbl6XtBJ4AKthrcWaJrIk2bHyc3rphEN+6jovfmqHYuXu/06EfFyqZVpnmmPfd9YcZku1VhqlbbZUa7lR2n4t1Zpf+gyVdVuMuqWye/TVg79vT5e07L7EuiSvaDU5ewJd0hGtlWZAQICPpPj20w7tZ9eMgICANo3Q9m5RgwYuICDAM4IGzg0NDUjRluSfawEtdD+xUTeZqe9M+9FM8KvOAGNteP9nal3HnvyfL4zSnv0tg/PFKGXo+J675VzGacc8mrsRNHABAQEHLEEDFxAQcECS4i0B7RA0cAEBAd4RNHDeYOr3asSJm6wpfjndTP1eXtSb2zozTdtp2WtKhE+vz6GuPIQI9P12HQN+WE/VihCf3ZJDpFrI7hVj5N27Sbcxud+PcwXM6s2r3xO7pHIZlh1arYETkb5YW351x2rXp6nqAyLSGXgeGIAlrftOso0jmsPU79WIEzdZU/xyupn6vbyoN7d1Zpq207JLGhxyTS35h0WJ7Ib/fbsjhUdFWHZzDkOvrqFwXJRNr2Sw7rEshvwy+aCGH+cKmNWbV78ndmlrt6ge7TTRLBGsXW8OAyYAl4nIYcB1wBxVHQzMiT93jBd+L6dusqb453Qz83uZ1ptJnZl/Z87KntVVyT8san0+FzoMilG3NcTuDWE6j7Ve73JUA6VvpSdN2b9zxazevPTgJcXuOtS2sBbVFFUtAUriP+8UkeVAb+AMrCVcAE9grUu91iQtt34vL9xkbmkLLjo39eZVnbn9ztyWvXpziKrlYfIPj9Dh4Chb30mn+4kNlM7KoLY0+d95P8+Vppi47Ew9eLb4Cl3B7SEuvhwNvA90jzd+AKVYt7DNxVwsIotFZHF9rOXbB7d+r6ZuMj9odHSdP+VEhgyroP8g+9simsQ24qbevKozEyebm7JHdsNHV+Zw6HU1pHeAEbdWs+G5DP737Q5EqiGUnvi30u9zpRGTejP14NmhcSWDnUeqaPVBBhHpgLWP6pWqWiWydz2vqqpI88WN75E4DSA/vWuznzHxezW6ycYdWUp6RpScnAhTb1jkWN9jSlNHl1MJodtYt/XmRZ154WQD+2WPNcBHV+bS6xsN9DjZ6jvrMCjG+L9b+yftXh9i238S36K2hXPFpN68qnM7SKxtXcK1agMnIulYjdvTTXbh2iIiPVW1JL4NmEv7npnfa/ojw5n+yHAARozcxtnnrkrZCZvXqY5oJMTuXel7HF0vPXlQq8dauK838zoz+86cll0Vlt6cQ+6gGAMv2NvvVFcuZBYqGoM1f8ui77n1CdP181yxMKk3bzx4NpNqc7eorTmKKljG3uWqel+Tt/6FJb68M/7/a26O74XfywS/nG6mfi8/6800badl3/FhmOJ/ZdBxSJR537Ku8oZcWUP1hhAbnrV8aj1OaqDPWYkbOFNMfXAm9Zbq77utjaK2pg/uGOC/WDtyNc6OuQGrH+4FoB+wAWuaSEJpWn56Vz2q4Gz3mfmKrkXVmhr3wT6vRZVs90rwk9+0s+lby8z+lntNmen5IjmpVaE3smDHy1Q2bDPyweV26auHTfmVrc8unn5Vu/fBzaPlfR1aQ4ceEBDgMx5u/NzcvsqO59CmZBQ1ICDgK4J38+Cms/++yo7n0AYNXEBAgDd4uKuWqr4H7Nt1dQbW3Fni/5+Z7Djtdi1qqoiOHGx2gE9c76sDQwaYpY3BhM5V641SNu1LMtlPYvbxTkaV96f6GfeTeXN/7F+fq8n+H3gwvcOh0beLiCxu8nxafGpYImzNoW1K0MAFBAR4h/1ByzKTQYZEc2ibEtyiBgQEeEYrr2TYEp87i905tO32Cs5vXVJuTj2/vnQ+A/pVoCr88aGJLF/V1VasqT5n+uP/oromjVhUiMZCXHHFKSmLN8m7F9+Z27w7TntrhPR7ymBHFARip3Uketbe2+bwS5WkTdtB3Yt9IT+cMG1TxZVpvOn5ZpvWn+jreA6tH7qke4ApQD3wBXChqlY4Pb7fuqRLL1rEBx/15tZ7J5GWFiUzI2o71lSfA3DddSdSVWVv818v403y7tV35ibvjtMOQ+TiAnRwJlTHSL+smNiYLLR/BmyNEFpSg3ZL3LA1Yqq4Mo334nyzi1c+uKb7KotIEda+yncCL4jIj4nPoU12HD90SW8Bw1X1cGAVcL2bg/upS8rJqWfEYVt5c87BAEQiYXZXZ9iON9Xn+IlJ3lOq7jFNuzDNatwAckJov3Qoi6uXHt5O5CedW57luR9miivT+FSebx6Oon5XVXuqarqq9lHVR1W1XFVPVNXBqnpSsgUC4IMuSVVnN/nYQuAc07RSrUvq0W0XFVWZTL18PoP6b2f12kL++tg4auuSe8W8QBVuv20uqjBz5sHMfPPglMZ7gdvvzIu8O067tIHQmnoih2QSml+NdgmjB9n/gwbmiiuvFFmtiuJkkCElpKRZ30eX1JSLsGYmNxdzMXAxQFaoZZ+0F7qkESO32Y4DCIdjDB60nb88Op4Vq7vy84sWce5Zy3jiudGOjuOWqVefRHl5Dvn5tdxx+1w2FeWxbJl9S4RpvCkm6h7TvDtOuyZG+i3biPy8M4Qh/GwFDXf2cJRn2Kt5yu3QwG/uXkz/QTsdGWBM41NFW1uL2uqjqPvqkpq8fiPWbezTzcWp6jRVHauqYzNCWc0e2wtd0uPPzuTam9/n8NHbmHrDIluxZeW5bCvPYcVqa1Dhvwv6c/AggzlIDikvzwGgsjKL+Qv6MHRIeUrjTTBV95jk3XHaESX9lq3EJucSOyYXKYkgpREyfraZjB9ugm1RMi4thu327wCaap7cYBrf6rQxo2+rNnAt6JIQkQuw1pl9X12v9jfXJf3oO6dx4Xe/zl23HMmnH3W1rcDZUZHNtrJc+vSqBGD0iBI2FuU7zoMbMjMjZGc37Pl5zOhS1m+wn7ZpvBlm35lZ3h2mrUrafWXE+qUTPcdKQwdmUP9iP+qf6kv9U32ha5j6v/SCzomvBPM61ZHbwcp3o+Zp03obu9x4FJ8qvlLCy5Z0SSJyKnANcLyqVrs9vt+6pIceHc91V8wjLT1K6ZaO3PvnibZjTfQ5BQW13PSb/wLWrfK77w5gyZJettM2jTfJu+l3ZpJ3p2nLZ3WE395NbGA6oZ9tBiB6UQGx8Tm20muKqeLKNN5U12Qb1TYnvPRDl/QnIBNovLdYqKo/S3QsP3VJkc5muw+FfV2qZYDPS7W0j/tfQCnaYpR29TPu+7Zyf+zfng0mS7UW1sygMlpmpEvq2KmPjj7uCluf/e+/rzlgdUlvtFaaAQEB/tLWBhna52SsgICAtofiyaJ9LwkauICAAO9oW+1bO2ngYopWu9dvhwz01+nVyXc8T0Sk2vU4CiHDfjATXXrthEON0s5YuNwovqaX+77P3HKz/r/sa5wPJDSy8pdmI9KDXnF/voQNFFOscDZxuSWCW9SAgIADlrY2iho0cAEBAd7wVdo2MCAg4KuFNdG3bbVw7bqBM/FcmTi2TP1cAGMnVfGzW4sJh5SZz3bmhT/bn/flV7kB+vSs5KbL5+553rPbTqa/NIZXZg1r1XwDnHPyUr5xzEpAWFtUwF2PH0d9xN4p7MV35sRF94cJc5ncewPltdmcNuNcAB445i0GdrTMYHkZdVTVZ/LNmd+2lbaJf9DUH+gIj3RJXpFyH1yT968C7gW6qmqZmzRMPFcmji1TP1copFx2x2auP28QZSXpPPjGahbOymfj6ubX3O6LX+UGKCrJ55Ibrb0+QhLj+QefZ97i/q2e7y6ddnP25M84/+ZzqG9I47eXzGHy+LW8Od9eI2Va7kbsuuheWTuUf6wczj0T39nz2hXzTt7z8/Vj5rOz3n7Hvol/0Em+TWlrV3B++OAaG7+vARtNEjDzXJk4tsz8XENHV1O8PoPSjZlEGkK8+1onjjql0na8f+X+MqOHlVC8tSNby+2tizT1koXDSmZGhHAoRlZGhLIKJ6Od3pXbDh9s7UVFfUsNinJavy/49wZ7qidT/2DKsLvQ/kBYi9qSDw74HLgfaz1qUuVwa2Li2DKJLezRwLbivSdoWUk6h4xxPz3AKV65xU44ai3vLBjkce6ap6wil+dnjeCFu56jriGNDz7rzeLP+zg6hmm5vfLojetWQlltDht2drL1eVP/YOr8f21vLWpKNp1p6oMTkTOAzar6SZKYi0VksYgsrlezuWgt0ejYOn/KiQwZVkH/QTtTEus3XuQ9LRxl4piNvPf+wFbI4f50yKnj6FEbOO+6czl76vfIzoxw8gRn63xNyz316pP4xS9P5aabJ3H66asZPtydsuj0/mt4fb39RqbRP/j6rCFcevUUauvSOPesZbbjvcq3LVTtPVJESn1wWLetNwA3J4v7kg9O7PVNucXEseUmtrw0na696vc879KzgbKS1NiAm2JS7vEji1i9vpAdVWaTau1yxKGbKSnrSOWubKLREO99OIBhB6XWqeaFRy8sMU7pu44ZG+zv3WrqH0yZ/8/DjZ+9ItU+uIOAgcAnIrIe6AN8KCLOFamGmDi2TP1cKz/OoffAerr3rSMtPcakMypYODs1Tjav3GKTU3h7CrB1ewcOG7SVzIwIoIw5tJgNJfZu8cC83F559I7uUcTaqk6U1thP28Q/mHL/Xxu7gkupD05VlwLdmnxmPTDW7SiqiefKxLFl6ueKRYWHbuzNHc+sJRSG2c91ZsMq+1epfpW7kazMBo4YXsz9j9nfZtE038vXdeM/Swby95teJRoLsXpjIa+/d4jttE3L7dRFd//Rb3Nk92IKMmuZd9ZTPPDpWF784lC+0X+N7cGFprj1D5r6/xzTtrrgUu+DU9U3mnxmPTYauPxwF52Q/Q3XeTFZk2lKZFOR69hQjvs1kWC4FnWwmRDReC3qpOTz6loid2mJUdoxgzWdq7/v41rUGmdbXzZl4Yq/U1ldbOSDy+vQWycMv8TWZ996/7cHrA+u6WcGtFb6AQEBKUbxdKJv/AJoJxAFIm4axHa9kiEgIKDtIGhrTPQ9wW0XFgQNXEBAgJe0sZUM7aOBC4mx498vwkPdT6qMrnS+pMkrTCfmmHjwADJ21Cf/UAuY7E0AIDXu3YODf7veKO2Za+a7jv36ad8zStsT7DdwXURkcZPn01R12r5HA2aLiAJ/a+b9pLSPBi4gIKDt46wPrsxGn9oxqrpZRLoBb4nIClV9z0mWUrKSISAg4KuBxGK2HnZQ1c3x/7cCrwL2Ni5uQru9guvSvZarbv+cgsJ6VIU3X+7Fa0/3tR3vty4J4msjH55DeVk2v7vB/pwyv1RLYF52k7yDe22QablNzjc3adfXCld962Aa6kNEI3DsNyr50dWl3HtlPz5dkEtuR6uRmPp/a0wn5AAAEBNJREFUGzloeOJb6tTpkrybxCsiuUAovo49F0vOcYvT4/iiSxKRXwCXYQ3/zlDVa5wePxoVHvnjYL5Y3pHsnAh/eu4DPlzQmU1r7bn8/dQlNXLG2avZtDGPnBz785f8VC2BWdlN8w7utUGm5TY539yknZ6p3P3iF2Tnxog0wK/PHMy4yVUA/PSmYo493b59BlKkS1K8HGToDrxqrRcgDXhGVd90epCU65JE5ATgDGCkqg7DcsI5ZkdZJl8stzboralOY+O6XLp0q3NwBP90SQCFXaoZN6GUWTMGOIrzV7UEJmU3zbuJNsi03Cbnm5u0RSA717pKizQI0QZBjKbhpoiYzUcSVHWtqo6MP4ap6u1usuOHLumnwJ2qWhd/z1ht0K1XDQcdspMVS53NQPdLlwRwyeWf8tjfRpCd7WwndL9VS+C+7KZ5N9UGeYXb880p0ShcfspQitdnMOWCMg4ZU83rT8L0O3vy9P09GHXMTi66oYSMzMR/YVKnS/pqCS/30FSXBAwBjhWR90XkPyIyzuTYWdkRbrxvGdPuHkzNbmfttV+6pPETSqioyGTNKnceNr/xSxVlqg3yApPzzSnhMPz17ZU8veRzVn6cw/oVWVx4fTGP/HcFf3pjFTsr0njhoW5JjxPoklqRprokVa3CumrsjHXbejXwQnxh/r5xe31wseZ9cOG0GDfet4x3Z3Rn/pzkX3RLpFqXdNjwciZMLOHxZ2dy7c3vc/jobUy9YZGt2LaiWgLnZTfNu6k2yBSvzjendMiPMnLiLj6Y25HC7hFEICNT+dq521n5cfL1yqnTJSlEY/YeKSLVuiSAIuAVtViEdUfeZd/YL/ngQs11QitX/n4Fm9bl8OpT/RznzU9d0vRHhvOj75zGhd/9OnfdciSfftSVe++wNwLup2oJzMpumncTbZA5ZuebUyrKw+yqDANQVyN8+F5H+h5cR/kW66pRFea/mc+AoYllsIEuqZVoTpcU55/ACcBcERkCZACO15odNrqSE6eUsm5VLg++YF39PPGnQSyet19b2Sx+6pJM8FO1BGZlN807uNcGmZbb5Hxzk/b2Lence0U/YjEhFoPjplQw4eQqrvn2QVSWp6EKBw2r4Zd3JTanpF6X1Lb64FKuSwLeBh4DRgH1wFRVfafZg8TJT++qRxWc7T4v2f4t89Ic94ueTJdqmeiWTBVTJpooAD1qpOvY8CfOVOb7YrIsUKvdL/MC/5ZqeaFLys/soRN7/8DWZ99c98cDWpdkrxYCAgLaEQratjZGbbcrGQICAtoYSkoHEOwQNHABAQHe0cb64NpHA5eWBoXu54zFst1vkis17rU9AJHO9paONUd6X2f7fu6LiXpbDcttqluvz3Z/aqb7qKg37e816UcrnmR/E559qd8cdh37JYIGLiAg4MAktVNA7BA0cAEBAd6ggE0VUqoIGriAgADvCK7gvMWtUw3MPVkmabv1mnnhovOr3KZOtj49K7np8rl7nvfstpPpL43hlVnJtxg0rTe//YFOvrPfnzqX4w5az/bqbM5+/DwALjtmEZMOXkdMhR3V2dw0czLbdrnvH24e/eqMorbkgxORUcDDWNr/CHBpfMmWK9w41Zpi4skySdut18wrF50f5TZ1shWV5HPJjWcCEJIYzz/4PPMW97cVa1pvbcEfaPc7e23ZUJ79aDi3nzZnz2vTF43ioXnWcsDvjfmUSyYu5rbZxztKPykK2sbmwaXcBwfcDfxeVUcBN8efu8KtU80LTNI28Zp54aIzwaTc5i66vYweVkLx1o5sLbe7Bti03vz1Bzrhw6JeVNV8uSHcXb/3/MpKj7TenWRM7T1ShB8+OAUa5y/kA8Vu03DrVNubR/eeLJO0Tb1mpi46v8rtJScctZZ3FgxyFGNab376A71wul1+7PtMGbaSXXUZ/OS5MxzH26KN9cH54YO7ErhHRDZh2XyvbyFmry4psr8U0QunmltPlmnapl4zUx+bX+X2irRwlIljNvLe+wMdxZnWm1/+QPDG6fbn/x7JKQ//iBmfD+G8MUsdxydF1RpFtfNIEX744H4O/EpV+wK/wjKO7MeXdElp+08aNXGqNeLWk2WatldeM7ceO7/K7RXjRxaxen0hO6rcTao18f+Zxqf6O2uONz4fzElD1rqOT0gb0yX54YM7H2j8+UVcbAUGZk41MPNkmaZt4jUzddH5WW6vmOzi9tS03vz0B3rhdOtXULHn5xMGr2fd9ta4Clc0GrX1SBV++OCKgeOBd4HJgJnbxiUp92Ttg1uvmamLzs9ymzrZALIyGzhieDH3P+ZsWo5pvfnpD3T6nd055S3G9i2mU3Yts3/+JH+dN45jBm1gQOcKYiqUVHXkttnH2U7fNkpKBxDs4IcPrgp4AKtxrcWaJrIk0bHys3vqUQMucJ0Xba9rUYvM1NIma1FNy62bXI8dAVA/4VDXsVmrtxil7Scm35nJWtQ1T99HzZZNZj64UKFOyDjV1mdn1z1zQPvgjmitdAMCAvxBAfXwCk5ETsW6GAoDj6jqnU6PkZJR1ICAgK8AGhde2nkkQUTCwEPA14HDgO/G59E6ot0v1QoICGg7eDiAMB5Yo6prAUTkOawN4z93cpBW64PzEhHZBmxI8JEuuNi4xoPYIO0g7VTGt2ba/VU1+WLoBIjImzSzQ14LZGH1wTcyTVWnNTnWOcCpqvqT+PMfAkeq6uVO8tQuruCSVbyILHbbYWkSG6QdpJ3KeL/zngxVtTfCkEKCPriAgIC2yGagb5PnfeKvOSJo4AICAtoiHwCDRWSgiGQA5wH/cnqQdnGLaoNpyT/SKrFB2kHaqYz3O+8pQ1UjInI5MAtrmshjqvqZ0+O0i0GGgICAADcEt6gBAQEHLEEDFxAQcMDSbhs4EekrInNF5HMR+UxErnB5nLCIfCQirzuM6yQiL4nIChFZLiJHOYz/VTzfy0TkWRHJSvL5x0Rkq4gsa/JaZxF5S0RWx/9vVhHRQuw98bx/KiKvikiLCxmbi2/y3lUioiLS7PynlmJF5Bfx9D8TkRatzi3kfZSILBSRj+POwGaVJi2dI3bqLUGsrXpLdn4mqrdEsXbqLUHebdXbAYWqtssH0BMYE/+5I7AKOMzFcX4NPAO87jDuCeAn8Z8zgE4OYnsD64Ds+PMXgAuSxBwHjAGWNXntbuC6+M/XAXc5iP0akBb/+a6WYluKj7/eF6sTeAPQxUHaJwBvA5nx590clns28PX4z6cB7zo5R+zUW4JYW/WW6PxMVm8J0rZVbwnibdXbgfRot1dwqlqiqh/Gf94JNCrRbSMifYBvAI84jMvH+sV7NJ5+vapWJI7ajzQgW0TSgBySqNtV9T1gXyvmGVgNLfH/z7Qbq6qzVbXRO74Qa56Rk7QB7geuIcEOAy3E/hy4U1Xr4p9p0f7YQrwt7X2CcyRpvbUUa7fekpyfCestQayteksQ79l2Ae2FdtvANUW+rER3wv9hnWhOHcoDgW3A4/Hb20dExLYXSVU3Y+naN2LtW1GpqrMd5gGgu1p7XwCUYu1g5oaLgJlOAkTkDGCzqn7iIr0hwLEi8r6I/EdExjmMt6W9b8o+54ijektwftmqt6bxTuttn7Qd15u42C7gQKLdN3CyvxLdbtzpwFZN4qJrgTSs26a/qupoYDfWrY7dtAuwriIGAr2AXBH5gYt87EGt+w7Hc35E5EasHdCedhCTg+X2u9lpenHSgM5Yu61dDbwgIk5cZLa0940kOkeS1VtLsXbrrWl8/PO2662ZtB3VWzPxjurtgMDve2STB5CO1ZfxaxexfwCKgPVYf8WrgX/YjO0BrG/y/FhghoO0vw082uT5j4C/2IgbwJf7olYCPeM/9wRW2o2Nv3YBsADIcZI2MALYGq+79Vi/uBuBHjbz/SZwQpPnXwBdHZS7kr1zOAWocnKO2K23ls4vu/W2b7yTemsh37brrYV42/V2oDza7RVc/C9Xc0p0W6jq9araR1UHYC0DeUdVbV1FqWopsElEhsZfOhFnGpeNwAQRyYmX40SsfhKn/Atrjwvi/79mN1AsmeA1wDdVdf9tyxKgqktVtZuqDojXXxFWp3apzUP8E6vDHBEZgjVI48SS0ai9hwTa+wTnSNJ6aynWbr01F2+33hLk21a9JYi3VW8HFH63sG4fwDFYtxafAh/HH6e5PNYknI+ijgL+v73zC5GyCsP475FKJCha2aKLgqjIQkrIyrZaFonIujKIwO4ybIMUhK4rvQoKvIkwkoiSJMSSItDFDdk1iFaXFnQrClYKugmzP5pRyNvFeSenYXZ2RiTwzPODhdnzfee85zt883C+8837nMMZfy9wVY/1twBfA0eBd8k3Yx3O30VZr/ub8sVYDywFxik36gFgoIe63wE/NI3d9l5itxw/zvxvUdvFvgzYmdc+Dazu8brvB44AM5S1pTt7uUe6GbcOdbsat27uz/nGrUPsrsatQ/2uxq2mP6dqGWOq5aJ9RDXGmIWwwBljqsUCZ4ypFgucMaZaLHDGmGqxwFWApLPpEHFU0u7MNDjftt5W2dGITEGbdy9KSSOShs4jxvF5XDTalrecc6rHWC9Jer7XPpo6sMDVwZmIWBERy4G/gNHmg5nQ3zMR8XREdPoB8wjQs8AZ839hgauPSeCmnF1NSvoImFXxvXtF0lR6mT0D5Vfvkl6T9I2kA8DVjYYkHZS0Mj8/LGla0oyk8UziHgU25+zxAUmDkvZkjClJ92XdpZLG0ptsByVNqCOS9ko6knU2tBzbluXjkgaz7EZJ+7LOpKRlF2IwzcVNLZvOGP6dqa2h5CxCMQRYHhFzKRK/RsRdkhYDn0kaozhN3ELxC7uGknL2Vku7g8CbwHC2NRARP0vaDpyKiFfzvPeAbRFxSNL1lFzIW4EXgUMRsVXSo5RshIV4KmMsAaYk7YmIE8DlwOGI2CzphWz7OcqGKqMR8a2ke4DXKelIpo+xwNXBEklf5udJSh7iEPBFRMxl+UPA7Y31NYof2M0UX7tdEXEW+FHSp23aXwVMNNqKiHbecAAPArc1GVxckY4Ww8BjWfcTSSe7uKZNktbm5+uyryco1lbvZ/lO4IOMMQTsboq9uIsYpnIscHVwJiJWNBfkF/10cxGwMSL2t5z3yAXsxyJgVUT82aYvXSNphCKW90bEH5IOAvNZukfG/aV1DIzxGlz/sB94VtKlUNwoVEw6J4Anco3uWtKtooXPgWFJN2TdgSz/nWKJ3WAM2Nj4R1JDcCaAdVm2Bmi7d0QTVwInU9yWUWaQDRYBjVnoOsqj72/AnKTHM4Yk3bFADNMHWOD6hx2U9bVplQ1c3qDM4D+kuGrMAu9QfM7+Q0T8BGygPA7OcO4R8WNgbeMlA7AJWJkvMWY59zZ3C0Ugj1EeVb9foK/7gEskfQW8TBHYBqeBu/MaVgNbs/xJYH327xjFUNT0OXYTMcZUi2dwxphqscAZY6rFAmeMqRYLnDGmWixwxphqscAZY6rFAmeMqZZ/AJqI1KdjHwg9AAAAAElFTkSuQmCC\" alt=\"img\"></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"img\"></p>\n<p>The concatenated data gives a better fit:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205121731546.png\" alt=\"output\"></p>\n<p>However, the generalization ability of this method has not been decided yet till now.</p>\n<h1 id=\"May-12th\"><a href=\"#May-12th\" class=\"headerlink\" title=\"May 12th\"></a>May 12th</h1><p>add ‘participant number’ dimension to X</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_4D = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> session_id_int <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">2</span>):</span><br><span class=\"line\">    session_id = <span class=\"string\">&#x27;&#123;:03d&#125;&#x27;</span>.<span class=\"built_in\">format</span>(session_id_int)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(session_id)</span><br><span class=\"line\">    <span class=\"comment\"># Get data</span></span><br><span class=\"line\">    localiser_epochs = mne.read_epochs(os.path.join(output_dir, <span class=\"string\">&#x27;preprocessing&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;&#x27;</span>, <span class=\"string\">&#x27;localiser&#x27;</span>, <span class=\"string\">&#x27;sub-&#123;&#125;_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz&#x27;</span>).<span class=\"built_in\">format</span>(session_id,session_id))  </span><br><span class=\"line\">    </span><br><span class=\"line\">    X_raw = localiser_epochs.get_data()</span><br><span class=\"line\">    </span><br><span class=\"line\">    picks_meg = mne.pick_types(localiser_epochs.info, meg=<span class=\"literal\">True</span>, ref_meg=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    event_selector = (y_raw &lt; n_stim * <span class=\"number\">2</span> + <span class=\"number\">1</span>)</span><br><span class=\"line\">    X_raw = X_raw[event_selector, ...]</span><br><span class=\"line\">    X_raw = X_raw[:, picks_meg, :]</span><br><span class=\"line\">    X = X_raw.copy()</span><br><span class=\"line\">    X = X[..., classifier_center_idx + classifier_window[<span class=\"number\">0</span>]:classifier_center_idx + classifier_window[<span class=\"number\">1</span>]] </span><br><span class=\"line\"></span><br><span class=\"line\">    X_4D.append(X)</span><br><span class=\"line\"><span class=\"comment\"># for epoch in localiser_epochs_concatenate:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(epoch.shape)</span></span><br><span class=\"line\"><span class=\"comment\"># localiser_epochs = mne.concatenate_epochs(localiser_epochs_concatenate)</span></span><br><span class=\"line\">X = np.stack(X_4D)</span><br></pre></td></tr></table></figure>\n\n<p>It takes me 1 hour to make the code logical elegant.</p>\n<h1 id=\"May-13th\"><a href=\"#May-13th\" class=\"headerlink\" title=\"May 13th\"></a>May 13th</h1><h2 id=\"Forth-meeting\"><a href=\"#Forth-meeting\" class=\"headerlink\" title=\"Forth meeting\"></a>Forth meeting</h2><h3 id=\"Objective-6\"><a href=\"#Objective-6\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>We have tested existing code, the following step is to try different models to predict.</p>\n<p>My supervisor’s suggestion is to use haiku trying CNN.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install -upgrade jax optax dm-haiku </span><br></pre></td></tr></table></figure>\n\n<p>to be learnt: </p>\n<p>active function: rectifier RELU</p>\n<h3 id=\"Result-1\"><a href=\"#Result-1\" class=\"headerlink\" title=\"Result:\"></a>Result:</h3><p>New model selection: CNN with Haiku</p>\n<h1 id=\"May-14th\"><a href=\"#May-14th\" class=\"headerlink\" title=\"May 14th\"></a>May 14th</h1><p>Find a  bug: concatenated data was not giving a correct result. The better performance was because of the randomness of every time training. The concatenated data won’t give a better prediction. </p>\n<p>possible solution: transfer learning instead of directly concatenation.</p>\n<h1 id=\"May-16th\"><a href=\"#May-16th\" class=\"headerlink\" title=\"May 16th\"></a>May 16th</h1><h3 id=\"Objective-7\"><a href=\"#Objective-7\" class=\"headerlink\" title=\"Objective\"></a>Objective</h3><p>to learning deep learning courses (Andrew Ng) in coursera because as said in ‘Knife don’t miss your job’, to solid the foundation of deep learning will help me build the CNN and understand others’ work</p>\n<h3 id=\"Result-2\"><a href=\"#Result-2\" class=\"headerlink\" title=\"Result:\"></a>Result:</h3><p>In the context of artificial neural networks, the rectifier or ReLU (Rectified Linear Unit) activation function is an activation function defined as the positive part of its argument.</p>\n<h4 id=\"Convolution\"><a href=\"#Convolution\" class=\"headerlink\" title=\"Convolution\"></a>Convolution</h4><p>Types of layer in a CNN:</p>\n<ul>\n<li>Covolution</li>\n<li>Pooling</li>\n<li>Fully connected </li>\n</ul>\n<p>Cases:</p>\n<p>Classic networks: </p>\n<ul>\n<li>LeNet-5</li>\n<li>AlexNet</li>\n<li>VGG</li>\n</ul>\n<p>ResNet</p>\n<p>Inception</p>\n<p>LeNet -5 </p>\n<h1 id=\"May-17th\"><a href=\"#May-17th\" class=\"headerlink\" title=\"May 17th\"></a>May 17th</h1><h2 id=\"Learning-JAX\"><a href=\"#Learning-JAX\" class=\"headerlink\" title=\"Learning JAX\"></a>Learning JAX</h2><p><strong>Question: why jax has its own numpy type: jax.numpy? what is the difference between it and numpy?</strong></p>\n<p>Jax.numpy is a little bit different from numpy: the former is immutable</p>\n<p><strong>Question: why do we need jax.numpy?</strong> </p>\n<p>because numpy only works on CPU while jax.numpy works on GPU</p>\n<p><strong>another advantage of JAX</strong></p>\n<p><code>jit()</code> can be used to compile the data input thus makes the program run faster</p>\n<h2 id=\"First-group-meeting\"><a href=\"#First-group-meeting\" class=\"headerlink\" title=\"First group meeting\"></a>First group meeting</h2><p>Yiqi introduced his recent work which is based on U-net, VAE</p>\n<h1 id=\"May-18th\"><a href=\"#May-18th\" class=\"headerlink\" title=\"May 18th\"></a>May 18th</h1><h2 id=\"Learning-JAX-1\"><a href=\"#Learning-JAX-1\" class=\"headerlink\" title=\"Learning JAX\"></a>Learning JAX</h2><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">grad() <span class=\"comment\"># for differentation</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> jax <span class=\"keyword\">import</span> jacfwd, jacrev <span class=\"comment\"># for Jacobian matrix</span></span><br><span class=\"line\">vmap() <span class=\"comment\"># for vectorization; it can makes you write your functions as if you were dealing wiht a single datapoint</span></span><br></pre></td></tr></table></figure>\n\n<p>JAX API structure</p>\n<ul>\n<li>NumPy &lt;-&gt; lax &lt;-&gt; XLA</li>\n<li>lax API is stricter and more powerful</li>\n<li>It’s a Python wrapper around XLA</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221751704.svg\" alt=\"nn\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CNN</span>(hk.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__(name=<span class=\"string\">&quot;CNN&quot;</span>)</span><br><span class=\"line\">        <span class=\"comment\"># self.conv1 = hk.Conv2D(output_channels=32, kernel_shape=(3,3), padding=&quot;SAME&quot;)</span></span><br><span class=\"line\">        <span class=\"comment\"># self.conv2 = hk.Conv2D(output_channels=16, kernel_shape=(3,3), padding=&quot;SAME&quot;)</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv1 = hk.Conv2D(output_channels=<span class=\"number\">64</span>, kernel_shape=(<span class=\"number\">11</span>,<span class=\"number\">11</span>), stride=<span class=\"number\">4</span>, padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv2 = hk.Conv2D(output_channels=<span class=\"number\">192</span>, kernel_shape=(<span class=\"number\">5</span>,<span class=\"number\">5</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv3 = hk.Conv2D(output_channels=<span class=\"number\">384</span>, kernel_shape=(<span class=\"number\">3</span>,<span class=\"number\">3</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv4 = hk.Conv2D(output_channels=<span class=\"number\">256</span>, kernel_shape=(<span class=\"number\">3</span>,<span class=\"number\">3</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv5 = hk.Conv2D(output_channels=<span class=\"number\">256</span>, kernel_shape=(<span class=\"number\">3</span>,<span class=\"number\">3</span>), padding=<span class=\"string\">&quot;SAME&quot;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.flatten = hk.Flatten()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.linear = hk.Linear(<span class=\"built_in\">len</span>(classes))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__call__</span>(<span class=\"params\">self, x_batch</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv1(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = hk.MaxPool(window_shape=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), strides=(<span class=\"number\">2</span>, <span class=\"number\">2</span>), padding=<span class=\"string\">&#x27;VALID&#x27;</span>)(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv2(x)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = hk.MaxPool(window_shape=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), strides=(<span class=\"number\">2</span>, <span class=\"number\">2</span>), padding=<span class=\"string\">&#x27;VALID&#x27;</span>)(x)        </span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv3(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv4(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv5(x_batch)</span><br><span class=\"line\">        x = jax.nn.relu(x)</span><br><span class=\"line\">        x = hk.MaxPool(window_shape=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), strides=<span class=\"number\">2</span>, padding=<span class=\"string\">&#x27;VALID&#x27;</span>)(x)</span><br><span class=\"line\">        <span class=\"comment\"># x = hk.AvgPool(window_shape=(6, 6), strides=(2, 2), padding=&#x27;SAME&#x27;)(x)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.flatten(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.linear(x)</span><br><span class=\"line\">        x = jax.nn.softmax(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"May-19th\"><a href=\"#May-19th\" class=\"headerlink\" title=\"May 19th\"></a>May 19th</h1><h2 id=\"Test-CNN\"><a href=\"#Test-CNN\" class=\"headerlink\" title=\"Test CNN\"></a>Test CNN</h2><p>CNN test was run but the prediction result is not as good as expected: </p>\n<p>the performance of it is about 0.4 for training dataset and 0.15 for test dataset. </p>\n<p>I think we should try to tune the parameters of model or test a different model since the current model is suitable for image recognition. Before that, literature reviews should be done. </p>\n<p>Later after I read Aoe’s work, I start to under stand it is because my image classification CNN model fails to extract the temporal and spatial information. </p>\n<blockquote>\n<p>Aoe, J., Fukuma, R., Yanagisawa, T., Harada, T., Tanaka, M., Kobayashi, M., Inoue, Y., Yamamoto, S., Ohnishi, Y., &amp; Kishima, H. (2019). Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. <em>Scientific Reports</em>, <em>9</em>(1). <a href=\"https://doi.org/10.1038/S41598-019-41500-X\">https://doi.org/10.1038/S41598-019-41500-X</a></p>\n</blockquote>\n<h2 id=\"Fifth-meeting\"><a href=\"#Fifth-meeting\" class=\"headerlink\" title=\"Fifth meeting\"></a>Fifth meeting</h2><p>I have the requirement of visualization during training: </p>\n<p>To use Tensor Board to show the training process</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">!rm -rf /logs/ <span class=\"comment\"># clear logs</span></span><br><span class=\"line\"><span class=\"comment\"># if &#x27;google.colab&#x27; in str(get_ipython()): # tensor board</span></span><br><span class=\"line\">%load_ext tensorboard  </span><br><span class=\"line\"><span class=\"comment\"># %tensorboard --logdir logs</span></span><br><span class=\"line\">%tensorboard --logdir=./models/test</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"May-20th\"><a href=\"#May-20th\" class=\"headerlink\" title=\"May 20th\"></a>May 20th</h1><h2 id=\"Tried-AlexNet-can-be-easily-get-from-Pytorch-hub\"><a href=\"#Tried-AlexNet-can-be-easily-get-from-Pytorch-hub\" class=\"headerlink\" title=\"Tried AlexNet (can be easily get from Pytorch hub)\"></a>Tried AlexNet (can be easily get from Pytorch hub)</h2><p>AlexNet</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">AlexNet  = torch.hub.load(<span class=\"string\">&#x27;pytorch/vision:v0.10.0&#x27;</span>, <span class=\"string\">&#x27;alexnet&#x27;</span>, pretrained=<span class=\"literal\">True</span>).cuda()</span><br></pre></td></tr></table></figure>\n\n<p>Resnet 18</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Resnet   = torch.hub.load(<span class=\"string\">&#x27;pytorch/vision:v0.10.0&#x27;</span>, <span class=\"string\">&#x27;resnet18&#x27;</span>, pretrained=<span class=\"literal\">True</span>).cuda()</span><br></pre></td></tr></table></figure>\n\n<p>These 2 models fail as well. The same reason: these models fail to extract the temporal and spatial information in the first convolutional layers.</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221758352.png\" alt=\"image-20220722175851266\"></p>\n<h2 id=\"Sixth-meeting\"><a href=\"#Sixth-meeting\" class=\"headerlink\" title=\"Sixth meeting\"></a>Sixth meeting</h2><h3 id=\"Objective-8\"><a href=\"#Objective-8\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to discuss about that if we should use concatenate data and pre-processing for standardization because the conditions of recording may varies a lot among different subjects: the device position or potential individual reasons.</p>\n<h3 id=\"Results-5\"><a href=\"#Results-5\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>Dr. Toby and I had a discussion together with Dr. Rossalin </p>\n<p>Rossalin advices me to try transfer learning or LSTM.</p>\n<p>After trying the model is usually used in image classification, it is a good idea to try the model LSTM RNN, which is known as a good fit for sequential data.</p>\n<h1 id=\"May-24th\"><a href=\"#May-24th\" class=\"headerlink\" title=\"May 24th\"></a>May 24th</h1><h2 id=\"Second-group-meeting\"><a href=\"#Second-group-meeting\" class=\"headerlink\" title=\"Second group meeting\"></a>Second group meeting</h2><p>Zarc gives a presentation about his NLP project.</p>\n<h1 id=\"May-27th\"><a href=\"#May-27th\" class=\"headerlink\" title=\"May 27th\"></a>May 27th</h1><h2 id=\"Learning-Tensorflow\"><a href=\"#Learning-Tensorflow\" class=\"headerlink\" title=\"Learning Tensorflow\"></a>Learning Tensorflow</h2><p>Tensorflow is a more popular packages which allows me to get access to many templates. Some research is also using Tensorflow as their machine learning library. But I found Pytorch is a more popular packages which allows me to get access to more well-known templates. Most related research is using Pytorch as their machine learning library.</p>\n<p>However, I found the variable and  placeholder operations are more commonly used in Tensorflow-v1 rather than the latest  Tensorflow-v1</p>\n<h3 id=\"Session-control\"><a href=\"#Session-control\" class=\"headerlink\" title=\"Session control\"></a>Session control</h3><p>In Tensorflow, a string is defined as a variable, and it is a variable, which is different from Python. (later on I found it was correct in Tensorflow v1 but changes in Tensorflow v2)</p>\n<p> <code>state = tf.Variable()</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">state = tf.Variable(<span class=\"number\">0</span>, name=<span class=\"string\">&#x27;counter&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define variable one</span></span><br><span class=\"line\">one = tf.constant(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define plus step (hint: no computation here)</span></span><br><span class=\"line\">new_value = tf.add(state, one)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># update State to new_value</span></span><br><span class=\"line\">update = tf.assign(state, new_value)</span><br></pre></td></tr></table></figure>\n\n<p>If I set variables in Tensorflow, initializing the variables is the most important thing! ! So after defining the variable, be sure to define <code>init = tf.initialize_all_variables()</code>.</p>\n<p>At this point, the variable is still not activated, and it needs to be added in <code>sess</code> , <code>sess.run(init)</code> , to activate<code>init</code>. (again, it changes in v2, we do not need to initialize the session in Tensorflow v2)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Variable, initialize</span></span><br><span class=\"line\"><span class=\"comment\"># init = tf.initialize_all_variables() # expired</span></span><br><span class=\"line\">init = tf.global_variables_initializer()  </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># Session</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">        sess.run(update)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(sess.run(state))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>Note: directly <code>print(state)</code> does not work! !</p>\n<p>Be sure to point the <code>sess</code> pointer to <code>state</code> and then <code>print</code> to get the desired result!</p>\n<h3 id=\"placeholder\"><a href=\"#placeholder\" class=\"headerlink\" title=\"placeholder\"></a>placeholder</h3><p><code>placeholder</code> is a placeholder in Tensorflow that temporarily stores variables.</p>\n<p>If Tensorflow wants to pass in data from the outside, it needs to use <code>tf.placeholder()</code>, and then transfer the data in this form <code>sess.run(***, feed_dict={input: **})</code>.</p>\n<p>Examoles：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\"></span><br><span class=\"line\"># Tensorflow requires defining placeholder&#x27;s type, usually float32</span><br><span class=\"line\">input1 = tf.placeholder(tf.float32)</span><br><span class=\"line\">input2 = tf.placeholder(tf.float32)</span><br><span class=\"line\"></span><br><span class=\"line\"># multiply input1 and input2</span><br><span class=\"line\">ouput = tf.multiply(input1, input2)</span><br></pre></td></tr></table></figure>\n\n<p>Next, the work of passing the value is handed over to <code>sess.run()</code>, the value that needs to be passed in is placed in <code>feed_dict={}</code> and corresponds to each <code>input</code> one by one. <code>placeholder</code> and <code>feed_dict={ }</code> are bound together.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with tf.Session() as sess:</span><br><span class=\"line\">    print(sess.run(ouput, feed_dict=&#123;input1: [7.], input2: [2.]&#125;))</span><br><span class=\"line\"># [ 14.]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Activation-function\"><a href=\"#Activation-function\" class=\"headerlink\" title=\"Activation function\"></a>Activation function</h3><p>when there are many layers, be careful to use activation function in case of the <strong>gradient exploding or gradient disappearance</strong>.</p>\n<h1 id=\"May-28th\"><a href=\"#May-28th\" class=\"headerlink\" title=\"May 28th\"></a>May 28th</h1><blockquote>\n<p>Although in the computer vision field convolutional layer often followed by a pooling layer to reduce the data dimension at the expense of information loss, in the scenes of MEG decoding, the size of MEG data is much smaller than the computer vision field. So in order to keep all the information, we don’t use the pooling layer. After the spatial convolutional layer, we use two layers of temporal convolutional layers to extract temporal features, a fully connected layer with dropout operation for feature fusion, and a softmax layer for final classification. (Huang2019)</p>\n</blockquote>\n<p>It is important to select if we should use pooling layers and how many to use.</p>\n<h1 id=\"May-30th\"><a href=\"#May-30th\" class=\"headerlink\" title=\"May 30th\"></a>May 30th</h1><h2 id=\"ML-optimizer\"><a href=\"#ML-optimizer\" class=\"headerlink\" title=\"ML optimizer\"></a>ML optimizer</h2><h3 id=\"Objective-9\"><a href=\"#Objective-9\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to learn how to use and select different optimizer, because it modifies model’s parameters like weights and learning rate, which helps to increase accuracy and reduce overall loss.</p>\n<h3 id=\"Results-6\"><a href=\"#Results-6\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><ul>\n<li>Stochastic Gradient Descent (SGD)</li>\n<li>Momentum</li>\n<li>AdaGrad</li>\n<li>RMSProp</li>\n<li>Adam</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202205302233928.png\" alt=\"speedup3\"></p>\n<p>X.shape gives (n_epochs, n_channels, n_times) corresponding to (batches, pixels,channels)  of images</p>\n<p>Apart for optimizer, scheduler may help a lot with providing a dynamic learning rate.</p>\n<h3 id=\"impression\"><a href=\"#impression\" class=\"headerlink\" title=\"impression\"></a>impression</h3><p>As I tried to apply regularization at the same time. It is important to bear in mind, if we give a momentum in SGD (about 0.9), we can easily apply L2 regularization when the weight_decay is larger than 0.</p>\n<h1 id=\"May-31st\"><a href=\"#May-31st\" class=\"headerlink\" title=\"May 31st\"></a>May 31st</h1><h3 id=\"Objective-10\"><a href=\"#Objective-10\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to learn data augmentation and learn a important rule: “No free lunch theorem”</p>\n<h3 id=\"Results-7\"><a href=\"#Results-7\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>D. H. Wolpert et. al. (1995) come up with “No free lunch theorem”: all optimization algorithms perform equally well when their performance is averaged across all possible problems.</p>\n<p>For any prediction function, if it performs well on some training samples, it must perform poorly on other training samples. If there are certain assumptions about the prior distribution of the data in the feature space, there are as many good and bad performances.</p>\n<p>Later I found relative power spectrum including delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-12 Hz), beta (12-30Hz), and gamma (above 30 Hz), provide important information to augmenting the MEG data.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train_numpy = X_train_tensors.cpu().numpy()</span><br><span class=\"line\">X_test_numpy = X_test_tensors.cpu().numpy()</span><br><span class=\"line\"></span><br><span class=\"line\">X = np.swapaxes(X_train_numpy, <span class=\"number\">2</span>, -<span class=\"number\">1</span>).squeeze()</span><br><span class=\"line\">data = X[X.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>, <span class=\"number\">70</span>, :]</span><br><span class=\"line\">psd_mne, freqs_mne = psd_array_welch(data, <span class=\"number\">100</span>, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                          n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> low, high <span class=\"keyword\">in</span> [(<span class=\"number\">0.5</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">12</span>), (<span class=\"number\">12</span>, <span class=\"number\">30</span>),</span><br><span class=\"line\">                  (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;processing bands (low, high) : (&#123;&#125;,&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(low, high))</span><br><span class=\"line\">    <span class=\"comment\"># Find intersecting values in frequency vector</span></span><br><span class=\"line\">    idx_delta = np.logical_and(freqs_mne &gt;= low, freqs_mne &lt;= high)</span><br><span class=\"line\">      <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs_mne[<span class=\"number\">1</span>] - freqs_mne[<span class=\"number\">0</span>]  <span class=\"comment\"># = 1 / 4 = 0.25</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute the absolute power by approximating the area under the curve</span></span><br><span class=\"line\">    power = simps(psd_mne[idx_delta], dx=freq_res)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Absolute power: &#123;:.4f&#125; uV^2&#x27;</span>.<span class=\"built_in\">format</span>(power))</span><br><span class=\"line\">    </span><br><span class=\"line\">    total_power = simps(psd_mne, dx=freq_res)</span><br><span class=\"line\">    rel_power = power / total_power</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Relative power: &#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(rel_power))</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Jun-1st\"><a href=\"#Jun-1st\" class=\"headerlink\" title=\"Jun 1st\"></a>Jun 1st</h1><h2 id=\"Seventh-meeting\"><a href=\"#Seventh-meeting\" class=\"headerlink\" title=\"Seventh meeting\"></a>Seventh meeting</h2><p>Dr Toby provide me the code to load data with dataloader</p>\n<p>it defines load_MEG_dataset function with following parameters: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_MEG_dataset</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">        subject_ids: <span class=\"type\">List</span>[<span class=\"built_in\">str</span>],</span></span><br><span class=\"line\"><span class=\"params\">        mode: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;individual&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        output_format: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;numpy&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        trial_data_format: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;2D&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        data_location: <span class=\"built_in\">str</span> = <span class=\"string\">&quot;./data/&quot;</span>,</span></span><br><span class=\"line\"><span class=\"params\">        center_timepoint: <span class=\"built_in\">int</span> = <span class=\"number\">20</span>,</span></span><br><span class=\"line\"><span class=\"params\">        window_width: <span class=\"type\">List</span>[<span class=\"built_in\">int</span>] = [-<span class=\"number\">400</span>, <span class=\"number\">400</span>],</span></span><br><span class=\"line\"><span class=\"params\">        shuffle: <span class=\"built_in\">bool</span> = <span class=\"literal\">False</span>,</span></span><br><span class=\"line\"><span class=\"params\">        pca_n_components: <span class=\"built_in\">int</span> = <span class=\"literal\">None</span>,</span></span><br><span class=\"line\"><span class=\"params\">        training: <span class=\"built_in\">bool</span> = <span class=\"literal\">True</span>,</span></span><br><span class=\"line\"><span class=\"params\">        train_test_split: <span class=\"built_in\">float</span> = <span class=\"number\">0.75</span>,</span></span><br><span class=\"line\"><span class=\"params\">        batch_size: <span class=\"built_in\">int</span> = <span class=\"number\">32</span>,</span></span><br><span class=\"line\"><span class=\"params\">        scale: <span class=\"built_in\">bool</span> = <span class=\"literal\">True</span>,</span></span><br><span class=\"line\"><span class=\"params\">        seed: <span class=\"built_in\">int</span> = <span class=\"number\">0</span>,</span></span><br><span class=\"line\"><span class=\"params\">    </span>)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Jun-6th\"><a href=\"#Jun-6th\" class=\"headerlink\" title=\"Jun 6th\"></a>Jun 6th</h1><h3 id=\"Objective-11\"><a href=\"#Objective-11\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try different loss function, because different evaluating methods may affect the learning process, and lead to a different approach to training results.</p>\n<h3 id=\"Results-8\"><a href=\"#Results-8\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>when apply other loss function instead of CrossEntropy, there are some format error occurs:</p>\n<p>solution: transform inputs from multi hot coding into one hot coding. </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">onehot</span>(<span class=\"params\">batches, n_classes, y</span>):</span><br><span class=\"line\">  yn = torch.zeros(batches, n_classes)</span><br><span class=\"line\">  <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(batches):</span><br><span class=\"line\">    x = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(batches)]</span><br><span class=\"line\">    x[i] = y[i]/<span class=\"number\">2</span>-<span class=\"number\">1</span>                     <span class=\"comment\">#ex. [12]-&gt; [5]</span></span><br><span class=\"line\">    yn[i][<span class=\"built_in\">int</span>(x[i])]+= <span class=\"number\">1</span>                  <span class=\"comment\">#[000010000]</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> yn</span><br></pre></td></tr></table></figure>\n\n<p>Later I found that we can use the function in Pytorch: F.onehot</p>\n<h1 id=\"Jun-7th\"><a href=\"#Jun-7th\" class=\"headerlink\" title=\"Jun 7th\"></a>Jun 7th</h1><p>try different models, reshape the data from [batches, channels, times point ]to be [batches, times point, channels] in corresponding to images format [batches, picture channels (layers), pixels] (not the same channels, the same names but different meanings, former one is electrode channels. latter one is picture layers)</p>\n<h1 id=\"Jun-8th\"><a href=\"#Jun-8th\" class=\"headerlink\" title=\"Jun 8th\"></a>Jun 8th</h1><h2 id=\"Third-session-meeting\"><a href=\"#Third-session-meeting\" class=\"headerlink\" title=\"Third session meeting\"></a>Third session meeting</h2><h3 id=\"Objective-12\"><a href=\"#Objective-12\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to learn the key points of writing a good introduction</p>\n<h3 id=\"Results-9\"><a href=\"#Results-9\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>from the history of ML to the current meaning </p>\n<ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> The <strong>history</strong> of <strong>ML</strong>, (black box…)</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> the <strong>history</strong> of disease classification or <strong>behaviour prediction</strong></li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> how people use the ML techniques to <strong>predict  behaviours</strong> these days</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> what is aversive state reactivation (one sentence); why people want to learn aversive state reactivation</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> how people tried to connect ML with aversive state reactivation</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> the problem (gap) is previous model only gives a low prediction accuracy</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> Introduction of CNN, LSTM, RNN or transfer learning</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> My aims is to optimize the model with new techniques: CNN, LSTM RNN or transfer learning</li>\n</ul>\n<p>Note: state what in each paragraph is not enough and leads to the next paragraph.</p>\n<h2 id=\"LSTM-RNN\"><a href=\"#LSTM-RNN\" class=\"headerlink\" title=\"LSTM RNN\"></a>LSTM RNN</h2><h3 id=\"Objective-13\"><a href=\"#Objective-13\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>try LSTM RNN</p>\n<h3 id=\"Results-10\"><a href=\"#Results-10\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>The problems when I try to use one hot data <code>labels = F.one_hot(labels)</code>, it is not applicable because in that case the dimensions could be 28 instead of 14 as we only have even numbers,</p>\n<p>Some packages automatically figure out where there missing labels during one hot operation but this one (pytorch) doesn’t</p>\n<h2 id=\"Eighth-meeting\"><a href=\"#Eighth-meeting\" class=\"headerlink\" title=\"Eighth meeting\"></a>Eighth meeting</h2><h3 id=\"questions\"><a href=\"#questions\" class=\"headerlink\" title=\"questions:\"></a>questions:</h3><ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> loss functions give similar values?</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> <del>is it correct to use enumerate to loop each data?</del></li>\n</ul>\n<p>In my case, CrossEntropy is the better for MEG data. It is the experience gained from Dr Toby. Even though I found the others’ research about hands behaviour prediction used MSE loss. It is not suitable for our results because theirs is about the movements while ours is not.</p>\n<h1 id=\"Jun-9th\"><a href=\"#Jun-9th\" class=\"headerlink\" title=\"Jun 9th\"></a>Jun 9th</h1><h2 id=\"Label-noise\"><a href=\"#Label-noise\" class=\"headerlink\" title=\"Label noise.\"></a>Label noise.</h2><h3 id=\"Objectives\"><a href=\"#Objectives\" class=\"headerlink\" title=\"Objectives:\"></a>Objectives:</h3><p>to figure out if labels format it self may affect the model performance. Because some models only accept data in one kind of format. </p>\n<p><strong>question</strong>: how to determine numbers of hidden layers in LSTM RNN.</p>\n<h3 id=\"Results-11\"><a href=\"#Results-11\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>We cannot correctly compare each label when we are using <strong>one-hot format</strong>. If the labels you predict are apples, bananas, and strawberries, obviously they do not directly have a comparison relationship. If we use 1, 2, 3 as labels, there will be a comparison relationship between the labels. Distances are different. With the comparison relationship, the distance between the first label and the last label is too far, which affects the learning of the model.</p>\n<p>One promotion:</p>\n<blockquote>\n<p>Knowledge distillation (KD) improves performance precisely by suppressing this label nosie. Based on this understanding, we introduce a particularly simple improvement method of knowledge disillation, which can significantly improve the performance of ordinary KD by setting different temperatures for each image. </p>\n<p>Xu, K., Rui, L., Li, Y., Gu, L. (2020). <em>Feature Normalized Knowledge Distillation for Image Classification.</em> In: Vedaldi, A., Bischof, H., Brox, T., Frahm, JM. (eds) Computer Vision – ECCV 2020. ECCV 2020. Lecture Notes in Computer Science(), vol 12370. Springer, Cham. <a href=\"https://doi.org/10.1007/978-3-030-58595-2_40\">https://doi.org/10.1007/978-3-030-58595-2_40</a></p>\n</blockquote>\n<p><strong>Hidden layers in LSTM RNN</strong></p>\n<p>The effect of the number of hidden layers for neural networks</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202206120108575.jpeg\" alt=\"img\"></p>\n<h1 id=\"Jun-10th\"><a href=\"#Jun-10th\" class=\"headerlink\" title=\"Jun 10th\"></a>Jun 10th</h1><p>try <code>CrossEntropyLoss()</code> with onehot format data</p>\n<p>convert the labels from “every 2 in 0 to 28” to “every 1 in 1 to 14”</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">y_train = (y_train / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br><span class=\"line\">y_test = (y_test / <span class=\"number\">2</span>) - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n<p>use <code>with torch.autocast(&#39;cuda&#39;)</code> to solve “cuda error” of <code>CrossEntropyLoss()</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> torch.autocast(<span class=\"string\">&#x27;cuda&#x27;</span>):</span><br><span class=\"line\">        <span class=\"comment\"># loss = criterion(outputs, torch.tensor(labels).cuda())</span></span><br><span class=\"line\">            loss = criterion(outputs, labels)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Jun-12th\"><a href=\"#Jun-12th\" class=\"headerlink\" title=\"Jun 12th\"></a>Jun 12th</h1><p>even though the accuracy of prediction for train data increases quickly as training, the accuracy for test data is still very low. It seems the validation loss does not converge. I decide the next step is going to do more literature research and adjust the parameters.</p>\n<h1 id=\"Jun-13th\"><a href=\"#Jun-13th\" class=\"headerlink\" title=\"Jun 13th\"></a>Jun 13th</h1><h3 id=\"Problems\"><a href=\"#Problems\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>the problem is overfitting. There could be 2 alternative options: 1, get more data; 2, try different learning rate or dynamic learning rate.</p>\n<p>the way the train-test split worked wasn’t ideal in the data loading function - because the data wasn’t shuffled prior to splitting, the train and test set would often consist of different subjects if we load multiple subjects. The data can be shuffled before splitting (by setting shuffle=True), which means that there will be a mix of subjects in both the training and testing data. This seems to boost accuracy in the test set a little bit.</p>\n<h1 id=\"Jun-14th\"><a href=\"#Jun-14th\" class=\"headerlink\" title=\"Jun 14th\"></a>Jun 14th</h1><h3 id=\"Objective-14\"><a href=\"#Objective-14\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try <code>CosineEmbeddingLoss()</code> because it is reported that cosine loss may improve the performance for small dataset</p>\n<blockquote>\n<p>Cosine loss could have better performance for small dataset (around 30%). </p>\n<p>Barz, B., &amp; Denzler, J. (2019). Deep Learning on Small Datasets without Pre-Training using Cosine Loss. <em>Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020</em>, 1360–1369. <a href=\"https://doi.org/10.48550/arxiv.1901.09054\">https://doi.org/10.48550/arxiv.1901.09054</a></p>\n</blockquote>\n<h3 id=\"Results-12\"><a href=\"#Results-12\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>however, the performance is not promoted</p>\n<h1 id=\"Jun-15th\"><a href=\"#Jun-15th\" class=\"headerlink\" title=\"Jun 15th\"></a>Jun 15th</h1><h2 id=\"Fourth-session-meeting\"><a href=\"#Fourth-session-meeting\" class=\"headerlink\" title=\"Fourth session meeting\"></a>Fourth session meeting</h2><p>I read others work, practice to extract the key words and main ideas:</p>\n<blockquote>\n<p><em>Affective modulation of the startle response in depression: Influence of the severity of depression, anhedonia and anxiety</em></p>\n</blockquote>\n<p>startle reflex (SR)</p>\n<ol>\n<li>affective rating</li>\n</ol>\n<p>​    get affective rating after participants watched every clips </p>\n<p>​    and analysis the difference between depressed patients and control.</p>\n<ol start=\"2\">\n<li><p>Startle amplitude</p>\n</li>\n<li><p>EMG</p>\n<p>higher baseline EMG activity during pleasant and unpleasant clips, relative to the neutral clips</p>\n</li>\n</ol>\n<p><strong>Conclusion</strong></p>\n<p>a reduced degree of self-reported mood modulation </p>\n<p><strong>Gap</strong></p>\n<p>The findings differ from those of Allen et al. (1999): they think it does not matter for depression or anhedonia for affective and emotional modulation.</p>\n<p><strong>key wards</strong></p>\n<p>Depression</p>\n<p>Anxiety</p>\n<p>Anhedonia</p>\n<p>Affective modulation</p>\n<p>Mood regulation</p>\n<p>Startle response</p>\n<p>EMG</p>\n<p>affective rating</p>\n<h2 id=\"Ninth-meeting\"><a href=\"#Ninth-meeting\" class=\"headerlink\" title=\"Ninth meeting\"></a>Ninth meeting</h2><h3 id=\"Problems-1\"><a href=\"#Problems-1\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>Since the past work does not give a good result and it has been nearly halfway of the project. My following work is suggested to be focused on:</p>\n<ol>\n<li><p>Multilayer Perceptron</p>\n</li>\n<li><p>transfer learning</p>\n</li>\n</ol>\n<h1 id=\"Jun-16th\"><a href=\"#Jun-16th\" class=\"headerlink\" title=\"Jun 16th\"></a>Jun 16th</h1><blockquote>\n<p> <strong>Convolutional Layer</strong> : Consider a convolutional layer which takes “l” feature maps as the input and has “k” feature maps as output. The filter size is “<strong>n*m</strong>”.<br>Here the input has <strong><em>l=32\\</em></strong> feature maps as inputs, <strong><em>k=64\\</em></strong> feature maps as outputs and filter size is <strong><em>n=3 and m=3\\</em></strong>. It is important to understand, that we don’t simply have a 3<em>3 filter, but actually, we have *</em>3*3*32** filter, as our input has 32 dimensions. And as an output from first conv layer, we learn 64 different <strong>3*3*32</strong> filters which total weights is “<strong>n*m*k*l</strong>”. Then there is a term called bias for each feature map. So, the total number of parameters are “<strong>(n*m*l+1)*k</strong>”.</p>\n<p><a href=\"https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\">https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca</a></p>\n</blockquote>\n<p>bicubic interpolation: torch.nn.functional.interpolate() with mode=’bicubic’ </p>\n<blockquote>\n<p><a href=\"https://stackoverflow.com/questions/54083474/bicubic-interpolation-in-pytorch\">https://stackoverflow.com/questions/54083474/bicubic-interpolation-in-pytorch</a></p>\n</blockquote>\n<p>Meeting these data and fitting problems, I realize the insufficiency of understanding data itself, so I look back to the Machine Learning courses materials from 2 years ago, trying to get some new approaches.</p>\n<p>When reading the Chapter 1 of <em>Computational Modelling of Cognition and Behaviour</em>, I get the following points: </p>\n<blockquote>\n<ol>\n<li>Data never speak for themselves but require a model to be understood and to be explained.</li>\n<li>Verbal theorizing alone ultimately cannot replace for quantitative analysis.</li>\n<li>There are always several alternative models that vie for explanation of data and we must select among them.</li>\n<li>Model selection rests on both quantitative evaluation and intellectual and scholarly judgment.</li>\n</ol>\n</blockquote>\n<h1 id=\"June-21th\"><a href=\"#June-21th\" class=\"headerlink\" title=\"June 21th\"></a>June 21th</h1><p>Have a meeting with Eammon, we talked about my recent work:</p>\n<p>Eammon gives me a suggestion: in behaviour level, picture of faces are different. Try and see what if we get rid of the picture of faces in labels.</p>\n<p>Here are the pictures shown to participants: </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221848253.png\" alt=\"image-20220722184848108\"></p>\n<h1 id=\"June-25th\"><a href=\"#June-25th\" class=\"headerlink\" title=\"June 25th\"></a>June 25th</h1><p>to try Mnet (was used to predict the Alzheimer’s disease by Aoe .etc)</p>\n<blockquote>\n<p>Aoe, J., Fukuma, R., Yanagisawa, T. <em>et al.</em> Automatic diagnosis of neurological diseases using MEG signals with a deep neural network. <em>Sci Rep</em> <strong>9,</strong> 5057 (2019). <a href=\"https://doi.org/10.1038/s41598-019-41500-xz\">https://doi.org/10.1038/s41598-019-41500-xz</a></p>\n</blockquote>\n<p>Score method:</p>\n<p>As an alternative option, the accuracy can be expressed as root mean square error. </p>\n<h1 id=\"Jun-27th\"><a href=\"#Jun-27th\" class=\"headerlink\" title=\"Jun 27th\"></a>Jun 27th</h1><h3 id=\"Objective-15\"><a href=\"#Objective-15\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to apply data augmentation because it was reported that relative power spectrum provide extra information which may improve model’s performance on MEG data.</p>\n<h3 id=\"Result-3\"><a href=\"#Result-3\" class=\"headerlink\" title=\"Result:\"></a>Result:</h3><p>one possible solution is to extract band power to augment the data</p>\n<blockquote>\n<p>“This model was implemented to check the proprieties of the RPS to extract meaningful features from the input data. The RPS was combined with an MLP to add nonlinearity and increase the capability of approximate the target variable.”</p>\n<p>The RPS was implemented in 4 steps: </p>\n<ol>\n<li>Compute the modified periodogram using Welch methods (Welch 1967) to get the power spectral density. </li>\n<li>Calculate the average band power approximating using the composite Simpson’s rule to get it for a specific target band. </li>\n<li>Divide the average band power of the specific target band by the total power of the signal to get the relative power spectrum.</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>Anelli, M. (2020). <em>Using Deep learning to predict continuous hand kinematics from Magnetoencephalographic (MEG) measurements of electromagnetic brain activity</em> (Doctoral dissertation, ETSI_Informatica).</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train_bp = np.squeeze(X_train_numpy, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># X_train_bp = X_train_bp[: :, :, :]</span></span><br><span class=\"line\">X_train_bp = standard_scaling_sklearn(X_train_bp)</span><br><span class=\"line\">X_test_bp = np.squeeze(X_test_numpy, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># X_train_bp = X_train_bp[: :, :, :]</span></span><br><span class=\"line\">X_test_bp = standard_scaling_sklearn(X_test_bp)</span><br><span class=\"line\">bands = [(<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">13</span>), (<span class=\"number\">13</span>, <span class=\"number\">30</span>), (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]</span><br><span class=\"line\">bp_train = bandpower_multi_bands(X_train_bp, fs=<span class=\"number\">800.0</span>, bands=bands, relative=<span class=\"literal\">True</span>)</span><br><span class=\"line\">bp_test = bandpower_multi_bands(X_test_bp, fs=<span class=\"number\">800.0</span>, bands=bands, relative=<span class=\"literal\">True</span>)</span><br><span class=\"line\">bp_train_tensor = torch.Tensor(bp_train).cuda()</span><br><span class=\"line\">bp_test_tensor = torch.Tensor(bp_test).cuda()</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"June-28th\"><a href=\"#June-28th\" class=\"headerlink\" title=\"June 28th\"></a>June 28th</h1><h3 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem:\"></a>Problem:</h3><p>My Google Colab subscriptions is expired but luckily I have got the access of HPC in KCL (create)</p>\n<h3 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution:\"></a>Solution:</h3><p>set up cluster as the tutorial: <a href=\"https://docs.er.kcl.ac.uk/CREATE/access/\">https://docs.er.kcl.ac.uk/CREATE/access/</a></p>\n<ol>\n<li>Start an interactive session:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">srun -p gpu --pty -t 6:00:00 --mem=30GB --gres=gpu /bin/bash</span><br></pre></td></tr></table></figure>\n\n<p><strong>Make a note of the node I am connected to, e.g. erc-hpc-comp001</strong></p>\n<p><code>sinfo avail</code> to check the available cores</p>\n<ol start=\"2\">\n<li>start Jupyter lab without the display on a specific port (here this is port 9998)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">jupyter lab --no-browser --port=9998 --ip=&quot;*&quot;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><strong>Open a separate connection</strong> to CREATE that connects to the node where Jupyter Lab is running using the port you specified earlier. (Problems known with VScode terminal)</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh -m hmac-sha2-512 -o ProxyCommand=&quot;ssh -m hmac-sha2-512 -W %h:%p k21116947@bastion.er.kcl.ac.uk&quot; -L 9998:erc-hpc-comp031:9998 k21116947@hpc.create.kcl.ac.uk</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Note:<ul>\n<li>k12345678 should be replaced with your username.</li>\n<li>erc-hpc-comp001 should be replaced with the name of node where Jupyter lab is running</li>\n<li>9998 should be replaced with the port you specified when running Jupyter lab (using e.g. <code>--port=9998</code>)</li>\n<li>authorize via <a href=\"https://portal.er.kcl.ac.uk/mfa/\">https://portal.er.kcl.ac.uk/mfa/</a></li>\n</ul>\n</li>\n</ul>\n<ol start=\"4\">\n<li><p>Start notebook in <a href=\"http://localhost:9998/lab\">http://localhost:9998/lab</a></p>\n</li>\n<li><p>VS code part: set the Jupyter server as remote :</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">http://localhost:9998/lab?token=XXX</span><br><span class=\"line\"># replace the localhost as erc-hpc-comp031</span><br></pre></td></tr></table></figure>\n\n<p>Note: However, After the latest weekly update, existing problem has been found is the connection via VS code is not stable. Reason could be the dynamic allocated node and port confuses the VS code connection server.</p>\n</li>\n</ol>\n<h1 id=\"June-29th\"><a href=\"#June-29th\" class=\"headerlink\" title=\"June 29th\"></a>June 29th</h1><h3 id=\"Objective-16\"><a href=\"#Objective-16\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try different normalization method: <strong>Z-Score Normalization</strong></p>\n<h3 id=\"Results-13\"><a href=\"#Results-13\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>which maps the raw data to a distribution with mean 0 and standard deviation </p>\n<ol>\n<li>Assuming that the mean of the original feature is μ and the variance is σ , the formula is as follows:</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202207221914685.png\" alt=\"img\"></p>\n<h1 id=\"July-1th\"><a href=\"#July-1th\" class=\"headerlink\" title=\"July 1th\"></a>July 1th</h1><h3 id=\"Objective-17\"><a href=\"#Objective-17\" class=\"headerlink\" title=\"Objective:\"></a>Objective:</h3><p>to try Mnet with band power (RPS Ment); the reason for splitting alpha into low and high is that kinematic show that alpha band significant after movement and beta before movement. It is also reported that gamma band is associated with it is related to synergistic muscle activation (Kolasinski et. al, 2019)</p>\n<blockquote>\n<p>Kolasinski, J., Dima, D. C., Mehler, D. M. A., Stephenson, A., Valadan, S., Kusmia, S., &amp; Rossiter, H. E. (2019). Spatially and temporally distinct encoding of muscle and kinematic information in rostral and caudal primary motor cortex. <em>BioRxiv</em>, 613323. <a href=\"https://doi.org/10.1101/613323\">https://doi.org/10.1101/613323</a></p>\n</blockquote>\n<h3 id=\"Results-14\"><a href=\"#Results-14\" class=\"headerlink\" title=\"Results:\"></a>Results:</h3><p>extract band powers to get a 6 RPS (relative power spectrum) for each frequency period:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bandpower_1d</span>(<span class=\"params\">data, sf, band, nperseg=<span class=\"number\">800</span>, relative=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># band = np.asarray(band)</span></span><br><span class=\"line\">    low, high = band</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute the modified periodogram (Welch)</span></span><br><span class=\"line\">    <span class=\"comment\"># <span class=\"doctag\">TODO:</span> generalize freq values</span></span><br><span class=\"line\">    psd, freqs = psd_array_welch(data, sf, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"built_in\">int</span>(<span class=\"number\">800</span> / <span class=\"number\">2</span>),</span><br><span class=\"line\">                                 n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs[<span class=\"number\">1</span>] - freqs[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Find closest indices of band in frequency vector</span></span><br><span class=\"line\">    idx_band = np.logical_and(freqs &gt;= low, freqs &lt;= high)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Integral approximation of the spectrum using Simpson&#x27;s rule.</span></span><br><span class=\"line\">    bp = simps(psd[idx_band], dx=freq_res)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> relative:</span><br><span class=\"line\">        bp /= simps(psd, dx=freq_res)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> bp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bandpower</span>(<span class=\"params\">x, fs, bands, nperseg=<span class=\"number\">800</span>, relative=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    psd, freqs = psd_array_welch(x, fs, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"built_in\">int</span>(fs/<span class=\"number\">2</span>),</span><br><span class=\"line\">                                 n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs[<span class=\"number\">1</span>] - freqs[<span class=\"number\">0</span>]</span><br><span class=\"line\">    n_channel, _ = x.shape</span><br><span class=\"line\">    bp = np.zeros((n_channel, <span class=\"built_in\">len</span>(bands)))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, band <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(bands):</span><br><span class=\"line\">        low, high = band</span><br><span class=\"line\">        <span class=\"comment\"># Find closest indices of band in frequency vector</span></span><br><span class=\"line\">        idx_band = np.logical_and(freqs &gt;= low, freqs &lt;= high)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Integral approximation of the spectrum using Simpson&#x27;s rule.</span></span><br><span class=\"line\">        _bp = simps(psd[..., idx_band], dx=freq_res, axis=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> relative:</span><br><span class=\"line\">            _bp /= simps(psd, dx=freq_res, axis=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># print(bp.shape, _bp.shape) #272,6  80,272</span></span><br><span class=\"line\">        bp[:, idx] = _bp</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bandpower_multi_bands</span>(<span class=\"params\">x, fs, bands,  nperseg=<span class=\"number\">800</span>, relative=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    </span><br><span class=\"line\">    n_epoch, n_channel, _ = x.shape</span><br><span class=\"line\">    bp = np.zeros((n_epoch, n_channel, <span class=\"built_in\">len</span>(bands)))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n_epoch):</span><br><span class=\"line\">        bp[e] = bandpower(x[e], fs, bands, nperseg=nperseg, relative=relative)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">standard_scaling_sklearn</span>(<span class=\"params\">data</span>):</span><br><span class=\"line\">    </span><br><span class=\"line\">    n_epoch = data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n_epoch):</span><br><span class=\"line\">        scaler = skScaler()</span><br><span class=\"line\">        data[e, ...] = scaler.fit_transform(data[e, ...])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br></pre></td></tr></table></figure>\n\n<p>In main code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X = np.swapaxes(X_train, <span class=\"number\">2</span>, -<span class=\"number\">1</span>).squeeze()</span><br><span class=\"line\">data = X[X.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>, <span class=\"number\">70</span>, :]</span><br><span class=\"line\">psd_mne, freqs_mne = psd_array_welch(data, <span class=\"number\">250</span>, <span class=\"number\">1.</span>, <span class=\"number\">70.</span>, n_per_seg=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                          n_overlap=<span class=\"number\">0</span>, n_jobs=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> low, high <span class=\"keyword\">in</span> [(<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">4</span>, <span class=\"number\">8</span>), (<span class=\"number\">8</span>, <span class=\"number\">10</span>), (<span class=\"number\">10</span>, <span class=\"number\">13</span>), (<span class=\"number\">13</span>, <span class=\"number\">30</span>),</span><br><span class=\"line\">                  (<span class=\"number\">30</span>, <span class=\"number\">70</span>)]:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;processing bands (low, high) : (&#123;&#125;,&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(low, high))</span><br><span class=\"line\">    <span class=\"comment\"># Find intersecting values in frequency vector</span></span><br><span class=\"line\">    idx_delta = np.logical_and(freqs_mne &gt;= low, freqs_mne &lt;= high)</span><br><span class=\"line\">      <span class=\"comment\"># Frequency resolution</span></span><br><span class=\"line\">    freq_res = freqs_mne[<span class=\"number\">1</span>] - freqs_mne[<span class=\"number\">0</span>]  <span class=\"comment\"># = 1 / 4 = 0.25</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute the absolute power by approximating the area under the curve</span></span><br><span class=\"line\">    power = simps(psd_mne[idx_delta], dx=freq_res)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Absolute power: &#123;:.4f&#125; uV^2&#x27;</span>.<span class=\"built_in\">format</span>(power))</span><br><span class=\"line\">    </span><br><span class=\"line\">    total_power = simps(psd_mne, dx=freq_res)</span><br><span class=\"line\">    rel_power = power / total_power</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Relative power: &#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(rel_power))</span><br><span class=\"line\">    </span><br><span class=\"line\">```</span><br><span class=\"line\">Outputs:</span><br><span class=\"line\">Effective window size : <span class=\"number\">1.024</span> (s)</span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">1</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0610</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.1251</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">4</span>,<span class=\"number\">8</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0315</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.0647</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">8</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0220</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.0452</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">10</span>,<span class=\"number\">13</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0031</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.0064</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">13</span>,<span class=\"number\">30</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.0577</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.1184</span></span><br><span class=\"line\">processing bands (low, high) : (<span class=\"number\">30</span>,<span class=\"number\">70</span>)</span><br><span class=\"line\">Absolute power: <span class=\"number\">0.2356</span> uV^<span class=\"number\">2</span></span><br><span class=\"line\">Relative power: <span class=\"number\">0.4837</span></span><br><span class=\"line\">```</span><br></pre></td></tr></table></figure>\n\n<p>The average power spectrum for all subjects:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172059472.png\" alt=\"image-20220817205940319\"></p>\n<p>The results show that beta and delta waves are in the large and major proportion. It may be considered as potential evidence that beta and delta waves are associated with not only anxious thinking, and active concentration (Baumeister et al., 2013), but also the aversive state. In the following classifier task, these findings are in line with results showing the involvement of beta and delta in concentration.</p>\n<blockquote>\n<p>Baumeister, J., Barthel, T., Geiss, K. R., &amp; Weiss, M. (2013). Influence of phosphatidylserine on cognitive performance and cortical activity after induced stress. <em><a href=\"Http://Dx.Doi.Org/10.1179/147683008X301478\">Http://Dx.Doi.Org/10.1179/147683008X301478</a></em>, <em>11</em>(3), 103–110. <a href=\"https://doi.org/10.1179/147683008X301478\">https://doi.org/10.1179/147683008X301478</a></p>\n</blockquote>\n<h3 id=\"Problems-2\"><a href=\"#Problems-2\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>find the initial loss is too huge and does not change afterwards. Guess it is because of too large initial loss or wrongly <code>loss.backward()</code></p>\n<h3 id=\"solution\"><a href=\"#solution\" class=\"headerlink\" title=\"solution:\"></a>solution:</h3><p>parameters of optimizer was set wrongly, fix it with <code>model.parameters()</code></p>\n<h1 id=\"July-2th\"><a href=\"#July-2th\" class=\"headerlink\" title=\"July 2th\"></a>July 2th</h1><h3 id=\"Problems-3\"><a href=\"#Problems-3\" class=\"headerlink\" title=\"Problems:\"></a>Problems:</h3><p>looking for solution to merge the function</p>\n<p>guess I am meeting “dying ReLU” problem</p>\n<h1 id=\"July-5th\"><a href=\"#July-5th\" class=\"headerlink\" title=\"July 5th\"></a>July 5th</h1><h3 id=\"Objectives-1\"><a href=\"#Objectives-1\" class=\"headerlink\" title=\"Objectives:\"></a>Objectives:</h3><p>to try dynamic learning rate and interpolate 130 time points to be 800 time points without losing too much information.</p>\n<h3 id=\"Solution-1\"><a href=\"#Solution-1\" class=\"headerlink\" title=\"Solution:\"></a>Solution:</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, <span class=\"string\">&#x27;max&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">scheduler.step(acc[-<span class=\"number\">1</span>]) <span class=\"comment\">#at last of each epoch training </span></span><br></pre></td></tr></table></figure>\n\n<p>the update step: I use the dynamic learning rate when the valid loss approaches a plateau (function 4, where <img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102154.gif\" alt=\"img\"> represents learning decay and L represents valid loss). </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172102153.gif\" alt=\"img\"></p>\n<p>Multilayer perceptron</p>\n<p>interpolate <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html\">https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html</a></p>\n<p>Learning rate scheduling <a href=\"https://pytorch.org/docs/stable/optim.html\">https://pytorch.org/docs/stable/optim.html</a></p>\n<h1 id=\"July-9th\"><a href=\"#July-9th\" class=\"headerlink\" title=\"July 9th\"></a>July 9th</h1><p>In order to make the input data the same shape as required, I use resample function <code>localiser_epochs.copy().resample(800, npad=&#39;auto&#39;)</code> to upsamle the data</p>\n<p>CBAM modules are added because the attention block is composed of 2 parts: the channel attention module and the spatial attention module. Two modules help model focus more on the important information: channel dimension and spatial dimension. First, for the channel attention module, input data process average pooling and max pooling separately, where the average pooling layer is used to aggregate spatial information and the max pooling layer is used to maintain more extensive and precise context information as images’ edges. </p>\n<blockquote>\n<p>Attention in Deep Learning, Alex Smola and Aston Zhang, Amazon Web Services (AWS), ICML 2019</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SpatialAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(SpatialAttention, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.compress = ChannelPool()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.spatialAttention = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">7</span>, <span class=\"number\">7</span>, padding=<span class=\"number\">3</span>), <span class=\"comment\">#padding = (7-1)/2</span></span><br><span class=\"line\">            )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;x&#x27;,x.shape)</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.compress(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.spatialAttention(x)</span><br><span class=\"line\">        <span class=\"comment\"># scale = F.sigmoid(x)</span></span><br><span class=\"line\">        scale = torch.sigmoid(x)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> x * scale</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Flatten_MEG</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x.view(x.size(<span class=\"number\">0</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ChannelAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            Implementation of a channel attention module.</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">class</span> <span class=\"title class_\">Showsize</span>(nn.Module):</span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">            <span class=\"built_in\">super</span>(ChannelAttention.Showsize, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">            <span class=\"comment\"># print(x.shape)</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, shape, reduction_factor=<span class=\"number\">16</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">super</span>(ChannelAttention, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">        _, in_channel, h, w = shape</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.mlp = nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># self.Showsize(),</span></span><br><span class=\"line\">            Flatten_MEG(),</span><br><span class=\"line\">            <span class=\"comment\"># self.Showsize(),</span></span><br><span class=\"line\">            nn.Linear(in_channel, in_channel // reduction_factor),</span><br><span class=\"line\">            nn.ReLU(),</span><br><span class=\"line\">            nn.Linear(in_channel // reduction_factor, in_channel),</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        avg_pool = F.avg_pool2d( x, (x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)), stride=(x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)))</span><br><span class=\"line\">        max_pool = F.max_pool2d( x, (x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)), stride=(x.size(<span class=\"number\">2</span>), x.size(<span class=\"number\">3</span>)))</span><br><span class=\"line\">        <span class=\"built_in\">sum</span> = <span class=\"variable language_\">self</span>.mlp(avg_pool) + <span class=\"variable language_\">self</span>.mlp(max_pool)</span><br><span class=\"line\">        scale = (</span><br><span class=\"line\">            torch.sigmoid(<span class=\"built_in\">sum</span>)</span><br><span class=\"line\">            .unsqueeze(<span class=\"number\">2</span>)</span><br><span class=\"line\">            .unsqueeze(<span class=\"number\">3</span>)</span><br><span class=\"line\">            .expand_as(x)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x * scale</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"July-10th\"><a href=\"#July-10th\" class=\"headerlink\" title=\"July 10th\"></a>July 10th</h1><p>In order to find the rationality of extracting features of brain states under different stimuli. I draw the topographical maps of all stimuli at different time. It may suggest that stimulus representations are in the downstream temporal region or visual cortex. Thus, as the following training results showed, my model is an effective and reasonable approach to classifying these states.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">sti=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>,<span class=\"number\">7</span>,<span class=\"number\">8</span>,<span class=\"number\">9</span>,<span class=\"number\">10</span>,<span class=\"number\">11</span>,<span class=\"number\">12</span>,<span class=\"number\">13</span>,<span class=\"number\">14</span>]                     </span><br><span class=\"line\"><span class=\"keyword\">for</span> stimuli <span class=\"keyword\">in</span> <span class=\"built_in\">range</span> (<span class=\"number\">1</span>,<span class=\"number\">15</span>):</span><br><span class=\"line\">    epochs_standard = fname.get_epochs(sub=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> sub <span class=\"keyword\">in</span> [sub <span class=\"keyword\">for</span> sub <span class=\"keyword\">in</span> <span class=\"built_in\">range</span> (<span class=\"number\">2</span>,<span class=\"number\">29</span>) <span class=\"keyword\">if</span> sub <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"number\">6</span>, <span class=\"number\">12</span>, <span class=\"number\">14</span> ,<span class=\"number\">23</span>]]:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sub == <span class=\"number\">1</span>:</span><br><span class=\"line\">            epochs_standard = fname.get_epochs(sub=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            epochs = fname.get_epochs(sub)[<span class=\"string\">&#x27;stimulus_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"number\">2</span>*stimuli)]</span><br><span class=\"line\">            epochs.info[<span class=\"string\">&#x27;dev_head_t&#x27;</span>] = epochs_standard.info[<span class=\"string\">&#x27;dev_head_t&#x27;</span>]</span><br><span class=\"line\">            epochs_standard = mne.concatenate_epochs([epochs_standard[<span class=\"string\">&#x27;stimulus_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"number\">2</span>*stimuli)], epochs[<span class=\"string\">&#x27;stimulus_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"number\">2</span>*stimuli)]])</span><br><span class=\"line\">    <span class=\"built_in\">exec</span>(<span class=\"string\">&#x27;evoked_&#123;&#125; = epochs_standard.average()&#x27;</span>.<span class=\"built_in\">format</span>(stimuli))</span><br><span class=\"line\">        <span class=\"comment\"># evoked_standard = mne.concatenate_epochs([evoked_standard, evoked])</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172051592.png\" alt=\"image-20220817205119443\"></p>\n<p>brain topographical map under different stimuli in the specific time (0.36 s, 0.79 s after giving the stimuli). The average brain states of all 24 subjects in all 14 stimuli are shown as the topographical map. The map shows these different brain states as an intensity map, where the red colour shows stronger intensity and blue shows weaker intensity.</p>\n<h1 id=\"July-12th\"><a href=\"#July-12th\" class=\"headerlink\" title=\"July 12th\"></a>July 12th</h1><p>The random prediction accuracy is expected to be 7.14% (1/14 = 7.14%). The classification accuracy of my model is around 23.07%, which is clearly higher than random chance. LSTM RNN gives an accuracy of about 15.38% while simple CNN only gives a mean accuracy of 11.53%. Compared with the other classification approach, my model exhibits the best classification performance (p = 6.8 × 10 –2 for LSTM RNN, p = 5.9 × 10 –2 for CNN, paired Wilcoxon signed-rank tests). The best classification accuracy of my model is able to reach 33.33%. </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172055038.png\" alt=\"image-20220817205549898\"></p>\n<p>early stopping was finally adopted when the number of epochs reaches around 130 in case of overfitting:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">EarlyStopping</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, patience=<span class=\"number\">7</span>, verbose=<span class=\"literal\">False</span>, delta=<span class=\"number\">0</span>, path=<span class=\"string\">&#x27;checkpoint.pt&#x27;</span>, trace_func=<span class=\"built_in\">print</span></span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.patience = patience</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.verbose = verbose</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.counter = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.best_score = <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.early_stop = <span class=\"literal\">False</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss_min = np.Inf</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.delta = delta</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.path = path</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.trace_func = trace_func</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__call__</span>(<span class=\"params\">self, val_loss, model</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">        score = -val_loss</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.best_score <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.best_score = score</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.save_checkpoint(val_loss, model)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> score &lt;= <span class=\"variable language_\">self</span>.best_score + <span class=\"variable language_\">self</span>.delta:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.counter += <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.trace_func(<span class=\"string\">f&#x27;EarlyStopping counter: <span class=\"subst\">&#123;self.counter&#125;</span> out of <span class=\"subst\">&#123;self.patience&#125;</span>&#x27;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.counter &gt;= <span class=\"variable language_\">self</span>.patience:</span><br><span class=\"line\">                <span class=\"variable language_\">self</span>.early_stop = <span class=\"literal\">True</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.best_score = score</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.save_checkpoint(val_loss, model)</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.counter = <span class=\"number\">0</span></span><br><span class=\"line\">            </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">save_checkpoint</span>(<span class=\"params\">self, val_loss, model</span>):</span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;Saves model when validation loss decrease.&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.verbose:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.trace_func(<span class=\"string\">f&#x27;Validation loss decreased (<span class=\"subst\">&#123;self.val_loss_min:<span class=\"number\">.4</span>f&#125;</span> --&gt; <span class=\"subst\">&#123;val_loss:<span class=\"number\">.4</span>f&#125;</span>).  Saving model ...&#x27;</span>)</span><br><span class=\"line\">        torch.save(model.state_dict(), <span class=\"variable language_\">self</span>.path)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.val_loss_min = val_loss</span><br></pre></td></tr></table></figure>\n\n<p>However, would early stopping necessarily prevent overfitting? There’s some interesting work showing that if you over-train the model it actually suddenly gets a lot better at some point (an approach referred to as “grokking” for some reason). It may be possible that more training doesn’t necessarily mean worse performance.</p>\n<h1 id=\"July-13th\"><a href=\"#July-13th\" class=\"headerlink\" title=\"July 13th\"></a>July 13th</h1><p>I want to visualize my model and data process steps.</p>\n<p>First save the model as .onnx file:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">x = torch.randn(<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">272</span>, <span class=\"number\">800</span>).requires_grad_(<span class=\"literal\">True</span>).cuda() </span><br><span class=\"line\">torch_out = rpsmnet(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Export the model</span></span><br><span class=\"line\">torch.onnx.export(rpsmnet,               <span class=\"comment\"># model being run</span></span><br><span class=\"line\">                  x,                         <span class=\"comment\"># model input (or a tuple for multiple inputs)</span></span><br><span class=\"line\">                  <span class=\"string\">&quot;super_resolution.onnx&quot;</span>,   <span class=\"comment\"># where to save the model (can be a file or file-like object)</span></span><br><span class=\"line\">                  export_params=<span class=\"literal\">True</span>,        <span class=\"comment\"># store the trained parameter weights inside the model file</span></span><br><span class=\"line\">                  opset_version=<span class=\"number\">10</span>,          <span class=\"comment\"># the ONNX version to export the model to</span></span><br><span class=\"line\">                  do_constant_folding=<span class=\"literal\">True</span>,  <span class=\"comment\"># whether to execute constant folding for optimization</span></span><br><span class=\"line\">                  input_names = [<span class=\"string\">&#x27;input&#x27;</span>],   <span class=\"comment\"># the model&#x27;s input names</span></span><br><span class=\"line\">                  output_names = [<span class=\"string\">&#x27;output&#x27;</span>], <span class=\"comment\"># the model&#x27;s output names</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>And I generate the flow chat of this model with Netron:</p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172106759.png\" alt=\"image-20220817210610588\"></p>\n<p>Detailed configuration of my model. Cov: convolution; Relu: rectified linear unit; MaxPool: max pooling; AveragePool: average pooling; Concat: concatenation; Identity: stands for relative power spectrum; Gemm: general matrix multiply</p>\n<p>The steps data are processed is generated with following code: </p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> hiddenlayer <span class=\"keyword\">as</span> hl</span><br><span class=\"line\"></span><br><span class=\"line\">transforms = [ hl.transforms.Prune(<span class=\"string\">&#x27;Constant&#x27;</span>) ] <span class=\"comment\"># Removes Constant nodes from graph.</span></span><br><span class=\"line\"></span><br><span class=\"line\">graph = hl.build_graph(rpsmnet, torch.zeros(<span class=\"number\">64</span>,<span class=\"number\">1</span>,<span class=\"number\">272</span>,<span class=\"number\">800</span>).cuda())</span><br><span class=\"line\">graph.theme = hl.graph.THEMES[<span class=\"string\">&#x27;blue&#x27;</span>].copy()</span><br><span class=\"line\">graph.save(<span class=\"string\">&#x27;ASRCnet_hiddenlayer&#x27;</span>, <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;png&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> torchviz <span class=\"keyword\">import</span> make_dot</span><br><span class=\"line\">x = torch.randn(<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">272</span>, <span class=\"number\">800</span>).requires_grad_(<span class=\"literal\">True</span>).cuda() <span class=\"comment\"># 定义一个网络的输入值</span></span><br><span class=\"line\">y = rpsmnet(x)    <span class=\"comment\"># 获取网络的预测值</span></span><br><span class=\"line\"><span class=\"comment\"># y = y.cuda()</span></span><br><span class=\"line\">MyConvNetVis = make_dot(y)<span class=\"comment\">#, params=dict(list(rpsmnet.named_parameters()) + [(&#x27;x&#x27;, x)]))</span></span><br><span class=\"line\">MyConvNetVis.<span class=\"built_in\">format</span> = <span class=\"string\">&quot;png&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 指定文件生成的文件夹</span></span><br><span class=\"line\">MyConvNetVis.directory = <span class=\"string\">&quot;data&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 生成文件</span></span><br><span class=\"line\">MyConvNetVis.view()</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172108920.png\" alt=\"image-20220817210806647\"></p>\n<h1 id=\"July-15th\"><a href=\"#July-15th\" class=\"headerlink\" title=\"July 15th\"></a>July 15th</h1><p>I want to visualize the pooling and convolution operations, so I use CAD to draw the illustrations:</p>\n<p>As shown in figure A, a kernel filter is applied to the input data pixel: after summing up input values and filter, a result value is generated and passed to the next step. With all similar processes conducted step by step, a feature map is generated. Afterwards, the max pooling step (figure B) comes to decrease the dimensions of data in order to keep more neurons activated which is reported to reduce the overfitting as well </p>\n<p><img src=\"https://raw.githubusercontent.com/ReveRoyl/PictureBed/main/BlogImg/202208172114867.png\" alt=\"image-20220817211402695\"></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cuidYc8Hw8WXB62O-lyFdi_YJ","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidpzBfBhQdFJaUj5gH5_FXQ"},{"post_id":"cuidscvgjRq-3L0XlaOzAQ7qL","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidloNyxEDYwf0q2Y5vrrBeF"},{"post_id":"cuidqeYB5bdsfvTR2qBJXoPE_","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid99D2Bnq6RdsQSgwAhhIM3"},{"post_id":"cuidpYPNBSBD6hB-cvuTJocRY","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid8zIL4KiyWt11G4UflzllR"},{"post_id":"cuidy5NiOES34NBq7_wzlCwQZ","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid7pRzDO8jVgPmymQ2JSoET"},{"post_id":"cuid4_mmUHVSUB1ArVFwpvSeR","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidtP64wjW4IvcfYZ1um8oB3"},{"post_id":"cuidsTPW2bWerHF6I4gAPJ42b","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidArwCGjTw_8LYFrCZdUyw1"},{"post_id":"cuidj2nhGs_L6P79IJY8t-7aG","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidVf6R9w-bjzEzyhqWxYPuC"},{"post_id":"cuidaWoIZsWDeYPrpvltEEuBO","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidU2QRcsGbsHnzG-y2hBZ4D"},{"post_id":"cuidLK1QHhP_PgqMkCA1qSkSQ","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidjna-MqdJwVkd098uLd8ky"},{"post_id":"cuid-WhXtxrRREjIOJSKv5i7u","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidWe891eAY8wgsgHj3Bvfw9"},{"post_id":"cuidu0miNSUXIO3CJyT3-PELI","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid1LfgZJW2EjmA6QYTxzDgP"},{"post_id":"cuidvmREG4e5FI5IOVsZYUYGl","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidBjIb8iss9epz7G67tGwYt"},{"post_id":"cuid5hrjeIfxgRbgYkDZELIn_","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid0TpzZxzAdVjPJpJenc-B6"},{"post_id":"cuidqjYPyoZYrZ42vdH7X5zDC","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidlS5nTVBcNtTREeToJB0zn"},{"post_id":"cuidEnRcQxLEpgtCzp0yR467K","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuidE9bL3Unm4KG7DF4PzMP4U"},{"post_id":"cuidolZXPGJU01gloewmdu1_C","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuiddrVJBT9EnzzL0qAfxve4J"},{"post_id":"cuid7Wyo5mniGShWDiObVqWIV","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuideXcbopxzjCuR9n7z9FV4e"},{"post_id":"cuidk8rR66MGMwM-5hDgjmb3O","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidTs6E7M-sTehELTfM7MFjP"},{"post_id":"cuidDpkP9Mitf5W5CE4eZnvoW","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuidZs14i1XPdlCKFcnaYUnsT"},{"post_id":"cuidXegoZNSod9Mu480VIkjj4","category_id":"cuiduzx55enbrKre-OXPbdRVj","_id":"cuidoKQkzVYH4g1GsPoVQ7eK3"},{"post_id":"cuidJNXOPFgeAWWe8yx3TZiXQ","category_id":"cuiduzx55enbrKre-OXPbdRVj","_id":"cuid70-FplgT9-MBmh7XCWmPe"},{"post_id":"cuidVeEF_HKFjb6iUVegXAOjc","category_id":"cuid1Hok2e5rxFsJ0dJZjro7-","_id":"cuid9lLp7WiIzbdzKpeduGQFW"},{"post_id":"cuid5W24V4g48420Tj8piig03","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid-GoFETy0aVRySGk1tErF6"},{"post_id":"cuidoXl_oWdnoZuTCq66PU-LB","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuidKx2a2PSvMMg0ZlQd8RHyE"},{"post_id":"cuidJC4hPGsp_xR6w1fHvAcbb","category_id":"cuid1Hok2e5rxFsJ0dJZjro7-","_id":"cuid0VbeB3gDnOrJRISl1URow"},{"post_id":"cuidR_xbwPn_dz3fhzCxoqPwz","category_id":"cuidJJUg_gLKGDcvftEODIHfk","_id":"cuid2G6A7nRuQRWzCyHEtmBWi"},{"post_id":"cuid5XlR5Sge2B3EODz-XHOn9","category_id":"cuid1Hok2e5rxFsJ0dJZjro7-","_id":"cuidsm4kD-Uim7FeYGSKs6K3j"},{"post_id":"cuidF1MTNTkhUJ2pw1ild8dRR","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuid_ZXpyaCtCop3UaiRaG7Ap"},{"post_id":"cuid4rsBWdnvTP6bNRnhUYhJk","category_id":"cuiduzx55enbrKre-OXPbdRVj","_id":"cuidPXkJXp4EmTHLLaZ3Gic8Q"},{"post_id":"cuidA9ZHNEITXPtGdbmIXuoqd","category_id":"cuidnENRJiZWMH9NOT9ZBprYh","_id":"cuidCSh120eoJcVhS_3-0NccC"},{"post_id":"cuidVvpPQRPfirPO4IeOLtsJC","category_id":"cuidnENRJiZWMH9NOT9ZBprYh","_id":"cuidlt1zcfSVwSEFpbQnHqRKY"},{"post_id":"cuid67Rc1YXk_ygkd5jSkevIF","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuidLH9JD0QNpTbcwNOFX6OjD"},{"post_id":"cuiddrYPM97ofY4Sk7bi11UVJ","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuidRsew42PjD-q0BCnL5Gu_S"},{"post_id":"cuidE4qV4KVFSutCCD7bxQyAK","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuidTSWjxn4pRiwnwRUFIi9kF"},{"post_id":"cuidjh3CMAtDJy7B6n36UGctG","category_id":"cuidv205CRCP2040jPeycN4Fj","_id":"cuidxyNqPpDHjnErGRVeJGC3k"},{"post_id":"cuidij2QWFgdePH8lT5LXgsJ8","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuidRjDyLs9KdzzP2cyB5F74G"},{"post_id":"cuidID30usOvAOeS3sIFv4IJB","category_id":"cuidwy15ZiBdA6fv5oDluj7zW","_id":"cuiddFgIAh0GPt8Cv_GtjFdFe"},{"post_id":"cuidPygZP_I2hVWgjwhQsrG41","category_id":"cuidDwwpPs-d4gZKLi8mrtF9V","_id":"cuid6d86uyHZQ9wVenIwxRNaE"},{"post_id":"cuidCX2GAfEhWTaKhL46U-bj9","category_id":"cuidnENRJiZWMH9NOT9ZBprYh","_id":"cuidZye-ijYN08Hr6dg-T_FEH"},{"post_id":"cuid1-tD-LESet6mSuhBXiMZX","category_id":"cuidXmj04GE7n1skmj0tWW_xv","_id":"cuidpY8JJmbTqJBnpP0h190Xs"},{"post_id":"cuidfkwlqYDtM34Q0zwmUn7wC","category_id":"cuidv205CRCP2040jPeycN4Fj","_id":"cuidQUk1MFFoGI6ft0lNfM_Lt"},{"post_id":"cuidmXoTyS2k4NzlyH_PI_-3q","category_id":"cuidv205CRCP2040jPeycN4Fj","_id":"cuidLUMOumIuW1wTmPKyfUpIs"}],"PostTag":[{"post_id":"cuidYc8Hw8WXB62O-lyFdi_YJ","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidIgIrljfrVCT6CQke7Pzqy"},{"post_id":"cuidscvgjRq-3L0XlaOzAQ7qL","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidPcnxfiPmU7GUNTlCJH6Hd"},{"post_id":"cuidqeYB5bdsfvTR2qBJXoPE_","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidrm5oniWEsEAhL0u7Y_iPg"},{"post_id":"cuidpYPNBSBD6hB-cvuTJocRY","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidU--G01SQL42FzjcXmqa-t"},{"post_id":"cuidy5NiOES34NBq7_wzlCwQZ","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuideA7XBP6xzcafGjYF7qO_X"},{"post_id":"cuid4_mmUHVSUB1ArVFwpvSeR","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidPGd3pZ85OvIix4xfJ-YLm"},{"post_id":"cuidsTPW2bWerHF6I4gAPJ42b","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuid2ObGKMh9rpSq9WfTjxS_4"},{"post_id":"cuidj2nhGs_L6P79IJY8t-7aG","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuiddKGSbQVF3iY79QNHJpRbc"},{"post_id":"cuidaWoIZsWDeYPrpvltEEuBO","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidQ5-8IqBJMoGumT6UvqBr_"},{"post_id":"cuidLK1QHhP_PgqMkCA1qSkSQ","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidXPqy6Vw9ty34sQWggaVNW"},{"post_id":"cuid-WhXtxrRREjIOJSKv5i7u","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidGdI96zVN1ZJ8-QQG0n0Eb"},{"post_id":"cuidu0miNSUXIO3CJyT3-PELI","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuid6SwK0Qgnl3wcvNiy5BWU1"},{"post_id":"cuidvmREG4e5FI5IOVsZYUYGl","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidgdUaAokYSIUfLSAIOedO7"},{"post_id":"cuid5hrjeIfxgRbgYkDZELIn_","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidqkRN5zz5J202WQ5kXjwTC"},{"post_id":"cuidqjYPyoZYrZ42vdH7X5zDC","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuid5Tj1uXl8k9gfhV1PfTI0s"},{"post_id":"cuidEnRcQxLEpgtCzp0yR467K","tag_id":"cuidBT5nuoDLv_LJKAq9HTPRW","_id":"cuid-7UHzJJfsb9R26dXjU-aA"},{"post_id":"cuidolZXPGJU01gloewmdu1_C","tag_id":"cuidBT5nuoDLv_LJKAq9HTPRW","_id":"cuidcCo3rSiZFIK0nyjJxshQP"},{"post_id":"cuidXegoZNSod9Mu480VIkjj4","tag_id":"cuideAbw-zlpG_HP0dT20r8zK","_id":"cuid_mlqLQOGa1FRZD-oWl63Y"},{"post_id":"cuid7Wyo5mniGShWDiObVqWIV","tag_id":"cuidDmIU4klNiwAcR0l9LCzdq","_id":"cuidbKlgxDMSRaaAF7ji1sj5m"},{"post_id":"cuidJNXOPFgeAWWe8yx3TZiXQ","tag_id":"cuideAbw-zlpG_HP0dT20r8zK","_id":"cuidiEE1ORmyOp7wW-QuJuUX1"},{"post_id":"cuidk8rR66MGMwM-5hDgjmb3O","tag_id":"cuidDmIU4klNiwAcR0l9LCzdq","_id":"cuidda5ep1l-5yKbFjlFf9HIe"},{"post_id":"cuid5W24V4g48420Tj8piig03","tag_id":"cuiduOILWuCGTvWAdq28g0syJ","_id":"cuidkWWfiTOGzHzQ1y0S0Ho-n"},{"post_id":"cuidoXl_oWdnoZuTCq66PU-LB","tag_id":"cuidBT5nuoDLv_LJKAq9HTPRW","_id":"cuidshH4UkYjn73W7xw0SZUTr"},{"post_id":"cuidDpkP9Mitf5W5CE4eZnvoW","tag_id":"cuidDmIU4klNiwAcR0l9LCzdq","_id":"cuidpMV68l-G1LYwZVcLWAMnT"},{"post_id":"cuidVeEF_HKFjb6iUVegXAOjc","tag_id":"cuidcWb-flU3z2_3KnqqWi0Ly","_id":"cuid1s4EJzWseIHrZH1rr_ejj"},{"post_id":"cuidJC4hPGsp_xR6w1fHvAcbb","tag_id":"cuidcWb-flU3z2_3KnqqWi0Ly","_id":"cuidnve6Bx8X8ksbqotPY3MJv"},{"post_id":"cuid5XlR5Sge2B3EODz-XHOn9","tag_id":"cuidcWb-flU3z2_3KnqqWi0Ly","_id":"cuidsRmwoeipMewGkQ4ixPo_A"},{"post_id":"cuidR_xbwPn_dz3fhzCxoqPwz","tag_id":"cuidTogDM22PIa-WEQrLafheW","_id":"cuidDq5Y3bhd7Tuv42-20GU8G"},{"post_id":"cuidVvpPQRPfirPO4IeOLtsJC","tag_id":"cuidaFewpMhDA0mcTEa8AxJ0o","_id":"cuidxbTXKTLvCe93l5ubI6arY"},{"post_id":"cuidF1MTNTkhUJ2pw1ild8dRR","tag_id":"cuidvjtx6h_EGBW0Zz6DqPhJw","_id":"cuidqyPBrvcnQGOzsEx_nnJv9"},{"post_id":"cuid4rsBWdnvTP6bNRnhUYhJk","tag_id":"cuidgSCjcjB0e294FD_r7b0Q2","_id":"cuid46R5nbDMVfYSEf_1F5De8"},{"post_id":"cuidA9ZHNEITXPtGdbmIXuoqd","tag_id":"cuid57S5LI4I2IQcMDDTFdimj","_id":"cuidkjAHvqjVir4Ky54FAk_EJ"},{"post_id":"cuid67Rc1YXk_ygkd5jSkevIF","tag_id":"cuidno2sSN0zqYPF-A8vssN4T","_id":"cuidaCUyoSgOuQDTgFiCdZ45B"},{"post_id":"cuidjh3CMAtDJy7B6n36UGctG","tag_id":"cuidTX9D8XtZ819xaR4gfo0ib","_id":"cuid6ZNBsCzfRRMCxpP-hL63d"},{"post_id":"cuidID30usOvAOeS3sIFv4IJB","tag_id":"cuide1VetPGUd1LQRXH9Oo7NX","_id":"cuidpjPn_5YxYE8caclvRAp9d"},{"post_id":"cuiddrYPM97ofY4Sk7bi11UVJ","tag_id":"cuidFTrjN5w9ttqnpNUYCjHwl","_id":"cuidhSkNbbiiZ2_L3cirMu6dw"},{"post_id":"cuidE4qV4KVFSutCCD7bxQyAK","tag_id":"cuidzIS-wozjy_enoxtbzpNLb","_id":"cuidZxd1hdt5Ki_fZbBOBs0mI"},{"post_id":"cuid1-tD-LESet6mSuhBXiMZX","tag_id":"cuidfill_N_JnDk8TBtjVdmTl","_id":"cuidEwIOktPw79uMdgLfwrcp7"},{"post_id":"cuidij2QWFgdePH8lT5LXgsJ8","tag_id":"cuidgSCjcjB0e294FD_r7b0Q2","_id":"cuidddgNPyEdiq-2HizilUQWH"},{"post_id":"cuidPygZP_I2hVWgjwhQsrG41","tag_id":"cuidpIZev-1hhh9EBF82VpxQK","_id":"cuidaEplpSEtvwU5c4ikUx2eX"},{"post_id":"cuidCX2GAfEhWTaKhL46U-bj9","tag_id":"cuidao0Gq8q5Q3yvycWY2a4wz","_id":"cuidk3dFPcPimnpJVfVwy_o32"},{"post_id":"cuidfkwlqYDtM34Q0zwmUn7wC","tag_id":"cuide1VetPGUd1LQRXH9Oo7NX","_id":"cuidUZi9pHv93fNTkjsC8fTFG"},{"post_id":"cuidmXoTyS2k4NzlyH_PI_-3q","tag_id":"cuide1VetPGUd1LQRXH9Oo7NX","_id":"cuidYPjnYdULhgX5SyuMckv5V"}],"Tag":[{"name":"Lecture Note","_id":"cuiduOILWuCGTvWAdq28g0syJ"},{"name":"blog building","_id":"cuidBT5nuoDLv_LJKAq9HTPRW"},{"name":"diary","_id":"cuideAbw-zlpG_HP0dT20r8zK"},{"name":"Essay","_id":"cuidDmIU4klNiwAcR0l9LCzdq"},{"name":"Neuroscience","_id":"cuidcWb-flU3z2_3KnqqWi0Ly"},{"name":"glossary","_id":"cuidTogDM22PIa-WEQrLafheW"},{"name":"Chengdu","_id":"cuidaFewpMhDA0mcTEa8AxJ0o"},{"name":"Cpp","_id":"cuidvjtx6h_EGBW0Zz6DqPhJw"},{"name":"tips","_id":"cuidgSCjcjB0e294FD_r7b0Q2"},{"name":"Albania","_id":"cuid57S5LI4I2IQcMDDTFdimj"},{"name":"ML","_id":"cuidno2sSN0zqYPF-A8vssN4T"},{"name":"DLL","_id":"cuidTX9D8XtZ819xaR4gfo0ib"},{"name":"project","_id":"cuide1VetPGUd1LQRXH9Oo7NX"},{"name":"python","_id":"cuidFTrjN5w9ttqnpNUYCjHwl"},{"name":"Pandas","_id":"cuidzIS-wozjy_enoxtbzpNLb"},{"name":"Mylove","_id":"cuidfill_N_JnDk8TBtjVdmTl"},{"name":"PhD","_id":"cuidpIZev-1hhh9EBF82VpxQK"},{"name":"Taiwan","_id":"cuidao0Gq8q5Q3yvycWY2a4wz"}]}}